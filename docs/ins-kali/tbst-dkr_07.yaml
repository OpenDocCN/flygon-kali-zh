- en: Chapter 7. Managing the Networking Stack of a Docker Container
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。管理Docker容器的网络堆栈
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: docker0 bridge
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: docker0桥
- en: Troubleshooting Docker bridge configuration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障排除Docker桥接配置
- en: Configuring DNS
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置DNS
- en: Troubleshooting communication between containers and the external network
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排除容器之间和外部网络之间的通信故障
- en: ibnetwork and the Container Network Model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ibnetwork和容器网络模型
- en: Docker networking tools based on overlay and underlay networks
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于覆盖和底层网络的Docker网络工具
- en: Comparison of Docker networking tools
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker网络工具的比较
- en: Configuring **OpenvSwitch** (**OVS**) to work with Docker
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置**OpenvSwitch**（OVS）以与Docker一起工作
- en: Docker networking
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker网络
- en: Each Docker container has its own network stack, and this is due to the Linux
    kernel `net` namespace, where a new `net` namespace for each container is instantiated
    and cannot be seen from outside the container or other containers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Docker容器都有自己的网络堆栈，这是由于Linux内核的`net`命名空间，为每个容器实例化了一个新的`net`命名空间，外部容器或其他容器无法看到。
- en: 'Docker networking is powered by the following network components and services:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Docker网络由以下网络组件和服务提供支持：
- en: '**Linux bridges**: L2/MAC learning switch built into the kernel to use for
    forwarding'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Linux桥接器**：内核中内置的L2/MAC学习交换机，用于转发'
- en: '**Open vSwitch**: Advanced bridge that is programmable and supports tunneling'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Open vSwitch**：可编程的高级桥接器，支持隧道'
- en: '**Network Address Translators (NAT)**: These are immediate entities that translate
    IP address + Ports (SNAT, DNAT)'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络地址转换器（NAT）**：这些是立即实体，用于转换IP地址+端口（SNAT，DNAT）'
- en: '**IPtables**: Policy engine in the kernel that is used for managing packet
    forwarding, firewall, and NAT features'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IPtables**：内核中的策略引擎，用于管理数据包转发、防火墙和NAT功能'
- en: '**Apparmor/SElinux**: Firewall policies for each application can be defined'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apparmor/SElinux**：可以为每个应用程序定义防火墙策略'
- en: 'Various networking components can be used to work with Docker, providing new
    ways to access and use Docker-based services. As a result, we see a lot of libraries
    that follow different approaches to networking. Some prominent ones are Docker
    Compose, Weave, Kubernetes, Pipework, and libnetwork. The following diagram depicts
    root ideas of Docker networking:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用各种网络组件来与Docker一起工作，提供了访问和使用基于Docker的服务的新方法。因此，我们看到了许多遵循不同网络方法的库。一些著名的库包括Docker
    Compose、Weave、Kubernetes、Pipework和libnetwork。以下图表描述了Docker网络的根本思想：
- en: '![Docker networking](graphics/image_07_001-2.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![Docker网络](graphics/image_07_001-2.jpg)'
- en: Docker networking modes
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Docker网络模式
- en: docker0 bridge
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker0桥
- en: '**docker0 bridge** is the heart of default networking. When the Docker service
    is started, a Linux bridge is created on the host machine. The interfaces on the
    containers talk to the bridge and the bridge proxies to the external world. Multiple
    containers on the same host can talk to each other through the Linux bridge.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**docker0桥**是默认网络的核心。启动Docker服务时，在主机上创建一个Linux桥接器。容器上的接口与桥接器通信，桥接器代理到外部世界。同一主机上的多个容器可以通过Linux桥接器相互通信。'
- en: 'docker0 can be configured via the `--net` flag, and has four modes in general:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: docker0可以通过`--net`标志进行配置，通常有四种模式：
- en: '`--net default`: In this mode, the default bridge is used as the bridge for
    containers to connect to each other'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--net default`：在此模式下，默认桥用作容器相互连接的桥'
- en: '`--net=none`: With this flag, the container created is truly isolated and cannot
    connect to the network'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--net=none`：使用此标志，创建的容器是真正隔离的，无法连接到网络'
- en: '`--net=container:$container2`: With this flag, the container created shares
    its network namespace with the container named `$container2`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--net=container:$container2`：使用此标志，创建的容器与名为`$container2`的容器共享其网络命名空间'
- en: '`--net=host`: In this mode, the container created shares its network namespace
    with the host'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--net=host`：在此模式下，创建的容器与主机共享其网络命名空间'
- en: Troubleshooting Docker bridge configuration
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除Docker桥接配置
- en: In this section, we will look at how the container ports are mapped to host ports
    and how we can troubleshoot the issue of connecting containers to the external
    world. This mapping can be done either implicitly by the Docker Engine or can
    be specified.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将看看容器端口是如何映射到主机端口的，以及我们如何解决连接容器到外部世界的问题。这种映射可以由Docker引擎隐式完成，也可以被指定。
- en: 'If we create two containers-**Container 1** and **Container 2**-both of them
    are assigned an IP address from a private IP address space and also connected
    to **docker0 bridge**, as shown in the following diagram:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建两个容器-**容器1**和**容器2**-它们都被分配了来自私有IP地址空间的IP地址，并且也连接到**docker0桥**，如下图所示：
- en: '![Troubleshooting Docker bridge configuration](graphics/image_07_002.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![故障排除Docker桥接配置](graphics/image_07_002.jpg)'
- en: Two containers talking via Docker0 bridge
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 两个容器通过Docker0桥进行通信
- en: Both the preceding containers will be able to ping each other as well as reach
    the external world. For external access, their ports will be mapped to a host
    port. As mentioned in the previous section, containers use network namespaces.
    When the first container is created, a new network namespace is created for the
    container.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 前述的两个容器将能够相互ping通，也能够访问外部世界。对于外部访问，它们的端口将被映射到主机端口。正如前一节中提到的，容器使用网络命名空间。当第一个容器被创建时，为该容器创建了一个新的网络命名空间。
- en: 'A **Virtual Ethernet** (**vEthernet** or **vEth**) link is created between
    the container and the Linux bridge. Traffic sent from the `eth0` port of the container
    reaches the bridge through the vEth interface and gets switched thereafter:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器和Linux桥之间创建了一个**虚拟以太网**（**vEthernet**或**vEth**）链接。从容器的`eth0`端口发送的流量通过vEth接口到达桥接，然后进行切换：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The output of the preceding command will be similar to the following one with
    bridge name and the vEth interfaces on the containers it is mapped to:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的输出将类似于以下内容，其中包括桥接名称和容器上的vEth接口：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Connecting containers to the external world
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将容器连接到外部世界
- en: 'The **iptables NAT** table on the host is used to masquerade all external connections,
    as shown here:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 主机上的**iptables NAT**表用于伪装所有外部连接，如下所示：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Reaching containers from the outside world
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从外部世界访问容器
- en: The port mapping is again done using the iptables NAT option in the host machine,
    as the following diagram shows, where port mapping of **Container 1** is done
    to communicate with the external world. We will look into it in detail in the
    later part of the chapter.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 端口映射再次使用主机上的iptables NAT选项进行，如下图所示，其中容器1的端口映射用于与外部世界通信。我们将在本章的后面部分详细讨论。
- en: '![Reaching containers from the outside world](graphics/image_07_003.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![从外部世界访问容器](graphics/image_07_003.jpg)'
- en: Port mapping of Container 1 to communicate with the external world
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 容器1的端口映射，以与外部世界通信
- en: 'Docker server, by default, creates a `docker0` bridge inside the Linux kernel
    that can pass packets back and forth between other physical or virtual network
    interfaces so that they behave as a single ethernet network:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Docker服务器默认在Linux内核中创建了一个`docker0`桥，可以在其他物理或虚拟网络接口之间传递数据包，使它们表现为单个以太网网络：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Once we have one or more containers up and running, we can confirm that Docker
    has properly connected them to the docker0 bridge by running the `brctl` command
    on the host machine and looking at the interfaces column of the output. First,
    install the bridge utilities using the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一个或多个容器正在运行，我们可以通过在主机上运行 `brctl` 命令并查看输出的接口列来确认 Docker 是否已将它们正确连接到 docker0
    桥接。首先，使用以下命令安装桥接实用程序：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is a host with two different containers connected:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个主机，连接了两个不同的容器：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Docker uses docker0 bridge settings whenever a container is created. It assigns
    a new IP address from the range available on the bridge whenever a new container
    is created:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 在创建容器时使用 docker0 桥接设置。每当创建新容器时，它会从桥接可用的范围中分配一个新的 IP 地址：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: By default, Docker provides a vnet docker0 that has the `172.17.42.1` IP address.
    Docker containers have IP addresses in the range of `172.17.0.0/16`
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker 提供了一个名为 vnet docker0 的桥接，其 IP 地址为 `172.17.42.1`。Docker 容器的 IP 地址在
    `172.17.0.0/16` 范围内。
- en: To change the default settings in Docker, modify the `/etc/default/docker` file.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要更改 Docker 中的默认设置，请修改 `/etc/default/docker` 文件。
- en: 'Change the default bridge from `docker0` to `br0`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 将默认的桥接从 `docker0` 更改为 `br0`：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following command displays the new bridge name and the IP address range
    of the Docker service:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令显示了 Docker 服务的新桥接名称和 IP 地址范围：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Configuring DNS
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 DNS
- en: Docker provides hostname and DNS configuration for each container without building
    a custom image. It overlays the `/etc` files inside the container with virtual
    files where it can write new information.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 为每个容器提供主机名和 DNS 配置，而无需构建自定义镜像。它通过虚拟文件覆盖容器内的 `/etc` 文件，可以在其中写入新信息。
- en: This can be seen by running the `mount` command inside the container. Containers
    receive the same `/resolv.conf` as of the host machine when they are created initially.
    If a host's `/resolv.conf` file is modified, it will be reflected in the container's
    `/resolv.conf` file only when the container is restarted.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过在容器内运行 `mount` 命令来查看。容器在初始创建时会接收与主机机器相同的 `/resolv.conf`。如果主机的 `/resolv.conf`
    文件被修改，只有在容器重新启动时，容器的 `/resolv.conf` 文件才会反映这些修改。
- en: 'In Docker, you can set the `dns` options in two ways:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Docker 中，可以通过两种方式设置 `dns` 选项：
- en: Using `docker run --dns=<ip-address>`
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `docker run --dns=<ip-address>`
- en: In the Docker daemon file, add `DOCKER_OPTS="--dns ip-address"`
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Docker 守护程序文件中，添加 `DOCKER_OPTS="--dns ip-address"`
- en: Tip
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You can also specify the search domain using `--dns-search=<DOMAIN>`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 `--dns-search=<DOMAIN>` 指定搜索域。
- en: 'The following diagram shows the nameserver being configured in container using
    the `DOCKER_OPTS` setting in the Docker daemon file:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了在容器中使用 Docker 守护程序文件中的 `DOCKER_OPTS` 设置配置名称服务器：
- en: '![Configuring DNS](graphics/image_07_004.jpg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![配置 DNS](graphics/image_07_004.jpg)'
- en: DOCKER_OPTS being used to set nameserver setting for Docker container
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DOCKER_OPTS 来设置 Docker 容器的名称服务器设置
- en: 'The main DNS files are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的 DNS 文件如下：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following is the command to add the DNS server:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是添加 DNS 服务器的命令：
- en: '[PRE10]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Here''s the command to add the hostname:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是添加主机名的命令：
- en: '[PRE11]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Troubleshooting communication between containers and the external network
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决容器与外部网络之间的通信问题
- en: 'Packets can only pass between containers if the `ip_forward` parameter is set
    to `1`. Usually, you will simply leave the Docker server at its default setting
    of `--ip-forward=true` and Docker will set `ip_forward` to `1` for you when the
    server starts up. To check the settings, use the following command:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在将 `ip_forward` 参数设置为 `1` 时，数据包才能在容器之间传递。通常情况下，您会将 Docker 服务器保留在默认设置 `--ip-forward=true`，并且当服务器启动时，Docker
    会为您设置 `ip_forward` 为 `1`。要检查设置，请使用以下命令：
- en: '[PRE12]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'By enabling `ip-forward`, users can make communication between containers and
    the external world possible; it will also be needed for inter-container communication
    if you are in a multiple bridge setup:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通过启用`ip-forward`，用户可以使容器与外部世界之间的通信成为可能；如果您处于多个桥接设置中，还需要进行容器间通信：
- en: '![Troubleshooting communication between containers and the external network](graphics/image_07_005.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![容器和外部网络之间通信的故障排除](graphics/image_07_005.jpg)'
- en: ip-forward = true forwards all the packets to/from the container to the external
    network
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: ip-forward = true 将所有数据包转发到/从容器到外部网络
- en: Docker will not delete or modify any pre-existing rules from Docker filter chain.
    This allows users to create rules to restrict access to containers. Docker uses
    docker0 bridge for packet flow between all containers in a single host. It adds
    a rule to the `FORWARD` chain in iptables (blank accept policy) for the packets
    to flow between two containers. The `--icc=false` option will `DROP` all the packets.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Docker不会删除或修改Docker过滤链中的任何现有规则。这允许用户创建规则来限制对容器的访问。Docker使用docker0桥来在单个主机中的所有容器之间进行数据包流动。它在iptables的`FORWARD`链中添加了一个规则（空白接受策略），以便两个容器之间的数据包流动。`--icc=false`选项将`DROP`所有数据包。
- en: 'When the Docker daemon is configured with both `--icc=false` and `--iptables=true` and
    the Docker run is invoked with the `--link=` option, the Docker server will insert
    a pair of iptables `ACCEPT` rules for the new container to connect to the ports
    exposed by the other container-the ports that it mentioned in the `EXPOSE` lines
    of its Dockerfile:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当Docker守护程序配置为`--icc=false`和`--iptables=true`，并且使用`--link=`选项调用Docker运行时，Docker服务器将为新容器插入一对iptables
    `ACCEPT`规则，以便连接到其他容器公开的端口-这些端口在其Dockerfile的`EXPOSE`行中提到：
- en: '![Troubleshooting communication between containers and the external network](graphics/image_07_006.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![容器和外部网络之间通信的故障排除](graphics/image_07_006.jpg)'
- en: ip-forward = false forwards all the packets to/from the container to external
    network
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ip-forward = false 将所有数据包转发到/从容器到外部网络
- en: By default, Docker's forward rule permits all external IPs. To allow only a
    specific IP or network to access the containers, insert a negated rule at the
    top of the Docker filter chain.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker的转发规则允许所有外部IP。要仅允许特定IP或网络访问容器，请在Docker过滤链的顶部插入一个否定规则。
- en: 'For example, you can restrict external access such that only the source IP
    `10.10.10.10` can access the containers using the following command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可以限制外部访问，使只有源IP`10.10.10.10`可以使用以下命令访问容器：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**References:**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考:**'
- en: '[https://docs.docker.com/v1.5/articles/networking/](https://docs.docker.com/v1.5/articles/networking/)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.docker.com/v1.5/articles/networking/](https://docs.docker.com/v1.5/articles/networking/)'
- en: '[https://docs.docker.com/engine/userguide/networking/](https://docs.docker.com/v1.5/articles/networking/)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.docker.com/engine/userguide/networking/](https://docs.docker.com/v1.5/articles/networking/)'
- en: '[http://containerops.org/](https://docs.docker.com/engine/userguide/networking/)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://containerops.org/](https://docs.docker.com/engine/userguide/networking/)'
- en: Restricting SSH access from one container to another
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制一个容器对另一个容器的SSH访问
- en: 'To restrict SSH access from one container to another, perform the following
    steps:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 要限制一个容器对另一个容器的SSH访问，请执行以下步骤：
- en: 'Create two containers, c1 and c2:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个容器，c1和c2：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can test connectivity between the containers using the IP address we've just
    discovered. Let's see this now using the `ping` tool.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用刚刚发现的IP地址测试容器之间的连通性。现在让我们使用`ping`工具来看一下。
- en: 'Let''s go into the other container, c1, and try to ping c2:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们进入另一个容器c1，并尝试ping c2：
- en: '[PRE15]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Install `openssh-server` on both the containers:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两个容器上安装`openssh-server`：
- en: '[PRE16]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Enable iptables on the host machine. Initially, you will be able to SSH from
    one container to another.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主机上启用iptables。最初，您将能够从一个容器SSH到另一个容器。
- en: 'Stop the Docker service and add `DOCKER_OPTS="--icc=false --iptables=true"`
    in the `default docker` file of the host machine. This option will enable the
    iptables firewall and drop all ports between the containers. By default, iptables
    are not enabled on the host:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停止Docker服务，并在主机机器的`default docker`文件中添加`DOCKER_OPTS="--icc=false --iptables=true"`。此选项将启用iptables防火墙并在容器之间关闭所有端口。默认情况下，主机上未启用iptables：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The Docker Upstart and SysVinit configuration file, customize the location
    of the Docker binary (especially for development testing):'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker Upstart和SysVinit配置文件，自定义Docker二进制文件的位置（特别是用于开发测试）：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Use `DOCKER_OPTS` to modify the daemon startup options:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`DOCKER_OPTS`来修改守护程序的启动选项：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Restart the Docker service:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重启Docker服务：
- en: '[PRE20]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Inspect the iptables:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查iptables：
- en: '[PRE21]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The `DROP` rule has been added to the iptables of the host machine, which drops
    connection between the containers. Now you won't be able to SSH between the containers.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`DROP`规则已添加到主机机器的iptables中，这会中断容器之间的连接。现在您将无法在容器之间进行SSH连接。'
- en: Linking containers
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 链接容器
- en: We can communicate or connect legacy containers using the `--link` parameter.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`--link`参数来通信或连接传统容器。
- en: 'Create the first container that will act as the server-`sshserver`:'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建将充当服务器的第一个容器-`sshserver`：
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Create a second container that acts like an SSH client:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个充当SSH客户端的第二个容器：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can see that there are more rules added to the Docker chain rule:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以看到Docker链规则中添加了更多规则：
- en: '[PRE24]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following diagram explains the communication between containers using the `--link`
    flag:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图解释了使用`--link`标志的容器之间的通信：
- en: '![Linking containers](graphics/image_07_007.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![链接容器](graphics/image_07_007.jpg)'
- en: Docker--link creates private channels between containers
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Docker--link在容器之间创建私有通道
- en: 'You can inspect your linked container with `docker inspect`:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用`docker inspect`检查您的链接容器：
- en: '[PRE25]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now you can successfully SSH into the SSH server with its IP:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在您可以成功地通过SSH连接到SSH服务器：
- en: '[PRE26]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Using the `--link` parameter, Docker creates a secure channel between the containers
    that doesn't need to expose any ports externally on the containers.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`--link`参数，Docker在容器之间创建了一个安全通道，无需在容器上外部公开任何端口。
- en: libnetwork and the Container Network Model
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: libnetwork和容器网络模型
- en: 'libnetwork is implemented in Go for connecting Docker containers. The aim is
    to provide a **Container Network Model** (**CNM**) that helps programmers provide
    the abstraction of network libraries. The long-term goal of libnetwork is to follow
    the Docker and Linux philosophy to deliver modules that work independently. libnetwork
    has the aim for providing a composable need for networking in containers. It also
    aims to modularize the networking logic in the Docker Engine and libcontainer
    to a single, reusable library by doing the following things:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork是用Go实现的，用于连接Docker容器。其目标是提供一个**容器网络模型**（**CNM**），帮助程序员提供网络库的抽象。libnetwork的长期目标是遵循Docker和Linux的理念，提供独立工作的模块。libnetwork的目标是提供容器网络的可组合需求。它还旨在通过以下方式将Docker
    Engine和libcontainer中的网络逻辑模块化为单一可重用库：
- en: Replacing the networking module of the Docker Engine with libnetwork
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用libnetwork替换Docker Engine的网络模块
- en: Allowing local and remote drivers to provide networking to containers
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许本地和远程驱动程序为容器提供网络
- en: Providing a `dnet` tool for managing and testing libnetwork-however, this is
    still a work in progress
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个用于管理和测试libnetwork的`dnet`工具-但是，这仍然是一个正在进行中的工作
- en: Note
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Reference:** [https://github.com/docker/libnetwork/issues/45](https://github.com/docker/libnetwork/issues/45)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考:** [https://github.com/docker/libnetwork/issues/45](https://github.com/docker/libnetwork/issues/45)'
- en: libnetwork implements the CNM. It formalizes the steps required to provide networking
    for containers while providing an abstraction that can be used to support multiple
    network drivers. Its endpoint APIs are primarily used for managing the corresponding
    object and bookkeeping them in order to provide the level of abstraction as required
    by the CNM.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork实现了CNM。它规范了为容器提供网络的步骤，同时提供了一个抽象，可用于支持多个网络驱动程序。其端点API主要用于管理相应的对象，并对其进行簿记，以提供CNM所需的抽象级别。
- en: CNM objects
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNM对象
- en: 'The CNM is built on three main components, as shown in the following diagram:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: CNM建立在三个主要组件上，如下图所示：
- en: '![CNM objects](graphics/image_07_008.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![CNM对象](graphics/image_07_008.jpg)'
- en: Network sandbox model of libnetwork
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork的网络沙盒模型
- en: Note
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: '**Reference:** [https://www.docker.com](https://www.docker.com)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考：**[https://www.docker.com](https://www.docker.com)'
- en: Sandbox
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 沙盒
- en: A sandbox contains the configuration of a container's network stack that includes
    management of routing tables, the container's interface, and DNS settings. The
    implementation of a sandbox can be a Linux network namespace, a FreeBSD jail,
    or another similar concept.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 沙盒包含容器的网络堆栈配置，包括路由表的管理、容器的接口和DNS设置。沙盒的实现可以是Linux网络命名空间、FreeBSD监狱或类似的概念。
- en: A sandbox may contain many endpoints from multiple networks. It also represents
    a container's network configuration, such as IP address, MAC address, and DNS
    entries.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 一个沙盒可以包含来自多个网络的许多端点。它还表示容器的网络配置，如IP地址、MAC地址和DNS条目。
- en: libnetwork makes use of the OS-specific parameters to populate the network configuration
    represented by a sandbox. It provides a framework to implement a sandbox in multiple
    OSes.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork利用特定于操作系统的参数来填充由沙盒表示的网络配置。它提供了一个框架来在多个操作系统中实现沙盒。
- en: '**Netlink** is used to manage the routing table in namespace and currently
    two implementations of a sandbox exist-`namespace_linux.go` and `configure_linux.go`-to
    uniquely identify the path on the host filesystem. A sandbox is associated with
    a single Docker container.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**Netlink**用于管理命名空间中的路由表，目前存在两种沙盒的实现-`namespace_linux.go`和`configure_linux.go`-以唯一标识主机文件系统上的路径。一个沙盒与一个Docker容器关联。'
- en: 'The following data structure shows the runtime elements of a sandbox:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下数据结构显示了沙盒的运行时元素：
- en: '[PRE27]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'A new sandbox is instantiated from a network controller (which is explained
    in detail later):'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新的沙盒是从网络控制器实例化的（稍后将详细解释）：
- en: '[PRE28]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Endpoint
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 端点
- en: An endpoint joins a sandbox to a network and provides connectivity for services
    exposed by a container to the other containers deployed in the same network. It
    can be an internal port of Open vSwitch or a similar vEth pair.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一个端点将一个沙盒连接到一个网络，并为容器公开的服务提供与部署在同一网络中的其他容器的连接。它可以是Open vSwitch的内部端口或类似的vEth对。
- en: An endpoint can belong to only one network and may only belong to one sandbox.
    It represents a service and provides various APIs to create and manage the endpoint.
    It has a global scope but gets attached to only one network.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 一个端点只能属于一个网络，也只能属于一个沙盒。它表示一个服务，并提供各种API来创建和管理端点。它具有全局范围，但只附加到一个网络。
- en: 'An endpoint is specified by the following struct:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 一个端点由以下结构指定：
- en: '[PRE29]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: An endpoint is associated with a unique ID and name. It is attached to a network
    and a sandbox ID. It is also associated with a IPv4 and IPv6 address spaces. Each
    endpoint is associated with an endpoint interface.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 一个端点与唯一的ID和名称相关联。它附加到一个网络和一个沙盒ID。它还与IPv4和IPv6地址空间相关联。每个端点与一个端点接口相关联。
- en: Network
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络
- en: A group of endpoints that are able to communicate with each other directly is
    called a **network**. It provides the required connectivity within the same host
    or multiple hosts and whenever a network is created or updated, the corresponding
    driver is notified. An example is a VLAN or Linux bridge that has a global scope
    within a cluster.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 能够直接相互通信的一组端点称为**网络**。它在同一主机或多个主机之间提供所需的连接，并在创建或更新网络时通知相应的驱动程序。例如，VLAN或Linux桥在集群中具有全局范围。
- en: 'A networks are controlled from a network controller, which we will discuss
    in the next section. Every network has a name, address space, ID, and network
    type:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是从网络控制器中控制的，我们将在下一节中讨论。每个网络都有名称、地址空间、ID和网络类型：
- en: '[PRE30]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Network controller
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络控制器
- en: 'A network controller object provides APIs to create and manage a network object.
    It is an entry point to the libnetwork by binding a particular driver to a given
    network, and it supports multiple active drivers, both inbuilt and remote. A network
    controller allows users to bind a particular driver to a given network:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 网络控制器对象提供API来创建和管理网络对象。它是通过将特定驱动程序绑定到给定网络来绑定到libnetwork的入口点，并支持多个活动驱动程序，包括内置和远程驱动程序。网络控制器允许用户将特定驱动程序绑定到给定网络：
- en: '[PRE31]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Each network controller has reference to the following things:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 每个网络控制器都引用以下内容：
- en: One or more drivers in a data structure driver table
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个数据结构驱动程序表中的驱动程序
- en: One or more sandboxes in a data structure
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个或多个数据结构中的沙盒
- en: A data store
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储
- en: An ipamTable![Network controller](graphics/image_07_009.jpg)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个ipamTable![网络控制器](graphics/image_07_009.jpg)
- en: Network controller handling the network between Docker container and Docker
    engine
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 网络控制器处理Docker容器和Docker引擎之间的网络
- en: The preceding diagram shows how the network controller sits between the Docker
    Engine, containers, and the networks they are attached to.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了网络控制器如何位于Docker引擎、容器和它们连接的网络之间。
- en: CNM attributes
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNM属性
- en: 'The following are the CNM attributes:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是CNM属性：
- en: '**Options:** These are not end user visible but are the key-value pairs of
    data to provide a flexible mechanism to pass driver-specific configuration from
    user to driver directly. libnetwork operates on the options only if a key matches
    a well-known label and as a result of this a value is picked up that is represented
    by a generic object.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项：**这些对终端用户不可见，但是数据的键值对，提供了一种灵活的机制，可以直接从用户传递到驱动程序。只有当键与已知标签匹配时，libnetwork才会处理选项，结果是选择了一个由通用对象表示的值。'
- en: '**Labels:** These are a subset of options that are end user variable represented
    in the UI using the `--labels` option. Their main function is to perform driver-specific
    operations, and they are passed from the UI.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签：**这些是在UI中使用`--labels`选项表示的终端用户可变的选项子集。它们的主要功能是执行特定于驱动程序的操作，并从UI传递。'
- en: CNM life cycle
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CNM生命周期
- en: Consumers of the CNM interact through the CNM objects and its APIs to network
    the containers that they manage; drivers register with a network controller.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: CNM的使用者通过CNM对象及其API与其管理的容器进行网络交互；驱动程序向网络控制器注册。
- en: Built-in drivers are registered inside libnetwork, while remote drivers register
    with libnetwork using a plugin mechanism.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 内置驱动程序在libnetwork内注册，而远程驱动程序使用插件机制向libnetwork注册。
- en: 'Each driver handles a particular network type as explained as follows:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 每个驱动程序处理特定的网络类型，如下所述：
- en: A network controller object is created using the `libnetwork.New()` API to manage
    the allocation of networks and optionally configure a driver with driver-specific
    options. The network object is created using the controller's `NewNetwork()` API, a
    `name`, and a `NetworkType` is added as a parameter.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`libnetwork.New()` API创建一个网络控制器对象，以管理网络的分配，并可选择使用特定于驱动程序的选项进行配置。使用控制器的`NewNetwork()`
    API创建网络对象，作为参数添加了`name`和`NetworkType`。
- en: The `NetworkType` parameter helps to choose a driver and binds the created network
    to that driver. All operations on network will be handled by the driver that is
    created using the preceding API.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NetworkType`参数有助于选择驱动程序并将创建的网络绑定到该驱动程序。对网络的所有操作都将由使用前面的API创建的驱动程序处理。'
- en: The `Controller.NewNetwork()` API takes in an optional options parameter that
    carries driver-specific options and labels, which the driver can use for its purpose.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Controller.NewNetwork()` API接受一个可选的选项参数，其中包含驱动程序特定的选项和标签，驱动程序可以用于其目的。'
- en: '`Network.CreateEndpoint()` is called to create a new endpoint in a given network.
    This API also accepts optional options parameters that vary with the driver.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调用`Network.CreateEndpoint()`在给定网络中创建一个新的端点。此API还接受可选的选项参数，这些参数随驱动程序而异。
- en: '`CreateEndpoint()` can choose to reserve IPv4/IPv6 addresses when an endpoint
    is created in a network. The driver assigns these addresses using the `InterfaceInfo`
    interface defined in `driverapi`. The IPv4/IPv6 addresses are needed to complete
    the endpoint as service definition along with the ports that the endpoint exposes.
    A service endpoint is a network address and the port number that the application
    container is listening on.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CreateEndpoint()`在创建网络中的端点时可以选择保留IPv4/IPv6地址。驱动程序使用`driverapi`中定义的`InterfaceInfo`接口分配这些地址。IPv4/IPv6地址是完成端点作为服务定义所需的，还有端点暴露的端口。服务端点是应用程序容器正在侦听的网络地址和端口号。'
- en: '`Endpoint.Join()` is used to attach a container to an endpoint. The `Join`
    operation will create a sandbox, if one doesn''t exist for that container. The
    drivers make use of the sandbox key to identify multiple endpoints attached to
    the same container.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Endpoint.Join()`用于将容器附加到端点。如果不存在该容器的沙盒，`Join`操作将创建一个沙盒。驱动程序利用沙盒密钥来标识附加到同一容器的多个端点。'
- en: There is a separate API to create an endpoint and another to join the endpoint.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个单独的API用于创建端点，另一个用于加入端点。
- en: An endpoint represents a service that is independent of the container. When
    an endpoint is created, it has resources reserved for a container to get attached
    to the endpoint later. It gives a consistent networking behavior.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 端点表示与容器无关的服务。创建端点时，为容器保留了资源，以便稍后附加到端点。它提供了一致的网络行为。
- en: '`Endpoint.Leave()` is invoked when a container is stopped. The driver can clean
    up the states that it allocated during the `Join()` call. libnetwork deletes the
    sandbox when the last referencing endpoint leaves the network.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当容器停止时，将调用`Endpoint.Leave()`。驱动程序可以清理在`Join()`调用期间分配的状态。当最后一个引用端点离开网络时，libnetwork将删除沙盒。
- en: libnetwork keeps holding on to IP addresses as long as the endpoint is still
    present. These will be reused when the container (or any container) joins again.
    It ensures that the container's resources are reused when they are stopped and
    started again.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只要端点仍然存在，libnetwork就会持有IP地址。当容器（或任何容器）再次加入时，这些地址将被重用。它确保了在停止和重新启动时重用容器的资源。
- en: '`Endpoint.Delete()` deletes an endpoint from a network. This results in deleting
    the endpoint and cleaning up the cached `sandbox.Info`.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Endpoint.Delete()`从网络中删除一个端点。这将导致删除端点并清理缓存的`sandbox.Info`。'
- en: '`Network.Delete()` is used to delete a network. Deleting is allowed if there
    are no endpoints attached to the network.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Network.Delete()` 用于删除网络。如果没有端点连接到网络，则允许删除。'
- en: Docker networking tools based on overlay and underlay networks
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于覆盖和底层网络的Docker网络工具
- en: An overlay is a virtual network that is built on top of anunderlying network
    infrastructure (the underlay). The purpose is to implement a network service that
    is not available in the physical network.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖是建立在底层网络基础设施（底层）之上的虚拟网络。其目的是实现在物理网络中不可用的网络服务。
- en: Network overlay dramatically increases the number of virtual subnets that can
    be created on top of the physical network, which in turn supports multi-tenancy
    and virtualization features.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 网络覆盖大大增加了可以在物理网络之上创建的虚拟子网的数量，从而支持多租户和虚拟化功能。
- en: Every container in Docker is assigned with an IP address that is used for communication
    with other containers. If a container has to communicate to the external network,
    you set up networking in the host system and expose or map the port from the container
    to the host machine. With this application running inside, containers will not
    be able to advertise their external IP and ports as the information is not available
    to them.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Docker中的每个容器都分配了一个用于与其他容器通信的IP地址。如果容器需要与外部网络通信，您需要在主机系统中设置网络并将容器的端口暴露或映射到主机。在容器内运行此应用程序时，容器将无法广告其外部IP和端口，因为它们无法获取此信息。
- en: The solution is to somehow assign unique IPs to each Docker container across
    all hosts and have some networking product that routes traffic between the hosts.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案是在所有主机上为每个Docker容器分配唯一的IP，并有一些网络产品在主机之间路由流量。
- en: 'There are different projects and tools to help with Docker networking, as follows:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 有不同的项目和工具可帮助处理Docker网络，如下所示：
- en: Flannel
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flannel
- en: Weave
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weave
- en: Project Calico
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Project Calico
- en: Flannel
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flannel
- en: '**Flannel** gives each container an IP that can be used for container-to-container
    communication. By packet encapsulation, it creates a virtual overlay network over
    host network. By default, flannel provides a `/24` subnet to the hosts, from which
    the Docker daemon will allocate IPs to the containers.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**Flannel** 为每个容器分配一个IP，可用于容器之间的通信。通过数据包封装，它在主机网络上创建一个虚拟覆盖网络。默认情况下，flannel为主机提供一个`/24`子网，Docker守护程序将从中为容器分配IP。'
- en: '![Flannel](graphics/image_07_010.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![Flannel](graphics/image_07_010.jpg)'
- en: Communication between containers using Flannel
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Flannel进行容器之间的通信
- en: Flannel runs an agent, `flanneld`, on each host and is responsible for allocating
    a subnet lease out of a preconfigured address space. Flannel uses `etcd` ([https://github.com/coreos/etcd](https://github.com/coreos/etcd))
    to store the network configuration, allocated subnets, and auxiliary data (such
    as the host's IP).
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Flannel在每个主机上运行一个代理`flanneld`，负责从预配置的地址空间中分配子网租约。Flannel使用`etcd` ([https://github.com/coreos/etcd](https://github.com/coreos/etcd))存储网络配置、分配的子网和辅助数据（如主机的IP）。
- en: In order to provide encapsulation, Flannel uses the **Universal TUN/TAP** device
    and creates an overlay network using UDP to encapsulate IP packets. The subnet
    allocation is done with the help of `etcd`, which maintains the overlay subnet
    to host mappings.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供封装，Flannel使用**Universal TUN/TAP**设备，并使用UDP创建覆盖网络以封装IP数据包。子网分配是通过`etcd`完成的，它维护覆盖子网到主机的映射。
- en: Weave
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Weave
- en: '**Weave** creates a virtual network that connects Docker containers deployed
    across hosts/VMs and enables their automatic discovery.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**Weave** 创建一个虚拟网络，连接部署在主机/虚拟机上的Docker容器，并实现它们的自动发现。'
- en: '![Weave](graphics/image_07_011.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![Weave](graphics/image_07_011.jpg)'
- en: Weave Network
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Weave网络
- en: Weave can traverse firewalls and operate in partially connected networks. Traffic
    can be optionally encrypted, allowing hosts/VMs to be connected across an untrusted
    network.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: Weave可以穿越防火墙，在部分连接的网络中运行。流量可以选择加密，允许主机/虚拟机在不受信任的网络中连接。
- en: Weave augments Docker's existing (single host) networking capabilities, such
    as the docker0 bridge, so that these can continue to be used by the containers.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Weave增强了Docker现有（单个主机）的网络功能，如docker0桥，以便这些功能可以继续被容器使用。
- en: Project Calico
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Calico项目
- en: '**Project Calico** provides a scalable networking solution for connecting containers,
    VMs, or bare metal. Calico provides connectivity using the scalable IP networking
    principle as a layer 3 approach. Calico can be deployed without overlays or encapsulation.
    The Calico service should be deployed as a container on each node. It provides
    each container with its own IP address and, also, handles all the necessary IP
    routing, security policy rules, and distribution of routes across a cluster of
    nodes.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**Calico项目**为连接容器、虚拟机或裸机提供可扩展的网络解决方案。Calico使用可扩展的IP网络原则作为第3层方法提供连接。Calico可以在不使用覆盖或封装的情况下部署。Calico服务应该作为每个节点上的一个容器部署。它为每个容器提供自己的IP地址，并处理所有必要的IP路由、安全策略规则和在节点集群中分发路由的工作。'
- en: 'The Calico architecture contains four important components in order to provide
    better networking solutions:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: Calico架构包含四个重要组件，以提供更好的网络解决方案：
- en: '**Felix**, the Calico worker process, is the heart of the Calico networking
    that primarily routes and provides the desired connectivity to and from the workloads
    on the host. It also provides the interface to the kernel for outgoing endpoint
    traff'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Felix**，Calico工作进程，是Calico网络的核心，主要路由并提供所需的与主机上工作负载之间的连接。它还为传出端点流量提供与内核的接口。'
- en: '**BIRD**, the route ic. BIRD, the route distribution open source BGP, exchanges
    routing information between hosts. The kernel endpoints that are picked up by
    BIRD are distributed to BGP peers in order to provide inter-host routing. Two
    BIRD processes run in the *calico-node* container, IPv4 (bird) and one for IPv6
    (bird6)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BIRD**，路由ic。BIRD，路由分发开源BGP，交换主机之间的路由信息。BIRD捡起的内核端点被分发给BGP对等体，以提供主机之间的路由。在*calico-node*容器中运行两个BIRD进程，一个用于IPv4（bird），另一个用于IPv6（bird6）。'
- en: '**confd**, a templating process to autogenerate configuration for BIRD, monitors
    the `etcd` store for any changes to BGP configuration, such as log levels and
    IPAM information. `confd` also dynamically generates BIRD configuration files
    based on data from `etcd` and is trigger automatically as updates are applied
    to the data. `confd` triggers BIRD to load new files whenever the configuration
    file is changed.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**confd**，一个用于自动生成BIRD配置的模板处理过程，监视`etcd`存储中对BGP配置的任何更改，如日志级别和IPAM信息。`confd`还根据来自`etcd`的数据动态生成BIRD配置文件，并在数据应用更新时自动触发。`confd`在配置文件更改时触发BIRD加载新文件。'
- en: '**calicoctl** is the command line used to configure and start the Calico service.
    It even allows the data store (`etcd`) to define and apply security policy. The
    tool also provides the simple interface for general management of Calico configuration
    irrespective of whether Calico is running on VMs, containers, or bare metal. The
    following commands are supported at `calicoctl;`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**calicoctl**是用于配置和启动Calico服务的命令行。它甚至允许使用数据存储（`etcd`）定义和应用安全策略。该工具还提供了通用管理Calico配置的简单界面，无论Calico是在虚拟机、容器还是裸机上运行，都支持以下命令在`calicoctl`上。'
- en: '[PRE32]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'As per the official GitHub page of the Calico repository ([https://github.com/projectcalico/calico-containers](https://github.com/projectcalico/calico-containers)),
    the following integration of Calico exists:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Calico存储库的官方GitHub页面（[https://github.com/projectcalico/calico-containers](https://github.com/projectcalico/calico-containers)），存在以下Calico集成：
- en: Calico as a Docker network plugin
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico作为Docker网络插件
- en: Calico without Docker networking
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有Docker网络的Calico
- en: Calico with Kubernetes
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Kubernetes
- en: Calico with Mesos
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Mesos
- en: Calico with Docker Swarm![Project Calico](graphics/image_07_012.jpg)
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Docker Swarm![Project Calico](graphics/image_07_012.jpg)
- en: Calico Architecture
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Calico架构
- en: Configuring an overlay network with the Docker Engine swarm node
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker引擎swarm节点配置覆盖网络
- en: With the release of Docker 1.9, the multi-host and overlay network has become
    one of its primary feature. It enables private networks that can be established
    to connect multiple containers. We will be creating the overlay network on a manager
    node running in swarm cluster without an external key-value store. The swarm network
    will make the network available to the nodes in the swarm that require it for
    a service.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 随着Docker 1.9的发布，多主机和覆盖网络已成为其主要功能之一。它可以建立私有网络，以连接多个容器。我们将在swarm集群中运行的管理器节点上创建覆盖网络，而无需外部键值存储。swarm网络将使需要该服务的swarm节点可用于网络。
- en: When we deploy the service that uses overlay network, the manager automatically
    extends the network to the nodes that are running the service tasks. Multi-host
    networking requires a store for service discovery, so now we will create a Docker
    machine to run this service.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 当部署使用覆盖网络的服务时，管理器会自动将网络扩展到运行服务任务的节点。多主机网络需要一个用于服务发现的存储，所以现在我们将创建一个Docker机器来运行这项服务。
- en: '![Configuring an overlay network with the Docker Engine swarm node](graphics/image_07_013.jpg)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker引擎swarm节点配置覆盖网络](graphics/image_07_013.jpg)'
- en: Overlay network across multiple hosts
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 跨多个主机的覆盖网络
- en: For the following deployment, we will be using Docker machine application that creates
    the Docker daemon on a virtualization or cloud platform. For the virtualization
    platform, we will be using VMware fusion as the provider.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于以下部署，我们将使用Docker机器应用程序在虚拟化或云平台上创建Docker守护程序。对于虚拟化平台，我们将使用VMware Fusion作为提供者。
- en: 'The Docker-machine installation is as follows:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: Docker-machine的安装如下：
- en: '[PRE33]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Mulithost networking requires a store for service discovery, so we will create
    a Docker machine to run that service, creating the new Docker daemon:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 多主机网络需要一个用于服务发现的存储，因此我们将创建一个Docker机器来运行该服务，创建新的Docker守护程序：
- en: '[PRE34]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Tip
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: To see how to connect your Docker client to the Docker Engine running on this
    virtual machine, run `docker-machine env swarm-consul`.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看如何将Docker客户端连接到在此虚拟机上运行的Docker引擎，请运行`docker-machine env swarm-consul`。
- en: 'We''ll start the consul container for service discovery:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将启动consul容器进行服务发现：
- en: '[PRE35]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Create two Docker daemons to run the Docker cluster, the first daemon is the
    swarm node that will automatically run a Swarm container used to coordinate the
    cluster:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 创建两个Docker守护程序来运行Docker集群，第一个守护程序是swarm节点，将自动运行用于协调集群的Swarm容器：
- en: '[PRE36]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Docker is up and running!
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: Docker已经启动运行！
- en: Tip
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: To see how to connect your Docker client to the Docker Engine running on this
    virtual machine, run `docker-machine env swarm-0`.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看如何将Docker客户端连接到在此虚拟机上运行的Docker引擎，请运行`docker-machine env swarm-0`。
- en: 'The second daemon is the Swarm `secondary` node that will automatically run
    a Swarm container and report the state back to the `master` node:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个守护程序是Swarm的`secondary`节点，将自动运行一个Swarm容器并将状态报告给`master`节点：
- en: '[PRE37]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Docker is up and running!
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Docker已经启动运行！
- en: Tip
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: To see how to connect your Docker client to the Docker Engine running on this
    virtual machine, run `docker-machine env swarm-1`.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看如何将Docker客户端连接到在此虚拟机上运行的Docker Engine，请运行`docker-machine env swarm-1`。
- en: 'Docker executable will communicate with one Docker daemon. Since we are in
    a cluster, we''ll ensure the communication of the Docker daemon to the cluster
    by running the following command:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Docker可执行文件将与一个Docker守护程序通信。由于我们在一个集群中，我们将通过运行以下命令来确保Docker守护程序与集群的通信：
- en: '[PRE38]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'After this, we''ll create a private `prod` network with an overlay driver:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将使用覆盖驱动程序创建一个私有的`prod`网络：
- en: '[PRE39]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We will be starting the two dummy `ubuntu:12.04` containers using the `--net
    parameter`:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用`--net参数`启动两个虚拟的`ubuntu:12.04`容器：
- en: '[PRE40]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'In the following code snippet, we can see that this Docker container has two
    network interfaces: one connected to the private overlay network and another to
    the Docker bridge:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下代码片段中，我们可以看到这个Docker容器有两个网络接口：一个连接到私有覆盖网络，另一个连接到Docker桥接口：
- en: '[PRE41]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The other container will also be connected to the `prod` network interface
    existing on the other host:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个容器也将连接到另一个主机上现有的`prod`网络接口：
- en: '[PRE42]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is how a private network can be configured across hosts in the Docker Swarm
    cluster.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在Docker Swarm集群中跨主机配置私有网络的方法。
- en: Comparison of all multi-host Docker networking solutions
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所有多主机Docker网络解决方案的比较
- en: '|  | **Calico** | **Flannel** | **Weave** | **Docker Overlay N/W** |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  | **Calico** | **Flannel** | **Weave** | **Docker Overlay N/W** |'
- en: '| **Network Model** | Layer-3 Solution | VxLAN or UDP | VxLAN or UDP | VxLAN
    |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| **网络模型** | 第3层解决方案 | VxLAN或UDP | VxLAN或UDP | VxLAN |'
- en: '| **Name Service** | No | No | Yes | No |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| **名称服务** | 否 | 否 | 是 | 否 |'
- en: '| **Protocol Support** | TCP,UDP, ICMP & ICMPv6 | All | All | All |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| **协议支持** | TCP，UDP，ICMP和ICMPv6 | 全部 | 全部 | 全部 |'
- en: '| **Distributed Storage** | Yes | Yes | No | Yes |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| **分布式存储** | 是 | 是 | 否 | 是 |'
- en: '| **Encryption Channel** | No | TLS | NaCI Library | No |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| **加密通道** | 否 | TLS | NaCI库 | 否 |'
- en: Configuring OpenvSwitch (OVS) to work with Docker
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置OpenvSwitch（OVS）以与Docker一起工作
- en: '**Open vSwitch** (**OVS**) is an open source **OpenFlow** capable virtual switch
    that is typically used with hypervisors to interconnect virtual machines within
    a host and between different hosts across networks. Overlay networks need to create
    a virtual data path using supported tunneling encapsulations, such as VXLAN or
    GRE.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**Open vSwitch**（**OVS**）是一个开源的**OpenFlow**能力虚拟交换机，通常与虚拟化程序一起使用，以在主机内部和跨网络的不同主机之间连接虚拟机。覆盖网络需要使用支持的隧道封装来创建虚拟数据路径，例如VXLAN或GRE。'
- en: The overlay data path is provisioned between tunnel endpoints residing in the
    Docker host that gives the appearance of all hosts within a given provider segment
    being directly connected to one another.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖数据路径是在Docker主机中的隧道端点之间进行配置的，这使得给定提供者段中的所有主机看起来直接连接在一起。
- en: 'As a new container comes online, the prefix is updated in the routing protocol
    announcing its location via a tunnel endpoint. As the other Docker hosts receive
    the updates, the forwarding is installed into OVS for which tunnel endpoint the
    host resides. When the host is deprovisioned, a similar process occurs and tunnel
    endpoint Docker hosts remove the forwarding entry for the deprovisioned container:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 当新容器上线时，前缀将在路由协议中更新，通过隧道端点宣布其位置。当其他Docker主机接收到更新时，转发将安装到OVS中，以确定主机所在的隧道端点。当主机取消配置时，类似的过程发生，隧道端点Docker主机将删除取消配置容器的转发条目：
- en: '![Configuring OpenvSwitch (OVS) to work with Docker](graphics/image_07_014.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![配置OpenvSwitch（OVS）以与Docker一起工作](graphics/image_07_014.jpg)'
- en: Communication between containers running on multiple hosts through OVS based
    VXLAN tunnels
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通过基于OVS的VXLAN隧道在多个主机上运行的容器之间的通信
- en: Note
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: By default, Docker uses the Linux docker0 bridge; however, there are cases where
    OVS might be required instead of the Linux bridge. A single Linux bridge can handle
    1,024 ports only; this limits the scalability of Docker as we can only create
    1,024 containers, each with a single network interface.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker使用Linux docker0桥；但是，在某些情况下，可能需要使用OVS而不是Linux桥。单个Linux桥只能处理1,024个端口；这限制了Docker的可扩展性，因为我们只能创建1,024个容器，每个容器只有一个网络接口。
- en: Troubleshooting OVS single host setup
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除OVS单主机设置
- en: 'Install OVS on a single host, create two containers, and connect them to an
    OVS bridge:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个主机上安装OVS，创建两个容器，并将它们连接到OVS桥：
- en: 'Install OVS:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装OVS：
- en: '[PRE43]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Install the `ovs-docker` utility:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`ovs-docker`实用程序：
- en: '[PRE44]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![Troubleshooting OVS single host setup](graphics/image_07_015.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![故障排除OVS单主机设置](graphics/image_07_015.jpg)'
- en: Single host OVS
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 单主机OVS
- en: Create an OVS bridge.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个OVS桥。
- en: 'Here, we will be adding a new OVS bridge and configuring it so that we can
    get the containers connected on a different network:'
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们将添加一个新的OVS桥并对其进行配置，以便我们可以将容器连接到不同的网络上：
- en: '[PRE45]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Add a port from the OVS bridge to the Docker container.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从OVS桥添加端口到Docker容器。
- en: 'Create two `ubuntu` Docker containers:'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建两个`ubuntu` Docker容器：
- en: '[PRE46]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Connect the container to the OVS bridge:'
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将容器连接到OVS桥：
- en: '[PRE47]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Test the connection between the two containers connected using the OVS bridge
    with the `ping` command. First, find out their IP addresses:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`ping`命令测试使用OVS桥连接的两个容器之间的连接。首先找出它们的IP地址：
- en: '[PRE48]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Since we know the IP Address of `container1` and `container2` , we can run
    the following command:'
  id: totrans-299
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们知道`container1`和`container2`的IP地址，我们可以运行以下命令：
- en: '[PRE49]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Troubleshooting OVS multiple host setups
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 故障排除OVS多主机设置
- en: 'First, we will connect Docker containers on multiple hosts using OVS:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将使用OVS在多个主机上连接Docker容器：
- en: 'Let us consider our setup, as shown in the following diagram, that contains
    two hosts-`Host1` and `Host2`-running Ubuntu 14.04:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑我们的设置，如下图所示，其中包含两个运行Ubuntu 14.04的主机-`Host1`和`Host2`：
- en: 'Install Docker and OVS on both the hosts:'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两台主机上安装Docker和OVS：
- en: '[PRE50]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Install the `ovs-docker` utility:'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装`ovs-docker`实用程序：
- en: '[PRE51]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![Troubleshooting OVS multiple host setups](graphics/image_07_016.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_IMG
  zh: '![故障排除OVS多主机设置](graphics/image_07_016.jpg)'
- en: Multi Host container communication with OVS
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OVS进行多主机容器通信
- en: Docker chooses a random network to run its containers by default. It creates
    a docker0 bridge and assigns an IP address (`172.17.42.1`) to it. So, both the `Host1`
    and `Host2` docker0 bridge IP addresses are the same, due to which it is difficult
    for containers in both the hosts to communicate. To overcome this, let's assign
    static IP addresses to the network, that is, (`192.168.10.0/24`).
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，Docker选择随机网络来运行其容器。它创建一个docker0桥，并为其分配一个IP地址（`172.17.42.1`）。因此，`Host1`和`Host2`的docker0桥IP地址相同，这使得两个主机中的容器难以通信。为了克服这一点，让我们为网络分配静态IP地址（`192.168.10.0/24`）。
- en: 'To change the default Docker subnet:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 更改默认的Docker子网：
- en: 'Execute the following commands on `Host1`:'
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Host1`上执行以下命令：
- en: '[PRE52]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Add the `br0` OVS bridge:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`br0` OVS桥：
- en: '[PRE53]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Create the tunnel to the other host:'
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建到另一个主机的隧道：
- en: '[PRE54]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Add the `br0` bridge to the `docker0` bridge:'
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`br0`桥添加到`docker0`桥：
- en: '[PRE55]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Execute the following commands on Host2:'
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Host2上执行以下命令：
- en: '[PRE56]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Add the `br0` OVS bridge:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加`br0` OVS桥：
- en: '[PRE57]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Create the tunnel to the other host and attach it to the:'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建到另一个主机的隧道并将其附加到：
- en: '[PRE58]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Add the `br0` bridge to the `docker0` bridge:'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`br0`桥添加到`docker0`桥：
- en: '[PRE59]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: The docker0 bridge is attached to another bridge-`br0.` This time, it's an OVS
    bridge, which means that all traffic between the containers is routed through
    `br0` too. Additionally, we need to connect together the networks from both the
    hosts in which the containers are running. A GRE tunnel ([http://en.wikipedia.org/wiki/Generic_Routing_Encapsulation](http://en.wikipedia.org/wiki/Generic_Routing_Encapsulation))
    is used for this purpose. This tunnel is attached to the `br0` OVS bridge and,
    as a result, to `docker0` as well. After executing the preceding commands on both
    the hosts, you should be able to ping the `docker0` bridge addresses from both
    the hosts.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: docker0桥连接到另一个桥-`br0`。这次，它是一个OVS桥，这意味着容器之间的所有流量也通过`br0`路由。此外，我们需要连接两个主机上的网络，容器正在其中运行。为此目的使用了GRE隧道。这个隧道连接到`br0`
    OVS桥，结果也连接到`docker0`。在两个主机上执行上述命令后，您应该能够从两个主机上ping通`docker0`桥的地址。
- en: 'On Host1:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在Host1上：
- en: '[PRE60]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'On Host2:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在Host2上：
- en: '[PRE61]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Create containers on both the hosts.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主机上创建容器。
- en: 'On Host1, use the following command:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在Host1上，使用以下命令：
- en: '[PRE62]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'On Host2, use the following command:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在Host2上，使用以下命令：
- en: '[PRE63]'
  id: totrans-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: Now we can ping `container2` from `container1.` In this way, we connect Docker
    containers on multiple hosts using OVS.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以从`container1` ping `container2`。这样，我们使用OVS在多个主机上连接Docker容器。
- en: Summary
  id: totrans-339
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learnt how Docker networking is powered with docker0 bridge,
    its troubleshooting issues, and configuration. We also looked at troubleshooting
    the communication issues between Docker networks and the external network. Following
    that, we did some deep dive into libnetwork and the CNM and its life cycle. Then,
    we looked into containers' communication across multiple hosts using different
    networking options, such as Weave, OVS, Flannel, and Docker's latest overlay network,
    with comparison, and the troubleshooting issues involved in their configuration.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了Docker网络是如何通过docker0桥进行连接的，以及它的故障排除问题和配置。我们还研究了Docker网络和外部网络之间的通信问题的故障排除。在此之后，我们深入研究了libnetwork和CNM及其生命周期。然后，我们研究了使用不同的网络选项在多个主机上跨容器进行通信，例如Weave、OVS、Flannel和Docker的最新overlay网络，以及它们配置中涉及的故障排除问题。
- en: We saw that Weave creates a virtual network, OVS uses GRE tunneling technology,
    Flannel provides a separate subnet, and the Docker overlay sets up each host to
    connect containers on multiple hosts. After that, we looked into Docker network
    configuration with OVS and troubleshooting the single host and multiple host setup.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到Weave创建了一个虚拟网络，OVS使用了GRE隧道技术，Flannel提供了一个独立的子网，Docker overlay设置了每个主机以连接多个主机上的容器。之后，我们研究了使用OVS进行Docker网络配置以及单个主机和多个主机设置的故障排除。
