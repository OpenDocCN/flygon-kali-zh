["```\n//run CentOS Container\n$ docker run -it centos\n\n# ls\nanaconda-post.log  dev  home  lib64       media  opt   root  sbin  sys  usr\nbin                etc  lib   lost+found  mnt    proc  run   srv   tmp  var\n\n//create one file (/I_WAS_HERE) at root directory\n# touch /I_WAS_HERE\n# ls /\nI_WAS_HERE         bin  etc   lib    lost+found  mnt  proc  run   srv  tmp  var\nanaconda-post.log  dev  home  lib64  media       opt  root  sbin  sys  usr \n\n//Exit container\n# exit\nexit \n\n//re-run CentOS Container\n# docker run -it centos \n\n//previous file (/I_WAS_HERE) was disappeared\n# ls /\nanaconda-post.log  dev  home  lib64       media  opt   root  sbin  sys  usr\nbin                etc  lib   lost+found  mnt    proc  run   srv   tmp  var  \n```", "```\n\n//there are 2 pod on the same Node\n$ kubectl get pods\nNAME                          READY     STATUS    RESTARTS   AGE\nBesteffort                    1/1       Running   0          1h\nguaranteed                    1/1       Running   0          1h \n\n//when application consumes a lot of memory, one Pod has been killed\n$ kubectl get pods\nNAME                          READY     STATUS    RESTARTS   AGE\nBesteffort                    0/1       Error     0          1h\nguaranteed                    1/1       Running   0          1h \n\n//clashed Pod is restarting\n$ kubectl get pods\nNAME                          READY     STATUS             RESTARTS   AGE\nBesteffort                    0/1       CrashLoopBackOff   0          1h\nguaranteed                    1/1       Running            0          1h\n\n//few moment later, Pod has been restarted \n$ kubectl get pods\nNAME                          READY     STATUS    RESTARTS   AGE\nBesteffort                    1/1       Running   1          1h\nguaranteed                    1/1       Running   0          1h\n\n```", "```\n//default Storage Class on AWS\n$ kubectl get sc\nNAME            TYPE\ndefault         kubernetes.io/aws-ebs\ngp2 (default)   kubernetes.io/aws-ebs\n\n//default Storage Class on GKE\n$ kubectl get sc\nNAME                 TYPE\nstandard (default)   kubernetes.io/gce-pd   \n```", "```\n//simulate to occur one data node down \n$ kubectl delete pod es-data-0\npod \"es-data-0\" deleted\n```", "```\n$ cat burstable.yml  \napiVersion: v1 \nkind: Pod \nmetadata: \n  name: burstable-pod \nspec: \n  containers: \n  - name: nginx \n    image: nginx \n    resources: \n      requests: \n        cpu: 0.1 \n        memory: 10Mi \n      limits: \n        cpu: 0.5 \n        memory: 300Mi \n```", "```\n\n//Pod is reaching to the memory limit\n$ kubectl get pods\nNAME            READY     STATUS    RESTARTS   AGE\nburstable-pod   1/1       Running   0          10m\n\n//got OOMKilled\n$ kubectl get pods\nNAME            READY     STATUS      RESTARTS   AGE\nburstable-pod   0/1       OOMKilled   0          10m\n\n//restarting Pod\n$ kubectl get pods\nNAME            READY     STATUS      RESTARTS   AGE\nburstable-pod   0/1       CrashLoopBackOff   0   11m \n\n//restarted\n$ kubectl get pods\nNAME            READY     STATUS    RESTARTS   AGE\nburstable-pod   1/1       Running   1          12m  \n```", "```\n//no resource setting\n$ cat besteffort-implicit.yml \napiVersion: v1\nkind: Pod\nmetadata:\n name: besteffort\nspec:\n containers:\n - name: nginx\n image: nginx\n\n//resource limit setting as 0\n$ cat besteffort-explicit.yml \napiVersion: v1\nkind: Pod\nmetadata:\n name: besteffort\nspec:\n containers:\n - name: nginx\n image: nginx\n resources:\n limits:\n      cpu: 0\n      memory: 0\n```", "```\n$ cat guaranteed.yml \napiVersion: v1\nkind: Pod\nmetadata:\n name: guaranteed-pod\nspec:\n containers:\n   - name: nginx\n     image: nginx\n     resources:\n      limits:\n       cpu: 0.3\n       memory: 350Mi\n      requests:\n       cpu: 0.3\n       memory: 350Mi\n\n$ kubectl get pods\nNAME             READY     STATUS    RESTARTS   AGE\nguaranteed-pod   1/1       Running   0          52s\n\n$ kubectl describe pod guaranteed-pod | grep -i qos\nQoS Class:  Guaranteed\n```", "```\n// supposed nginx is Guaranteed, tomcat as Burstable...\n$ cat guaranteed-fail.yml \napiVersion: v1\nkind: Pod\nmetadata:\n name: burstable-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n     limits:\n       cpu: 0.3\n       memory: 350Mi\n     requests:\n       cpu: 0.3\n       memory: 350Mi\n  - name: tomcat\n    image: tomcat\n    resources:\n      requests:\n       cpu: 0.2\n       memory: 100Mi\n\n$ kubectl create -f guaranteed-fail.yml \npod \"guaranteed-fail\" created\n\n//at the result, Pod is configured as Burstable\n$ kubectl describe pod guaranteed-fail | grep -i qos\nQoS Class:  Burstable\n```", "```\n//nginx set only cpu limit, tomcat set only memory limit\n$ cat guaranteed-fail2.yml \napiVersion: v1\nkind: Pod\nmetadata:\n name: guaranteed-fail2\nspec:\n containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n       cpu: 0.3\n  - name: tomcat\n    image: tomcat\n    resources:\n      requests:\n       memory: 100Mi\n\n$ kubectl create -f guaranteed-fail2.yml \npod \"guaranteed-fail2\" created\n\n//result is Burstable again\n$ kubectl describe pod |grep -i qos\nQoS Class:  Burstable\n```"]