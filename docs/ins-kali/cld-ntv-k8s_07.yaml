- en: '*Chapter 5*: Services and Ingress – Communicating with the Outside World'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第5章*：服务和Ingress-与外部世界通信'
- en: This chapter contains a comprehensive discussion of the methods that Kubernetes
    provides to allow applications to communicate with each other, and with resources
    outside the cluster. You'll learn about the Kubernetes Service resource and all
    its possible types – ClusterIP, NodePort, LoadBalancer, and ExternalName – as
    well as how to implement them. Finally, you'll learn how to use Kubernetes Ingress.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含了Kubernetes提供的方法的全面讨论，允许应用程序相互通信，以及与集群外部的资源通信。您将了解Kubernetes服务资源及其所有可能的类型-ClusterIP、NodePort、LoadBalancer和ExternalName-以及如何实现它们。最后，您将学习如何使用Kubernetes
    Ingress。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Understanding Services and cluster DNS
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解服务和集群DNS
- en: Implementing ClusterIP
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现ClusterIP
- en: Using NodePort
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用NodePort
- en: Setting up a LoadBalancer Service
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置LoadBalancer服务
- en: Creating an ExternalName Service
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建ExternalName服务
- en: Configuring Ingress
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置Ingress
- en: Technical requirement
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In order to run the commands detailed in this chapter, you will need a computer
    that supports the `kubectl` command-line tool along with a working Kubernetes
    cluster. Review [*Chapter 1*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016),
    *Communicating with Kubernetes*, to see several methods for getting up and running
    with Kubernetes quickly, and for instructions on how to install the `kubectl`
    tool.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了运行本章中详细介绍的命令，您需要一台支持`kubectl`命令行工具的计算机，以及一个可用的Kubernetes集群。请查看[*第1章*](B14790_01_Final_PG_ePub.xhtml#_idTextAnchor016)，*与Kubernetes通信*，了解快速启动和运行Kubernetes的几种方法，以及如何安装`kubectl`工具的说明。
- en: The code used in this chapter can be found in the book's GitHub repository at
    [https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中使用的代码可以在书籍的GitHub存储库中找到，网址为[https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5](https://github.com/PacktPublishing/Cloud-Native-with-Kubernetes/tree/master/Chapter5)。
- en: Understanding Services and cluster DNS
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解服务和集群DNS
- en: In the last few chapters, we've talked about how to run applications effectively
    on Kubernetes using resources including Pods, Deployments, and StatefulSets. However,
    many applications, such as web servers, need to be able to accept network requests
    from outside their containers. These requests could come either from other applications
    or from devices accessing the public internet.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几章中，我们已经讨论了如何有效地在Kubernetes上运行应用程序，使用包括Pods、Deployments和StatefulSets在内的资源。然而，许多应用程序，如Web服务器，需要能够接受来自其容器外部的网络请求。这些请求可能来自其他应用程序，也可能来自访问公共互联网的设备。
- en: Kubernetes provides several types of resources to handle various scenarios when
    it comes to allowing resources outside and inside the cluster to access applications
    running on Pods, Deployments, and more.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了几种资源类型，用于处理允许集群外部和内部资源访问运行在Pods、Deployments等应用程序的各种情况。
- en: 'These fall into two major resource types, Services and Ingress:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这些属于两种主要资源类型，服务和Ingress：
- en: '**Services** have several subtypes – ClusterIP, NodePort, and LoadBalancer
    – and are generally used to provide simple access to a single application from
    inside or outside the cluster.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**有几种子类型-ClusterIP、NodePort和LoadBalancer-通常用于提供从集群内部或外部简单访问单个应用程序。'
- en: '**Ingress** is a more advanced resource that creates a controller that takes
    care of pathname- and hostname-based routing to various resources running inside
    the cluster. Ingress works by using rules to forward traffic to Services. You
    need to use Services to use Ingress.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ingress是一个更高级的资源，它创建一个控制器，负责基于路径名和主机名的路由到集群内运行的各种资源。Ingress通过使用规则将流量转发到服务来工作。您需要使用服务来使用Ingress。
- en: Before we get started with our first type of Service resource, let's review
    how Kubernetes handles DNS inside the cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始第一种类型的服务资源之前，让我们回顾一下Kubernetes如何处理集群内部的DNS。
- en: Cluster DNS
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群DNS
- en: Let's start by discussing which resources in Kubernetes get their own DNS names
    by default. DNS names in Kubernetes are restricted to Pods and Services. Pod DNS
    names contain several parts structured as subdomains.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先讨论在Kubernetes中哪些资源默认拥有自己的DNS名称。Kubernetes中的DNS名称仅限于Pod和服务。Pod DNS名称包含几个部分，结构化为子域。
- en: 'A typical **Fully Qualified Domain Name** (**FQDN**) for a Pod running in Kubernetes
    looks like this:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中运行的Pod的典型完全限定域名（FQDN）如下所示：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let''s break it down, starting from the rightmost side:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从最右边开始分解：
- en: '`my-cluster-domain.example` corresponds to the configured DNS name for the
    Cluster API itself. Depending on the tool used to set up the cluster, and the
    environment that it runs in, this can be an external domain name or an internal
    DNS name.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-cluster-domain.example`对应于Cluster API本身的配置DNS名称。根据用于设置集群的工具以及其运行的环境，这可以是外部域名或内部DNS名称。'
- en: '`svc` is a section that will occur even in a Pod DNS name – so we can just
    assume it will be there. However, as you will see shortly, you won''t generally
    be accessing Pods or Services through their FQDNs.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`svc`是一个部分，即使在Pod DNS名称中也会出现 - 因此我们可以假设它会在那里。但是，正如您很快会看到的，您通常不会通过它们的FQDN访问Pod或服务。'
- en: '`my-namespace` is pretty self-explanatory. This section of the DNS name will
    be whatever namespace your Pod is operating in.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-namespace`相当容易理解。DNS名称的这一部分将是您的Pod所在的命名空间。'
- en: '`my-subdomain` corresponds to the `subdomain` field in the Pod spec. This field
    is completely optional.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`my-subdomain`对应于Pod规范中的`subdomain`字段。这个字段是完全可选的。'
- en: Finally, `my-hostname` will be set to whatever the name of the Pod is in the
    Pod metadata.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`my-hostname`将设置为Pod在Pod元数据中的名称。
- en: Together, this DNS name allows other resources in the cluster to access a particular
    Pod. This generally isn't very helpful by itself, especially if you're using Deployments
    and StatefulSets that generally have multiple Pods. This is where Services come
    in.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这个DNS名称允许集群中的其他资源访问特定的Pod。这通常本身并不是很有用，特别是如果您正在使用通常有多个Pod的部署和有状态集。这就是服务的用武之地。
- en: 'Let''s take a look at the A record DNS name for a Service:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看服务的A记录DNS名称：
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As you can see, it's very similar to the Pod DNS name, with the difference that
    we only have one value to the left of our namespace – which is the Service name
    (again, as with Pods, this is generated based on the metadata name).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这与Pod DNS名称非常相似，不同之处在于我们在命名空间左侧只有一个值 - 就是服务名称（与Pod一样，这是基于元数据名称生成的）。
- en: One result of how these DNS names are handled is that within a namespace, you
    can access a Service or Pod via just its Service (or Pod) name, and the subdomain.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这些DNS名称的处理方式的一个结果是，在命名空间内，您可以仅通过其服务（或Pod）名称和子域访问服务或Pod。
- en: For instance, take our previous Service DNS name. From within the `my-namespace`
    namespace, the Service can be accessed simply by the DNS name `my-svc`. From outside
    the `my-namespace` namespace, you can access the Service via `my-svc.my-namespace`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以前的服务DNS名称。在`my-namespace`命名空间内，可以通过DNS名称`my-svc`简单地访问服务。在`my-namespace`之外，可以通过`my-svc.my-namespace`访问服务。
- en: Now that we've learned how in-cluster DNS works, we can discuss how that translates
    to the Service proxy.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了集群内DNS的工作原理，我们可以讨论这如何转化为服务代理。
- en: Service proxy types
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务代理类型
- en: Services, explained as simply as possible, provide an abstraction to forward
    requests to one or more Pods that are running an application.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 服务，尽可能简单地解释，提供了一个将请求转发到一个或多个运行应用程序的Pod的抽象。
- en: When creating a Service, we define a selector that tells the Service which Pods
    to forward requests to. Through functionality in the `kube-proxy` component, when
    requests hit a Service, they will be forwarded to the various Pods that match
    the Service's selector.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 创建服务时，我们定义了一个选择器，告诉服务将请求转发到哪些Pod。通过`kube-proxy`组件的功能，当请求到达服务时，它们将被转发到与服务选择器匹配的各个Pod。
- en: 'There are three possible proxy modes that you can use in Kubernetes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，有三种可能的代理模式：
- en: '**Userspace proxy mode**: The oldest proxy mode, available since Kubernetes
    version 1.0\. This proxy mode will forward requests to the matched Pods in a round-robin
    fashion.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户空间代理模式**：最古老的代理模式，自Kubernetes版本1.0以来可用。这种代理模式将以轮询方式将请求转发到匹配的Pod。'
- en: '**Iptables proxy mode**: Available since 1.1, and the default since 1.2\. This
    offers a lower overhead than userspace mode and can use round robin or random
    selection.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Iptables代理模式**：自1.1版本以来可用，并且自1.2版本以来是默认选项。这比用户空间模式的开销要低，并且可以使用轮询或随机选择。'
- en: '**IPVS proxy mode**: The newest option, available since 1.8\. This proxy mode
    allows other load balancing options (not just Round Robin):'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IPVS代理模式**：自1.8版本以来提供的最新选项。此代理模式允许其他负载平衡选项（不仅仅是轮询）：'
- en: a. Round Robin
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: a. 轮询
- en: b. Least Connection (the least number of open connections)
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: b. 最少连接（最少数量的打开连接）
- en: c. Source Hashing
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: c. 源哈希
- en: d. Destination Hashing
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: d. 目标哈希
- en: e. Shortest Expected Delay
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: e. 最短预期延迟
- en: f. Never Queue
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: f. 从不排队
- en: Relevant to this list is a discussion of what round-robin load balancing is,
    for those not familiar.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与此列表相关的是对轮询负载均衡的讨论，对于那些不熟悉的人。
- en: 'Round-robin load balancing involves looping through the potential list of Service
    endpoints from beginning to end, per network request. The following diagram shows
    a simplified view of this process it pertains to Kubernetes Pods behind a Service:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 轮询负载均衡涉及循环遍历潜在的服务端点列表，每个网络请求一次。以下图表显示了这个过程的简化视图，它与Kubernetes服务后面的Pod相关：
- en: '![Figure 5.1 – A Service load-balancing to Pods](image/B14790_05_001.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 - 服务负载均衡到Pods](image/B14790_05_001.jpg)'
- en: Figure 5.1 – A Service load-balancing to Pods
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 - 服务负载均衡到Pods
- en: As you can see, the Service alternates which Pod it sends requests to. The first
    request goes to Pod A, the second goes to Pod B, the third goes to Pod C, and
    then it loops around. Now that we know how Services actually handle requests,
    let's review the major types of Services, starting with ClusterIP.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，服务会交替将请求发送到不同的Pod。第一个请求发送到Pod A，第二个发送到Pod B，第三个发送到Pod C，然后循环。现在我们知道服务实际上如何处理请求了，让我们来回顾一下主要类型的服务，从ClusterIP开始。
- en: Implementing ClusterIP
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现ClusterIP
- en: 'ClusterIP is a simple type of Service exposed on an internal IP inside the
    cluster. This type of Service is not reachable from outside of the cluster. Let''s
    take a look at the YAML file for our Service:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterIP是在集群内部公开的一种简单类型的服务。这种类型的服务无法从集群外部访问。让我们来看看我们服务的YAML文件：
- en: clusterip-service.yaml
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: clusterip-service.yaml
- en: '[PRE2]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As with other Kubernetes resources, we have our metadata block with our `name`
    value. As you can recall from our discussion on DNS, this `name` value is how
    you can access your Service from elsewhere in the cluster. For this reason, ClusterIP
    is a great option for Services that only need to be accessed by other Pods within
    a cluster.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他Kubernetes资源一样，我们有我们的元数据块和我们的`name`值。正如您可以从我们关于DNS的讨论中回忆起来，这个`name`值是您如何可以从集群中的其他地方访问您的服务的。因此，ClusterIP是一个很好的选择，适用于只需要被集群内其他Pod访问的服务。
- en: 'Next, we have our `Spec`, which consists of three major pieces:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有我们的`Spec`，它由三个主要部分组成：
- en: First, we have our `type`, which corresponds to the type of our Service. Since
    the default type is `ClusterIP`, you don't actually need to specify a type if
    you want a ClusterIP Service.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们有我们的`type`，它对应于我们服务的类型。由于默认类型是`ClusterIP`，如果您想要一个ClusterIP服务，实际上不需要指定类型。
- en: Next, we have our `selector`. Our `selector` consists of key-value pairs that
    must match labels in the metadata of the Pods in question. In this case, our Service
    will look for Pods with `app=web-application` and `environment=staging` to forward
    traffic to.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们有我们的`selector`。我们的`selector`由键值对组成，必须与相关Pod的元数据中的标签匹配。在这种情况下，我们的服务将寻找具有`app=web-application`和`environment=staging`标签的Pod来转发流量。
- en: Finally, we have our `ports` block, where we can map ports on our Service to
    `targetPort` numbers on our Pods. In this case, port `80` (the HTTP port) on our
    Service will map to port `8080` on our application Pod. More than one port can
    be opened on our Service, but the `name` field is required when opening multiple
    ports.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们有我们的`ports`块，我们可以将服务上的端口映射到我们Pod上的`targetPort`号码。在这种情况下，我们服务上的端口`80`（HTTP端口）将映射到我们应用程序Pod上的端口`8080`。我们的服务可以打开多个端口，但在打开多个端口时，`name`字段是必需的。
- en: Next, let's review the `protocol` options in depth, since these are important
    to our discussion of Service ports.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们深入审查`protocol`选项，因为这些对我们讨论服务端口很重要。
- en: Protocol
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协议
- en: 'In the case of our previous ClusterIP Service, we chose `TCP` as our protocol.
    Kubernetes currently (as of version 1.19) supports several protocols:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的ClusterIP服务的情况下，我们选择了`TCP`作为我们的协议。截至目前（截至版本1.19），Kubernetes支持多种协议：
- en: '**TCP**'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TCP**'
- en: '**UDP**'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UDP**'
- en: '**HTTP**'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP**'
- en: '**PROXY**'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PROXY**'
- en: '**SCTP**'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SCTP**'
- en: This is an area where new features are likely coming, especially where HTTP
    (L7) services are concerned. Currently, there is not full support of all of these
    protocols across environments or cloud providers.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个新功能可能会出现的领域，特别是涉及HTTP（L7）服务的地方。目前，在不同环境或云提供商中，并不完全支持所有这些协议。
- en: Important note
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For more information, you can check the main Kubernetes documentation ([https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/))
    for the current state of Service protocols.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多信息，您可以查看主要的Kubernetes文档（[https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/)）了解当前服务协议的状态。
- en: Now that we've discussed the specifics of Service YAMLs with Cluster IP, we
    can move on to the next type of Service – NodePort.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了Cluster IP的服务YAML的具体内容，我们可以继续下一个类型的服务 - NodePort。
- en: Using NodePort
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用NodePort
- en: NodePort is an external-facing Service type, which means that it can actually
    be accessed from outside the Cluster. When creating a NodePort Service, a ClusterIP
    Service of the same name will automatically be created and routed to by the NodePort,
    so you will still be able to access the Service from inside the cluster. This
    makes NodePort a good option for external access to applications when a LoadBalancer
    Service is not feasible or possible.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: NodePort是一种面向外部的服务类型，这意味着它实际上可以从集群外部访问。创建NodePort服务时，将自动创建同名的ClusterIP服务，并由NodePort路由到，因此您仍然可以从集群内部访问服务。这使NodePort成为在无法或不可能使用LoadBalancer服务时外部访问应用程序的良好选择。
- en: NodePort sounds like what it is – this type of Service opens a port on every
    Node in the cluster on which the Service can be accessed. This port will be in
    a range that is by default between `30000`-`32767` and will be linked automatically
    on Service creation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: NodePort听起来像它的名字 - 这种类型的服务在集群中的每个节点上打开一个可以访问服务的端口。这个端口默认在`30000`-`32767`之间，并且在服务创建时会自动链接。
- en: 'Here''s what our NodePort Service YAML looks like:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们的NodePort服务YAML的样子：
- en: nodeport-service.yaml
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: NodePort服务.yaml
- en: '[PRE3]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can tell, the only difference from the ClusterIP Service is the Service
    type – however, it is important to note that our intended port `80` in the `ports`
    section will only be used when accessing the automatically created ClusterIP version
    of the Service. From outside the cluster, we'll need to see what the generated
    port link is to access the Service on our Node IP.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，与ClusterIP服务唯一的区别是服务类型 - 然而，重要的是要注意，我们在“端口”部分中的预期端口`80`只有在访问自动创建的ClusterIP版本的服务时才会被使用。从集群外部，我们需要查看生成的端口链接以访问我们的节点IP上的服务。
- en: 'To do this, we can create our Service with the following command:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们可以使用以下命令创建我们的服务：
- en: '[PRE4]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And then run this command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行这个命令：
- en: '[PRE5]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The result of the preceding command will be the following output:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令的结果将是以下输出：
- en: '[PRE6]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: From this output, we look to the `NodePort` line to see that our assigned port
    for this Service is `31598`. Thus, this Service can be accessed on any node at
    `[NODE_IP]:[ASSIGNED_PORT]`.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们看`NodePort`行，看到我们为这个服务分配的端口是`31598`。因此，这个服务可以在任何节点上通过`[NODE_IP]:[ASSIGNED_PORT]`访问。
- en: 'Alternatively, we can manually assign a NodePort IP to the Service. The YAML
    for a manually assigned NodePort is as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以手动为服务分配一个NodePort IP。手动分配NodePort的YAML如下：
- en: manual-nodeport-service.yaml
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 手动NodePort服务.yaml
- en: '[PRE7]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see, we have chosen a `nodePort` in the range `30000`-`32767`, in
    this case, `31233`. To see exactly how this NodePort Service works across Nodes,
    take a look at the following diagram:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们选择了一个在`30000`-`32767`范围内的`nodePort`，在这种情况下是`31233`。要确切地了解这个NodePort服务在节点之间是如何工作的，请看下面的图表：
- en: '![Figure 5.2 – NodePort Service](image/B14790_05_002.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图5.2 - NodePort服务](image/B14790_05_002.jpg)'
- en: Figure 5.2 – NodePort Service
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 - NodePort服务
- en: As you can see, though the Service is accessible at every Node in the cluster
    (Node A, Node B, and Node C), network requests are still load-balanced across
    the Pods in all Nodes (Pod A, Pod B, and Pod C), not just the Node that is accessed.
    This is an effective way to ensure that the application can be accessed from any
    Node. When using cloud services, however, you already have a range of tools to
    spread requests between servers. The next type of Service, LoadBalancer, lets
    us use those tools in the context of Kubernetes.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，虽然服务可以在集群中的每个节点（节点A、节点B和节点C）访问，但网络请求仍然在所有节点的Pod（Pod A、Pod B和Pod C）之间进行负载均衡，而不仅仅是访问的节点。这是确保应用程序可以从任何节点访问的有效方式。然而，在使用云服务时，您已经有了一系列工具来在服务器之间分发请求。下一个类型的服务，LoadBalancer，让我们在Kubernetes的上下文中使用这些工具。
- en: Setting up a LoadBalancer Service
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置LoadBalancer服务
- en: LoadBalancer is a special Service type in Kubernetes that provisions a load
    balancer based on where your cluster is running. For instance, in AWS, Kubernetes
    will provision an Elastic Load Balancer.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: LoadBalancer是Kubernetes中的特殊服务类型，根据集群运行的位置提供负载均衡器。例如，在AWS中，Kubernetes将提供弹性负载均衡器。
- en: Important note
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: For a full list of LoadBalancer services and configurations, check the documentation
    for Kubernetes Services at [https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 有关LoadBalancer服务和配置的完整列表，请查阅Kubernetes服务文档，网址为[https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer)。
- en: 'Unlike with `ClusterIP` or NodePort, we can amend the functionality of a LoadBalancer
    Service in cloud-specific ways. Generally, this is done using an annotations block
    in the Service YAML file – which, as we''ve discussed before, is just a set of
    keys and values. To see how this is done for AWS, let''s review the spec for a
    LoadBalancer Service:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与`ClusterIP`或NodePort不同，我们可以以特定于云的方式修改LoadBalancer服务的功能。通常，这是通过服务YAML文件中的注释块完成的-正如我们之前讨论的那样，它只是一组键和值。要了解如何在AWS中完成此操作，让我们回顾一下LoadBalancer服务的规范：
- en: loadbalancer-service.yaml
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: loadbalancer-service.yaml
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Though we can create a LoadBalancer without any annotations, the supported AWS-specific
    annotations give us the ability (as seen in the preceding YAML code) to specify
    which TLS certificate (via its ARN in Amazon Certificate Manager) we want to be
    attached to our load balancer. AWS annotations also allow configuring logs for
    load balancers, and more.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们可以创建没有任何注释的LoadBalancer，但是支持的AWS特定注释使我们能够（如前面的YAML代码所示）指定要附加到我们的负载均衡器的TLS证书（通过其在Amazon证书管理器中的ARN）。AWS注释还允许配置负载均衡器的日志等。
- en: 'Here are a few key annotations supported by the AWS Cloud Provider as of the
    writing of this book:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是AWS云提供商支持的一些关键注释，截至本书编写时：
- en: '`service.beta.kubernetes.io/aws-load-balancer-ssl-cert`'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-ssl-cert`'
- en: '`service.beta.kubernetes.io/aws-load-balancer-proxy-protocol`'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-proxy-protocol`'
- en: '`service.beta.kubernetes.io/aws-load-balancer-ssl-ports`'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`service.beta.kubernetes.io/aws-load-balancer-ssl-ports`'
- en: Important note
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: A full list of annotations and explanations for all providers can be found on
    the **Cloud Providers** page in the official Kubernetes documentation, at [https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 有关所有提供商的注释和解释的完整列表可以在官方Kubernetes文档的**云提供商**页面上找到，网址为[https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)。
- en: 'Finally, with LoadBalancer Services, we''ve covered the Service types you will
    likely use the most. However, for special cases where the Service itself runs
    outside of Kubernetes, we can use another Service type: ExternalName.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过LoadBalancer服务，我们已经涵盖了您可能最常使用的服务类型。但是，对于服务本身在Kubernetes之外运行的特殊情况，我们可以使用另一种服务类型：ExternalName。
- en: Creating an ExternalName Service
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建ExternalName服务
- en: Services of type ExternalName can be used to proxify applications that are not
    actually running on your cluster, while still keeping the Service as a layer of
    abstraction that can be updated at any time.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 类型为ExternalName的服务可用于代理实际未在集群上运行的应用程序，同时仍保持服务作为可以随时更新的抽象层。
- en: 'Let''s set the scene: you have a legacy production application running on Azure
    that you want to access from within your cluster. You can access this legacy application
    at `myoldapp.mydomain.com`. However, your team is currently working on containerizing
    this application and running it on Kubernetes, and that new version is currently
    working in your `dev` namespace environment on your cluster.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来设定场景：你有一个在Azure上运行的传统生产应用程序，你希望从集群内部访问它。你可以在`myoldapp.mydomain.com`上访问这个传统应用程序。然而，你的团队目前正在将这个应用程序容器化，并在Kubernetes上运行它，而这个新版本目前正在你的`dev`命名空间环境中在你的集群上运行。
- en: Instead of asking your other applications to talk to different places depending
    on the environment, you can always point to a Service called `my-svc` in both
    your production (`prod`) and development (`dev`) namespaces.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 与其要求你的其他应用程序根据环境对不同的地方进行通信，你可以始终在你的生产（`prod`）和开发（`dev`）命名空间中都指向一个名为`my-svc`的Service。
- en: 'In `dev`, this Service could be a `ClusterIP` Service that leads to your newly
    containerized application on Pods. The following YAML shows how the in-development,
    containerized Service should work:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在`dev`中，这个Service可以是一个指向你的新容器化应用程序的Pods的`ClusterIP` Service。以下YAML显示了开发中的容器化Service应该如何工作：
- en: clusterip-for-external-service.yaml
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: clusterip-for-external-service.yaml
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the `prod` namespace, this Service would instead be an `ExternalName` Service:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在`prod`命名空间中，这个Service将会是一个`ExternalName` Service：
- en: externalname-service.yaml
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: externalname-service.yaml
- en: '[PRE10]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Since our `ExternalName` Service is not actually forwarding requests to Pods,
    we don't need a selector. Instead, we specify an `ExternalName`, which is the
    DNS name we want the Service to direct to.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的`ExternalName` Service实际上并不转发请求到Pods，所以我们不需要一个选择器。相反，我们指定一个`ExternalName`，这是我们希望Service指向的DNS名称。
- en: 'The following diagram shows how an `ExternalName` Service could be used in
    this pattern:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了如何在这种模式中使用`ExternalName` Service：
- en: '![Figure 5.3 – ExternalName Service configuration](image/B14790_05_003.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图5.3 - ExternalName Service配置](image/B14790_05_003.jpg)'
- en: Figure 5.3 – ExternalName Service configuration
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 - ExternalName Service配置
- en: In the preceding diagram, our **EC2 Running Legacy Application** is an AWS VM,
    external to the cluster. Our **Service B** of type **ExternalName** will route
    requests out to the VM. That way, our **Pod C** (or any other Pod in the cluster)
    can access our external legacy application simply through the ExternalName services'
    Kubernetes DNS name.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，我们的**EC2 Running Legacy Application**是一个AWS VM，不属于集群。我们的类型为**ExternalName**的**Service
    B**将请求路由到VM。这样，我们的**Pod C**（或集群中的任何其他Pod）可以通过ExternalName服务的Kubernetes DNS名称简单地访问我们的外部传统应用程序。
- en: With `ExternalName`, we've finished our review of all the Kubernetes Service
    types. Let's move on to a more complex method of exposing applications – the Kubernetes
    Ingress resource.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`ExternalName`，我们已经完成了对所有Kubernetes Service类型的审查。让我们继续讨论一种更复杂的暴露应用程序的方法 -
    Kubernetes Ingress资源。
- en: Configuring Ingress
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Ingress
- en: As mentioned at the beginning of the chapter, Ingress provides a granular mechanism
    for routing requests into a cluster. Ingress does not replace Services but augments
    them with capabilities such as path-based routing. Why is this necessary? There
    are plenty of reasons, including cost. An Ingress with 10 paths to `ClusterIP`
    Services is a lot cheaper than creating a new LoadBalancer Service for each path
    – plus it keeps things simple and easy to understand.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 正如本章开头提到的，Ingress提供了一个将请求路由到集群中的细粒度机制。Ingress并不取代Services，而是通过诸如基于路径的路由等功能来增强它们。为什么这是必要的？有很多原因，包括成本。一个具有10个路径到`ClusterIP`
    Services的Ingress比为每个路径创建一个新的LoadBalancer Service要便宜得多 - 而且它保持了事情简单和易于理解。
- en: 'Ingresses do not work like other Services in Kubernetes. Just creating the
    Ingress itself will do nothing. You need two additional components:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 与 Kubernetes 中的其他服务不同。仅仅创建 Ingress 本身是不会有任何作用的。您需要两个额外的组件：
- en: 'An Ingress controller: you can choose from many implementations, built on tools
    such as Nginx or HAProxy.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ingress 控制器：您可以选择许多实现，构建在诸如 Nginx 或 HAProxy 等工具上。
- en: ClusterIP or NodePort Services for the intended routes.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于预期路由的 ClusterIP 或 NodePort 服务。
- en: First, let's discuss how to configure the Ingress controller.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们讨论如何配置 Ingress 控制器。
- en: Ingress controllers
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ingress 控制器
- en: Generally, clusters will not come configured with any pre-existing Ingress controllers.
    You'll need to select and deploy one to your cluster. `ingress-nginx` is likely
    the most popular choice, but there are several others – see [https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)
    for a full list.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，集群不会预先配置任何现有的 Ingress 控制器。您需要选择并部署一个到您的集群中。`ingress-nginx` 可能是最受欢迎的选择，但还有其他几种选择
    - 请参阅[https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/)获取完整列表。
- en: Let's learn how to deploy an Ingress controller - for the purposes of this book,
    we'll stick with the Nginx Ingress controller created by the Kubernetes community,
    `ingress-nginx`.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们学习如何部署 Ingress 控制器 - 为了本书的目的，我们将坚持使用由 Kubernetes 社区创建的 Nginx Ingress 控制器
    `ingress-nginx`。
- en: 'Installation may differ from controller to controller, but for `ingress-nginx`
    there are two main parts. First, to deploy the main controller itself, run the
    following command, which may change depending on the target environment and newest
    Nginx Ingress version:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 安装可能因控制器而异，但对于 `ingress-nginx`，有两个主要部分。首先，要部署主控制器本身，请运行以下命令，具体取决于目标环境和最新的 Nginx
    Ingress 版本：
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Secondly, we may need to configure our Ingress depending on which environment
    we're running in. For a cluster running on AWS, we can configure the Ingress entry
    point to use an Elastic Load Balancer that we create in AWS.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们可能需要根据我们运行的环境来配置我们的 Ingress。对于在 AWS 上运行的集群，我们可以配置 Ingress 入口点以使用我们在 AWS
    中创建的弹性负载均衡器。
- en: Important note
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: To see all environment-specific setup instructions, see the `ingress-nginx`
    docs at [https://kubernetes.github.io/ingress-nginx/deploy/](https://kubernetes.github.io/ingress-nginx/deploy/).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有特定于环境的设置说明，请参阅 `ingress-nginx` 文档[https://kubernetes.github.io/ingress-nginx/deploy/](https://kubernetes.github.io/ingress-nginx/deploy/)。
- en: The Nginx ingress controller is a set of Pods that will auto-update the Nginx
    configuration whenever a new Ingress resource (a custom Kubernetes resource) is
    created. In addition to the Ingress controller, we will need a way to route requests
    to the Ingress controller – known as the entry point.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Nginx Ingress 控制器是一组 Pod，它将在创建新的 Ingress 资源（自定义的 Kubernetes 资源）时自动更新 Nginx 配置。除了
    Ingress 控制器，我们还需要一种方式将请求路由到 Ingress 控制器 - 称为入口点。
- en: Ingress entry point
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress 入口点
- en: The default `nginx-ingress` install will also create a singular Service that
    serves requests to the Nginx layer, at which point the Ingress rules take over.
    Depending on how you configure your Ingress, this can be a LoadBalancer or NodePort
    Service. In a cloud environment, you will likely use a cloud LoadBalancer Service
    as the entry point to the cluster Ingress.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的 `nginx-ingress` 安装还将创建一个服务，用于为 Nginx 层提供请求，此时 Ingress 规则接管。根据您配置 Ingress
    的方式，这可以是一个负载均衡器或节点端口服务。在云环境中，您可能会使用云负载均衡器服务作为集群 Ingress 的入口点。
- en: Ingress rules and YAML
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress 规则和 YAML
- en: Now that we have our Ingress controller up and running, we can start configuring
    our Ingress rules.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们的 Ingress 控制器已经启动并运行，我们可以开始配置我们的 Ingress 规则了。
- en: 'Let''s start with a simple example. We have two Services, `service-a` and `service-b`,
    that we want to expose on different paths via our Ingress. Once your Ingress controller
    and any associated Elastic Load Balancers are created (assuming we''re running
    on AWS), let''s first create our Services by working through the following steps:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个简单的例子开始。我们有两个服务，`service-a`和`service-b`，我们希望通过我们的Ingress在不同的路径上公开它们。一旦您的Ingress控制器和任何相关的弹性负载均衡器被创建（假设我们在AWS上运行），让我们首先通过以下步骤来创建我们的服务：
- en: 'First, let''s look at how to create Service A in YAML. Let''s call the file
    `service-a.yaml`:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们看看如何在YAML中创建服务A。让我们将文件命名为`service-a.yaml`：
- en: service-a.yaml
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: service-a.yaml
- en: '[PRE12]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You can create our Service A by running the following command:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过运行以下命令来创建我们的服务A：
- en: '[PRE13]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, let''s create our Service B, for which the YAML code looks very similar:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们创建我们的服务B，其YAML代码看起来非常相似：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create our Service B by running the following command:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令来创建我们的服务B：
- en: '[PRE15]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Finally, we can create our Ingress with rules for each path. Here is the YAML
    code for our Ingress that will split requests as necessary based on path-based
    routing rules:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以为每个路径创建Ingress规则。以下是我们的Ingress的YAML代码，根据基于路径的路由规则，将根据需要拆分请求：
- en: ingress.yaml
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: ingress.yaml
- en: '[PRE16]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'In our preceding YAML, the ingress has a singular `host` value, which would
    correspond to the host request header for traffic coming through the Ingress.
    Then, we have two paths, `/a` and `/b`, which lead to our two previously created
    `ClusterIP` Services. To put this configuration in a graphical format, let''s
    take a look at the following diagram:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的YAML中，ingress有一个单一的`host`值，这对应于通过Ingress传入的流量的主机请求头。然后，我们有两个路径，`/a`和`/b`，它们分别指向我们之前创建的两个`ClusterIP`服务。为了将这个配置以图形的形式呈现出来，让我们看一下下面的图表：
- en: '![Figure 5.4 – Kubernetes Ingress example](image/B14790_05_004.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图5.4 - Kubernetes Ingress示例](image/B14790_05_004.jpg)'
- en: Figure 5.4 – Kubernetes Ingress example
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 - Kubernetes Ingress示例
- en: As you can see, our simple path-based rules result in network requests getting
    routed directly to the proper Pods. This is because `nginx-ingress` uses the Service
    selector to get a list of Pod IPs, but does not directly use the Service to communicate
    with the Pods. Rather, the Nginx (in this case) config is automatically updated
    as new Pod IPs come online.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们简单的基于路径的规则导致网络请求直接路由到正确的Pod。这是因为`nginx-ingress`使用服务选择器来获取Pod IP列表，但不直接使用服务与Pod通信。相反，Nginx（在这种情况下）配置会在新的Pod
    IP上线时自动更新。
- en: 'The `host` value isn''t actually required. If you leave it out, any traffic
    that comes through the Ingress, regardless of the host header (unless it matches
    a different rule that specifies a host) will be routed according to the rule.
    The following YAML shows this:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`host`值实际上并不是必需的。如果您将其省略，那么通过Ingress传入的任何流量，无论主机头如何（除非它匹配指定主机的不同规则），都将根据规则进行路由。以下的YAML显示了这一点：'
- en: ingress-no-host.yaml
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-no-host.yaml
- en: '[PRE17]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This previous Ingress definition will flow traffic to the path-based routing
    rules even if there is no host header value.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这个先前的Ingress定义将流量流向基于路径的路由规则，即使没有主机头值。
- en: 'Similarly, it is possible to split traffic into multiple separate branching
    paths based on the host header, like this:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，也可以根据主机头将流量分成多个独立的分支路径，就像这样：
- en: ingress-branching.yaml
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-branching.yaml
- en: '[PRE18]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Finally, you can also secure your Ingress with TLS in many cases, though this
    functionality differs on a per Ingress controller basis. For Nginx, this can be
    done by using a Kubernetes Secret. We''ll get to this functionality in the next
    chapter but for now, check out the configuration on the Ingress side:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在许多情况下，您还可以使用TLS来保护您的Ingress，尽管这个功能在每个Ingress控制器的基础上有所不同。对于Nginx，可以使用Kubernetes
    Secret来实现这一点。我们将在下一章介绍这个功能，但现在，请查看Ingress端的配置：
- en: ingress-secure.yaml
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ingress-secure.yaml
- en: '[PRE19]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This configuration will look for a Kubernetes Secret named `my-tls-secret` in
    the default namespace to attach to the Ingress for TLS.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置将查找名为`my-tls-secret`的Kubernetes Secret，以附加到Ingress以进行TLS。
- en: That ends our discussion of Ingress. A lot of Ingress functionality can be specific
    to which Ingress controller you decide to use, so check out the documentation
    for your chosen implementation.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了我们对Ingress的讨论。Ingress的许多功能可能取决于您决定使用的Ingress控制器，因此请查看您选择的实现的文档。
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we reviewed the various methods that Kubernetes provides in
    order to expose applications running on the cluster to the outside world. The
    major methods are Services and Ingress. Within Services, you can use ClusterIP
    Services for in-cluster routing and NodePort for access to a Service directly
    via ports on Nodes. LoadBalancer Services let you use existing cloud load-balancing
    systems, and ExternalName Services let you route requests out of the cluster to
    external resources.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们回顾了Kubernetes提供的各种方法，以便将在集群上运行的应用程序暴露给外部世界。主要方法是服务和Ingress。在服务中，您可以使用ClusterIP服务进行集群内路由，使用NodePort直接通过节点上的端口访问服务。LoadBalancer服务允许您使用现有的云负载均衡系统，而ExternalName服务允许您将请求路由到集群外部的资源。
- en: Finally, Ingress provides a powerful tool to route requests in the cluster by
    path. To implement Ingress you need to install a third-party or open source Ingress
    controller on your cluster.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，Ingress提供了一个强大的工具，可以通过路径在集群中路由请求。要实现Ingress，您需要在集群上安装第三方或开源Ingress控制器。
- en: 'In the next chapter, we''ll talk about how to inject configuration information
    into your applications running on Kubernetes using two resource types: ConfigMap
    and Secret.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何使用ConfigMap和Secret两种资源类型将配置信息注入到在Kubernetes上运行的应用程序中。
- en: Questions
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What type of Service would you use for applications that are only accessed internally
    in a cluster?
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于仅在集群内部访问的应用程序，您会使用哪种类型的服务？
- en: How can you tell which port a NodePort Service is active on?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您如何确定NodePort服务正在使用哪个端口？
- en: Why can Ingress be more cost-effective than purely Services?
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么Ingress比纯粹的服务更具成本效益？
- en: Other than supporting legacy applications, how might ExternalName Services be
    useful on a cloud platform?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了支持传统应用程序外，在云平台上ExternalName服务可能有什么用处？
- en: Further reading
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Information on cloud providers, from the Kubernetes documentation: [https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关云提供商的信息，请参阅Kubernetes文档：[https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)
