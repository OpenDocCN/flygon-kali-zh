- en: Docker Support
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker支持
- en: We have already discussed the basics of microservices architecture and Spring
    Cloud projects in the first part of this book. In the second part, we looked at
    the most common elements of that architecture and we discussed how to implement
    them using Spring Cloud. So far, we have talked about some important topics related
    to microservice migration, such as centralized logging, distributed tracing, security,
    and automated testing. Now, as we are armed with that knowledge, we may proceed
    to the final part of the book, where we will discuss the real power of microservices
    as a cloud-native development approach. The ability to isolate applications from
    each other using containerization tools, implementing continuous deployment in
    the software delivery process and the ability to easily scale an application are
    things that all contribute to the rapidly growing popularity of microservices.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在本书的第一部分讨论了微服务架构和Spring Cloud项目的基础知识。在第二部分，我们看了看该架构的最常见元素，并讨论了如何使用Spring
    Cloud来实现它们。到目前为止，我们已经讨论了与微服务迁移相关的一些重要主题，如集中日志记录、分布式跟踪、安全性和自动化测试。现在，有了这些知识，我们可以继续本书的最后部分，在那里我们将讨论微服务作为云原生开发方法的真正力量。使用容器化工具隔离应用程序之间的能力，实现软件交付过程中的持续部署，以及轻松扩展应用程序的能力，这些都是导致微服务迅速增长的原因。
- en: 'As you will probably remember from earlier chapters, we have used Docker images
    for running third-party tools and solutions on the local machine. With that in
    mind, I would like to introduce you to the main concepts of Docker, such as its
    basic commands and use cases. This information will help you to run the samples
    presented in previous chapters. We will then discuss how to build images with
    our example Spring Boot application, as well as how to run them inside the containers
    on the local machine. We will use simple Docker commands for that, as well as
    more advanced tools such as the Jenkins server, which helps you to perform full,
    continuous delivery and enables a Continuous Integration process in your organization.
    Finally, we will introduce one of the most popular tools used for the automation
    of deploying, scaling, and managing containerized applications: Kubernetes. All
    of our examples will be run locally on a single-node Kubernetes cluster via Minikube.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能还记得的，我们在前几章中已经使用Docker镜像在本地机器上运行第三方工具和解决方案。基于此，我想向你介绍Docker的主要概念，如其基本命令和用例。这些信息将帮助你运行前几章中介绍的示例。然后，我们将讨论如何使用我们的示例Spring
    Boot应用程序构建镜像，以及如何在本地机器上的容器中运行它们。我们将使用简单的Docker命令，以及更高级的工具，如Jenkins服务器，它可以帮助你执行完整的持续交付，并在组织中实现持续集成流程。最后，我们将介绍用于自动部署、扩展和管理容器化应用程序的最流行工具之一：Kubernetes。我们所有的示例都将在单节点Kubernetes集群上通过Minikube本地运行。
- en: 'The topics we will cover in this chapter are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将涵盖的主题如下：
- en: Most useful Docker commands
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最有用的Docker命令
- en: Building Docker containers with Spring Boot microservices
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Boot微服务构建Docker容器
- en: Running Spring Cloud components on Docker
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Docker上运行Spring Cloud组件
- en: Continuous Integration/Continuous Delivery with Jenkins and Docker
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Jenkins和Docker进行持续集成/持续交付
- en: Deploying and running microservices on Minikube
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Minikube上部署和运行微服务
- en: Introducing Docker
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Docker
- en: Docker is a tool that helps you to create, deploy, and run applications by using
    containers. It was designed with the view to benefit both developers and system
    administrators in accordance with the DevOps philosophy. Docker helps to improve
    the software delivery process by solving some important concerns related with
    it. One of those concerns is the idea of immutable delivery, which is related
    to something called **it works for me**. It is especially important that a developer
    uses the same image for their tests as the one that is used in production when
    working in Docker. The only difference that should be seen is during configuration.
    Software delivery in an immutable delivery pattern seems to be particularly important
    for a microservices-based system as there are many applications deployed independently.
    Thanks to Docker, developers can now focus on writing code without worrying about
    the target OS (where the application would be launched). The operation can, therefore,
    use the same interface for deploying, starting, and maintaining all the applications.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Docker是一个通过使用容器来创建、部署和运行应用程序的工具。它旨在符合DevOps哲学，以使开发人员和系统管理员都能受益。Docker通过解决与软件交付相关的一些重要问题来改善软件交付过程。其中一个问题是不可变交付的概念，与**它在我的机器上可以运行**相关。对于在Docker中工作的开发人员来说，特别重要的是在测试中使用与生产环境中使用的相同镜像。唯一的区别应该在配置时可见。在不可变交付模式下的软件交付似乎对基于微服务的系统尤为重要，因为有许多独立部署的应用程序。由于Docker，开发人员现在可以专注于编写代码，而不必担心目标操作系统（应用程序将在其中启动）。因此，运维人员可以使用相同的接口来部署、启动和维护所有应用程序。
- en: There are also many other reasons for Docker's growing popularity. After all,
    the containerization idea is nothing new in the Information Technology world.
    Linux containers were introduced many years ago and have been a part of the kernel
    since 2008\. However, Docker has introduced several new things and solutions that
    other technologies haven't. Firstly, it provides a simple interface that allows
    you to easily package an application with dependencies to a single container before
    running it across different versions and implementations of Linux kernel. The
    container may be run locally or remotely on any Docker-enabled server, and every
    container starts in seconds. We can also easily run every command on it without
    going inside a container. In addition, the sharing and distribution mechanisms
    of Docker images allows developers to commit their changes and push and pull images
    in the same way they share source code, for example, using Git. Currently, almost
    all of the most popular software tools are published on Docker Hub as an image,
    some we have successfully used for running the tools required for our sample applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Docker日益流行还有许多其他原因。毕竟，在信息技术世界中，容器化的概念并不新鲜。Linux容器在多年前就被引入，并且自2008年以来一直是内核的一部分。然而，Docker引入了一些其他技术没有的新东西和解决方案。首先，它提供了一个简单的界面，允许您在不同版本和实现的Linux内核上轻松打包应用程序及其依赖项到单个容器中，然后运行。容器可以在任何启用Docker的服务器上本地或远程运行，并且每个容器在几秒钟内启动。我们还可以轻松地在其中运行每个命令，而无需进入容器。此外，Docker镜像的共享和分发机制允许开发人员以与共享源代码相同的方式提交其更改并推送和拉取镜像，例如使用Git。目前，几乎所有最流行的软件工具都作为镜像发布在Docker
    Hub上，其中一些我们已成功用于运行我们样本应用程序所需的工具。
- en: 'There are some essential definitions and elements that Docker architecture
    is composed of; the most important is a container. Containers run on a single
    machine and share the OS kernel with that machine. They contain everything you
    need to run specific software on your machine code: runtime, system tools, system
    libraries, and settings. Containers are created from the instructions found within
    a Docker image. Images are like a kind of recipe or template that defines the
    steps for installing and running necessary software on a container. Containers
    can also be compared to virtual machines as they have similar resource isolation
    and allocation benefits. However, they virtualize the operating system instead
    of the hardware, making them more portable and efficient than VMs. The following
    diagram illustrates the architectural differences between a Docker container and
    a virtual machine:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Docker架构由一些基本定义和元素组成；最重要的是容器。容器在单台机器上运行，并与该机器共享操作系统内核。它们包含了在您的机器上运行特定软件所需的一切：运行时、系统工具、系统库和设置。容器是根据Docker镜像中的指令创建的。镜像类似于一种定义在容器中安装和运行必要软件步骤的配方或模板。容器也可以与虚拟机进行比较，因为它们具有类似的资源隔离和分配优势。然而，它们虚拟化的是操作系统而不是硬件，使它们比虚拟机更具可移植性和效率。以下图示了Docker容器和虚拟机之间的架构差异：
- en: '![](img/5c4496c4-a46a-4400-a77d-9e5fff6d99ca.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5c4496c4-a46a-4400-a77d-9e5fff6d99ca.png)'
- en: All containers are launched on a physical or virtual machine that is called
    a **Docker host**. Docker hosts, in turn, run a Docker daemon, which listens for
    the commands sent by the Docker client through a Docker API. Docker clients may
    be command-line tools or other software such as Kinematic. Besides running a daemon,
    a Docker host is responsible for storing cached images and containers created
    from those images. Every image is built from a set of layers. Each layer contains
    only the incremental differences from the parent layer. Such an image is not small
    and needs to be stored elsewhere. This place is called the **Docker registry**.
    You may create your own private repository or use the existing public repository
    available on the web. The most popular repository is Docker Hub, which contains
    almost all of the required images.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 所有容器都在称为**Docker主机**的物理或虚拟机上启动。Docker主机反过来运行一个Docker守护进程，该守护进程通过Docker API监听Docker客户端发送的命令。Docker客户端可以是命令行工具或其他软件，如Kinematic。除了运行守护进程外，Docker主机还负责存储从这些镜像创建的缓存镜像和容器。每个镜像都是由一组层构建的。每个层仅包含与父层的增量差异。这样的镜像并不小，需要存储在其他地方。这个地方被称为**Docker注册表**。您可以创建自己的私有存储库，或使用Web上提供的现有公共存储库。最受欢迎的存储库是Docker
    Hub，其中包含几乎所有所需的镜像。
- en: Installing Docker
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Docker
- en: 'Docker installation instructions for Linux are specific to each distribution
    ([https://docs.docker.com/install/#supported-platforms](https://docs.docker.com/install/#supported-platforms)).
    However, sometimes you have to run a Docker daemon after installation, which you
    can do by calling the following command:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Linux上的Docker安装说明针对每个发行版都是特定的（[https://docs.docker.com/install/#supported-platforms](https://docs.docker.com/install/#supported-platforms)）。然而，有时安装后需要运行Docker守护进程，可以通过调用以下命令来实现：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this section, we will focus on instructions for the Windows platform. Generally,
    you have two available options when installing Docker Community Edition (CE) on
    Windows or Mac. The fastest and easiest way is by using Docker for Windows, which
    is available at [https://www.docker.com/docker-windows](https://www.docker.com/docker-windows).
    This is a native Windows application that provides an easy-to-use development
    environment for building, shipping, and running containerized applications. This
    is definitely the best option to utilize, because it uses Windows-native Hyper-V
    virtualization and networking. There is, however, one disadvantage—it is available
    only for Microsoft Windows 10 Professional or Enterprise 64-bit. Earlier versions
    of Windows should use Docker Toolbox, which can be downloaded here at, [https://docs.docker.com/toolbox/toolbox_install_windows/](https://docs.docker.com/toolbox/toolbox_install_windows/).
    This includes the Docker platform, the command-line with Docker Machine, Docker
    Compose, Kitematic, and VirtualBox. Note that you can’t run Docker Engine natively
    on Windows using Docker Toolbox because it uses Linux-specific kernel features.
    Instead, you must use the Docker Machine command (`docker-machine`), which creates
    a Linux VM on the local machine and runs it using Virtual Box. This VM may be
    accessed by your machine using a virtual address that is, by default, `192.168.99.100`.
    All previously discussed examples were integrating with the Docker tools available
    at that IP address.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将专注于Windows平台的指令。通常，在Windows或Mac上安装Docker Community Edition（CE）时，您有两个可用的选项。最快最简单的方法是使用Docker
    for Windows，可以在[https://www.docker.com/docker-windows](https://www.docker.com/docker-windows)上找到。这是一个本地的Windows应用程序，为构建、发布和运行容器化应用程序提供了一个易于使用的开发环境。这绝对是最佳选择，因为它使用了Windows本机的Hyper-V虚拟化和网络。然而，有一个缺点——它只适用于Microsoft
    Windows 10专业版或企业版64位。较早版本的Windows应该使用Docker Toolbox，可以在[https://docs.docker.com/toolbox/toolbox_install_windows/](https://docs.docker.com/toolbox/toolbox_install_windows/)上下载。这包括了Docker平台、带有Docker
    Machine的命令行、Docker Compose、Kitematic和VirtualBox。请注意，您不能在Windows上使用Docker Toolbox本机运行Docker
    Engine，因为它使用了Linux特定的内核功能。相反，您必须使用Docker Machine命令（`docker-machine`），它在本地机器上创建一个Linux虚拟机，并使用Virtual
    Box运行它。默认情况下，可以通过虚拟地址访问这个虚拟机，即`192.168.99.100`。所有先前讨论的示例都是使用该IP地址上可用的Docker工具集成的。
- en: Commonly used Docker commands
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常用的Docker命令
- en: 'After installing Docker Toolbox on Windows you should run Docker Quickstart
    Terminal. It does everything that is needed, including creating and starting Docker
    Machine and providing the command line interface. If you type a Docker command
    without any parameters, you should now be able to see the full list of available
    Docker client commands with descriptions. These are the types of commands we will
    look at:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上安装Docker Toolbox后，您应该运行Docker Quickstart Terminal。它会完成所有需要的工作，包括创建和启动Docker
    Machine以及提供命令行界面。如果您在没有任何参数的情况下输入Docker命令，现在应该能够看到可用的Docker客户端命令的完整列表和描述。这些是我们将要研究的命令类型：
- en: Running and stopping a container
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行和停止容器
- en: List and remove container
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出和删除容器
- en: Pull and push images
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉取和推送镜像
- en: Building an image
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建镜像
- en: Networking
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络
- en: Running and stopping a container
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行和停止容器
- en: 'The first Docker command that is usually run after installation is `docker
    run`. As you may remember, this command is one of the most commonly used in previous
    examples. This command does two things: it pulls and downloads the image definition
    from the registry, in case it is not cached locally, and starts the container.
    There are many options that can be set for this command, which you can easily
    check by running `docker run --help`. Some options have one-letter shortcuts,
    which are often the most commonly used options. Option `–d` runs a container in
    the background, while `–i` keeps `stdin` open even if it is not attached. If your
    container has to expose any ports outside, you can use the activate option `–p`
    with the definition `<port_outside_container>:<port_inside_container>`. Some images
    need additional configurations that are usually done through environment variables
    that can be overridden with the `–e` option. It is also often useful to set a
    friendly name for the container using the `--name` option in order to run other
    commands on it with ease. Take a look at the example Docker command visible here.
    It starts the container with Postgres, creates a database user with a password,
    and exposes it on port `55432`. Now, the Postgres database is available at the
    address `192.168.99.100:55432`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 通常在安装后运行的第一个Docker命令是`docker run`。您可能还记得，这个命令是以前示例中最常用的命令之一。这个命令做了两件事：如果没有在本地缓存，它会从注册表中拉取和下载镜像定义，并启动容器。这个命令有许多可以设置的选项，您可以通过运行`docker
    run --help`轻松查看。一些选项有一个字母的快捷方式，通常是最常用的选项。选项`-d`在后台运行容器，而`-i`即使没有连接也保持`stdin`打开。如果您的容器需要在外部暴露任何端口，可以使用激活选项`-p`和定义`<port_outside_container>:<port_inside_container>`。一些镜像需要通过环境变量进行额外的配置，这些环境变量可以通过`-e`选项进行覆盖。使用`--name`选项为容器设置一个友好的名称通常也很有用，以便轻松地在其上运行其他命令。看一下这里可见的示例Docker命令。它启动了带有Postgres的容器，创建了一个带有密码的数据库用户，并将其暴露在端口`55432`上。现在，Postgres数据库可以在地址`192.168.99.100:55432`上访问：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The container with Postgres persists data. The recommended mechanism for containers
    that store data accessed by outside applications is via volumes. A volume may
    be passed to the container with the `–v` option, where the value consists of fields
    separated by a colon, `:`. The first field is the name of the volume, while the
    second is the path where the file or directory is mounted in the container. The
    next interesting option is the ability to limit the maximum RAM allocated for
    the container using the `–m` option. The following are the commands that create
    new volumes and mount them to the launched container. The maximum amount of RAM
    is set to 500 MB. The container is automatically removed after stopping using
    the activated option `--rm`, shown as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 具有Postgres的容器保留数据。通过卷是存储外部应用程序访问的数据的容器的推荐机制。可以使用`-v`选项将卷传递给容器，其中值由冒号`:`分隔的字段组成。第一个字段是卷的名称，第二个字段是文件或目录在容器中挂载的路径。下一个有趣的选项是使用`-m`选项限制为容器分配的最大RAM。以下是创建新卷并将其挂载到启动容器的命令。最大RAM量设置为500
    MB。使用激活选项`--rm`后，容器在停止后将自动删除，如下所示：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Every running container can be stopped using the `docker stop` command. We
    have already set a name for our container so we can easily use it as a label,
    shown as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用`docker stop`命令停止每个正在运行的容器。我们已经为容器设置了名称，因此可以轻松使用它作为标签，如下所示：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The entire state of the container is written to the disk, so we may run it
    again with exactly the same set of data as we did before stopping, for example:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的整个状态被写入磁盘，因此我们可以再次运行它，其数据集与停止之前完全相同，例如：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'If you only want to restart a container, you can use the following command
    instead of stopping/starting container:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只想重新启动一个容器，可以使用以下命令，而不是停止/启动容器：
- en: '[PRE5]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Listing and removing containers
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 列出和删除容器
- en: 'If you have started some containers, you may want to consider displaying a
    list of all the running containers on your Docker machine. The `docker ps` command
    should be used for that. This command displays some basic information about the
    container, such as a list of exposed ports and the name of the source image. This
    command prints only the currently started containers. If you would like to see
    containers that have been stopped or are inactive, use option `-a` on the Docker
    command, as follows:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经启动了一些容器，您可能希望考虑在Docker机器上显示所有正在运行的容器的列表。应该使用`docker ps`命令。此命令显示有关容器的一些基本信息，例如公开端口的列表和源映像的名称。此命令仅打印当前启动的容器。如果您想要查看已停止或不活动的容器，请在Docker命令上使用`-a`选项，如下所示：
- en: '![](img/cce5a0a7-6103-4def-af56-718b3cd98812.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cce5a0a7-6103-4def-af56-718b3cd98812.png)'
- en: 'If a container is no longer needed, it can be removed using the `docker rm`
    command. Sometimes it is necessary that you remove a running container, which
    is not allowed by default. To force this option, set the `-f` option on Docker
    with the following command:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不再需要容器，可以使用`docker rm`命令将其删除。有时需要删除正在运行的容器，默认情况下是不允许的。要强制执行此选项，请在Docker上设置`-f`选项，使用以下命令：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should remember that the `docker ps` command removes only the container.
    The image from which it has been created is still cached locally. Such images
    can take up a significant amount of space, ranging from a megabyte to several
    hundred megabytes. You may remove every image by using the `docker rmi` command
    with the image ID or name as a parameter, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该记住，`docker ps`命令仅删除容器。从中创建的镜像仍然在本地缓存。这些镜像可能占用大量空间，从几兆字节到几百兆字节不等。您可以使用`docker
    rmi`命令并将镜像ID或名称作为参数来删除每个镜像，如下所示：
- en: '[PRE7]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We haven’t created any Docker images yet, but it''s not unusual to generate
    a large amount of unwanted or unnamed images during image creation. These images
    can be easily recognized, as they are denoted with a name of `<none>`. In Docker
    nomenclature, these are called **dangling images** and can be easily removed with
    the following command. The list of all currently cached images can be displayed
    with the `docker images` command, shown as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有创建任何Docker镜像，但在创建镜像时生成大量不需要的或未命名的镜像并不罕见。这些镜像很容易识别，因为它们用`<none>`的名称表示。在Docker术语中，这些被称为**悬空镜像**，可以使用以下命令轻松删除。可以使用`docker
    images`命令显示当前所有缓存的镜像列表，如下所示：
- en: '[PRE8]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Pulling and pushing images
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拉取和推送镜像
- en: 'We''ve already discussed Docker Hub. It is the biggest and most popular Docker
    repository available on the web. It is available at [https://hub.docker.com](https://hub.docker.com).
    The Docker client, by default, tries to pull all the images for that repository.
    There are many certified official images for common software such as Redis, Java,
    Nginx, or Mongo, but you may also find hundreds of thousands of images created
    by other people as well. If you use the command `docker run` , the image is pulled
    from the repository in case it is not cached locally. You may also run the following
    command `docker pull`, which is only responsible for downloading an image:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过Docker Hub。这是网络上最大最受欢迎的Docker存储库。它可以在[https://hub.docker.com](https://hub.docker.com)上找到。默认情况下，Docker客户端会尝试拉取该存储库的所有镜像。有许多常见软件的官方认证镜像，如Redis、Java、Nginx或Mongo，但您也可能找到其他人创建的数十万个镜像。如果您使用`docker
    run`命令，那么如果本地没有缓存，镜像将从存储库中拉取。您还可以运行以下命令`docker pull`，它只负责下载镜像：
- en: '[PRE9]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding command downloads the newest version of an  image (with the latest
    tag's name). If you would like to use an older version of a Postgres Docker image,
    you should append the tag with the specific version's number. The full list of
    available versions is usually published on the image's site, and is no different
    in this case. Visit [https://hub.docker.com/r/library/postgres/tags/](https://clicktime.symantec.com/a/1/Im1LdWl8NQ4ddISjfwL_OxcUojdkW-H3fP-oquj1vZs=?d=zKV7R9H5uhYC7J5kAN4WlSdYuV7w56mec0MwOxbVt-onFGmsM6Sx37HIaVHJUb3QiEeB2UoRmfzGJLL2nbKFa0anD4Lnn9-ximh393HGo36BjpeP0FoTIe_ikOi5QeJ1AeoMYVgQp_eESUZZNBRlDtcfYxSSkGpgZ_sGge1ts1DBD0AiZXddlCKygZL3ttJma9imoX-dIYGhyIi7l13N-8Y_5N5OYuthQeHXR4cE3e6ZicVVMyrnPGOm4nPLOHZiFzLZsTnDT0QQgFKRuqd4dsZekUaglgG9Y90wlN16gLc1DewmmCqRs_KiE1hwsBfCnFIku3QSPBvVa8e7YWJmMEGwuCxlybf2ywMx81HkC4uMHvQfq1EiVA0PYg5arA%3D%3D&u=https%3A%2F%2Fhub.docker.com%2Fr%2Flibrary%2Fpostgres%2Ftags%2F) for
    a list of the available tags.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令下载最新版本的镜像（使用最新标签的名称）。如果您想使用旧版本的Postgres Docker镜像，您应该附加特定版本号的标签。可用版本的完整列表通常发布在镜像的网站上，在这种情况下也是如此。访问[https://hub.docker.com/r/library/postgres/tags/](https://clicktime.symantec.com/a/1/Im1LdWl8NQ4ddISjfwL_OxcUojdkW-H3fP-oquj1vZs=?d=zKV7R9H5uhYC7J5kAN4WlSdYuV7w56mec0MwOxbVt-onFGmsM6Sx37HIaVHJUb3QiEeB2UoRmfzGJLL2nbKFa0anD4Lnn9-ximh393HGo36BjpeP0FoTIe_ikOi5QeJ1AeoMYVgQp_eESUZZNBRlDtcfYxSSkGpgZ_sGge1ts1DBD0AiZXddlCKygZL3ttJma9imoX-dIYGhyIi7l13N-8Y_5N5OYuthQeHXR4cE3e6ZicVVMyrnPGOm4nPLOHZiFzLZsTnDT0QQgFKRuqd4dsZekUaglgG9Y90wlN16gLc1DewmmCqRs_KiE1hwsBfCnFIku3QSPBvVa8e7YWJmMEGwuCxlybf2ywMx81HkC4uMHvQfq1EiVA0PYg5arA%3D%3D&u=https%3A%2F%2Fhub.docker.com%2Fr%2Flibrary%2Fpostgres%2Ftags%2F)获取可用标签列表。
- en: '[PRE10]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Once you have run and validated your image, you should think about saving it
    remotely. The most appropriate place for it is, of course, Docker Hub. However,
    sometimes you might want to store images in alternative storage, such as a private
    repository. Before pushing an image, you have to tag it with your registry username,
    image name, and its version number. The following command creates a new image
    from a Postgres source image with the name `piomin/postgres` and the `1.0` version
    tag:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您运行并验证了您的镜像，您应该考虑远程保存它。最合适的地方当然是Docker Hub。然而，有时您可能希望将镜像存储在备用存储中，比如私有仓库。在推送镜像之前，您必须使用您的注册表用户名、镜像名称和版本号对其进行标记。以下命令使用名称`piomin/postgres`和`1.0`版本标签从Postgres源镜像创建一个新镜像：
- en: '[PRE11]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now if you run the `docker images` command you will see two images with the
    same ID. The first has the name Postgres and the latest tag, while the second
    has the name `piomin/postgres` and the tag `1.0`. What is important is that `piomin`
    is my username on Docker Hub. So, before proceeding any further we should first
    register the image there. After, we should also log in to our Docker client using
    the `docker login` command. Here, you will be prompted for a username, password,
    and the email address you used for registration. Finally, you can push a tagged
    image with the following `docker push` command:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在如果运行`docker images`命令，您将看到两个具有相同ID的镜像。第一个名称为Postgres，带有最新标签，而第二个名称为`piomin/postgres`，带有标签`1.0`。重要的是`piomin`是我在Docker
    Hub上的用户名。因此，在继续之前，我们应该首先在那里注册镜像。之后，我们还应该使用`docker login`命令登录到我们的Docker客户端。在这里，您将被提示输入用户名、密码和您用于注册的电子邮件地址。最后，您可以使用以下`docker
    push`命令推送带有标签的镜像：
- en: '[PRE12]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now all that''s left to do is log in to your Docker Hub account using a web
    browser to check if the pushed image has appeared. If everything worked correctly,
    you will see a new public repository with your image on-site. The following screenshot
    shows the image currently pushed to my Docker Hub account:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在剩下的就是使用Web浏览器登录到您的Docker Hub帐户，检查推送的镜像是否出现。如果一切正常，您将在现场看到一个新的公共存储库，其中包含您的镜像。以下截图显示了当前推送到我的Docker
    Hub帐户的镜像：
- en: '![](img/8ab7815a-c6bc-47e4-bc66-9c939ad920e2.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8ab7815a-c6bc-47e4-bc66-9c939ad920e2.png)'
- en: Building an image
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建镜像
- en: 'In the previous section, we pushed the copy of the Postgres Docker image to
    a Docker Hub registry. Usually, we push our own images created from the file  `Dockerfile`,
    which defines all the instructions required when installing and configuring software
    on the container. The details related to the structure of `Dockerfile` will be
    discussed later. What is important for now, though, is the command used for building
    a Docker image,  `docker build`. This command should be run in the same directory
    where `Dockerfile` is located. When building a new image it is recommended to
    set its name and tag using the `-t` option. The following command creates the
    image `piomin/order-service` , tagged with a `1.0` version. The image may be pushed
    to your Docker Hub account in the same way as the previous image was with Postgres,
    as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们将Postgres Docker镜像的副本推送到了Docker Hub注册表。通常，我们会推送从`Dockerfile`文件创建的自己的镜像，该文件定义了在容器上安装和配置软件时所需的所有指令。有关`Dockerfile`结构的详细信息将在稍后讨论。现在重要的是用于构建Docker镜像的命令`docker
    build`。此命令应在存储`Dockerfile`的同一目录中运行。在构建新镜像时，建议使用`-t`选项设置其名称和标签。以下命令创建了带有`1.0`版本标签的镜像`piomin/order-service`。可以以与之前的Postgres镜像相同的方式将该镜像推送到您的Docker
    Hub帐户：
- en: '[PRE13]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Networking
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络
- en: 'Networking is an important aspect of Docker architecture since we often have
    to provide communication between applications running on different containers.
    A common use case may be a web application that needs access to a database. We''re
    now going to refer to another example that has already been introduced in [Chapter
    11](554c4049-1dc9-430d-8fe7-19f3b9ac99a3.xhtml), *Message Driven Microservices*.
    It is communication between Apache Kafka and ZooKeeper. Kafka requires ZooKeeper
    because it stores a variety of configuration as a key/value pair in the ZK data
    tree and uses it across the cluster. As you may remember, we first had to create
    a custom network and run those two containers there. The following command is
    used to create a user-defined network on a Docker host:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是Docker架构的一个重要方面，因为我们经常需要在不同容器上运行的应用程序之间提供通信。一个常见的用例可能是需要访问数据库的Web应用程序。我们现在将参考另一个已经在第11章“消息驱动的微服务”中介绍过的示例。这是Apache
    Kafka和ZooKeeper之间的通信。Kafka需要ZooKeeper，因为它在ZK数据树中存储各种配置作为键/值对，并在整个集群中使用它。您可能还记得，我们首先必须创建一个自定义网络，并在那里运行这两个容器。以下命令用于在Docker主机上创建用户定义的网络：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'After the previous command has finished running, you can check out the list
    of available networks using the following command. By default, Docker creates
    three networks for you, so you should see four networks with the names bridge,
    host, none, and `kafka-network`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个命令运行完成后，您可以使用以下命令查看可用网络的列表。默认情况下，Docker为您创建了三个网络，因此您应该看到四个网络，名称分别为bridge、host、none和`kafka-network`：
- en: '[PRE15]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The next step is to pass the network name to the container created with the `docker
    run` command. It can be achieved through the `--network` parameter, as you can
    see in the following example. If you set the same network''s name for two different
    containers, they will be started on the same network. Let''s analyze what this
    means in practice. If you were inside one container, you could call it its name
    instead of using its IP address, which is why we could have set the environment
    variable `ZOOKEEPER_IP` to ZooKeeper when starting a container with Apache Kafka.
    Kafka, which starts inside this container, connects the ZooKeeper instance on
    the default port as follows:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将网络名称传递给使用`docker run`命令创建的容器。可以通过`--network`参数实现，如下例所示。如果为两个不同的容器设置相同的网络名称，它们将在同一网络上启动。让我们分析一下这在实践中意味着什么。如果您在一个容器内部，可以使用其名称而不是使用其IP地址来调用它，这就是为什么我们在启动带有Apache
    Kafka的容器时可以将环境变量`ZOOKEEPER_IP`设置为ZooKeeper。Kafka在此容器内启动，连接到默认端口上的ZooKeeper实例，如下所示：
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Creating a Docker image with microservices
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用微服务创建Docker镜像
- en: We have already discussed the basic Docker commands that are available for running,
    creating, and managing containers. It's now time to create and build our first
    Docker image that starts the sample microservice that we introduced in the previous
    chapter. For that, we should move back to the repository available at the address
    [https://github.com/piomin/sample-spring-cloud-comm.git](https://github.com/piomin/sample-spring-cloud-comm.git)
    and then switch to the branch `feign_with_discovery`  on [https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery](https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery).
    There, you will find a `Dockerfile` for every single microservice, gateway, and
    discovery. Before discussing these examples however we should refer to the `Dockerfile`
    reference to understand the basic commands that we can place there. In fact, `Dockerfile`
    is not the only way to build Docker images; we're also going to show you how to
    create an image with a microservice using the Maven plugin.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了基本的Docker命令，用于运行、创建和管理容器。现在是时候创建和构建我们的第一个Docker镜像了，该镜像启动了我们在上一章介绍的示例微服务。为此，我们应该返回到地址[https://github.com/piomin/sample-spring-cloud-comm.git](https://github.com/piomin/sample-spring-cloud-comm.git)提供的存储库，然后切换到`feign_with_discovery`分支[https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery](https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery)。在那里，您将找到每个微服务、网关和发现的`Dockerfile`。然而，在讨论这些示例之前，我们应该参考`Dockerfile`参考以了解我们可以在其中放置的基本命令。实际上，`Dockerfile`并不是构建Docker镜像的唯一方式；我们还将向您展示如何使用Maven插件创建微服务镜像。
- en: Dockerfiles
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dockerfiles
- en: 'Docker can build images automatically by reading the instructions provided
    in a `Dockerfile`,  a document that contains all the commands that are invoked
    on the command line to assemble an image. All of those commands have to be preceded
    by the keywords defined in the `Dockerfile` specification. The following is a
    list of the most commonly used instructions. They are executed in the order in
    which they are found in the `Dockerfile`. Here, we can also append some comments
    that have to be followed by the `#` character:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Docker可以通过阅读`Dockerfile`中提供的指令来自动构建镜像，`Dockerfile`是一个包含在命令行上调用的所有命令的文档，用于组装镜像。所有这些命令都必须在`Dockerfile`规范中定义的关键字之前。以下是最常用的指令列表。它们按照它们在`Dockerfile`中找到的顺序执行。在这里，我们还可以附加一些注释，这些注释必须在`#`字符之后：
- en: '| **Instruction** | **Description** |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| **指令** | **描述** |'
- en: '| --- | --- |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `FROM` | This  initializes a new build stage and sets the base image for
    subsequent instructions. In fact, every valid `Dockerfile` has to start with a
    `FROM` instruction. |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `FROM` | 这初始化了一个新的构建阶段，并为后续指令设置了基础镜像。实际上，每个有效的`Dockerfile`都必须以`FROM`指令开始。
    |'
- en: '| `MAINTAINER` | This sets author identities of the generated images. This
    instruction is deprecated, so you may find it in many older images. We should
    use the `LABEL` instruction instead of `MAINTAINER` , as follows:`LABEL maintainer="piotr.minkowski@gmail.com"`.
    |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `MAINTAINER` | 这设置了生成的镜像的作者身份。此指令已被弃用，因此您可能会在许多旧镜像中找到它。我们应该使用`LABEL`指令而不是`MAINTAINER`，如下所示：`LABEL
    maintainer="piotr.minkowski@gmail.com"`。|'
- en: '| `RUN` | This executes Linux commands for configuring and installing the required
    software in a new layer on top of the current image and then commits the results.
    It can have two forms:`RUN <command>` or `RUN ["executable", "param1", "param2"]`.
    |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '`RUN` | 这在当前镜像的新层上执行Linux命令来配置和安装所需的软件，然后提交结果。它有两种形式：`RUN <command>`或`RUN ["executable",
    "param1", "param2"]`。'
- en: '| `ENTRYPOINT` | This configures a final script that is used when bootstrapping
    the container that will run as an executable. It overrides all elements specified
    using `CMD` and has two forms: `ENTRYPOINT ["executable", "param1", "param2"]`
    and `ENTRYPOINT` the command `param1 param2`. It is worth noticing that only the
    last `ENTRYPOINT` instruction in the `Dockerfile` will have an affect. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '`ENTRYPOINT` | 这配置了一个最终脚本，用于引导将作为可执行文件运行的容器。它覆盖了使用`CMD`指定的所有元素，有两种形式：`ENTRYPOINT
    ["executable", "param1", "param2"]`和`ENTRYPOINT`命令`param1 param2`。值得注意的是，`Dockerfile`中的最后一个`ENTRYPOINT`指令将产生影响。'
- en: '| `CMD` | `Dockerfile` can contain only one `CMD` instruction. This instruction
    provides the default arguments to  `ENTRYPOINT` using a JSON array format. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '`CMD` | `Dockerfile`只能包含一个`CMD`指令。此指令使用JSON数组格式为`ENTRYPOINT`提供默认参数。'
- en: '| `ENV` | This sets the environment variable for a container in key/value form.
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '`ENV` | 这以键/值形式为容器设置环境变量。'
- en: '| `COPY` | This copies new files or directories from a given source path to
    the filesystem inside the container at the path defined by the target path. It
    has the following form: `COPY [--chown=<user>:<group>] <src>... <dest>`. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '`COPY` | 这将新文件或目录从给定的源路径复制到容器内部的文件系统中，路径由目标路径定义。它的形式如下：`COPY [--chown=<user>:<group>]
    <src>... <dest>`。'
- en: '| `ADD` | This is an alternative to a `COPY` instruction. It is allowed to
    do a little more than `COPY`, for example, it allows `<src>` to be a URL address.
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '`ADD` | 这是`COPY`指令的替代方法。它允许做的事情比`COPY`更多，例如允许`<src>`是一个URL地址。'
- en: '| `WORKDIR` | This sets the working directory for `RUN`, `CMD`, `ENTRYPOINT`,
    `COPY`, and `ADD.` |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '`WORKDIR` | 这为`RUN`，`CMD`，`ENTRYPOINT`，`COPY`和`ADD`设置工作目录。'
- en: '| `EXPOSE` | This is responsible for informing Docker that the container listens
    on the specified network ports at runtime. It does not actually publish the port.
    The ports are published through the `-p` option on the `docker run` command. |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '`EXPOSE` | 这负责通知Docker容器在运行时监听指定的网络端口。它实际上不会发布端口。端口是通过`docker run`命令的`-p`选项发布的。'
- en: '| `VOLUME` | This creates a mount point with the specified name. Volumes are
    the preferred mechanism for persisting data inside Docker containers. |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '`VOLUME` | 这创建了一个指定名称的挂载点。卷是在Docker容器内持久保存数据的首选机制。'
- en: '| `USER` | This sets the username and, optionally, the user group used when
    running the image, as well as for the `RUN`, `CMD`, and `ENTRYPOINT` instructions.
    |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '`USER` | 这在运行镜像时设置用户名和可选的用户组，以及`RUN`，`CMD`和`ENTRYPOINT`指令。'
- en: 'Let’s take a look how this works in practice. We should define a `Dockerfile`
    for every microservice and place it in the root directory of its Git project.
    The following is a `Dockerfile` created for `account-service`:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这在实践中是如何工作的。我们应该为每个微服务定义一个`Dockerfile`，并将其放在其Git项目的根目录中。以下是为`account-service`创建的`Dockerfile`：
- en: '[PRE17]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The preceding example is not very complicated. It only adds the microservice-generated
    fat JAR file to the Docker container and uses the `java -jar` command as `ENTRYPOINT`.
    Even so, let''s analyze it step-by-step. Our example `Dockerfile` performs the
    following instructions:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的例子并不是很复杂。它只是将微服务生成的大JAR文件添加到Docker容器中，并使用`java -jar`命令作为`ENTRYPOINT`。即便如此，让我们一步一步地分析它。我们的示例`Dockerfile`执行以下指令：
- en: The image extends an existing OpenJDK image that is an official, open-source
    implementation of the Java Platform Standard Edition. OpenJDK images come in many
    flavors. The main difference between available images' variants is in their size.
    The image tagged with `8u151-jdk-slim-stretch` provides JDK 8 and includes all
    the libraries needed to run the Spring Boot microservice. It is also much smaller
    than a basic image with this version of Java (`8u151-jdk`).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该镜像扩展了现有的OpenJDK镜像，这是Java平台标准版的官方开源实现。OpenJDK镜像有许多不同的变体。可用镜像变体之间的主要区别在于它们的大小。标记为`8u151-jdk-slim-stretch`的镜像提供了JDK
    8，并包含运行Spring Boot微服务所需的所有库。它还比具有此版本Java（`8u151-jdk`）的基本镜像要小得多。
- en: Here, we defined two environment variables that can be overridden during runtime
    that have the `-e` option of the `docker run` command. The first is the active
    Spring profile name, which is by default initialized with a `zone1` value. The
    second is the discovery server's address, which is by default equal to [http://localhost:8761/eureka/](http://localhost:8761/eureka/).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这里，我们定义了两个环境变量，可以在运行时使用`docker run`命令的`-e`选项进行覆盖。第一个是活动的Spring配置文件名称，默认情况下初始化为`zone1`值。第二个是发现服务器的地址，默认情况下等于[http://localhost:8761/eureka/](http://localhost:8761/eureka/)。
- en: The fat JAR file contains all the required dependencies together with an application's
    binaries. So, we have to put a generated JAR file inside the container using the
    `ADD` instruction.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个大JAR文件包含了所有所需的依赖项以及应用程序的二进制文件。因此，我们必须使用`ADD`指令将生成的JAR文件放入容器中。
- en: 'We configure our container to run as an executable Java application. The defined
    `ENTRYPOINT` is equivalent to running the following command on a local machine:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们配置容器以作为可执行的Java应用程序运行。定义的`ENTRYPOINT`相当于在本地机器上运行以下命令：
- en: '[PRE18]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Using the `EXPOSE` instruction we have informed Docker that it may expose our
    application's HTTP API, which is available inside the container on port `8091`.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`EXPOSE`指令，我们已经通知Docker可以在容器内部的8091端口上公开我们的应用程序的HTTP API。
- en: Running containerized microservices
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行容器化的微服务
- en: Assuming we have prepared a valid `Dockerfile` for each service, the next step
    is to build the whole Maven project with the `mvn clean install` command, before
    building a Docker image for every service.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们为每个服务准备了一个有效的`Dockerfile`，下一步是使用`mvn clean install`命令构建整个Maven项目，然后为每个服务构建一个Docker镜像。
- en: 'When building a Docker image, you should always be in the `root` directory
    of every microservice source code. The first container that has to be run in our
    microservices-based system is a discovery server. Its Docker image has been named
    `piomin/discovery-service`. Before running Docker''s `build` command, go to the
    module `discovery-service`. This `Dockerfile` is a little simpler than other microservices,
    because there is no environment variables to set inside the container, shown as
    follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建Docker镜像时，你应该始终在每个微服务源代码的`root`目录中。在我们基于微服务的系统中，必须首先运行的容器是发现服务器。它的Docker镜像被命名为`piomin/discovery-service`。在运行Docker的`build`命令之前，进入`discovery-service`模块。这个`Dockerfile`比其他微服务要简单一些，因为在容器内没有要设置的环境变量，如下所示：
- en: '[PRE19]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'There are only five steps to perform here, which you can see in the logs generated
    during the target image''s build, just after running the `docker build` command.
    If everything works correctly, you should see the progress of all five steps as
    defined in `Dockerfile` and the following final messages telling you that the
    image has been successfully built and tagged:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这里只需要执行五个步骤，你可以在目标镜像构建期间生成的日志中看到，就在运行`docker build`命令之后。如果一切正常，你应该看到`Dockerfile`中定义的所有五个步骤的进度，以及以下最终消息，告诉你镜像已成功构建和标记：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Once we have successfully built an image, we should run it. We recommend creating
    a network where all the containers with our microservices will be launched. To
    launch a container inside a newly created network, we have to pass its name to
    the `docker run` command using the `--network` parameter. In order to check if
    a container has been successfully started, run the `docker logs` command. This
    command prints all the lines logged by the application to the console, as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们成功构建了一个镜像，我们应该运行它。我们建议创建一个网络，所有包含我们微服务的容器都将在其中启动。要在新创建的网络中启动一个容器，我们必须使用`--network`参数将其名称传递给`docker
    run`命令。为了检查一个容器是否成功启动，运行`docker logs`命令。这个命令打印应用程序在控制台上记录的所有行，如下所示：
- en: '[PRE21]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The next step is to build and run the containers with our four microservices—`account-service`,
    `customer-service`, `order-service`, and `product-service`. The procedure is the
    same for each service. For example, if you would like to build `account-service`,
    first go to that directory within the example project''s source code. The `build`
    command is the same here as it is for the discovery service; the only difference
    is in the image name, as shown in the following snippet:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是构建和运行包含我们四个微服务的容器——`account-service`、`customer-service`、`order-service`和`product-service`。对于每个服务，过程都是一样的。例如，如果你想构建`account-service`，首先进入示例项目源代码中的该目录。这里的`build`命令与发现服务的相同；唯一的区别在于镜像名称，如下面的片段所示：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The command to run the Docker image is a little more complicated for `discovery-service`.
    In this case, we have to pass the address of the Eureka server to the starting
    container. Because this container is running in the same network as the discovery
    service container, we may use its name instead of its IP address or any other
    identifier. Optionally, we can also set the container''s memory limit by using
    the `-m` parameter, for example, to 256 MB. Finally, we can see the logs generated
    by the application running on the container by using the `docker logs` command
    as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Docker镜像的命令对于`discovery-service`来说要复杂一些。在这种情况下，我们必须将Eureka服务器的地址传递给启动容器。因为这个容器运行在与发现服务容器相同的网络中，我们可以使用它的名称而不是它的IP地址或任何其他标识符。可选地，我们还可以使用`-m`参数设置容器的内存限制，例如256
    MB。最后，我们可以使用`docker logs`命令查看运行在容器上的应用程序生成的日志，如下所示：
- en: '[PRE23]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The same steps as described previously should be repeated for all other microservices.
    The final result is the five running containers that can be displayed using the `docker
    ps` command, as shown in the following screenshot:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有其他微服务，应该重复之前描述的相同步骤。最终结果是五个正在运行的容器，可以使用`docker ps`命令显示，如下图所示：
- en: '![](img/2638f3f5-f1ee-446e-8090-25e5c1622119.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2638f3f5-f1ee-446e-8090-25e5c1622119.png)'
- en: 'All the microservices are registered in the Eureka server. The Eureka dashboard
    is available at the address `http://192.168.99.100:8761/`, as shown in the following
    screenshot:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 所有微服务都注册在Eureka服务器中。Eureka仪表板可在地址`http://192.168.99.100:8761/`上找到，如下图所示：
- en: '![](img/da00480d-f780-4d73-a76d-7f1055e5e176.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](img/da00480d-f780-4d73-a76d-7f1055e5e176.png)'
- en: 'There is one more interesting Docker command that we mention here: `docker
    stats`. This command prints some statistics related to the started container,
    such as memory or CPU usage. If you use the  `--format` parameter of that command
    you can customize the way it prints the statistics; for example, you can print
    the container name rather than its ID. Before running that command you may perform
    some tests in order to check that everything is working as it should. It''s worth
    checking whether the communication between microservices that was started on the
    containers has finished successfully. You may also want to try to call the endpoint
    `GET /withAccounts/{id}` from `customer-service` , which calls an endpoint exposed
    by `account-service`. We run the following command:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一个有趣的Docker命令，我们在这里提到：`docker stats`。这个命令打印一些与启动的容器相关的统计信息，比如内存或CPU使用情况。如果你使用该命令的`--format`参数，你可以自定义它打印统计信息的方式；例如，你可以打印容器名称而不是它的ID。在运行该命令之前，你可以进行一些测试，以检查一切是否按预期工作。值得检查的是，启动在容器上的微服务之间的通信是否成功完成。你可能还想尝试从`customer-service`调用`GET
    /withAccounts/{id}`端点，这个端点调用了`account-service`暴露的一个端点。我们运行以下命令：
- en: '[PRE24]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following screenshot is visible:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的屏幕截图可见：
- en: '![](img/4eb480b3-3149-4c73-bdc3-7885ad46bf71.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4eb480b3-3149-4c73-bdc3-7885ad46bf71.png)'
- en: Building an image using the Maven plugin
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Maven插件构建镜像
- en: 'As we''ve mentioned previously, `Dockerfile` is not the only way of creating
    and building containers. There are some other approaches available, for example,
    by using Maven plugin. We have many available plugins dedicated to building images,
    which are used with  `mvn` commands. One of the more popular among them is `com.spotify:docker-maven-plugin`.
    This has the equivalent tags in its configuration that can be used instead of
    `Dockerfile` instructions. The configuration of the plugin inside `pom.xml` for
    `account-service `is as follows:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，`Dockerfile`并不是创建和构建容器的唯一方法。还有其他一些可用的方法，例如使用Maven插件。我们有许多可用的专用于构建镜像的插件，这些插件与`mvn`命令一起使用。其中比较流行的一个是`com.spotify:docker-maven-plugin`。它在其配置中具有等效的标签，可以代替`Dockerfile`指令使用。`pom.xml`中`account-service`的插件配置如下：
- en: '[PRE25]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This plugin can be invoked during Maven''s `build` command. If you would like
    to build a Docker image just after building the application, use the following
    Maven command:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件可以在Maven的`build`命令期间调用。如果您想在构建应用程序后立即构建Docker镜像，请使用以下Maven命令：
- en: '[PRE26]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Alternatively, you can also set the `dockerDirectory` tag in order to perform
    a build based on `Dockerfile`. No matter which method you choose, the effect is
    the same. Any new image that is built with an application will be available on
    your Docker machine. When using `docker-maven-plugin`, you can force the automated
    image to push to the repository by setting `pushImage` to `true`, shown as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您还可以设置`dockerDirectory`标签，以便基于`Dockerfile`执行构建。无论您选择哪种方法，效果都是一样的。使用`docker-maven-plugin`构建的任何新镜像都将在您的Docker机器上可用。使用`docker-maven-plugin`时，您可以通过将`pushImage`设置为`true`来强制自动化镜像推送到存储库，如下所示：
- en: '[PRE27]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Advanced Docker images
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级Docker镜像
- en: 'Until now, we have built rather simple Docker images. However, it is sometimes
    necessary to create a more advanced image. We will need such an image for the
    purpose of Continuous Delivery presentation. This Docker image will be run as
    a Jenkins slave and would be connected to the Jenkins master, which is started
    as a Docker container. We have not found such an image on Docker Hub, so we created
    in by ourselves. Here, the image has to contain Git, Maven, JDK8, and Docker.
    These are all the tools required for building our example microservices using
    the Jenkins slave. I will give you a brief summary of the basics related to Continuous
    Delivery using the Jenkins server in a later section of this chapter. For now,
    we will focus on just building the required image. The following is the full definition
    of the image provided inside `Dockerfile`:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们构建了相当简单的Docker镜像。然而，有时需要创建更高级的镜像。我们需要这样的镜像来进行持续交付演示。这个Docker镜像将作为Jenkins从属运行，并连接到作为Docker容器启动的Jenkins主机。我们在Docker
    Hub上没有找到这样的镜像，所以我们自己创建了它。在这里，镜像必须包含Git、Maven、JDK8和Docker。这些都是使用Jenkins从属构建我们示例微服务所需的所有工具。我将在本章的后面部分简要介绍使用Jenkins服务器进行持续交付的基础知识。现在，我们将专注于构建所需的镜像。以下是`Dockerfile`中提供的镜像的完整定义：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Let''s analyze what''s happened. Here, we have extended the Docker base image.
    This is a pretty smart solution, because that image now provides Docker inside
    Docker. Although running Docker inside Docker is generally not recommended, there
    are some desirable use cases, such as Continuous Delivery with Docker. Besides
    Docker, there is other software installed on the image using the `RUN` instruction,
    such as Git, JDK, Maven, or Curl. We have also added an OS user, which has `sudoers`
    permission in the `dockerd` script, which is responsible for running the Docker
    daemon on the machine. This is not the only process that has to be started in
    the running container; launching JAR with the Jenkins slave is also required.
    Those two commands are executed inside `entrypoint.sh`, which is set as an `ENTRYPOINT`
    of the image. The full source code of this Docker image is available on GitHub
    at [https://github.com/piomin/jenkins-slave-dind-jnlp.git](https://github.com/piomin/jenkins-slave-dind-jnlp.git).
    You can omit building it from source code and just download a ready image from
    my Docker Hub account by using the following command:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析一下发生了什么。在这里，我们扩展了Docker基础镜像。这是一个非常聪明的解决方案，因为该镜像现在提供了Docker内部的Docker。虽然通常不建议在Docker内部运行Docker，但有一些理想的用例，比如使用Docker进行持续交付。除了Docker之外，还使用`RUN`指令在镜像上安装了其他软件，如Git、JDK、Maven或Curl。我们还添加了一个具有`dockerd`脚本中`sudoers`权限的操作系统用户，该脚本负责在机器上运行Docker守护进程。这不是在运行容器中必须启动的唯一进程；还需要启动带有Jenkins从属的JAR。这两个命令在`entrypoint.sh`中执行，该文件被设置为镜像的`ENTRYPOINT`。此Docker镜像的完整源代码可在GitHub上找到[https://github.com/piomin/jenkins-slave-dind-jnlp.git](https://github.com/piomin/jenkins-slave-dind-jnlp.git)。您可以忽略从源代码构建它，只需从我的Docker
    Hub帐户下载一个准备好的镜像，使用以下命令：
- en: '[PRE29]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Here''s the script `entrypoint.sh` inside Docker image that starts Docker deamon
    and Jenkins slave:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Docker镜像内部的脚本`entrypoint.sh`，它启动Docker守护进程和Jenkins从属：
- en: '[PRE30]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Continuous Delivery
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付
- en: One of the key benefits of migrating to microservice-based architecture is the
    ability to deliver software quickly. This should be the main motivation for implementing
    continuous delivery or a continuous deployment process in your organization. In
    short, the continuous delivery process is an approach that tries to automate all
    the stages of software delivery such as building, testing a code, and releasing
    an application. There are many tools that empower that process. One of them is
    Jenkins, an open source automation server written in Java. Docker is something
    that can take your **Continuous Integration** (**CI**) or **Continuous Delivery** (**CD**) processes
    to a higher level. Immutable delivery, for example, is one of the most important
    advantages of Docker.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移到基于微服务的架构的一个关键好处是能够快速交付软件。这应该是在您的组织中实施持续交付或持续部署流程的主要动机。简而言之，持续交付流程是一种尝试自动化软件交付的所有阶段的方法，例如构建、测试代码和发布应用程序。有许多工具可以支持这个过程。其中之一是Jenkins，一个用Java编写的开源自动化服务器。Docker是可以将您的**持续集成**（**CI**）或**持续交付**（**CD**）流程提升到更高水平的东西。例如，不可变交付是Docker的最重要的优势之一。
- en: Integrating Jenkins with Docker
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Jenkins与Docker集成
- en: 'The main goal here is to design and run the continuous delivery process locally using
    Jenkins and Docker. There are four elements that have a part in this process.
    The first of them is already prepared: the source code repository of our microservices,
    which is available on GitHub. The second element, Jenkins, needs to be run and
    configured. Jenkins is a key element of our continuous delivery system. It has
    to download the application''s source code from the GitHub repository, build it,
    and then place the resulting JAR file in Docker image, push that image to Docker
    Hub, and finally run the container with a microservice. All of the tasks within
    this process are directly performed on a Jenkins master but on its slave node.
    Both Jenkins and its slave are launched as Docker containers. The architecture
    of this solution is illustrated as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的主要目标是使用Jenkins和Docker在本地设计和运行持续交付流程。有四个元素参与了这个过程。其中第一个已经准备好了：我们的微服务源代码存储库，可以在GitHub上找到。第二个元素Jenkins需要运行和配置。Jenkins是我们持续交付系统的关键元素。它必须从GitHub存储库下载应用程序的源代码，构建它，然后将生成的JAR文件放入Docker镜像中，将该镜像推送到Docker
    Hub，最后在微服务中运行容器。这个过程中的所有任务都是直接在Jenkins主节点上执行的，但是在它的从节点上执行。Jenkins和它的从节点都是作为Docker容器启动的。这个解决方案的架构如下所示：
- en: '![](img/f069db09-864d-4eb4-b61a-e56760ded97d.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f069db09-864d-4eb4-b61a-e56760ded97d.png)'
- en: 'It''s worth mentioning that Jenkins is built on the basis of the concept of
    plugins. The core is too simple an engine for automated builds. The real power
    of Jenkins is in its plugins, and there are hundreds of them in the Update Center.
    For now, we will only discuss a few opportunities available to us thanks to the
    Jenkins server. We will need the following plugins installed to be able to build
    and run our microservices in Docker containers:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Jenkins是建立在插件概念的基础上的。核心太简单了，无法进行自动化构建。Jenkins的真正力量在于它的插件，在更新中心有数百个插件。现在，我们只讨论几个Jenkins服务器为我们提供的机会。我们需要安装以下插件才能构建和运行我们的微服务在Docker容器中：
- en: '**Pipeline**: This is a suite of plugins that lets you create automation using
    Groovy scripts following the idea **Pipeline as code** ([https://wiki.jenkins.io/display/JENKINS/Pipeline+Plugin](https://clicktime.symantec.com/a/1/4g9YbrLxE43FYJrIE5v0J-RjoqlfXZm5h2piohXV60o=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FPipeline%2BPlugin))'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipeline**：这是一套插件，可以让您使用Groovy脚本创建自动化，遵循**Pipeline as code**的理念（[https://wiki.jenkins.io/display/JENKINS/Pipeline+Plugin](https://clicktime.symantec.com/a/1/4g9YbrLxE43FYJrIE5v0J-RjoqlfXZm5h2piohXV60o=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FPipeline%2BPlugin))'
- en: '**Docker Pipeline**: This allows you to build Docker containers in pipelines
    ([https://wiki.jenkins.io/display/JENKINS/Docker+Pipeline+Plugin](https://clicktime.symantec.com/a/1/3BcsCubSP1UZ0ssSZFCe2iSCQQ_b1asMBhlt_0nQFKI=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FDocker%2BPipeline%2BPlugin))'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker Pipeline**：这允许您在流水线中构建Docker容器（[https://wiki.jenkins.io/display/JENKINS/Docker+Pipeline+Plugin](https://clicktime.symantec.com/a/1/3BcsCubSP1UZ0ssSZFCe2iSCQQ_b1asMBhlt_0nQFKI=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FDocker%2BPipeline%2BPlugin))'
- en: '**Git**: This integrates Git with Jenkins ([https://wiki.jenkins.io/display/JENKINS/Git+Plugin](https://clicktime.symantec.com/a/1/Zbv8hM_2L26s_PMbntThO-9W_A4uUxsqo7UyU5nbae8=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FGit%2BPlugin))'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git**：这将Git与Jenkins集成([https://wiki.jenkins.io/display/JENKINS/Git+Plugin](https://clicktime.symantec.com/a/1/Zbv8hM_2L26s_PMbntThO-9W_A4uUxsqo7UyU5nbae8=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fwiki.jenkins.io%2Fdisplay%2FJENKINS%2FGit%2BPlugin))'
- en: '**Maven integration**: This provides some useful commands when building an
    application with Maven and Jenkins ([https://plugins.jenkins.io/maven-plugin](https://clicktime.symantec.com/a/1/jmIwLdZZ-wtodkRm1Goje_nuKFV98VcZYPHn5cWj1KM=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fplugins.jenkins.io%2Fmaven-plugin))'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Maven集成**：这在使用Maven和Jenkins构建应用程序时提供了一些有用的命令([https://plugins.jenkins.io/maven-plugin](https://clicktime.symantec.com/a/1/jmIwLdZZ-wtodkRm1Goje_nuKFV98VcZYPHn5cWj1KM=?d=GiSMteljxw-3ox0rf3cMazK9IOHzeSrn0vm9sus4y_n0hehkoAHvPijqT9dNXanC2Z3KtWbAm0BF-YDyp2HFvxXpFa6IkS_tvoddqdWrcb2R6vx-7YEpFHbt4IzErozigZnPecmyLha58i_mX_GOqw8nGcIkFmptcNTdFqB6DA-shedWhYxMv5VpzsTWPmDZA52S7fjMHuYvrTP5MOqqgejXYWvZr4d9OaWe0jeXJ-MEIccIx-UiD_tYy9OK2eYpd4eiaegTQb9XhbUR0ZNPGlpo4vSShb3yAI2Kf9JPcQ4hOSXoj5JpZSvnKhm1C9Yn68IsYCIBmwjYZZYyuS3y9uUI9zHbgSpVOx8ehvCmMWx0MAwCJ5gDR1ZIXXNcnw%3D%3D&u=https%3A%2F%2Fplugins.jenkins.io%2Fmaven-plugin))'
- en: 'The required plugins can be configured using the UI dashboard, either after
    startup or via Manage Jenkins *|* Manage Plugins. To run Jenkins locally, we will
    use its Docker image. The following commands create the network called `jenkins`
    and start the Jenkins master container, exposing the UI dashboard on port `38080`.
    Notice that when you start the Jenkins container and use its web console for the
    first time you need to set it up using the initial generated password. You can
    easily retrieve this password from Jenkins logs by invoking the `docker logs jenkins`
    command as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用UI仪表板配置所需的插件，无论是在启动后还是通过管理Jenkins *|*管理插件。为了在本地运行Jenkins，我们将使用其Docker镜像。以下命令创建名为`jenkins`的网络，并启动Jenkins主容器，将UI仪表板暴露在端口`38080`上。请注意，当您启动Jenkins容器并首次使用其Web控制台时，您需要使用初始生成的密码进行设置。您可以通过调用`docker
    logs jenkins`命令轻松从Jenkins日志中检索此密码：
- en: '[PRE31]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Once we have successfully configured the Jenkins master with its required plugins,
    we need to add new slaves'' nodes. To do this, you should go to the section Manage
    Jenkins *|* Manage Nodes and then select New Node. In the displayed form, you
    have to set `/home/jenkins` as a remote root directory, and the launch agent via
    Java Web Start as the launch method. Now you may start the Docker container with
    a Jenkins slave, as previously discussed. Note that you will have to override
    two environment variables indicating the slave''s name and secret. The `name`
    parameter is set during node creation, while the secret is automatically generated
    by the server. You can take a look at the node''s details page for more information,
    as shown in the following screenshot:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们成功配置了Jenkins主服务器及其所需的插件，我们需要添加新的从属节点。要做到这一点，您应该转到“管理Jenkins *|*管理节点”部分，然后选择“新节点”。在显示的表单中，您必须将`/home/jenkins`设置为远程根目录，并通过Java
    Web Start作为启动方法启动代理。现在，您可以像之前讨论的那样启动带有Jenkins从属的Docker容器。请注意，您将需要覆盖两个指示从属名称和密钥的环境变量。`name`参数在节点创建时设置，而密钥是由服务器自动生成的。您可以查看节点详细信息页面以获取更多信息，如下图所示：
- en: '![](img/a171112c-7bfe-4bd0-a491-1746adc35d68.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/a171112c-7bfe-4bd0-a491-1746adc35d68.png)'
- en: 'The following is the Docker command that starts a container with the Jenkins
    slave with Docker in Docker:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用Docker启动带有Jenkins从属的容器的Docker命令：
- en: '[PRE32]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: This short introduction to the configuration of Jenkins should help you to repeat
    the discussed continuous delivery process on your own machine. Remember that we
    have only looked at a few aspects related to Jenkins, including settings, which
    will allow you to set up a CI or CD environment for your own microservices-based
    system. If you are interested in pursuing this topic in greater depth, you should
    refer to the documentation available at [https://jenkins.io/doc](https://jenkins.io/doc).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对Jenkins配置的简要介绍应该帮助您在自己的机器上重复讨论的持续交付过程。请记住，我们只看了一些与Jenkins相关的方面，包括设置，这将允许您为自己的基于微服务的系统设置CI或CD环境。如果您有兴趣更深入地探讨这个主题，您应该参考[https://jenkins.io/doc](https://jenkins.io/doc)上提供的文档。
- en: Building pipelines
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建管道
- en: In older versions of Jenkins server, the basic unit of work was a job. Currently,
    its main feature is the ability to define pipelines as code. This change is related
    to more modern trends in IT architecture that consider application delivery as
    critical as the application that's being delivered. Since all the components of
    the application stack are already automated and represented as code in the version
    control system, the same benefits can be leveraged for CI or CD pipelines.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在较旧版本的Jenkins服务器中，工作的基本单位是作业。目前，它的主要特点是能够将管道定义为代码。这一变化与IT架构中更现代的趋势有关，这些趋势认为应用程序交付与被交付的应用程序一样重要。由于应用程序堆栈的所有组件已经在版本控制系统中自动化并表示为代码，因此可以利用相同的优势来进行CI或CD管道。
- en: 'The Jenkins Pipeline provides a set of tools designed for modeling simple and
    more advanced delivery pipelines as code. The definition of such a pipeline is
    typically written into a text file called a `Jenkinsfile`. It supports the domain-specific
    language with additional, specific steps available through the *Shared Libraries* feature. Pipeline
    supports two syntaxes: Declarative (introduced in Pipeline 2.5) and Scripted Pipeline.
    No matter which syntax is used, it will be logically divided into stages and steps.
    Steps are the most fundamental part of a pipeline as they tell Jenkins what to
    do. Stages logically group a couple of steps, which are then displayed on the
    pipeline''s result screen. The following code is an example of a scripted pipeline
    and defines a build process for `account-service`. Similar definitions have to
    be created for other microservices. All of these definitions are located in the
    `root` directory of every application''s source code as `Jenkinsfile`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Jenkins Pipeline提供了一组工具，旨在将简单和更高级的交付流水线建模为代码。这种流水线的定义通常写入一个名为`Jenkinsfile`的文本文件中。它支持通过*共享库*功能提供的附加特定步骤的领域特定语言。Pipeline支持两种语法：声明性（在Pipeline
    2.5中引入）和脚本化Pipeline。无论使用哪种语法，它都会在逻辑上分为阶段和步骤。步骤是流水线的最基本部分，因为它们告诉Jenkins要做什么。阶段在逻辑上将一些步骤分组，然后在流水线的结果屏幕上显示出来。以下代码是脚本化流水线的示例，并定义了`account-service`的构建过程。必须为其他微服务创建类似的定义。所有这些定义都位于每个应用程序源代码的`root`目录中，名为`Jenkinsfile`：
- en: '[PRE33]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The previous definition is divided into four stages. In the first, `Checkout`,
    we clone the Git repository with the source code of all the example applications.
    In the second stage, `Build` , we build an application from the `account-service`
    module and then read the whole Maven project's version number from `root`'s `pom.xml`.
    In the `Image` stage we build an image from `Dockerfile` and push it to the Docker
    repository. Finally, we run a container with the `account-service` application
    inside the `Run` stage. All the described stages are executed on `dind-node-1`
    following the definition of a node element, which is a root for all the other
    elements in the pipeline definition.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 先前的定义分为四个阶段。在第一个“Checkout”阶段中，我们克隆了包含所有示例应用程序源代码的Git存储库。在第二个阶段“Build”中，我们从`account-service`模块构建应用程序，然后从`root`的`pom.xml`中读取整个Maven项目的版本号。在“Image”阶段中，我们从`Dockerfile`构建一个镜像，并将其推送到Docker存储库。最后，在“Run”阶段中，我们在`Run`阶段内运行一个包含`account-service`应用程序的容器。所有描述的阶段都在`dind-node-1`上执行，遵循节点元素的定义，该节点元素是流水线定义中所有其他元素的根。
- en: 'Now we can proceed to defining the pipeline in Jenkins'' web console. Select
    New Item, then check the Pipeline item type and enter its name. After confirmation
    you should be redirected to the pipeline''s configuration page. The only thing
    you have to do once there is to provide the location of `Jenkinsfile` in the Git
    repository and then set the SCM authentication credentials as shown in the following
    screenshot:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以继续在Jenkins的Web控制台中定义流水线。选择“新建项”，然后检查“Pipeline”项目类型并输入其名称。确认后，您应该被重定向到流水线的配置页面。一旦到达那里，您唯一需要做的事情就是提供Git存储库中`Jenkinsfile`的位置，然后设置SCM身份验证凭据，如下截图所示：
- en: '![](img/de3445e9-d691-4ca5-8344-ac9a2cd9cc06.png)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![](img/de3445e9-d691-4ca5-8344-ac9a2cd9cc06.png)'
- en: 'After saving the changes, the configuration of the pipeline is ready. In order
    to start the build, click the Build Now button. There are two things that should
    be clarified at this stage. In the production mode you can use the `webhook` mechanism,
    which is provided by the most popular Git host vendors, including GitHub, BitBucket,
    and GitLab. This mechanism automatically triggers your build on Jenkins after
    pushing the changes to the repository. In order to demonstrate this, we would
    have to run the version control system locally with Docker, for example using
    GitLab. There is also another simplified way of testing. The containerized application
    is run directly on Jenkins'' Docker in Docker slave; under normal circumstances,
    we would launch on the separated remote machine dedicated only to the deployment
    of applications. The following screenshot is Jenkins'' web console illustrating
    the build process, divided into different stages, for `product-service`:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 保存更改后，流水线的配置已准备就绪。要开始构建，请单击“立即构建”按钮。在这个阶段有两件事情需要澄清。在生产模式下，您可以使用`webhook`机制，这是由最流行的Git主机供应商（包括GitHub、BitBucket和GitLab）提供的。这种机制在将更改推送到存储库后会自动触发Jenkins上的构建。为了演示这一点，我们需要在本地使用Docker运行版本控制系统，例如使用GitLab。还有另一种简化的测试方法。容器化应用程序直接在Jenkins的Docker中运行，正常情况下，我们会在专门用于部署应用程序的独立远程机器上启动。以下截图是Jenkins的Web控制台，展示了`product-service`的构建过程，分为不同的阶段：
- en: '![](img/389420f0-9f82-4ff8-94f3-50dc772ae4c8.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/389420f0-9f82-4ff8-94f3-50dc772ae4c8.png)'
- en: 'We should now create one pipeline per microservice. The list of all the created
    pipelines is as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们应该为每个微服务创建一个流水线。创建的所有流水线列表如下：
- en: '![](img/6f01811b-9091-425b-90cf-e19bdbffef91.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6f01811b-9091-425b-90cf-e19bdbffef91.png)'
- en: Working with Kubernetes
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes进行工作
- en: We have already launched our example microservices on Docker containers. We
    have even used CI and CD automated pipelines in order to run them on the local
    machine. You may, however, be asking an important question. How can we organize
    our environment on a larger scale and in production mode where we have to run
    multiple containers across multiple machines? Well, this is exactly what we have
    to do when implementing microservices in accordance with the idea of cloud native
    development. It turns out that many challenges still remain in this instance.
    Assuming that we have many microservices launched in multiple instances, there
    will be plenty of containers to manage. Doing things such as starting the correct
    containers at the correct time, handling storage considerations, scaling up or
    down, and dealing with failures manually would be a nightmare. Fortunately, there
    are some platforms available that help in clustering and orchestrating Docker
    containers at scale. Currently, the leader in this field is Kubernetes.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在Docker容器上启动了示例微服务。我们甚至使用了CI和CD自动化流水线来在本地机器上运行它们。然而，您可能会问一个重要的问题。在更大规模和生产模式下，我们如何组织我们的环境，需要在多台机器上运行多个容器？当按照云原生开发理念实施微服务时，这正是我们需要做的。事实证明，在这种情况下仍然存在许多挑战。假设我们在多个实例中启动了许多微服务，将有大量容器需要管理。手动执行诸如在正确的时间启动正确的容器、处理存储考虑、扩展或缩减规模以及处理故障等操作将是一场噩梦。幸运的是，有一些平台可用于帮助在规模上对Docker容器进行集群和编排。目前，这个领域的领导者是Kubernetes。
- en: Kubernetes is an open-source platform for managing containerized workloads and
    services. It can act as a container platform, as a microservices platform, as
    a cloud platform, and a lot more. It automates such actions as running containers
    across different machines, scaling up and down, distributing load between containers,
    and keeping storage consistency between multiple instances of an application.
    It also has a number of additional features, including service discovery, load
    balancing, configuration management, service naming, and rolling updates. Not
    all of these features would be useful for us however as many similar features
    are provided by Spring Cloud.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个用于管理容器化工作负载和服务的开源平台。它可以作为容器平台、微服务平台、云平台等。它自动化了在不同机器上运行容器、扩展和缩减规模、在容器之间分配负载以及在应用程序的多个实例之间保持存储一致性等操作。它还具有许多其他功能，包括服务发现、负载平衡、配置管理、服务命名和滚动更新。然而，并非所有这些功能对我们都有用，因为Spring
    Cloud提供了许多类似的功能。
- en: It is worth mentioning that Kubernetes is not the only container management
    tool out there. There is also Docker Swarm, the native tool provided within Docker.
    However, since Docker has announced native support for Kubernetes, it seems to
    be a natural choice. There are several important concepts and components regarding
    Kubernetes that we should know before we move on to any practical examples.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Kubernetes并不是唯一的容器管理工具。还有Docker Swarm，这是Docker内置的本地工具。然而，由于Docker宣布原生支持Kubernetes，它似乎是一个自然的选择。在我们继续进行任何实际示例之前，我们应该了解一些关于Kubernetes的重要概念和组件。
- en: Concepts and components
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概念和组件
- en: The first term you will probably have to deal with when using Kubernetes is
    pod, which is a basic building block in Kubernetes. A pod represents a running
    process in the cluster. It can consist of one or more containers that are guaranteed
    to be co-located on the host machine and will share the same resources. One container
    per pod is the most common Kubernetes use case. Each pod has a unique IP address
    within the cluster but all containers deployed inside the same pod can communicate
    with others via `localhost`.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用Kubernetes时，您可能首先要处理的术语是pod，它是Kubernetes中的基本构建块。一个pod代表集群中正在运行的进程。它可以由一个或多个容器组成，这些容器保证在主机上共同存在并共享相同的资源。每个pod中一个容器是最常见的Kubernetes用例。每个pod在集群中都有一个唯一的IP地址，但所有部署在同一个pod中的容器可以通过`localhost`相互通信。
- en: Another common component is a service. A service logically groups a set of pods
    and defines a policy of access to it; it is sometimes called a microservice. By
    default, a service is exposed inside a cluster but it can also be exposed onto
    an external  IP address. We can expose a service using one of the four available
    behaviors: `ClusterIP`, `NodePort`, `LoadBalancer` , and `ExternalName`. The default option
    is `ClusterIP`. This exposes the service on a cluster-internal IP, which makes
    it reachable only from within the cluster. `NodePort` exposes the service on each
    Node's IP at a static port, and automatically create `ClusterIP` for exposing
    service inside a cluster. In turn, `LoadBalancer` exposes the service externally
    using a cloud provider’s load balancer, and `ExternalName` maps the service to
    the contents of the `externalName` field. We should also take a few moments to
    discuss Kubernetes's replication controller. This handles replication and scaling
    by running a specified number of copies of a pod across the cluster. It is also
    responsible for replacing pods if the underlying node fails. Every controller
    in Kubernetes is a separate process run by `kube-controller-manager`. You can
    also find node controller, endpoints controller, and service account and token
    controllers in Kubernetes.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的组件是服务。服务在逻辑上将一组pod分组，并定义了对其的访问策略；有时也称为微服务。默认情况下，服务在集群内部公开，但也可以公开到外部IP地址。我们可以使用四种可用的行为之一来公开服务：`ClusterIP`、`NodePort`、`LoadBalancer`和`ExternalName`。默认选项是`ClusterIP`。这将在集群内部IP上公开服务，使其只能从集群内部访问。`NodePort`将服务公开到每个节点的IP地址上的静态端口，并自动创建`ClusterIP`以在集群内部公开服务。`LoadBalancer`使用云提供商的负载均衡器将服务外部公开，`ExternalName`将服务映射到`externalName`字段的内容。我们还应该花一些时间讨论Kubernetes的复制控制器。它通过在集群中运行指定数量的pod的副本来处理复制和扩展。它还负责在基础节点失败时替换pod。Kubernetes中的每个控制器都是由`kube-controller-manager`运行的单独进程。您还可以在Kubernetes中找到节点控制器、端点控制器和服务帐户和令牌控制器。
- en: Kubernetes uses an `etcd` key/value store as a backing store for all cluster
    data. Inside every node of the cluster is an agent called **kubelet**, which is
    responsible for ensuring that containers are running in a pod. Every command sent
    to Kubernetes by a user is processed by Kubernetes API exposed by `kubeapi-server`.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用`etcd`键/值存储作为所有集群数据的后备存储。在集群的每个节点内部都有一个名为**kubelet**的代理，负责确保容器在pod中运行。用户发送给Kubernetes的每个命令都是通过`kubeapi-server`公开的Kubernetes
    API处理的。
- en: Of course, this is a really simplified explanation of Kubernetes's architecture.
    There are more components and tools available that have to be configured properly
    in order to run highly available Kubernetes clusters successfully. This is not
    a trivial task to perform, and it requires a significant amount of knowledge about
    this platform. Fortunately, there is a tool out there that makes it easy to run
    a Kubernetes cluster locally—Minikube.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这只是对Kubernetes架构的一个非常简化的解释。还有更多的组件和工具可供配置，以便成功运行高可用的Kubernetes集群。这并不是一个简单的任务，它需要对这个平台有相当多的了解。幸运的是，有一个工具可以让您轻松地在本地运行Kubernetes集群——Minikube。
- en: Running Kubernetes locally via Minikube
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过Minikube在本地运行Kubernetes
- en: Minikube is a tool that makes it easy to run Kubernetes locally. It runs a single-node
    Kubernetes cluster inside a VM on the local machine. It is definitely the most
    suitable choice in development mode. Of course, Minikube does not support all
    of the features provided by Kubernetes; only the most important ones, including
    DNS, NodePorts, Config Map, Dashboard, and Ingress.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube是一个工具，可以让您轻松地在本地运行Kubernetes。它在本地机器上的VM内运行一个单节点Kubernetes集群。这绝对是开发模式下最合适的选择。当然，Minikube并不支持Kubernetes提供的所有功能；只支持最重要的功能，包括DNS、NodePorts、Config
    Map、Dashboard和Ingress。
- en: 'To run Minikube on Windows, we need to have a virtualization tool installed.
    However, if you have already run Docker, you will have probably installed Oracle
    VM VirtualBox. In this case, you don''t have to do anything other than download
    and install the latest release of Minikube, which you can check at [https://github.com/kubernetes/minikube/releases](https://clicktime.symantec.com/a/1/eXr_fIrvCIRYzEHt0YvbtkptTqcVd9nJzBV28fxoaTY=?d=7tChM-hIl54SsiVoHKrovXbmLIi8ouu38bfWFa5LjYebKneJvW_c2_HMgDdoq431rSiEnNRRoWc7WI40qLP-zxO_svn7BtB5YkP7_3z6XE1bc9UDw_gg4B_LUQLmxfklfTjgbs0J-dnBHLc3GOsVYjvBMyOE-nmJR1SuKthIzdMfxP8oasaAGIamKBmwy-pKxDOZYKGzKE4iEAO1nFo15LHQ7enPYrMhvcEhb3LDIMsYYwnwVTe52q36t77MaAeAFdq7DgkU1BLlVMydfq9vglCYhLnhnOOzSDesZnjGR3spuBjVhNyCD3pcc73yC-ARPXPUpScKDxqUYA8pZg40QrbDOyzuC95KNm-9vIqcPXR6iDgu8QK_SscvFxnDi4A%3D&u=https%3A%2F%2Fgithub.com%2Fkubernetes%2Fminikube%2Freleases) ,
    and `kubectl.exe` , as described at [https://storage.googleapis.com/kubernetes-release/release/stable.txt](https://storage.googleapis.com/kubernetes-release/release/stable.txt).
    Both files `minikube.exe` and `kubectl.exe` should be included in the `PATH` environment
    variable. In addition, Minikube provides its own installer, `minikube-installer.exe` ,
    which will automatically add `minikube.exe` to your path. You may then start Minikube
    from your command line by running the following command:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Windows上运行Minikube，我们需要安装一个虚拟化工具。但是，如果您已经运行了Docker，那么您可能已经安装了Oracle VM VirtualBox。在这种情况下，您无需做任何其他操作，只需下载并安装最新版本的Minikube即可，您可以在[https://github.com/kubernetes/minikube/releases](https://clicktime.symantec.com/a/1/eXr_fIrvCIRYzEHt0YvbtkptTqcVd9nJzBV28fxoaTY=?d=7tChM-hIl54SsiVoHKrovXbmLIi8ouu38bfWFa5LjYebKneJvW_c2_HMgDdoq431rSiEnNRRoWc7WI40qLP-zxO_svn7BtB5YkP7_3z6XE1bc9UDw_gg4B_LUQLmxfklfTjgbs0J-dnBHLc3GOsVYjvBMyOE-nmJR1SuKthIzdMfxP8oasaAGIamKBmwy-pKxDOZYKGzKE4iEAO1nFo15LHQ7enPYrMhvcEhb3LDIMsYYwnwVTe52q36t77MaAeAFdq7DgkU1BLlVMydfq9vglCYhLnhnOOzSDesZnjGR3spuBjVhNyCD3pcc73yC-ARPXPUpScKDxqUYA8pZg40QrbDOyzuC95KNm-9vIqcPXR6iDgu8QK_SscvFxnDi4A%3D&u=https%3A%2F%2Fgithub.com%2Fkubernetes%2Fminikube%2Freleases]和[https://storage.googleapis.com/kubernetes-release/release/stable.txt](https://storage.googleapis.com/kubernetes-release/release/stable.txt)中查看，以及`kubectl.exe`，如[https://storage.googleapis.com/kubernetes-release/release/stable.txt](https://storage.googleapis.com/kubernetes-release/release/stable.txt)中所述。`minikube.exe`和`kubectl.exe`这两个文件都应该包含在`PATH`环境变量中。此外，Minikube还提供了自己的安装程序`minikube-installer.exe`，它将自动将`minikube.exe`添加到您的路径中。然后，您可以通过运行以下命令从命令行启动Minikube：
- en: '[PRE34]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The preceding command initializes a `kubectl` context called `minikube`. It
    contains the configuration that allows you to communicate with the Minikube cluster.
    You can now use `kubectl` commands in order to maintain your local cluster created
    by Minikube and deploy your containers there. An alternative solution to a command-line
    interface is Kubernetes dashboard. Kubernetes dashboard can be enabled for your
    node by calling `minikube` dashboard. You can create, update, or delete deployment
    using this dashboard, as well as list and view a configuration of all pods, services,
    ingresses, and replication controllers. It is possible to easily stop and remove
    a local cluster by invoking the following commands:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令初始化了一个名为`minikube`的`kubectl`上下文。它包含了允许您与Minikube集群通信的配置。现在，您可以使用`kubectl`命令来维护由Minikube创建的本地集群，并在其中部署您的容器。命令行界面的另一种替代方案是Kubernetes仪表板。可以通过调用`minikube
    dashboard`为您的节点启用Kubernetes仪表板。您可以使用此仪表板创建、更新或删除部署，以及列出和查看所有pod、服务、入口和复制控制器的配置。通过调用以下命令，可以轻松停止和删除本地集群：
- en: '[PRE35]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Deploying an application
  id: totrans-171
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署应用程序
- en: 'Every configuration existing on a Kubernetes cluster is represented by Kubernetes
    objects. These objects can be managed through the Kubernetes API and should be
    expressed in a YAML format. You may use that API directly, but will probably decide
    to leverage the `kubectl` command-line interface to make all the necessary calls
    for you. The description of a newly created object in Kubernetes has to provide
    specification that describes its desired state, as well as some basic information
    about the object. The following are some required fields in the YAML configuration
    file that should always be set:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群上存在的每个配置都由Kubernetes对象表示。这些对象可以通过Kubernetes API进行管理，并且应该以YAML格式表示。您可以直接使用该API，但可能会决定利用`kubectl`命令行界面为您进行所有必要的调用。在Kubernetes中新创建的对象的描述必须提供描述其期望状态的规范，以及有关对象的一些基本信息。以下是YAML配置文件中应始终设置的一些必需字段：
- en: '`apiVersion`: This indicates the version of the Kubernetes API used to create
    an object. An API always requires the JSON format in a request but `kubectl` automatically
    converts YAML input into JSON.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apiVersion`：这表示用于创建对象的Kubernetes API的版本。API始终需要JSON格式的请求，但`kubectl`会自动将YAML输入转换为JSON。'
- en: '`kind`: This sets the kind of object to create. There are some predefined types
    available such as Deployment, Service, Ingress, or ConfigMap.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kind`：这设置要创建的对象的类型。有一些预定义的类型可用，例如Deployment、Service、Ingress或ConfigMap。'
- en: '`metadata`: This allows you to identify the object by name, UID or, optional
    namespace.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：这允许您通过名称、UID或可选命名空间来标识对象。'
- en: '`spec`: This is the proper definition of an object. The precise format of a
    specification depends on an object''s kind and contains nested fields specific
    to that object.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec`：这是对象的正确定义。规范的精确格式取决于对象的类型，并包含特定于该对象的嵌套字段。'
- en: 'Usually, when creating new objects on Kubernetes, its `kind` is deployment.
    In the `Deployment` YAML file, shown as follows, there are two important fields
    set. The first of, `replicas`, specifies the number of desired pods. In practice,
    this means that we run two instances of the containerized application. The second,
    `spec.template.spec.containers.image`, sets the name and version of the Docker
    image that will be launched inside a pod. The container will be exposed on port
    `8090`, on which `order-service` listens for HTTP connections:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，在Kubernetes上创建新对象时，其`kind`是deployment。在以下显示的`Deployment` YAML文件中，设置了两个重要字段。首先，`replicas`指定了所需pod的数量。实际上，这意味着我们运行两个容器化应用的实例。其次，`spec.template.spec.containers.image`设置了将在pod内启动的Docker镜像的名称和版本。容器将在端口`8090`上公开，`order-service`在此端口上监听HTTP连接：
- en: '[PRE36]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Assuming the preceding code is stored in the file `order-deployment.yaml`,
    we can now deploy our containerized application on Kubernetes using imperative
    management as follows:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 假设前面的代码存储在文件`order-deployment.yaml`中，我们现在可以使用命令式管理在Kubernetes上部署我们的容器化应用，如下所示：
- en: '[PRE37]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Alternatively, you can perform the same action based on the declarative management
    approach, illustrated as follows:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以基于声明性管理方法执行相同的操作，如下所示：
- en: '[PRE38]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We now have to create the same deployment file for all the microservices and
    `discovery-service`. The subject of `discovery-service` is a very curious matter.
    We have the option to use built-in Kubernetes discovery based on pods and services,
    but our main goal here is to deploy and run Spring Cloud components on that platform.
    So, before deploying any microservices, we should first deploy, run, and expose
    Eureka on Kubernetes. The following is a deployment file of `discovery-service`
    that can also can be applied to Kubernetes by calling the `kubectl apply` command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们必须为所有微服务和`discovery-service`创建相同的部署文件。`discovery-service`的主题是一个非常有趣的问题。我们可以选择使用基于pod和服务的内置Kubernetes发现，但我们在这里的主要目标是在该平台上部署和运行Spring
    Cloud组件。因此，在部署任何微服务之前，我们应该首先在Kubernetes上部署、运行和公开Eureka。以下是`discovery-service`的部署文件，也可以通过调用`kubectl
    apply`命令应用于Kubernetes：
- en: '[PRE39]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'If you create a Deployment, Kubernetes automatically creates pods for you.
    Their number is equal to the value set in the `replicas` field. A pod is not able
    to expose the API provided by the application deployed on the container, it just
    represents a running process on your cluster. To access the API provided by the
    microservices running inside pods, we have to define a service. Let''s remind
    ourselves what a service is. A service is an abstraction that defines a logical
    set of pods and a policy by which to access them. The set of pods targeted by
    a service is usually determined by a label selector. There are four types of service
    available in Kubernetes. The simplest and default one is `ClusterIP`, which exposes
    a service internally. If you would like to access a service from outside the cluster,
    you should define the type `NodePort`.  This option has been set out in the following
    example YAML file; now, all the microservices can communicate with Eureka using
    its Kubernetes service name:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您创建一个Deployment，Kubernetes会自动为您创建pod。它们的数量等于`replicas`字段中设置的值。一个pod无法公开容器上部署的应用程序提供的API，它只是代表集群中正在运行的进程。要访问在pod内运行的微服务提供的API，我们必须定义一个服务。让我们想一想服务是什么。服务是一个定义了一组逻辑pod和访问它们的策略的抽象。服务的目标pod集通常由标签选择器确定。Kubernetes中有四种类型的服务。最简单和默认的是`ClusterIP`，它在内部公开服务。如果您想从集群外部访问服务，您应该定义类型`NodePort`。这个选项已在以下示例YAML文件中设置；现在，所有微服务都可以使用其Kubernetes服务名称与Eureka进行通信：
- en: '[PRE40]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: In fact, all of our microservices deployed on Minikube should be available outside
    the cluster, as we would like to access the API exposed by them. To do this, you
    need to provide the similar YAML configuration to that in the preceding example,
    changing only the service's name, labels and port.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们部署在Minikube上的所有微服务都应该在集群外可用，因为我们希望访问它们所公开的API。为此，您需要提供类似于前面示例中的YAML配置，只需更改服务的名称、标签和端口。
- en: 'There is only one last component that should be present in our architecture:
    API Gateway. We could deploy a container with the Zuul proxy, however we need
    to introduce the popular Kubernetes object, Ingress. This component is responsible for
    managing external access to services that are typically exposed via HTTP. Ingress
    provides load balancing, SSL termination, and name-based virtual hosting. The
    Ingress configuration YAML file is shown as follows; note that all the services
    can be accessed on the same port, `80`, on different URL paths:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们架构中应该存在的最后一个组件只有一个：API网关。我们可以部署一个带有Zuul代理的容器，但是我们需要引入流行的Kubernetes对象Ingress。这个组件负责管理通常通过HTTP公开的服务的外部访问。Ingress提供负载平衡、SSL终止和基于名称的虚拟主机。Ingress配置YAML文件如下所示；请注意，所有服务都可以在不同的URL路径上的相同端口`80`上访问：
- en: '[PRE41]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Maintaining a cluster
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 维护集群
- en: 'Maintaining a Kubernetes cluster is rather complex. In this section, we will
    show you how to use some basic commands and the UI dashboard in order to view
    the object currently existing on the cluster. Let''s first list the elements that
    have been created for the purpose of running our example microservices-based system.
    First, we display a list of deployments by running the command `kubectl get deployments`,
    which should result in the following:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 维护Kubernetes集群相当复杂。在本节中，我们将向您展示如何使用一些基本命令和UI仪表板来查看集群上当前存在的对象。让我们首先列出为运行我们的示例基于微服务的系统而创建的元素。首先，通过运行命令`kubectl
    get deployments`来显示部署列表，应该会得到以下结果：
- en: '![](img/2e7394a7-2440-45a6-abdb-b4bb42eec586.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e7394a7-2440-45a6-abdb-b4bb42eec586.png)'
- en: 'One deployment can create a number of pods. You can check the list of pods
    by calling the `kubectl get pods` command as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一个部署可以创建多个pod。您可以通过调用`kubectl get pods`命令来检查pod列表，如下所示：
- en: '![](img/3603bc5a-2cef-41ac-a82e-3b2a96cfbeeb.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3603bc5a-2cef-41ac-a82e-3b2a96cfbeeb.png)'
- en: 'The same list can be viewed using the UI dashboard. You can view these details
    by clicking on the selected row, or check out the container logs by clicking the
    icon available on the right-hand side of each row, as shown in the following screenshot:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用UI仪表板查看相同的列表。您可以通过单击所选行来查看这些详细信息，或者通过单击每行右侧的图标来查看容器日志，如下面的屏幕截图所示：
- en: '![](img/82fecacc-7077-472a-b216-14d941e30e55.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/82fecacc-7077-472a-b216-14d941e30e55.png)'
- en: 'The full list of available services can be displayed using the command `kubectl
    get services`. There are some interesting fields here, including one that indicates
    an IP address on which a service is available inside a cluster (CLUSTER-IP), and
    a pair of ports (PORT(S)) on which services are exposed internally and externally.
    We can also call the HTTP API exposed on `account-service` at the address `http://192.168.99.100:31099`,
    or the Eureka UI dashboard at the address`http://192.168.99.100:31931`, as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用命令`kubectl get services`显示所有可用服务的完整列表。这里有一些有趣的字段，包括一个指示集群内服务可用的IP地址（CLUSTER-IP），以及一对内部和外部暴露的端口（PORT(S)）。我们还可以调用`account-service`上暴露的HTTP
    API，地址为`http://192.168.99.100:31099`，或者Eureka UI仪表板，地址为`http://192.168.99.100:31931`，如下所示：
- en: '![](img/0307a557-39dc-4f7d-98af-f49d8c3c73a7.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0307a557-39dc-4f7d-98af-f49d8c3c73a7.png)'
- en: 'Similar to previous objects, services can also be displayed using the Kubernetes
    dashboard, as shown in the following screenshot:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的对象类似，服务也可以使用Kubernetes仪表板显示，如下屏幕截图所示：
- en: '![](img/6d5eb014-3315-437a-861c-69c44ff7a67b.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d5eb014-3315-437a-861c-69c44ff7a67b.png)'
- en: Summary
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed a lot of topics not obviously related to Spring
    Cloud, but the tools explained in this chapter will allow you to take advantage
    of migrating to microservices-based architecture. When using Docker, Kubernetes,
    or tools for CI or CD, there is an obvious advantage to cloud-native development
    with Spring Cloud. Of course, all of the presented examples have been launched
    on the local machine, but you can refer to these to imagine how that process could
    be designed in a production environment across a cluster of remote machines.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了许多与Spring Cloud显然不相关的主题，但是本章中解释的工具将使您能够利用迁移到基于微服务的架构。使用Docker、Kubernetes或CI/CD工具时，与Spring
    Cloud一起进行云原生开发显然具有明显的优势。当然，所有呈现的示例都是在本地机器上启动的，但您可以参考这些示例来想象如何在远程机器集群的生产环境中设计该过程。
- en: In this chapter, we wanted to show you how simple and quick it can be to move
    from running Spring microservices manually on the local machine to a fully-automated
    process that builds the application from source code, creates and runs a Docker
    image with your application, and deploys it on a cluster consisting of multiple
    machines. It is not easy to describe all of the features provided by such complex
    tools as Docker, Kubernetes, or Jenkins in a single chapter. Instead, the main
    purpose here was to give you a look at the bigger picture of how to design and
    maintain a modern architecture based on concepts such as containerization, automated
    deploying, scaling, and a private, on-premise cloud.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们想向您展示从在本地机器上手动运行Spring微服务到从源代码构建应用程序，创建和运行Docker镜像，并将其部署在由多台机器组成的集群的完全自动化过程可以是多么简单快速。在单独的一章中很难描述Docker、Kubernetes或Jenkins等复杂工具提供的所有功能。相反，这里的主要目的是让您了解如何设计和维护基于容器化、自动部署、扩展和私有本地云等概念的现代架构的整体情况。
- en: We're now getting very close to the end of the book. We have already discussed
    most of the planned topics related to the Spring Cloud framework. In the next
    chapter, we will show you how to use two of the most popular cloud platforms available
    on the web, allowing you to continuously deliver Spring Cloud applications.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经接近本书的结尾。我们已经讨论了与Spring Cloud框架相关的大部分计划主题。在下一章中，我们将向您展示如何在网络上使用两个最受欢迎的云平台，让您能够持续交付Spring
    Cloud应用程序。
