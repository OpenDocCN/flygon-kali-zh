- en: Chapter 6. Optimizing Divide and Conquer Solutions – The Fork/Join Framework
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。优化分而治之解决方案-Fork/Join框架
- en: 'In [Chapter 2](part0022_split_000.html#KVCC1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 2. Managing Lots of Threads – Executors"), *Managing Lots of Threads
    – Executors*, [Chapter 3](part0028_split_000.html#QMFO1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 3. Getting the Maximum from Executors"), *Getting the Maximum from Executors*,
    and [Chapter 4](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 4. Getting Data from the Tasks – The Callable and Future Interfaces"),
    *Getting Data from the Tasks – The Callable and Future Interfaces*, you learned
    how to work with executors as a mechanism to improve the performance of concurrent
    applications that executes lots of concurrent tasks. The Java 7 concurrency API
    introduces a special kind of executor through the Fork/Join framework. This framework
    is designed to implement optimal concurrent solutions to those problems that can
    be solved using the divide and conquer design paradigm. In this chapter, we will
    cover the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](part0022_split_000.html#KVCC1-2fff3d3b99304faa8fa9b27f1b5053ba "第2章。管理大量线程-执行者")中，*管理大量线程-执行者*，[第3章](part0028_split_000.html#QMFO1-2fff3d3b99304faa8fa9b27f1b5053ba
    "第3章。从执行者中获得最大效益")，*从执行者中获得最大效益*，和[第4章](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba
    "第4章。从任务中获取数据-Callable和Future接口")，*从任务中获取数据-Callable和Future接口*，您学会了如何使用执行者作为一种机制来提高并发应用程序的性能，执行大量并发任务。Java
    7并发API引入了一种特殊类型的执行者，通过Fork/Join框架。该框架旨在实现使用分而治之设计范例解决问题的最佳并发解决方案。在本章中，我们将涵盖以下主题：
- en: An introduction to the Fork/Join framework
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fork/Join框架简介
- en: The first example – the k-means clustering algorithm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个示例- k均值聚类算法
- en: The second example – a data filtering algorithm
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二个示例-数据过滤算法
- en: The third example – the merge sort algorithm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三个示例-归并排序算法
- en: An introduction to the Fork/Join framework
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fork/Join框架简介
- en: 'The executor framework, introduced in Java 5, provides a mechanism to execute
    concurrent tasks without creating, starting, and finishing threads. This framework
    uses a pool of threads that executes the tasks you send to the executor reusing
    them for multiple tasks. This mechanism provides some advantages to programmers
    and these are as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在Java 5中引入的执行者框架提供了一种执行并发任务的机制，而无需创建、启动和完成线程。该框架使用一个线程池来执行您发送给执行者的任务，并重用它们执行多个任务。这种机制为程序员提供了一些优势，如下所示：
- en: It's easier to program concurrent applications because you don't have to worry
    to create threads.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写并发应用程序更容易，因为您不必担心创建线程。
- en: It's easier to control the resources used by the executor and your application.
    You can create an executor that only uses a predefined number of threads. If you
    send more tasks, the executor stores them in a queue until a thread is available.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更容易控制执行者和应用程序使用的资源。您可以创建一个只使用预定义数量线程的执行者。如果发送更多任务，执行者会将它们存储在队列中，直到有线程可用。
- en: Executors reduce the overhead introduced by thread creation reusing the threads.
    Internally, it manages a pool of threads that reuses threads to execute multiple
    tasks.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行者通过重用线程减少了线程创建引入的开销。在内部，它管理一个线程池，重用线程执行多个任务。
- en: The divide and conquer algorithm is a very popular design technique. To solve
    a problem using this technique, you divide it into smaller problems. You repeat
    the process in a recursive way until the problems you have to solve are small
    enough to be solved directly. These kinds of problems can be solved using the
    executor, but to solve them in a more efficient way, the Java 7 concurrency API
    introduced the Fork/Join framework.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分而治之算法是一种非常流行的设计技术。使用这种技术解决问题，您将其分解为更小的问题。您以递归方式重复这个过程，直到您要解决的问题足够小，可以直接解决。这种类型的问题可以使用执行者解决，但为了以更有效的方式解决它们，Java
    7并发API引入了Fork/Join框架。
- en: 'This framework is based on the `ForkJoinPool` class, which is a special kind
    of executor, two operations, the `fork()` and `join()` methods (and their different
    variants), and an internal algorithm named the **work-stealing algorithm**. In
    this chapter, you will learn the basic characteristics, limitations, and components
    of the Fork/Join framework implementing the following three examples:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架基于`ForkJoinPool`类，这是一种特殊类型的执行者，两个操作，`fork()`和`join()`方法（及其不同的变体），以及一个名为**工作窃取算法**的内部算法。在本章中，您将学习Fork/Join框架的基本特征、限制和组件，实现以下三个示例：
- en: The k-means clustering algorithm applied to the clustering of a set of documents
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用于一组文档聚类的k均值聚类算法
- en: A data filter algorithm to get the data that meets certain criteria
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个数据过滤算法，以获取符合某些条件的数据
- en: The merge sort algorithm to sort big groups of data in an efficient way
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 归并排序算法以高效的方式对大量数据进行排序
- en: Basic characteristics of the Fork/Join framework
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fork/Join框架的基本特征
- en: 'As we mentioned before, the Fork/Join framework must be used to implement solutions
    to problems based on the divide and conquer technique. You have to divide the
    original problem into smaller problems until they are small enough to be solved
    directly. With this framework, you will implement tasks whose main method will
    be something like this:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，Fork/Join框架必须用于实现基于分而治之技术的问题的解决方案。您必须将原始问题分解为更小的问题，直到它们足够小，可以直接解决。使用该框架，您将实现主要方法类似于以下内容的任务：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The most important part is the one that allows you to divide and execute the
    child tasks in an efficient way and to get the results of those child tasks to
    calculate the results of the parent tasks. This functionality is supported by
    two methods provided by the `ForkJoinTask` class as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最重要的部分是允许您以高效的方式分割和执行子任务，并获取这些子任务的结果以计算父任务的结果。这个功能由`ForkJoinTask`类提供的两个方法支持，如下所示：
- en: 'The `fork()` method: This method allows you to send a child task to the Fork/Join
    executor'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fork()`方法：此方法允许您向Fork/Join执行者发送子任务'
- en: 'The `join()` method: This method allows you to wait for the finalization of
    a child task and returns its result'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: join()方法：此方法允许您等待子任务的完成并返回其结果
- en: 'These methods have different variants, as you will see in the examples. The
    Fork/Join framework has another critical part: the work-stealing algorithm, which
    determines which tasks to be executed. When a task is waiting for the finalization
    of a child task using the `join()` method, the thread that is executing that task
    takes another task from the pool of tasks that are waiting and starts its execution.
    In this way, the threads of the Fork/Join executor are always executing a task
    by improving the performance of the application.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法有不同的变体，正如您将在示例中看到的那样。Fork/Join框架还有另一个关键部分：工作窃取算法，它确定要执行哪些任务。当一个任务正在等待使用join()方法等待子任务的完成时，执行该任务的线程会从等待的任务池中取出另一个任务并开始执行。这样，Fork/Join执行器的线程总是通过执行任务来提高应用程序的性能。
- en: Java 8 includes a new feature in the Fork/Join framework. Now every Java application
    has a default `ForkJoinPool` named common pool. You can obtain it by calling the
    `ForkJoinPool.commonPool()` static method. You don't need to create one explicitly
    (although you can). This default Fork/Join executor will use by default the number
    of threads determined by the available processors of your computer. You can change
    this default behavior changing the value of the system property `java.util.concurrent.ForkJoinPool.common.parallelism`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Java 8在Fork/Join框架中包含了一个新特性。现在每个Java应用程序都有一个名为common pool的默认ForkJoinPool。您可以通过调用ForkJoinPool.commonPool()静态方法来获取它。您不需要显式创建一个（尽管您可以）。这个默认的Fork/Join执行器将默认使用计算机可用处理器确定的线程数。您可以通过更改系统属性java.util.concurrent.ForkJoinPool.common.parallelism的值来更改此默认行为。
- en: Some features of the Java API use the Fork/Join framework to implement concurrent
    operations. For example, the `parallelSort()` method of the `Arrays` class to
    sort an array in a parallel way and the parallel streams introduced in Java 8
    (which will be described later in [Chapter 7](part0047_split_000.html#1CQAE2-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 7. Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Reduce
    Model* and [Chapter 8](part0051_split_000.html#1GKCM1-2fff3d3b99304faa8fa9b27f1b5053ba
    "Chapter 8. Processing Massive Datasets with Parallel Streams – The Map and Collect
    Model"), *Processing Massive Datasets with Parallel Streams – The Map and Collect
    Model*) use this framework.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Java API的一些特性使用Fork/Join框架来实现并发操作。例如，Arrays类的parallelSort()方法以并行方式对数组进行排序，以及Java
    8中引入的并行流（稍后将在第7章和第8章中描述）使用了这个框架。
- en: Limitations of the Fork/Join framework
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fork/Join框架的限制
- en: 'As the Fork/Join framework has been thought to solve a determined kind of problems,
    it has some limitations you have to take into account when you use it to implement
    your problem, which are as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Fork/Join框架被设计用来解决一种确定类型的问题，因此在使用它来实现您的问题时，您必须考虑一些限制，如下所示：
- en: The basic problems that you're not going to subdivide have to be not very large,
    but not very small. According to the Java API documentation, it should have between
    100 and 10,000 basic computational steps.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不打算细分的基本问题不应该太大，但也不应该太小。根据Java API文档，它应该在100到10,000个基本计算步骤之间。
- en: You should not use blocking I/O operations like reading user input or data from
    a network socket waiting until the data is available. Such operations will cause
    your CPU cores to become idle, reducing the parallelism level, so you will not
    achieve the full performance.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不应该使用阻塞I/O操作，比如读取用户输入或等待网络套接字中的数据可用。这样的操作会导致CPU核心空闲，降低并行级别，因此您将无法实现完全的性能。
- en: You can't throw checked exceptions inside a task. You have to include the code
    to handle them (for example, wrapping into unchecked `RuntimeException`). Unchecked
    exceptions have a special treatment, as you will see in the examples.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您不能在任务中抛出已检查的异常。您必须包含处理它们的代码（例如，包装成未检查的RuntimeException）。未检查的异常有特殊处理，正如您将在示例中看到的那样。
- en: Components of the Fork/Join framework
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fork/Join框架的组件
- en: 'There are five basic classes in the Fork/Join framework:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: Fork/Join框架中有五个基本类：
- en: 'The `ForkJoinPool` class: This class implements the `Executor` and `ExecutorService`
    interfaces, and it is the `Executor` interface you''re going to use to execute
    your Fork/Join tasks. Java provides you with a default `ForkJoinPool` object (named
    common pool), but you have some constructors to create one if you want. You can
    specify the parallelism level (the maximum number of running parallel threads).
    By default, it uses the number of available processors as the concurrency level.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ForkJoinPool类：该类实现了Executor和ExecutorService接口，它是您要使用来执行Fork/Join任务的Executor接口。Java为您提供了一个默认的ForkJoinPool对象（名为common
    pool），但如果您愿意，您可以使用一些构造函数来创建一个。您可以指定并行级别（最大运行并行线程数）。默认情况下，它使用可用处理器的数量作为并发级别。
- en: 'The `ForkJoinTask` class: This is the base abstract class of all of the Fork/Join
    tasks. It''s an abstract class, and it provides the `fork()` and `join()` methods
    and some variants of them. It also implements the `Future` interface and provides
    methods to determine if the task finished in a normal way, if it was cancelled
    or if it throws an unchecked exception. The `RecursiveTask`, `RecursiveAction`,
    and `CountedCompleter` classes provide `compute()` abstract methods, which should
    be implemented in subclasses to perform actual computations.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ForkJoinTask`类：这是所有Fork/Join任务的基本抽象类。它是一个抽象类，提供了`fork()`和`join()`方法以及它们的一些变体。它还实现了`Future`接口，并提供了方法来确定任务是否以正常方式完成，是否被取消，或者是否抛出未检查的异常。`RecursiveTask`、`RecursiveAction`和`CountedCompleter`类提供了`compute()`抽象方法，应该在子类中实现以执行实际的计算。'
- en: 'The `RecursiveTask` class: This class extends the `ForkJoinTask` class. It''s
    also an abstract class, and it should be your start point to implement Fork/Join
    tasks that returns a result.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecursiveTask`类：这个类扩展了`ForkJoinTask`类。它也是一个抽象类，应该是实现返回结果的Fork/Join任务的起点。'
- en: 'The `RecursiveAction` class: This class extends the `ForkJoinTask` class. It''s
    also an abstract class, and it should be your start point to implement Fork/Join
    tasks that don''t return a result.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecursiveAction`类：这个类扩展了`ForkJoinTask`类。它也是一个抽象类，应该是实现不返回结果的Fork/Join任务的起点。'
- en: 'The `CountedCompleter` class: This class extends the `ForkJoinTask` class.
    It''s a new feature of the Java 8 API, and it should be your start point to implement
    tasks that trigger other tasks when they''re completed.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CountedCompleter`类：这个类扩展了`ForkJoinTask`类。这是Java 8 API的一个新特性，应该是实现任务在完成时触发其他任务的起点。'
- en: The first example – the k-means clustering algorithm
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第一个例子 - k均值聚类算法
- en: The **k-means clustering** algorithm is a clustering algorithm to group a set
    of items not previously classified into a predefined number of k clusters. It's
    very popular within the data mining and machine learning world to organize and
    classify data in an unsupervised way.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**k均值聚类**算法是一种聚类算法，用于将一组未经分类的项目分组到预定义数量的k个集群中。在数据挖掘和机器学习领域非常受欢迎，以无监督的方式组织和分类数据。'
- en: Each item is normally defined by a vector of characteristics or attributes.
    All the items have the same number of attributes. Each cluster is also defined
    by a vector with the same number of attributes that represents all the items classified
    into that cluster. This vector is named the centroid. For example, if the items
    are defined by numeric vectors, the clusters are defined by the mean of the items
    classified into that cluster.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 每个项目通常由一组特征或属性的向量来定义。所有项目具有相同数量的属性。每个集群也由具有相同数量属性的向量来定义，表示所有分类到该集群的项目。这个向量被称为质心。例如，如果项目由数值向量定义，那么集群由分类到该集群的项目的平均值来定义。
- en: 'Basically, the algorithm has four steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这个算法有四个步骤：
- en: '**Initialization**: In the first step, you have to create the initial vectors
    that represent the K clusters. Normally, you will initialize those vectors randomly.'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**初始化**：在第一步中，你需要创建代表K个集群的初始向量。通常，你会随机初始化这些向量。'
- en: '**Assignment**: Then, you classify each item into a cluster. To select the
    cluster, you calculate the distance between the item and every cluster. You will
    use a distance measure as the **Euclidean distance** to calculate the distance
    between the vector that represents the item and the vector to represents the cluster.
    You will assign the item to the cluster with the shortest distance.'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**分配**：然后，你将每个项目分类到一个集群中。为了选择集群，你需要计算项目与每个集群之间的距离。你将使用**欧几里得距离**作为距离度量来计算代表项目的向量与代表集群的向量之间的距离。你将把项目分配给距离最短的集群。'
- en: '**Update**: Once all the items have been classified, you have to recalculate
    the vectors that define each cluster. As we mentioned earlier, you normally calculate
    the mean of all the vectors of the items classified into the cluster.'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**更新**：一旦所有项目被分类，你需要重新计算定义每个集群的向量。正如我们之前提到的，通常计算分类到集群的所有向量的平均值。'
- en: '**End**: Finally, you check whether some item has changed its assignment cluster.
    If there has been any change, you go to the assignment step again. Otherwise,
    the algorithm ends, and you have your items classified.'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**结束**：最后，你要检查是否有任何项目改变了分配的集群。如果有任何改变，你需要再次进行分配步骤。否则，算法结束，你的项目被分类了。'
- en: 'This algorithm has the following two main limitations:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法有以下两个主要限制：
- en: If you make a random initialization of the initial vectors of the clusters,
    as we suggested earlier, two executions to classify the same item set may give
    you different results.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你对集群的初始向量进行随机初始化，就像我们之前建议的那样，对同一组项目进行两次执行可能会得到不同的结果。
- en: The numbers of cluster are previously predefined. A bad choice of this attribute
    will give you poor results from a classification point of view.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群的数量是预先定义的。选择这个属性不好会导致分类结果不佳。
- en: Despite of this, this algorithm is very popular to cluster different kinds of
    items. To test our algorithm, you are going to implement an application to cluster
    a set of documents. As a document collection, we have taken a reduced version
    of the Wikipedia pages with information about movies corpus we introduced in [Chapter
    4](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba "Chapter 4. Getting
    Data from the Tasks – The Callable and Future Interfaces"), *Getting Data from
    the Tasks – The Callable and Future Interfaces*. We only took 1,000 documents.
    To represent each document, we have to use the vector space model representation.
    With this representation, each document is represented as a numeric vector where
    each dimension of the vector represents a word or a term and its value is a metric
    that defines the importance of that word or term in the document.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，该算法非常受欢迎，可用于对不同类型的项目进行聚类。为了测试我们的算法，您将实现一个应用程序来对一组文档进行聚类。作为文档集合，我们使用了我们在[第4章](part0033_split_000.html#VF2I1-2fff3d3b99304faa8fa9b27f1b5053ba
    "第4章。从任务获取数据 - Callable和Future接口")中介绍的有关电影语料库的维基百科页面的缩减版本，*从任务获取数据 - Callable和Future接口*。我们只取了1,000个文档。为了表示每个文档，我们必须使用向量空间模型表示。通过这种表示，每个文档都表示为一个数值向量，其中向量的每个维度表示一个单词或术语，其值是定义该单词或术语在文档中重要性的度量。
- en: When you represent a document collection using the vector space model, the vectors
    will have as many dimensions as the number of different words of the whole collection,
    so the vectors will have a lot of zero values because each document doesn't have
    all the words. You can use a more optimized representation in memory to avoid
    all those zero values and save memory increasing the performance of your application.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用向量空间模型表示文档集合时，向量的维度将与整个集合中不同单词的数量一样多，因此向量将具有许多零值，因为每个文档并不包含所有单词。您可以使用更优化的内存表示来避免所有这些零值，并节省内存，从而提高应用程序的性能。
- en: In our case, we have chosen **term frequency–inverse document frequency** (**tf-idf**)
    as the metric that defines the importance of each word and the 50 words with higher
    tf-idf as the terms that represents each document.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们选择**词项频率-逆文档频率**（**tf-idf**）作为定义每个词的重要性的度量标准，并选择具有更高tf-idf的50个词作为代表每个文档的词语。
- en: 'We use two files: the `movies.words` file stores a list of all the words used
    in the vectors, and the `movies.data` stores the representation of each document.
    The `movies.data` file has the following format:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用两个文件：`movies.words`文件存储了向量中使用的所有单词的列表，而`movies.data`存储了每个文档的表示。`movies.data`文件的格式如下：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `10000202` is the identifier of the document, and the rest of the file
    follows the formant `word:tfxidf`.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`10000202`是文档的标识符，文件的其余部分遵循`word:tfxidf`的格式。
- en: As with other examples, we are going to implement the serial and concurrent
    versions and execute both versions to verify that the Fork/Join framework gives
    us an improvement of the performance of this algorithm.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他示例一样，我们将实现串行和并发版本，并执行两个版本以验证Fork/Join框架是否提高了该算法的性能。
- en: The common classes
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常见的类
- en: 'There are some parts that are shared between the serial and concurrent versions.
    These parts include:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 串行和并发版本之间有一些共享的部分。这些部分包括：
- en: '`VocabularyLoader`: This is a class to load the list of words that forms the
    vocabulary of our corpus.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`VocabularyLoader`：这是一个加载构成我们语料库词汇表的单词列表的类。'
- en: '`Word`, `Document`, and `DocumentLoader`: These three classes to load the information
    about the documents. These classes have a little difference between the serial
    and concurrent versions of the algorithm.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Word`，`Document`和`DocumentLoader`：这三个类用于加载有关文档的信息。这些类在串行和并发版本的算法之间有一些差异。'
- en: '`DistanceMeasure`: This is a class to calculate the **Euclidean** distance
    between two vectors.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DistanceMeasure`：这是一个计算两个向量之间的**欧几里得**距离的类。'
- en: '`DocumentCluster`: This is a class to store the information about the clusters.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DocumentCluster`：这是一个存储有关聚类信息的类。'
- en: Let's see these classes in detail.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看这些类。
- en: The VocabularyLoader class
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VocabularyLoader类
- en: As we mentioned before, our data is stored in two files. One of those files
    is the `movies.words` file. This file stores a list with all the words used in
    the documents. The `VocabularyLoader` class will transform that file into `HashMap`.
    The key of `HashMap` is the whole word, and the value is an integer value with
    the index of that word in the list. We use that index to determine the position
    of the word in the vector space model that represents each document.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们的数据存储在两个文件中。其中一个文件是`movies.words`文件。该文件存储了文档中使用的所有单词的列表。`VocabularyLoader`类将该文件转换为`HashMap`。`HashMap`的键是整个单词，值是该单词在列表中的索引的整数值。我们使用该索引来确定表示每个文档的向量空间模型中单词的位置。
- en: 'The class has only one method, named `load()`, that receives the path of the
    file as a parameter and returns the `HashMap`:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 该类只有一个名为`load()`的方法，该方法接收文件路径作为参数并返回`HashMap`：
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The Word, Document, and DocumentLoader classes
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Word，Document和DocumentLoader类
- en: These classes store all the information about the documents we will use in our
    algorithm. First, the `Word` class stores information about a word in a document.
    It includes the index of the word and the tf-idf of that word in the document.
    This class only includes those attributes (`int` and `double`, respectively),
    and implements the `Comparable` interface to sort two words using their tf-idf
    value, so we don't include the source code of this class.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类存储了我们算法中将使用的所有文档信息。首先，`Word`类存储了文档中单词的信息。它包括单词的索引和文档中该单词的tf-idf。该类仅包括这些属性（分别为`int`和`double`），并实现了`Comparable`接口，以使用它们的tf-idf值对两个单词进行排序，因此我们不包括此类的源代码。
- en: 'The `Document` class stores all the relevant information about the document.
    First, an array of `Word` objects with the words in the document. This is our
    representation of the vector space model. We only store the words used in the
    document to save a lot of memory space. Then, a `String` with the name of the
    file that stores the document and finally a `DocumentCluster` object to know the
    cluster associated with the document. It also includes a constructor to initialize
    those attributes and methods to get and set their value. We only include the code
    of the `setCluster()` method. In this case, this method will return a Boolean
    value to indicate if the new value of this attribute is the same as the old value
    or a new one. We will use that value to determine if we stop the algorithm or
    not:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`Document`类存储有关文档的所有相关信息。首先是一个包含文档中单词的`Word`对象数组。这是我们的向量空间模型的表示。我们只存储文档中使用的单词，以节省大量内存空间。然后是一个包含存储文档的文件名的`String`，最后是一个`DocumentCluster`对象，用于知道与文档关联的聚类。它还包括一个用于初始化这些属性的构造函数和用于获取和设置它们的值的方法。我们只包括`setCluster()`方法的代码。在这种情况下，此方法将返回一个布尔值，以指示此属性的新值是否与旧值相同或新值。我们将使用该值来确定是否停止算法：'
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Finally, the `DocumentLoader` class loads the information about the document.
    It includes a static method, `load()` that receives the path of the file, and
    the `HashMap` with the vocabulary and returns an `Array` of `Document` objects.
    It loads the file line by line and converts each line to a `Document` object.
    We have the following code:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`DocumentLoader`类加载有关文档的信息。它包括一个静态方法`load()`，该方法接收文件的路径和包含词汇表的`HashMap`，并返回`Document`对象的`Array`。它逐行加载文件并将每行转换为`Document`对象。我们有以下代码：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To convert a line of the text file to a `Document` object, we use the `processItem()`
    method:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 要将文本文件的一行转换为`Document`对象，我们使用`processItem()`方法：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As we mentioned earlier, the first item in the line is the identifier of the
    document. We obtain it from `tokens[0]`, and we pass it to the `Document` class
    constructor. Then, for the rest of the tokens, we split them again to obtain the
    information of every word that includes the whole word and the tf-idf value.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，行中的第一项是文档的标识符。我们从`tokens[0]`获取它，并将其传递给`Document`类的构造函数。然后，对于其余的标记，我们再次拆分它们以获取每个单词的信息，包括整个单词和tf-idf值。
- en: The DistanceMeasurer class
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`DistanceMeasurer`类'
- en: 'This class calculates the Euclidean distance between a document and a cluster
    (represented as a vector). The words in our word arrays after sorting are placed
    in the same order as in centroid array, but some words might be absent. For such
    words, we assume that tf-idf is zero, so the distance is just the square of the
    corresponding value from the centroid array:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 该类计算文档与聚类（表示为向量）之间的欧氏距离。在对我们的单词数组进行排序后，单词按照与质心数组相同的顺序排列，但有些单词可能不存在。对于这样的单词，我们假设tf-idf为零，因此距离就是来自质心数组的相应值的平方：
- en: '[PRE6]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The DocumentCluster class
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文档聚类类
- en: 'This class stores the information about each cluster generated by the algorithm.
    This information includes a list of all the documents associated with this cluster
    and the centroid of the vector that is the vector that represents the cluster.
    In this case, this vector has as many dimensions as words are in the vocabulary.
    The class has the two attributes, a constructor to initialize them, and methods
    to get and set their value. It also includes two very important methods. First,
    the `calculateCentroid()` method. It calculates the centroid of the cluster as
    the mean of the vectors that represents the documents associated with this cluster.
    We have the following code:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该类存储算法生成的每个聚类的信息。此信息包括与该聚类关联的所有文档的列表以及表示该聚类的向量的质心。在这种情况下，该向量的维度与词汇表中的单词数量相同。该类具有两个属性，一个用于初始化它们的构造函数，以及用于获取和设置它们的值的方法。它还包括两个非常重要的方法。首先是`calculateCentroid()`方法。它计算聚类的质心，作为表示与该聚类关联的文档的向量的平均值。我们有以下代码：
- en: '[PRE7]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The second method is the `initialize()` method that receives a `Random` object
    and initializes the centroid vector of the cluster with random numbers as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种方法是`initialize()`方法，它接收一个`Random`对象，并使用随机数初始化聚类的质心向量如下：
- en: '[PRE8]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The serial version
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 串行版本
- en: 'Once we have described the common parts of the application, let''s see how
    to implement the serial version of the k-means clustering algorithm. We are going
    to use two classes: `SerialKMeans`, which implements the algorithm, and `SerialMain`,
    which implements the `main()` method to execute the algorithm.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们描述了应用程序的共同部分，让我们看看如何实现k-means聚类算法的串行版本。我们将使用两个类：`SerialKMeans`，它实现了该算法，以及`SerialMain`，它实现了执行该算法的`main()`方法。
- en: The SerialKMeans class
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`SerialKMeans`类'
- en: 'The `SerialKMeans` class implements the serial version of the k-means clustering
    algorithm. The main method of the class is the `calculate()` method. It receives
    the following as parameters:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`SerialKMeans`类实现了k-means聚类算法的串行版本。该类的主要方法是`calculate()`方法。它接收以下参数：'
- en: The array of `Document` objects with the information about the documents
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含有关文档的`Document`对象的数组
- en: The number of clusters you want to generate
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您想要生成的聚类数
- en: The size of the vocabulary
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词汇表的大小
- en: A seed for the random number generator
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机数生成器的种子
- en: 'The method returns an `Array` of `DocumentCluster` object. Each cluster will
    have the list of documents associated with it. First, the document creates the
    `Array` of clusters determined by the `numberClusters` parameter and initializes
    them using the `initialize()` method and a `Random` object as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法返回`DocumentCluster`对象的`Array`。每个聚类将有与之关联的文档列表。首先，文档通过`numberClusters`参数确定`Array`的聚类，并使用`initialize()`方法和`Random`对象对它们进行初始化，如下所示：
- en: '[PRE9]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Then, we repeat the assignment and update phases until all the documents stay
    in the same cluster. Finally, we return the array of clusters with the final organization
    of the documents as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们重复分配和更新阶段，直到所有文档都留在同一个集群中。最后，我们返回具有文档最终组织的集群数组如下：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The assignment phase is implemented in the `assignment()` method. This method
    receives the array of `Document` and `DocumentCluster` objects. For each document,
    it calculates the Euclidean distance between the document and all the clusters
    and assigns the document to the cluster with the lowest distance. It returns a
    Boolean value to indicate if one or more of the documents has changed their assigned
    cluster from one step to the next one. We have the following code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 分配阶段在`assignment()`方法中实现。该方法接收`Document`和`DocumentCluster`对象数组。对于每个文档，它计算文档与所有集群之间的欧几里德距离，并将文档分配给距离最近的集群。它返回一个布尔值，指示一个或多个文档是否从一步到下一步更改了其分配的集群。我们有以下代码：
- en: '[PRE11]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The update step is implemented in the `update()` method. It receives the array
    of `DocumentCluster` with the information of the clusters, and it simply recalculates
    the centroid of each cluster:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 更新步骤在`update()`方法中实现。它接收具有集群信息的`DocumentCluster`数组，并简单地重新计算每个集群的质心。
- en: '[PRE12]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The SerialMain class     The `SerialMain` class includes the `main()` method to launch the tests of the
    k-means algorithm. First, it loads the data (words and documents) from the files:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`SerialMain`类包括`main()`方法来启动k-means算法的测试。首先，它从文件中加载数据（单词和文档）：'
- en: '[PRE13]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Then, it initializes the number of clusters we want to generate and the seed
    for the random number generator. If they don''t come as parameters of the `main()`
    method, we use a default value as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它初始化我们要生成的集群数量和随机数生成器的种子。如果它们不作为`main()`方法的参数传入，我们将使用默认值如下：
- en: '[PRE14]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Finally, we launch the algorithm measuring its execution time and write the
    number of documents per cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们启动算法，测量其执行时间，并写入每个集群的文档数量。
- en: '[PRE15]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The concurrent version
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发版本
- en: To implement the concurrent version of the algorithm, we have used the Fork/Join
    framework. We have implemented two different tasks based on the `RecursiveAction`
    class. As we mentioned earlier, the `RecursiveAction` task is used when you want
    to use the Fork/Join framework with tasks that do not return a result. We have
    implemented the assignment and the update phases as tasks to be executed in a
    Fork/Join framework.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现算法的并发版本，我们使用了Fork/Join框架。我们基于`RecursiveAction`类实现了两个不同的任务。正如我们之前提到的，当您希望使用Fork/Join框架处理不返回结果的任务时，我们实现了分配和更新阶段作为要在Fork/Join框架中执行的任务。
- en: To implement the concurrent version of the k-means algorithm, we are going to
    modify some of the common classes to use concurrent data structures. Then, we
    are going to implement the two tasks, and finally, we are going to implement the
    `ConcurrentKMeans` that implements the concurrent version of the algorithm and
    the `ConcurrentMain` class to test it.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现k-means算法的并发版本，我们将修改一些常见类以使用并发数据结构。然后，我们将实现两个任务，最后，我们将实现实现算法的并发版本的`ConcurrentKMeans`和用于测试的`ConcurrentMain`类。
- en: Two tasks for the Fork/Join framework – AssignmentTask and UpdateTask
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Fork/Join框架的两个任务 - AssignmentTask和UpdateTask
- en: As we mentioned earlier, we have implemented the assignment and update phases
    as tasks to be implemented in the Fork/Join framework.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们已经将分配和更新阶段实现为Fork/Join框架中要实现的任务。
- en: The assignment phase assigns a document to the cluster that has the lowest Euclidean
    distance with the document. So, we have to process all the documents and calculate
    the Euclidean distances of all the documents and all the clusters. We are going
    to use the number of documents a task has to process as the measure to control
    whether we have to split the task or not. We start with the tasks that have to
    process all the documents and we are going to split them until we have tasks that
    have to process a number of documents lower than a predefined size.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 分配阶段将文档分配给与文档具有最小欧几里德距离的集群。因此，我们必须处理所有文档并计算所有文档和所有集群的欧几里德距离。我们将使用任务需要处理的文档数量作为控制是否需要拆分任务的度量标准。我们从需要处理所有文档的任务开始，直到我们将它们拆分为需要处理小于预定义大小的文档数量的任务。
- en: 'The `AssignmentTask` class has the following attributes:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`AssignmentTask`类具有以下属性：'
- en: The array of `ConcurrentDocumentCluster` objects with the data of the clusters
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有集群数据的`ConcurrentDocumentCluster`对象数组
- en: The array of `ConcurrentDocument` objects with the data of the documents
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有文档数据的`ConcurrentDocument`对象数组
- en: Two integer attributes, `start` and `end`, that determines the number of documents
    the task has to process
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有两个整数属性`start`和`end`，确定任务需要处理的文档数量
- en: An `AtomicInteger` attribute, `numChanges`, that stores the number of documents
    that have changed its assigned cluster from the last execution to the current
    one
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`AtomicInteger`属性`numChanges`，存储从上次执行到当前执行更改其分配的集群的文档数量
- en: An integer attribute, `maxSize`, that stores the maximum number of documents
    a task can process
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个整数属性`maxSize`，存储任务可以处理的最大文档数量
- en: We have implemented a constructor to initialize all these attributes and methods
    to get and set its values.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了一个构造函数来初始化所有这些属性和方法来获取和设置它的值。
- en: 'The main method of these tasks is (as with every task) the `compute()` method.
    First, we check the number of documents the tasks have to process. If it''s less
    or equal than the `maxSize` attribute, we process those documents. We calculate
    the Euclidean distance between each document and all the clusters and select the
    cluster with the lowest distance. If it''s necessary, we increment the `numChanges`
    atomic variable using the `incrementAndGet()` method. The atomic variable can
    be updated by more than one thread at the same time without using synchronization
    mechanisms and without causing any memory inconsistencies. Refer to the following
    code:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务的主要方法（与每个任务一样）是`compute()`方法。首先，我们检查任务需要处理的文档数量。如果小于或等于`maxSize`属性，则处理这些文档。我们计算每个文档与所有聚类之间的欧氏距离，并选择距离最小的聚类。如果有必要，我们使用`incrementAndGet()`方法增加`numChanges`原子变量。原子变量可以在不使用同步机制的情况下由多个线程同时更新，而不会导致任何内存不一致。参考以下代码：
- en: '[PRE16]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If the number of documents the task has to process is too big, we split that
    set into two parts and create two new tasks to process each of those parts as
    follows:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务需要处理的文档数量太大，我们将该集合分成两部分，并创建两个新任务来处理每一部分，如下所示：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: To execute those tasks in the Fork/Join pool, we have used the `invokeAll()`
    method. This method will return when the tasks have finished their execution.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Fork/Join池中执行这些任务，我们使用了`invokeAll()`方法。该方法将在任务完成执行时返回。
- en: The update phase recalculates the centroid of each cluster as the mean of all
    the documents. So, we have to process all the clusters. We are going to use the
    number of clusters a task has to process as the measure to control if we have
    to split the task or not. We start with a task that has to process all the clusters,
    and we are going to split it until we have tasks that have to process a number
    of clusters lower than a predefined size.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 更新阶段重新计算每个聚类的质心作为所有文档的平均值。因此，我们必须处理所有聚类。我们将使用任务需要处理的聚类数量作为控制任务是否需要分割的度量。我们从需要处理所有聚类的任务开始，并将其分割，直到我们有需要处理的聚类数量低于预定义大小的任务。
- en: 'The `UpdateTask` class has the following attributes:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`UpdateTask`类具有以下属性：'
- en: The array of `ConcurrentDocumentCluster` objects with the data of the clusters
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含聚类数据的`ConcurrentDocumentCluster`对象数组
- en: Two integer attributes, `start` and `end`, that determine the number of clusters
    the task has to process
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定任务需要处理的聚类数量的整数属性`start`和`end`
- en: An integer attribute, `maxSize`, that stores the maximum number of clusters
    a task can process
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个整数属性`maxSize`，用于存储任务可以处理的最大聚类数
- en: We have implemented a constructor to initialize all these attributes and methods
    to get and set its values.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了一个构造函数来初始化所有这些属性和方法来获取和设置其值。
- en: 'The `compute()` method first checks the number of clusters the task has to
    process. If that number is less than or equal to the `maxSize` attribute, it processes
    those clusters and updates their centroid:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`compute()`方法首先检查任务需要处理的聚类数量。如果该数量小于或等于`maxSize`属性，则处理这些聚类并更新它们的质心。'
- en: '[PRE18]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If the number of clusters the task has to process is too big, we are going
    to divide the set of clusters the task has to process in two and create two tasks
    to process each of that part as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任务需要处理的聚类数量太大，我们将把任务需要处理的聚类集合分成两部分，并创建两个任务来处理每一部分，如下所示：
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The ConcurrentKMeans class
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并发K均值类
- en: 'The `ConcurrentKMeans` class implements the concurrent version of the k-means
    clustering algorithm. As the serial version, the main method of the class is the
    `calculate()` method. It receives the following as parameters:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentKMeans`类实现了并发版本的k均值聚类算法。与串行版本一样，该类的主要方法是`calculate()`方法。它接收以下参数：'
- en: The array of `ConcurrentDocument` objects with the information about the documents
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含有关文档信息的`ConcurrentDocument`对象数组
- en: The number of clusters you want to generate
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您想要生成的聚类数量
- en: The size of the vocabulary
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 词汇量的大小
- en: A seed for the random number generator
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机数生成器的种子
- en: The maximum number of items a Fork/Join tasks will process without splitting
    the task into other tasks
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fork/Join任务在不分割任务的情况下处理的最大项目数
- en: 'The `calculate()` method returns an array of the `ConcurrentDocumentCluster`
    objects with the information of the clusters. Each cluster has the list of documents
    associated with it. First, the document creates the array of clusters determined
    by the `numberClusters` parameter and initializes them using the `initialize()`
    method and a `Random` object:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`calculate()`方法返回一个包含聚类信息的`ConcurrentDocumentCluster`对象数组。每个聚类都有与之关联的文档列表。首先，文档根据`numberClusters`参数创建聚类数组，并使用`initialize()`方法和`Random`对象进行初始化：'
- en: '[PRE20]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we repeat the assignment and update phases until all the documents stay
    in the same cluster. Before the loop, we create `ForkJoinPool` that is going to
    execute that task and all of its subtasks. Once the loop has finished, as with
    other `Executor` objects, we have to use the `shutdown()` method with a Fork/Join
    pool to finish its executions. Finally, we return the array of clusters with the
    final organization of the documents:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们重复分配和更新阶段，直到所有文档都留在同一个聚类中。在循环之前，我们创建一个将执行该任务及其所有子任务的`ForkJoinPool`。一旦循环结束，与其他`Executor`对象一样，我们必须使用`shutdown()`方法来结束Fork/Join池的执行。最后，我们返回具有文档最终组织的聚类数组：
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The assignment phase is implemented in the `assignment()` method. This method
    receives the array of clusters, the array of documents, and the `maxSize` attribute.
    First, we delete the list of associated documents to all the clusters:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 分配阶段在`assignment()`方法中实现。该方法接收聚类数组、文档数组和`maxSize`属性。首先，我们删除所有聚类的关联文档列表：
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Then, we initialize the necessary objects: an `AtomicInteger` to store the
    number of documents whose assigned cluster has changed and the `AssignmentTask`
    that will begin the process.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们初始化必要的对象：一个`AtomicInteger`来存储已更改其分配簇的文档数量，以及将开始该过程的`AssignmentTask`。
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, we execute the tasks in the pool in an asynchronous way using the `execute()`
    method of `ForkJoinPool` and wait for its finalization with the `join()` method
    of the `AssignmentTask` object as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`ForkJoinPool`的`execute()`方法以异步方式执行池中的任务，并使用`AssignmentTask`对象的`join()`方法等待其完成，如下所示：
- en: '[PRE24]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Finally, we check the number of documents that has changed its assigned cluster.
    If there have been changes, we return the `true` value. Otherwise, we return the
    `false` value. We have the following code:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查已更改其分配的簇的文档数量。如果有更改，我们返回`true`值。否则，我们返回`false`值。我们有以下代码：
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The update phase is implemented in the `update()` method. It receives the array
    of clusters and the `maxSize` parameters. First, we create an `UpdateTask` object
    to update all the clusters. Then, we execute that task in the `ForkJoinPool` object
    the method receives as parameter as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 更新阶段在`update()`方法中实现。它接收簇数组和`maxSize`参数。首先，我们创建一个`UpdateTask`对象来更新所有簇。然后，我们在`ForkJoinPool`对象中执行该任务，方法接收如下参数：
- en: '[PRE26]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The ConcurrentMain class
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`ConcurrentMain`类'
- en: The `ConcurrentMain` class includes the `main()` method to launch the tests
    of the k-means algorithm. Its code is equal to the `SerialMain` class, but changing
    the serial classes for the concurrent ones.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentMain`类包括`main()`方法，用于启动k-means算法的测试。其代码与`SerialMain`类相同，但将串行类更改为并发类。'
- en: Comparing the solutions
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较解决方案
- en: 'To compare the two solutions, we have executed different experiments changing
    the values of three different parameters:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了比较这两种解决方案，我们执行了不同的实验，改变了三个不同参数的值。
- en: The k-parameter will establish the number of clusters we want to generate. We
    have tested the algorithms with the values 5, 10, 15, and 20.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k参数将确定我们要生成的簇的数量。我们已使用值5、10、15和20测试了算法。
- en: The seed for the `Random` number generator. This seed determines how the initial
    centroid positions. We have tested the algorithms with the values 1 and 13.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Random`数生成器的种子。此种子确定初始质心位置。我们已使用值1和13测试了算法。'
- en: For the concurrent algorithm, the `maxSize` parameter that determines the maximum
    number of items (documents or clusters), a task can process without being split
    into other tasks. We have tested the algorithms with the values 1, 20, and 400.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于并发算法，`maxSize`参数确定任务在不被拆分为其他任务的情况下可以处理的最大项目（文档或簇）数量。我们已使用值1、20和400测试了算法。
- en: 'We have executed the experiments using the JMH framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using methods such as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the execution times we have obtained in milliseconds:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用JMH框架（[http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)）执行了实验，该框架允许在Java中实现微基准测试。使用基准测试框架比简单使用`currentTimeMillis()`或`nanoTime()`等方法测量时间更好。我们在具有四核处理器的计算机上执行了10次，并计算了这10次的平均执行时间。以下是我们以毫秒为单位获得的执行时间：
- en: '|   |   | Serial | Concurrent |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '|   |   | 串行 | 并发 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **K** | **Seed** |   | **MaxSize=1** | **MaxSize=20** | **maxSize=400** |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| **K** | **Seed** |   | **MaxSize=1** | **MaxSize=20** | **maxSize=400** |'
- en: '| 5 | 1 | 6676.141 | 4696.414 | 3291.397 | 3179.673 |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 1 | 6676.141 | 4696.414 | 3291.397 | 3179.673 |'
- en: '| 10 | 1 | 6780.088 | 3365.731 | 2970.056 | 2825.488 |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 1 | 6780.088 | 3365.731 | 2970.056 | 2825.488 |'
- en: '| 15 | 1 | 12936.178 | 5308.734 | 4737.329 | 4490.443 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 1 | 12936.178 | 5308.734 | 4737.329 | 4490.443 |'
- en: '| 20 | 1 | 19824.729 | 7937.820 | 7347.445 | 6848.873 |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 1 | 19824.729 | 7937.820 | 7347.445 | 6848.873 |'
- en: '| 5 | 13 | 3738.869 | 2714.325 | 1984.152 | 1916.053 |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 13 | 3738.869 | 2714.325 | 1984.152 | 1916.053 |'
- en: '| 10 | 13 | 9567.416 | 4693.164 | 3892.526 | 3739.129 |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 13 | 9567.416 | 4693.164 | 3892.526 | 3739.129 |'
- en: '| 15 | 13 | 12427.589 | 5598.996 | 4735.518 | 4468.721 |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| 15 | 13 | 12427.589 | 5598.996 | 4735.518 | 4468.721 |'
- en: '| 20 | 13 | 18157.913 | 7285.565 | 6671.283 | 6325.664 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 20 | 13 | 18157.913 | 7285.565 | 6671.283 | 6325.664 |'
- en: 'We can draw the following conclusions:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出以下结论：
- en: The seed has an important and unpredictable impact in the execution time. Sometimes,
    the execution times are lower with seed 13, but other times are lower with seed
    1.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 种子对执行时间有重要且不可预测的影响。有时，种子13的执行时间较低，但其他时候种子1的执行时间较低。
- en: When you increment the number of clusters, the execution time increments too.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当增加簇的数量时，执行时间也会增加。
- en: The `maxSize` parameter doesn't have much influence in the execution time. The
    parameter K or seed has a higher influence in the execution time. If you increase
    the value of the parameter, you will obtain better performance. The difference
    is bigger between 1 and 20 than between 20 and 400.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxSize`参数对执行时间影响不大。参数K或seed对执行时间影响更大。如果增加参数值，将获得更好的性能。1和20之间的差异比20和400之间的差异更大。'
- en: In all the cases, the concurrent version of the algorithm has better performance
    than the serial one.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在所有情况下，并发版本的算法性能均优于串行版本。
- en: 'For example, if we compare the serial algorithm with parameters K=20 and seed=13
    with the concurrent version with parameters K=20, seed=13, and maxSize=400 using
    the speed-up, we obtain the following result:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们将参数K=20和seed=13的串行算法与参数K=20、seed=13和maxSize=400的并发版本进行比较，使用加速比，我们将获得以下结果：
- en: '![Comparing the solutions](img/00017.jpeg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![比较解决方案](img/00017.jpeg)'
- en: The second example – a data filtering algorithm
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二个例子 - 数据过滤算法
- en: Suppose that you have a lot of data that describes a list of items. For example,
    you have a lot of attributes (name, surname, address, phone number, and so on)
    of a lot of people. It's a common need to obtain the data that meets certain criteria,
    for example, you want to obtain people who live in a determined street or with
    a determined name.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 假设您有大量描述物品列表的数据。例如，您有很多人的属性（姓名、姓氏、地址、电话号码等）。通常需要获取满足某些条件的数据，例如，您想获取住在特定街道或具有特定姓名的人的数据。
- en: In this section, you will implement one of those filtering programs. We have
    used the **Census-Income KDD** dataset from the UCI (you can download it from
    [https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29)),
    that contains weighted census data extracted from the 1994 and 1995 current population
    surveys conducted by the U.S. Census Bureau.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，您将实现其中一个过滤程序。我们使用了UCI的**Census-Income KDD**数据集（您可以从[https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29](https://archive.ics.uci.edu/ml/datasets/Census-Income+%28KDD%29)下载），其中包含了从美国人口普查局1994年和1995年进行的加权人口普查数据。
- en: In the concurrent version of this example, you will learn how to cancel tasks
    that are running in the Fork/Join pool and how to manage unchecked exceptions
    that can be thrown in a task.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例的并发版本中，您将学习如何取消在Fork/Join池中运行的任务，以及如何处理任务中可能抛出的未经检查的异常。
- en: Common parts
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共同部分
- en: 'We have implemented some classes to read the data from a file and to filter
    the data. These classes are used by the serial and concurrent versions of the
    algorithm. These are the classes:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了一些类来从文件中读取数据和过滤数据。这些类被算法的串行和并发版本使用。这些类包括：
- en: 'The `CensusData` class: This class stores 39 attributes that define every person.
    It defines the attributes and methods to get and set their value. We are going
    to identify each attribute by a number. The `evaluateFilter()` method of this
    class contains the association between the number and the name of the attribute.
    You can check the file [https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.names](https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.names)
    to get the details of every attribute.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CensusData`类：这个类存储了定义每个人的39个属性。它定义了获取和设置它们值的属性和方法。我们将通过数字来标识每个属性。这个类的`evaluateFilter()`方法包含了数字和属性名称之间的关联。您可以查看文件[https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.names](https://archive.ics.uci.edu/ml/machine-learning-databases/census-income-mld/census-income.names)来获取每个属性的详细信息。'
- en: 'The `CensusDataLoader` class: This class loads the census data from a file.
    It has the `load()` method that receives the path to the file as an input parameter
    and returns an array of `CensusData` with the information of all the persons of
    the file.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CensusDataLoader`类：这个类从文件中加载人口普查数据。它有一个`load()`方法，接收文件路径作为输入参数，并返回一个包含文件中所有人的信息的`CensusData`数组。'
- en: 'The `FilterData` class: This class defines a filter of data. A filter includes
    the number of an attribute and the value of that attribute.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FilterData`类：这个类定义了数据的过滤器。过滤器包括属性的编号和属性的值。'
- en: 'The `Filter` class: This class implements the methods to determine if a `CensusData`
    object meets the conditions of a list of filters.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Filter`类：这个类实现了确定`CensusData`对象是否满足一系列过滤条件的方法。'
- en: We don't include the source code of these classes. They are very simple, and
    you can check the source code of the example.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不包括这些类的源代码。它们非常简单，您可以查看示例的源代码。
- en: The serial version
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 串行版本
- en: 'We have implemented the serial version of the filter algorithm in two classes.
    The `SerialSearch` class makes the filtering of data. It provides two methods:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在两个类中实现了过滤算法的串行版本。`SerialSearch`类进行数据过滤。它提供了两种方法：
- en: 'The `findAny()` method: It receives the array of `CensusData` object as a parameter
    with all the data from the file and a list of filters and returns a `CensusData`
    object with the first person it finds that meet all the criteria from the filters.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`findAny()`方法：它接收`CensusData`对象数组作为参数，其中包含来自文件的所有数据，以及一系列过滤器，并返回一个`CensusData`对象，其中包含满足所有过滤器条件的第一个人的数据。'
- en: 'The `findAll()` method: It receives the array of `CensusData` object as a parameter
    with all the data from the file and a list of filters and returns an array of
    `CensusData` objects with all the persons that meets all the criteria from the
    filter.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`findAll()`方法：它接收`CensusData`对象数组作为参数，其中包含来自文件的所有数据，以及一系列过滤器，并返回一个`CensusData`对象数组，其中包含满足所有过滤器条件的所有人的数据。'
- en: The `SerialMain` class implements the `main()` method of this version and tests
    it to measure the execution time of this algorithm in some circumstances.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`SerialMain`类实现了这个版本的`main()`方法，并对其进行了测试，以测量在某些情况下该算法的执行时间。'
- en: The SerialSearch class
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SerialSearch类
- en: 'As we mentioned before, this class implements the filtering of data. It provides
    two methods. The first one, the `findAny()` method, looks for the first data object
    that meets the filters. When it finds the first data object, it finishes its execution.
    Refer to the following code:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这个类实现了数据的过滤。它提供了两种方法。第一个方法`findAny()`查找满足过滤器条件的第一个数据对象。当它找到第一个数据对象时，它就结束了执行。参考以下代码：
- en: '[PRE27]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The second one, the `findAll()` method, returns an array of `CensusData` objects
    with all the objects that meet the filters as follows:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个方法`findAll()`返回一个`CensusData`对象数组，其中包含满足过滤器条件的所有对象，如下所示：
- en: '[PRE28]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The SerialMain class
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SerialMain类
- en: 'You''re going to use this class to test the filtering algorithm in different
    circumstances. First, we load the data from the file as follows:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用这个类来测试不同情况下的过滤算法。首先，我们从文件中加载数据，如下所示：
- en: '[PRE29]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The first case we are going to test is to use the `findAny()` method to find
    an object that exists in the first places of the array. You construct a list of
    filters and then call the `findAny()` method with the data of the file and the
    list of filters:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要测试的第一种情况是使用`findAny()`方法来查找数组的前几个位置中存在的对象。您构建一个过滤器列表，然后使用文件的数据和过滤器列表调用`findAny()`方法：
- en: '[PRE30]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Our filters look for the following attributes:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的过滤器寻找以下属性：
- en: '`32`: This is the country of the birth father attribute'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`32`：这是出生父亲的国家属性'
- en: '`31`: This is the country of the birth mother attribute'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`31`：这是出生母亲的国家属性'
- en: '`1`: This is the class of the worker attributes; `Not in universe` is one of
    their possible values'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1`：这是工人属性的类；`Not in universe`是它们可能的值之一'
- en: '`14`: This is the reason for unemployment attribute; `Not in universe` is one
    of their possible values'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`14`：这是失业原因属性；`Not in universe`是它们可能的值之一'
- en: 'We are going to test other cases as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按以下方式测试其他情况：
- en: Use the `findAny()` method to find an object that exists in the last positions
    of the array
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`findAny()`方法查找数组中最后几个位置中存在的对象
- en: Use the `findAny()`method to try to find an object that doesn't exist
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`findAny()`方法尝试查找一个不存在的对象
- en: Use the `findAny()` method in an error situation
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在错误情况下使用`findAny()`方法
- en: Use the `findAll()` method to obtain all the objects that meet a list of filters
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`findAll()`方法获取满足一系列过滤器的所有对象
- en: Use the `findAll()` method in an error situation
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在错误情况下使用`findAll()`方法
- en: The concurrent version
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发版本
- en: 'We are going to include more elements in our concurrent version:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在我们的并发版本中包含更多元素：
- en: 'A task manager: When you use the Fork/Join framework, you start with one task
    and you split that task into two (or more) child tasks that you split again and
    again until your problem has the desired size. There can be situations when you
    want to finish the execution of all those tasks. For example, when you implement
    the `findAny()` method and you find an object that meets all the criteria, you
    don''t need to continue with the execution of the rest of the tasks.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务管理器：当您使用Fork/Join框架时，您从一个任务开始，然后将该任务分成两个（或更多）子任务，然后再次分割，直到您的问题达到所需的大小。有时您希望完成所有这些任务的执行。例如，当您实现`findAny()`方法并找到满足所有条件的对象时，您就不需要继续执行其余任务。
- en: 'A `RecursiveTask` class to implement the `findAny()` method: It''s the `IndividualTask`
    class that extends `RecursiveTask`.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`RecursiveTask`类来实现`findAny()`方法：它是扩展了`RecursiveTask`的`IndividualTask`类。
- en: 'A `RecursiveTask` class to implement the `findAll()` method: It''s the `ListTask`
    class that extends `RecursiveTask`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`RecursiveTask`类来实现`findAll()`方法：它是扩展了`RecursiveTask`的`ListTask`类。
- en: Let's see the details of all those classes.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看所有这些类的细节。
- en: The TaskManager class
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务管理器类
- en: 'We are going to use this class to control the cancellation of tasks. We are
    going to cancel the execution of tasks in the following two situations:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用这个类来控制任务的取消。我们将在以下两种情况下取消任务的执行：
- en: You're executing the `findAny()` operation and you find an object that meets
    the requirements
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您正在执行`findAny()`操作，并且找到一个满足要求的对象
- en: You're executing the `findAny()` or `findAll()` operations and there's an unchecked
    exception in one of the tasks
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您正在执行`findAny()`或`findAll()`操作，并且其中一个任务出现了未经检查的异常
- en: 'The class declares two attributes: `ConcurrentLinkedDeque` to store all the
    tasks we need to cancel and an `AtomicBoolean` variable to guarantee that only
    one task executes the `cancelTasks()` method:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 该类声明了两个属性：`ConcurrentLinkedDeque`用于存储我们需要取消的所有任务，以及`AtomicBoolean`变量来保证只有一个任务执行`cancelTasks()`方法：
- en: '[PRE31]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'It defines methods to add a task to `ConcurrentLinkedDeque`, delete a task
    from the `ConcurrentLinkedDeque`, and cancel all the tasks stored in it. To cancel
    the tasks, we use the `cancel()` method defined in the `ForkJoinTask` class. The
    `true` parameter forces the interruption of the task if it is running as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 它定义了添加任务到`ConcurrentLinkedDeque`，从`ConcurrentLinkedDeque`中删除任务以及取消其中存储的所有任务的方法。要取消任务，我们使用`ForkJoinTask`类中定义的`cancel()`方法。如果任务正在运行，则`true`参数会强制中断任务的执行，如下所示：
- en: '[PRE32]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `cancelTasks()` method receives a `RecursiveTask` object as a parameter.
    We're going to cancel all the tasks except the one that is calling this method.
    We don't want to cancel the tasks that have found the result. The `compareAndSet(false,
    true)` method sets the `AtomicBoolean` variable to `true` and returns `true` only
    if the current value is `false`. If the `AtomicBoolean` variable already has a
    `true` value, then `false` is returned. The whole operation is performed atomically,
    so it's guaranteed that the body of if statement will be executed at most once
    even if the `cancelTasks()` method is concurrently called several times from different
    threads.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '`cancelTasks()`方法接收一个`RecursiveTask`对象作为参数。我们将取消除调用此方法的任务之外的所有任务。我们不想取消已经找到结果的任务。`compareAndSet(false,
    true)`方法将`AtomicBoolean`变量设置为`true`，并且仅当当前值为`false`时返回`true`。如果`AtomicBoolean`变量已经有一个`true`值，则返回`false`。整个操作是原子性执行的，因此可以保证即使从不同的线程并发调用`cancelTasks()`方法多次，if语句的主体也最多只会执行一次。'
- en: The IndividualTask class
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 个人任务类
- en: 'The `IndividualTask` class extends the `RecursiveTask` class parameterized
    with the `CensusData` task and implements the `findAny()` operation. It defines
    the following attributes:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`IndividualTask`类扩展了参数化为`CensusData`任务的`RecursiveTask`类，并实现了`findAny()`操作。它定义了以下属性：'
- en: An array with all the `CensusData` objects
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个包含所有`CensusData`对象的数组
- en: The `start` and `end` attributes that determine the elements it has to process
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定它需要处理的元素的`start`和`end`属性
- en: The `size` attribute that determines the maximum number of elements the task
    will process without splitting the task
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`属性确定任务在不分割的情况下将处理的最大元素数量'
- en: A `TaskManager` class to cancel the tasks if necessary
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`TaskManager`类来取消任务（如果有必要）
- en: 'The following code gives a list of filters to apply:'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下代码提供了要应用的过滤器列表：
- en: '[PRE33]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The main method of the class is the `compute()` method. It returns a `CensusData`
    object. If the number of elements the task has to process is less than the size
    attribute, it looks for the object directly. If the method finds the desired object,
    it returns the object and uses the method `cancelTasks()` to cancel the execution
    of the rest of the tasks. If the method doesn''t find the desired object, it returns
    null. We have the following code:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 该类的主要方法是`compute()`方法。它返回一个`CensusData`对象。如果任务需要处理的元素数量少于size属性，则直接查找对象。如果方法找到所需的对象，则返回该对象并使用`cancelTasks()`方法取消其余任务的执行。如果方法找不到所需的对象，则返回null。我们有以下代码：
- en: '[PRE34]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'If the number of items it has to process is more than the size attribute, we
    create two child tasks to process half of the elements:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它需要处理的项目数量超过size属性，则创建两个子任务来处理一半的元素：
- en: '[PRE35]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then, we add the new created tasks to the task manager and deleted the actual
    tasks. If we want to cancel the tasks, we want to cancel only the tasks that are
    running:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将新创建的任务添加到任务管理器中，并删除实际的任务。如果我们想要取消任务，我们只想取消正在运行的任务：
- en: '[PRE36]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Then, we send the tasks to `ForkJoinPool` with the `fork()` method that sends
    them in an asynchronous way and wait for its finalization with the `quietlyJoin()`
    method. The difference between the `join()` and `quietlyJoin()` methods is that
    the `join()` method launches and exception if the task is canceled or an unchecked
    exception is thrown inside the method while the `quietlyJoin()` method doesn't
    throw any exception.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`fork()`方法将任务发送到`ForkJoinPool`，以异步方式发送它们，并使用`quietlyJoin()`方法等待其完成。`join()`和`quietlyJoin()`方法之间的区别在于，`join()`方法在任务被取消或方法内部抛出未检查的异常时会抛出异常，而`quietlyJoin()`方法不会抛出任何异常。
- en: '[PRE37]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Then, we delete the child tasks from the `TaskManager` class as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们按以下方式从`TaskManager`类中删除子任务：
- en: '[PRE38]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, we obtain the results of the tasks using the `join()` method. If a task
    throws an unchecked exception, it will be propagated without special handling
    and cancellation will be just ignored as follows:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`join()`方法获取任务的结果。如果任务抛出未检查的异常，它将被传播而不进行特殊处理，并且取消将被忽略，如下所示：
- en: '[PRE39]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The ListTask class
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ListTask类
- en: The `ListTask` class extends the `RecursiveTask` class parameterized with a
    `List` of `CensusData`. We are going to use this task to implement the `findAll()`
    operation. It's very similar to the `IndividualTask` task. Both use the same attributes,
    but they have differences in the `compute()` method.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '`ListTask`类扩展了参数为`List`的`CensusData`的`RecursiveTask`类。我们将使用这个任务来实现`findAll()`操作。它与`IndividualTask`任务非常相似。两者都使用相同的属性，但在`compute()`方法中有所不同。'
- en: 'First, we initialize a `List` object to return the results and check the number
    of elements the task has to process. If the number of elements the task has to
    process is less than the size attribute, add all the objects that meet the criteria
    specified in the filters to the list of results:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们初始化一个`List`对象来返回结果并检查任务需要处理的元素数量。如果任务需要处理的元素数量少于size属性，则将满足过滤器指定条件的所有对象添加到结果列表中：
- en: '[PRE40]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'If the number of items it has to process is more than the size attribute, we
    will create two child tasks to process half of the elements:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它需要处理的项目数量超过size属性，则创建两个子任务来处理一半的元素：
- en: '[PRE41]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Then, we will add the new created tasks to the task manager and delete the
    actual tasks. The actual task won''t be canceled; its child tasks will be canceled,
    as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将新创建的任务添加到任务管理器中，并删除实际的任务。实际任务不会被取消；其子任务将被取消，如下所示：
- en: '[PRE42]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Then, we will send the tasks to `ForkJoinPool` with the `fork()` method that
    sends them in an asynchronous way and wait for its finalization with the `quietlyJoin()`
    method:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`fork()`方法将任务发送到`ForkJoinPool`，以异步方式发送它们，并使用`quietlyJoin()`方法等待其完成：
- en: '[PRE43]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Then, we will delete the child tasks from `TaskManager`:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将从`TaskManager`中删除子任务：
- en: '[PRE44]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Now, we obtain the results of the tasks using the `join()` method. If a task
    throws an unchecked exception, it will be propagated without special handling
    and cancellation will be just ignored:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`join()`方法获取任务的结果。如果任务抛出未检查的异常，它将被传播而不进行特殊处理，并且取消将被忽略：
- en: '[PRE45]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The ConcurrentSearch class
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConcurrentSearch类
- en: 'The `ConcurrentSearch` class implements the `findAny()` and `findAll()` methods.
    They have the same interface as the ones of the serial version. Internally, they
    initialize the `TaskManager` object and the first task and send to default `ForkJoinPool`
    using the `execute` method; they wait for the finalization of the task and write
    the results. This is the code of the `findAny()` method:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ConcurrentSearch类实现了`findAny()`和`findAll()`方法。它们与串行版本的方法具有相同的接口。在内部，它们初始化了`TaskManager`对象和第一个任务，并使用`execute`方法发送到默认的`ForkJoinPool`；它们等待任务的完成并写入结果。这是`findAny()`方法的代码：
- en: '[PRE46]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'This is the code of the `findAll()` method:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`findAll()`方法的代码：
- en: '[PRE47]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The ConcurrentMain class
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConcurrentMain类
- en: The `ConcurrentMain` class is used to test the concurrent version of our object
    filter. It is identical to the `SerialMain` class, but uses the concurrent version
    of the operations.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentMain`类用于测试对象过滤的并行版本。它与`SerialMain`类相同，但使用操作的并行版本。'
- en: Comparing the two versions
  id: totrans-273
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较两个版本
- en: 'To compare the serial and concurrent versions of the filtering algorithm, we
    tested them in six different situations:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 比较过滤算法的串行和并行版本，我们在六种不同的情况下对它们进行了测试：
- en: '**Test 1**: We test the `findAny()` method looking for an object that exists
    in the first positions of the `CensusData` array'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试1**：我们测试`findAny()`方法，查找存在于`CensusData`数组的第一个位置的对象'
- en: '**Test 2**: We test the `findAny()` method looking for an object that exists
    in the last positions of the `CensusData` array'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试2**：我们测试`findAny()`方法，查找存在于`CensusData`数组的最后位置的对象'
- en: '**Test 3**: We test the `findAny()` method looking for an object that doesn''t
    exist'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试3**：我们测试`findAny()`方法，查找不存在的对象'
- en: '**Test 4**: We test the `findAny()` method in an error situation'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试4**：我们测试`findAny()`方法在错误情况下'
- en: '**Test 5**: We test the `findAll()` method in a normal situation'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试5**：我们测试`findAll()`方法在正常情况下'
- en: '**Test 6**: We test the `findAll()` method in an error situation'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试6**：我们测试`findAll()`方法在错误情况下'
- en: For the concurrent version of the algorithm, we have tested three different
    values of the size parameter that determines the maximum number of elements a
    task can process without forking in two child tasks. We have tested with 10, 200,
    and 2,000.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 对于算法的并发版本，我们测试了确定任务在不分成两个子任务的情况下可以处理的最大元素数量的大小参数的三个不同值。我们测试了10、200和2,000。
- en: 'We have executed the tests using the JMH framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using methods as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. As with
    other examples, we have measured the execution time in milliseconds:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用JMH框架（[http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)）执行了测试，该框架允许您在Java中实现微基准测试。使用基准测试框架比仅使用`currentTimeMillis()`或`nanoTime()`等方法来测量时间更好。我们在具有四核处理器的计算机上执行了10次测试，并计算了这10次的平均执行时间。与其他示例一样，我们以毫秒为单位测量执行时间：
- en: '| Test case | Serial | Concurrent size = 10 | Concurrent size = 200 | Concurrent
    size = 2000 | Best |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 测试用例 | 串行 | 并发大小=10 | 并发大小=200 | 并发大小=2000 | 最佳 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| **Test 1** | 1.177 | 8.124 | 4.547 | 4.073 | Serial |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| **测试1** | 1.177 | 8.124 | 4.547 | 4.073 | 串行 |'
- en: '| **Test 2** | 95.237 | 157.412 | 34.581 | 35.691 | Concurrent |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| **测试2** | 95.237 | 157.412 | 34.581 | 35.691 | 并发 |'
- en: '| **Test 3** | 66.616 | 41.916 | 74.829 | 37.140 | Concurrent |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| **测试3** | 66.616 | 41.916 | 74.829 | 37.140 | 并发 |'
- en: '| **Test 4** | 0.540 | 25869.339 | 643.144 | 9.673 | Serial |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| **测试4** | 0.540 | 25869.339 | 643.144 | 9.673 | 串行 |'
- en: '| **Test 5** | 61.752 | 37.349 | 40.344 | 22.911 | Concurrent |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| **测试5** | 61.752 | 37.349 | 40.344 | 22.911 | 并发 |'
- en: '| **Test 6** | 0.802 | 31663.607 | 231.440 | 7.706 | Serial |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| **测试6** | 0.802 | 31663.607 | 231.440 | 7.706 | 串行 |'
- en: 'We can draw the following conclusions:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出以下结论：
- en: The serial version of the algorithm has better performance when we have to process
    a smaller number of elements.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 算法的串行版本在处理较少数量的元素时性能更好。
- en: The concurrent version of the algorithm has better performance when we have
    to process all the elements or a bit amount of them.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们需要处理所有元素或其中一部分元素时，并发版本的算法性能更好。
- en: In error situations, the serial version of the algorithm has better performance
    than the concurrent version. The concurrent version has a very poor performance
    in this situation when the value of the `size` parameter is small.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在错误情况下，串行版本的算法性能优于并发版本。当`size`参数的值较小时，并发版本在这种情况下性能非常差。
- en: In this case, concurrency does not always gives us an improvement of the performance.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，并发并不总是能提高性能。
- en: The third example – the merge sort algorithm
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三个示例 - 归并排序算法
- en: The merge sort algorithm is a very popular sorting algorithm that is always
    implemented using the divide and conquer technique, so it's a very good candidate
    to test with the Fork/Join framework.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 归并排序算法是一种非常流行的排序算法，总是使用分而治之的技术实现，因此它是使用Fork/Join框架进行测试的一个很好的候选者。
- en: To implement the merge sort algorithm, we divide the unsorted lists into sublists
    of one element. Then, we merge those unsorted sublists to produce ordered sublists
    until we have processed all the sublists, and we have only the original list,
    but with all the elements sorted.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现归并排序算法，我们将未排序的列表分成一个元素的子列表。然后，我们合并这些未排序的子列表以产生有序的子列表，直到我们处理完所有子列表，我们只剩下原始列表，但其中所有元素都已排序。
- en: To make the concurrent version of our algorithm, we have used the new Fork/Join
    tasks, the `CountedCompleter` tasks, introduced in the Java 8 version. The most
    important characteristics of these tasks are that they include a method to be
    executed when all their child tasks have finished their execution.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的算法的并发版本，我们使用了Java 8版本引入的新Fork/Join任务，`CountedCompleter`任务。这些任务最重要的特点是它们包括一个方法，在所有子任务完成执行时执行。
- en: To test out implementations, we have used the **Amazon product co-purchasing
    network metadata** (you can download it from [https://snap.stanford.edu/data/amazon-meta.html](https://snap.stanford.edu/data/amazon-meta.html)).
    In particular, we have created a list with the salesrank of 542,184 products.
    We are going to test our versions of the algorithm, sorting this list of products,
    and compare the execution time with the `sort()` and `parallelSort()` methods
    of the `Arrays` class.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试我们的实现，我们使用了**亚马逊产品共购买网络元数据**（您可以从[https://snap.stanford.edu/data/amazon-meta.html](https://snap.stanford.edu/data/amazon-meta.html)下载）。特别是，我们创建了一个包含542,184个产品销售排名的列表。我们将测试我们的算法版本，对这个产品列表进行排序，并将执行时间与`Arrays`类的`sort()`和`parallelSort()`方法进行比较。
- en: Shared classes
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 共享类
- en: 'As we mentioned earlier, we have built a list of 542,184 products of Amazon
    with information about each product including an ID, its title, group, salesrank,
    number of reviews, number of similar products, and number of categories the product
    belongs to. We have implemented the `AmazonMetaData` class to store the information
    of a product. This class declares the necessary attributes and the methods to
    get and set their values. This class implements the `Comparable` interface to
    compare two instances of this class. We want to sort the elements by salesrank
    in ascending order. To implement the `compare()` method, we use the `compare()`
    method of the `Long` class to compare the salesrank of both objects as follows:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们已经构建了一个包含542,184个亚马逊产品的列表，其中包含每个产品的信息，包括ID、标题、组、销售排名、评论数量、相似产品数量和产品所属的类别数量。我们已经实现了`AmazonMetaData`类来存储产品的信息。这个类声明了必要的属性和获取和设置它们的方法。这个类实现了`Comparable`接口来比较这个类的两个实例。我们想要按销售排名升序排序元素。为了实现`compare()`方法，我们使用`Long`类的`compare()`方法来比较这两个对象的销售排名，如下所示：
- en: '[PRE48]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: We have also implemented `AmazonMetaDataLoader` that provides the `load()` method.
    This method receives a route to the file with the data as a parameter and returns
    an array of `AmazonMetaData` objects with the information of all the products.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还实现了`AmazonMetaDataLoader`，它提供了`load()`方法。这个方法接收一个包含数据的文件路径作为参数，并返回一个包含所有产品信息的`AmazonMetaData`对象数组。
- en: Note
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We don't include the source code of these classes to focus on the characteristics
    of the Fork/Join framework.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不包括这些类的源代码，以便专注于Fork/Join框架的特性。
- en: The serial version
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 串行版本
- en: We have implemented the serial version of the merge sort algorithm in the `SerialMergeSort`
    class, which implements the algorithm and the `SerialMetaData` class and provides
    the `main()` method to test the algorithm.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`SerialMergeSort`类中实现了归并排序算法的串行版本，该类实现了算法和`SerialMetaData`类，并提供了`main()`方法来测试算法。
- en: The SerialMergeSort class
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SerialMergeSort类
- en: 'The `SerialMergeSort` class implements the serial version of the merge sort
    algorithm. It provides the `mergeSort()` method that receives the following parameters:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`SerialMergeSort`类实现了归并排序算法的串行版本。它提供了`mergeSort()`方法，接收以下参数：'
- en: The array with all the data we want to sort
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要排序的包含所有数据的数组
- en: The first element the method has to process (included)
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法必须处理的第一个元素（包括）
- en: The last element the method has to process (not included)
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 方法必须处理的最后一个元素（不包括）
- en: 'If the method has to process only one element, it returns. Otherwise, it makes
    two recursive calls to the `mergeSort()` method. The first call will process the
    first half of the elements, and the second call will process the second half of
    the elements. Finally, we make a call to the `merge()` method to merge the two
    halves of the elements and get a sorted list of elements:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 如果方法只需要处理一个元素，它就返回。否则，它会对`mergeSort()`方法进行两次递归调用。第一次调用将处理元素的前一半，第二次调用将处理元素的后一半。最后，我们调用`merge()`方法来合并两半元素并得到一个排序好的元素列表：
- en: '[PRE49]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: We have used the `(end+start)>>>1` operator to obtain the mid-element to split
    the array. If you have, for example, 1.5 billions of elements (not that impossible
    with modern memory chips), it still fits the Java array. However, *(end+start)/2*
    will overflow resulting in a negative number array. You can find a detailed explanation
    of this problem at [http://googleresearch.blogspot.ru/2006/06/extra-extra-read-all-about-it-nearly.html](http://googleresearch.blogspot.ru/2006/06/extra-extra-read-all-about-it-nearly.html).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`(end+start)>>>1`运算符来获取中间元素以分割数组。例如，如果你有15亿个元素（在现代内存芯片中并不那么不可能），它仍然适合Java数组。然而，*(end+start)/2*会溢出，导致数组为负数。你可以在[http://googleresearch.blogspot.ru/2006/06/extra-extra-read-all-about-it-nearly.html](http://googleresearch.blogspot.ru/2006/06/extra-extra-read-all-about-it-nearly.html)找到这个问题的详细解释。
- en: 'The `merge()` method merges two lists of elements to obtain a sorted list.
    It receives the following parameters:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '`merge()`方法合并两个元素列表以获得一个排序好的列表。它接收以下参数：'
- en: The array with all the data we want to sort
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要排序的包含所有数据的数组
- en: The three elements (`start`, `mid`, and `end`) that determine the two parts
    of the array (start-mid, mid-end) we want to merge and sort
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定我们要合并和排序的数组的两部分（start-mid，mid-end）的三个元素（`start`、`mid`和`end`）
- en: 'We create a temporary array to sort the elements, sort the elements in the
    array processing both parts of the list, and store the sorted list in the same
    positions of the original array. Check the following code:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建一个临时数组来对元素进行排序，对数组中的元素进行排序，处理列表的两部分，并将排序后的列表存储在原始数组的相同位置。检查以下代码：
- en: '[PRE50]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: The SerialMetaData class
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SerialMetaData类
- en: 'The `SerialMetaData` class provides the `main()` method to test the algorithm.
    We''re going to execute every sort algorithm 10 times to calculate the average
    execution time. First, we load the data from the file and create a copy of the
    array:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '`SerialMetaData`类提供了`main()`方法来测试算法。我们将执行每种排序算法10次，以计算平均执行时间。首先，我们从文件中加载数据并创建数组的副本：'
- en: '[PRE51]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Then, we sort the first array using the `sort()` method of the `Arrays` class:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用`Arrays`类的`sort()`方法对第一个数组进行排序：
- en: '[PRE52]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Then, we sort the second array using our implementation of the merge sort algorithm:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用自己实现的归并排序算法对第二个数组进行排序：
- en: '[PRE53]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Finally, we check that the sorted arrays are identical:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们检查排序后的数组是否相同：
- en: '[PRE54]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The concurrent version
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并发版本
- en: As we mentioned before, we are going to use the new Java 8 `CountedCompleter`
    class as the base class for our Fork/Join tasks. This class provides a mechanism
    to execute a method when all its child tasks have finished their execution. It's
    the `onCompletion()` method. So, we use the `compute()` method to divide the array
    and the `onCompletion()` method to merge the sublists into an ordered list.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，我们将使用新的Java 8 `CountedCompleter`类作为Fork/Join任务的基类。这个类提供了一个机制，当所有子任务都完成执行时执行一个方法。这就是`onCompletion()`方法。因此，我们使用`compute()`方法来划分数组，使用`onCompletion()`方法来将子列表合并成一个有序列表。
- en: 'The concurrent solution you are going to implement has three classes:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 您要实现的并发解决方案有三个类：
- en: The `MergeSortTask` class that extends the `CountedCompleter` class and implements
    the task that executes the merge sort algorithm
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展`CountedCompleter`类并实现执行归并排序算法的任务的`MergeSortTask`类
- en: The `ConcurrentMergeSort` task that launches the first task
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConcurrentMergeSort`任务启动第一个任务'
- en: The `ConcurrentMetaData` class that provides the `main()` method to test the
    concurrent version of the merge sort algorithm
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供`main()`方法来测试并发版本的归并排序算法的`ConcurrentMetaData`类
- en: The MergeSortTask class
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`MergeSortTask`类'
- en: 'As we mentioned earlier, this class implements the tasks that are going to
    execute the merge sort algorithm. This class uses the following attributes:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，这个类实现了将执行归并排序算法的任务。这个类使用以下属性：
- en: The array of data we want to sort
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们想要排序的数据数组
- en: The start and end positions of the array the task has to sort
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务必须排序的数组的起始和结束位置
- en: 'The class also has a constructor to initialize its parameters:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 该类还有一个构造函数来初始化其参数：
- en: '[PRE55]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The `compute()` method, if the difference between the start and end indexes
    are greater or equal that `1024`, we split the task into two child tasks to process
    two subsets of the original set. Both tasks use the `fork()` method to send a
    task to the `ForkJoinPool` in an asynchronous way. Otherwise, we execute `SerialMergeSorg.mergeSort()`
    to sort the part of the array (which have `1024` or less elements) and then we
    call the `tryComplete()` method. This method will internally call the `onCompletion()`
    method when the child task has finished its execution. Take a look at the following
    code:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`compute()`方法中开始和结束索引之间的差大于或等于`1024`，我们将任务分成两个子任务来处理原始集合的两个子集。两个任务都使用`fork()`方法以异步方式将任务发送到`ForkJoinPool`。否则，我们执行`SerialMergeSorg.mergeSort()`来对数组的一部分进行排序（其中有`1024`个或更少的元素），然后调用`tryComplete()`方法。当子任务完成执行时，此方法将在内部调用`onCompletion()`方法。请查看以下代码：
- en: '[PRE56]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'In our case, we will use the `onCompletion()` method to make the merge and
    sort operations to obtain the sorted list. Once a task finishes the execution
    of the `onCompletion()` method, it calls `tryComplete()` over its parent to try
    to complete that task. The source code of the `onCompletion()` method is very
    similar to the `merge()` method of the serial version of the algorithm. Refer
    to the following code:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们将使用`onCompletion()`方法来进行合并和排序操作以获得排序后的列表。一旦任务完成`onCompletion()`方法的执行，它会在其父任务上调用`tryComplete()`来尝试完成该任务。`onCompletion()`方法的源代码与算法的串行版本的`merge()`方法非常相似。请参考以下代码：
- en: '[PRE57]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: The ConcurrentMergeSort class
  id: totrans-347
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`ConcurrentMergeSort`类'
- en: In the concurrent version, this class is very simple. It implements the `mergeSort()`
    method that receives the array of data to sort and the start index (which will
    always be 0) and the end index (which will always be the length of the array)
    to sort the array as parameters. We have chosen to maintain the same interface
    rather than the serial version.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 在并发版本中，这个类非常简单。它实现了`mergeSort()`方法，该方法接收要排序的数据数组以及开始索引（始终为0）和结束索引（始终为数组的长度）作为参数来对数组进行排序。我们选择保持相同的接口而不是串行版本。
- en: The method creates a new `MergeSortTask`, sends it to the default `ForkJoinPool`
    using the `invoke()` method that returns when the task has finished its execution
    and the array is sorted.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法创建一个新的`MergeSortTask`，使用`invoke()`方法将其发送到默认的`ForkJoinPool`，当任务完成执行并且数组已排序时返回。
- en: '[PRE58]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The ConcurrentMetaData class
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并发版本的`ConcurrentMetaData`类
- en: The `ConcurrentMetaData` class provides the `main()` method to test the concurrent
    version of the merge sort algorithm. In our case, the code is equal to the code
    of the `SerialMetaData` class, but using the concurrent versions of the classes
    and the `Arrays.parallelSort()` method instead of the `Arrays.sort()` method,
    so we don't include the source code of the class.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcurrentMetaData`类提供了`main()`方法来测试并发版本的归并排序算法。在我们的情况下，代码与`SerialMetaData`类的代码相同，但使用类的并发版本和`Arrays.parallelSort()`方法而不是`Arrays.sort()`方法，因此我们不包括该类的源代码。'
- en: Comparing the two versions
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较两个版本
- en: 'We have executed our serial and concurrent versions of the merge sort algorithm
    and compared the execution times between them and against the methods `Arrays.sort()`
    and `Arrays.parallelSort()`. We have executed the four versions using the JMH
    framework ([http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/))
    that allows you to implement micro benchmarks in Java. Using a framework for benchmarking
    is a better solution that simply measures time using methods as `currentTimeMillis()`
    or `nanoTime()`. We have executed them 10 times in a computer with a four-core
    processor and calculated the medium execution time of those 10 times. These are
    the execution times in millisecond we have obtained when we sort our dataset with
    542,184 objects:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经执行了我们的串行和并发版本的归并排序算法，并比较了它们之间以及与`Arrays.sort()`和`Arrays.parallelSort()`方法的执行时间。我们使用了JMH框架（[http://openjdk.java.net/projects/code-tools/jmh/](http://openjdk.java.net/projects/code-tools/jmh/)）来执行这四个版本，该框架允许您在Java中实现微基准测试。使用基准测试框架比简单地使用`currentTimeMillis()`或`nanoTime()`等方法来测量时间更好。我们在一个四核处理器的计算机上执行了10次，并计算了这10次的平均执行时间。这是我们在对包含542,184个对象的数据集进行排序时获得的执行时间（毫秒）：
- en: '|   | Arrays.sort() | Serial merge sort | Arrays.parallelSort() | Concurrent
    merge sort |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '|   | Arrays.sort() | 串行归并排序 | Arrays.parallelSort() | 并发归并排序 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| **Execution time (ms)** | 561.324 | 711.004 | 261.418 | 353.846 |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
  zh: '| **执行时间（毫秒）** | 561.324 | 711.004 | 261.418 | 353.846 |'
- en: 'We can draw the following conclusions:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出以下结论：
- en: The method `Arrays.parallelSort()` obtains the best result. For serial algorithms,
    the `Arrays.sort()` method obtains better execution time than our implementation.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Arrays.parallelSort()`方法获得了最佳结果。对于串行算法，`Arrays.sort()`方法获得的执行时间比我们的实现更好。'
- en: For our implementations, the concurrent version of the algorithm has better
    performance than the serial one.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于我们的实现，算法的并发版本比串行版本具有更好的性能。
- en: 'We can compare our serial and concurrent versions of the merge sort algorithm
    using the speed-up:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用加速比来比较归并排序算法的串行和并发版本：
- en: '![Comparing the two versions](img/00018.jpeg)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
  zh: '![比较两个版本](img/00018.jpeg)'
- en: Other methods of the Fork/Join framework
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Fork/Join框架的其他方法
- en: In the three examples of this chapter, we have used a lot of methods of the
    class that forms the Fork/Join framework, but there are other interesting methods
    you have to know.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的三个示例中，我们使用了Fork/Join框架的类的许多方法，但还有其他有趣的方法您需要了解。
- en: We have used the methods `execute()` and `invoke()` from the `ForkJoinPool`
    class to send tasks to the pool. We can use another method named `submit()`. The
    main difference between them is that the `execute()` method sends the task to
    `ForkJoinPool` and returns immediately a void value, the `invoke()` method sends
    the task to the `ForkJoinPool` and returns when the task has finished its execution,
    and the `submit()` method sends the task to the `ForkJoinPool` and returns immediately
    a `Future` object to control the status of the task and obtain its result.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了`ForkJoinPool`类的`execute()`和`invoke()`方法将任务发送到池中。我们可以使用另一个名为`submit()`的方法。它们之间的主要区别在于，`execute()`方法将任务发送到`ForkJoinPool`并立即返回一个void值，`invoke()`方法将任务发送到`ForkJoinPool`并在任务完成执行时返回，`submit()`方法将任务发送到`ForkJoinPool`并立即返回一个`Future`对象以控制任务的状态并获取其结果。
- en: In all the examples of this chapter, we have used classes based on the `ForkJoinTask`
    class, but you can use the `ForkJoinPool` tasks based on the `Runnable` and `Callable`
    interfaces. To do this, you can use the method `submit()` that has versions that
    accept a `Runnable` object, a `Runnable` object with a result, and a `Callable`
    object.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的所有示例中，我们使用了基于`ForkJoinTask`类的类，但您也可以使用基于`Runnable`和`Callable`接口的`ForkJoinPool`任务。为此，您可以使用接受`Runnable`对象、带有结果的`Runnable`对象和`Callable`对象的版本的`submit()`方法。
- en: The `ForkJoinTask` class provides the method `get(long timeout, TimeUnit unit)`
    to obtain the results returned by a task. This method waits for the period of
    time specified in the parameters for the result of the task. If the task finishes
    its execution before that period of time, the method returns the result. Otherwise,
    it throws a `TimeoutException` exception.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: '`ForkJoinTask`类提供了`get(long timeout, TimeUnit unit)`方法来获取任务返回的结果。该方法等待参数中指定的时间段以获取任务的结果。如果任务在此时间段之前完成执行，则方法返回结果。否则，它会抛出`TimeoutException`异常。'
- en: The `ForkJoinTask` provides an alternative to the `invoke()` method. It is the
    `quietlyInvoke()` method. The main difference between the two versions is that
    the `invoke()` method returns the result of the execution of the task or throws
    any exception if necessary. The `quietlyInvoke()` method don't return the result
    of the task and doesn't throw any exception. It's similar to the `quietlyJoin()`
    method used in the examples.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '`ForkJoinTask`提供了`invoke()`方法的替代方法。它是`quietlyInvoke()`方法。两个版本之间的主要区别在于`invoke()`方法返回任务执行的结果，或者在必要时抛出任何异常。`quietlyInvoke()`方法不返回任务的结果，也不抛出任何异常。它类似于示例中使用的`quietlyJoin()`方法。'
- en: Summary
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'The divide and conquer design technique is a very popular approach to solve
    different kinds of problems. You divide the original problem into smaller problems
    and those problems into smaller ones until we have enough simple problems to solve
    it directly. In version 7, the Java concurrency API introduced a special kind
    of `Executor` optimized for these kinds of problems. It''s the Fork/Join Framework.
    It''s based on the following two operations:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 分而治之的设计技术是解决不同类型问题的一种非常流行的方法。您将原始问题分解为较小的问题，然后将这些问题分解为更小的问题，直到我们有足够简单的问题直接解决它。在版本7中，Java并发API引入了一种专门针对这些问题优化的`Executor`。它就是Fork/Join框架。它基于以下两个操作：
- en: '**fork**: This allows you to create a new child task'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**fork**：这允许您创建一个新的子任务'
- en: '**join**: This allows you to wait for the finalization of a child task and
    get its results'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**join**：这允许您等待子任务的完成并获取其结果'
- en: 'Using those operations, Fork/Join tasks have the following appearance:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些操作，Fork/Join任务具有以下外观：
- en: '[PRE59]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: In this chapter, you have solved three different problems using the Fork/Join
    framework such as the k-means clustering algorithm, a data filtering algorithm,
    and the merge sort algorithm.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您已经使用了Fork/Join框架解决了三种不同的问题，如k均值聚类算法、数据过滤算法和归并排序算法。
- en: 'You have used default `ForkJoinPool`, provided by the API (this is a new feature
    of the Java 8 version), and created a new `ForkJoinPool` object. You have also
    used the three types of `ForkJoinTask` `s`:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经使用了API提供的默认`ForkJoinPool`（这是Java 8版本的新功能），并创建了一个新的`ForkJoinPool`对象。您还使用了三种类型的`ForkJoinTask`：
- en: The `RecursiveAction` class, used as the base class for those `ForkJoinTasks`
    that don't return a result.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecursiveAction`类，用作那些不返回结果的`ForkJoinTasks`的基类。'
- en: The `RecursiveTask` class, used as the base class for those `ForkJoinTasks`
    that return a result.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RecursiveTask`类，用作那些返回结果的`ForkJoinTasks`的基类。'
- en: The `CountedCompleter` class, introduced in Java 8 and used as the base class
    for those `ForkJoinTasks` that need to execute a method or launch another task
    when all its child subtasks finish their execution.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CountedCompleter`类，引入于Java 8，并用作那些需要在所有子任务完成执行时执行方法或启动另一个任务的`ForkJoinTasks`的基类。'
- en: In the next chapter, you will learn how to use the MapReduce programming technique
    using the new Java 8 **parallel streams** to get the best performance processing
    very big datasets.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何使用新的Java 8 **并行流**来使用MapReduce编程技术，以获得处理非常大数据集的最佳性能。
