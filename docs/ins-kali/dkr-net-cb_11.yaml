- en: Chapter 11. Troubleshooting Docker Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章。故障排除Docker网络
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下示例：
- en: Using tcpdump to verify network paths
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用tcpdump验证网络路径
- en: Verifying VETH pairs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证VETH对
- en: Verifying published ports and outbound masquerading
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证发布的端口和出站伪装
- en: Verifying name resolution
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证名称解析
- en: Building a test container
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个测试容器
- en: Resetting the local Docker network database
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重置本地Docker网络数据库
- en: Introduction
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: As we've seen in earlier chapters, Docker leverages a combination of relatively
    well-known Linux networking constructs to deliver container networking. Throughout
    this book, we've looked at many different ways you can configure, consume, and
    validate Docker networking configuration. What we haven't done is outline a troubleshooting
    and validation methodology you can use when you run into issues. When troubleshooting
    container networking, it is important to understand and be able to troubleshoot
    each specific networking component used in delivering end-to-end connectivity.
    The goal of this chapter is to provide specific steps you can take when you need
    to validate or troubleshoot a Docker networking issue.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章中看到的，Docker利用了一系列相对知名的Linux网络构造来提供容器网络。在本书中，我们已经看过许多不同的方式，您可以配置、使用和验证Docker网络配置。我们还没有概述当您遇到问题时可以使用的故障排除和验证方法。在故障排除容器网络时，重要的是要理解并能够排除用于提供端到端连接的每个特定网络组件。本章的目标是提供在需要验证或故障排除Docker网络问题时可以采取的具体步骤。
- en: Using tcpdump to verify network paths
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用tcpdump验证网络路径
- en: Although we glanced over its usage in previous chapters, anyone working with
    networking on a Linux-based system should be comfortable with `tcpdump`. `tcpdump`
    allows you to capture network traffic on one or more interfaces on the host. In
    this recipe, we'll walk through how we can use `tcpdump` to verify container network
    traffic in a couple of different Docker networking scenarios.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在之前的章节中简要介绍了它的用法，但任何在基于Linux的系统上使用网络的人都应该熟悉`tcpdump`。`tcpdump`允许您在主机上的一个或多个接口上捕获网络流量。在这个示例中，我们将介绍如何使用`tcpdump`来验证几种不同的Docker网络场景中的容器网络流量。
- en: Getting ready
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'In this recipe, we''ll be using a single Docker host. It is assumed that Docker
    is installed and in its default configuration. You''ll also need root-level access
    in order to inspect and change the hosts networking and firewall configuration.
    You''ll also need the `tcpdump` utility installed. If you don''t have it on your
    system, you can install it with this command:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将使用一个单独的Docker主机。假设Docker已安装并处于默认配置。您还需要root级别的访问权限，以便检查和更改主机的网络和防火墙配置。您还需要安装`tcpdump`实用程序。如果您的系统上没有它，您可以使用以下命令安装它：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How to do it…
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: '`tcpdump` is an amazing troubleshooting tool. When used properly, it can give
    you a detailed view of packets as they traverse interfaces on a Linux host. To
    demonstrate, let''s start a single container on our Docker host:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`tcpdump`是一个令人惊叹的故障排除工具。当正确使用时，它可以让您详细查看Linux主机上接口上的数据包。为了演示，让我们在我们的Docker主机上启动一个单个容器：'
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Since we didn't specify any network parameters, this container will run on the
    `docker0` bridge and have any exposed ports published to the hosts interfaces.
    Traffic generated from the container will also be hidden behind the hosts IP interfaces
    as the traffic heads toward the outside network. Using `tcpdump`, we can see this
    traffic at every stage.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有指定任何网络参数，这个容器将在`docker0`桥上运行，并且任何暴露的端口都将发布到主机接口上。从容器生成的流量也将隐藏在主机的IP接口后，因为流量朝向外部网络。使用`tcpdump`，我们可以在每个阶段看到这个流量。
- en: 'Let''s first examine inbound traffic that''s coming into the host:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先检查进入主机的流量：
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In our case, this container was exposing port `80`, which has now been published
    to the host''s interfaces on port `32768`. Let''s first ensure that the traffic
    is coming into the host on the right port. To do this, we can capture on the hosts
    `eth0` interface for traffic destined to port `32768`:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，这个容器暴露了端口`80`，现在已经发布到主机接口的端口`32768`上。让我们首先确保流量进入主机的正确端口。为了做到这一点，我们可以在主机的`eth0`接口上捕获到目标端口为`32768`的流量：
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To use `tcpdump` to capture this inbound traffic, we used a couple of different
    parameters:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`tcpdump`捕获这个入站流量，我们使用了一些不同的参数：
- en: '`q`: This tells `tcpdump` to be quiet, or not generate as much output. Since
    we really only want to see the layer 3 and layer 4 information this cleans up
    the output quite nicely'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`q`：这告诉`tcpdump`保持安静，或者不要生成太多输出。因为我们只想看到第3层和第4层的信息，这样可以清理输出得很好'
- en: '`nn`: This tells `tcpdump` not to attempt to resolve IPs to DNS names. Again,
    we want to see the IP address here'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn`：这告诉`tcpdump`不要尝试将IP解析为DNS名称。同样，我们想在这里看到IP地址'
- en: '`i`: This specifies the interface we want to capture on, in this case, `eth0`'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`i`：这指定了我们要捕获的接口，在这种情况下是`eth0`'
- en: '`src port`: Tell `tcpdump` to filter on traffic that has a destination port
    of `32768`'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`src port`：告诉`tcpdump`过滤具有目的端口为`32768`的流量'
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: The `dst` parameter could be removed from this command. Doing so would filter
    on any traffic with a port of `32768` thus showing you the entire flow including
    the return traffic.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`dst`参数可以从此命令中删除。这样做将过滤任何端口为`32768`的流量，从而显示整个流量，包括返回流量。'
- en: As shown in the preceding code, we can see the host receiving traffic on its
    physical interface (`10.10.10.101`) on port `32768` coming from a remote source
    of `10.20.30.41`. In this case, `10.20.30.41` is a test server that is originating
    traffic toward the container's published port.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，我们可以看到主机在其物理接口（`10.10.10.101`）上接收到来自远程源（`10.20.30.41`）的端口`32768`的流量。在这种情况下，`10.20.30.41`是一个测试服务器，它正在向容器的发布端口发出流量。
- en: 'Now that we''ve seen the traffic get to the host, let''s look at it as it traverses
    the `docker0` bridge:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经看到流量到达主机，让我们看看它是如何穿过`docker0`桥的：
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this case, we can see the traffic by just filtering on the `docker0` bridge
    interface. As expected, we see the same traffic, with the same source, but now
    reflecting the accurate destination IP and port of the service running in the
    container thanks to the published port functionality.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以通过只在`docker0`桥接口上过滤流量来看到流量。正如预期的那样，我们看到相同的流量，具有相同的源，但现在反映了容器中运行的服务的准确目的地IP和端口，这要归功于发布端口功能。
- en: 'While this is certainly the easiest means to capture traffic, it''s not very
    effective if you have multiple containers running on the `docker0` bridge. The
    current filtering would provide you all of the traffic traversing the bridge rather
    than just the specific container you were looking for. In these cases, you can
    also specify the IP address in the filter like this:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这当然是捕获流量的最简单方法，但如果您在`docker0`桥上运行多个容器，这种方法并不是非常有效。当前的过滤器将为您提供桥上所有的流量，而不仅仅是您正在寻找的特定容器。在这种情况下，您还可以在过滤器中指定IP地址，就像这样：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: We're specifying the destination IP as a filter here. If we wished to see both
    traffic source and destined to that IP address, we could replace `dst` with `host`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里将目的地IP指定为过滤器。如果我们希望看到源和目的地都是该IP地址的流量，我们可以用`host`替换`dst`。
- en: 'This sort of packet capture is essential to validating that features like port
    publication are working as expected. Captures can be done on the majority of interface
    types including those that don''t have an IP address associated with them. A good
    example of such an interface is the host side of a VETH pair used to connect a
    containers namespace back to the default namespace. When troubleshooting container
    connectivity, it might be handy to be able to correlate traffic arriving on the
    `docker0` bridge with a specific host-side VETH interface. We can do this by correlating
    data from multiple places. For instance, assume that we do the following `tcpdump`:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种数据包捕获对于验证端口发布等功能是否按预期工作至关重要。捕获可以在大多数接口类型上进行，包括那些没有与其关联的IP地址的接口。这种接口的一个很好的例子是用于将容器命名空间连接回默认命名空间的VETH对的主机端。在排除容器连接问题时，能够将到达`docker0`桥的流量与特定主机端VETH接口相关联可能会很方便。我们可以通过从多个地方相关数据来实现这一点。例如，假设我们执行以下`tcpdump`：
- en: '[PRE6]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Note that in this case we passed the `e` parameter to `tcpdump`. This tells
    `tcpdump` to display the source and destination MAC address for each frame. In
    this case, we can see that we have two MAC addresses. One of these will be the
    MAC address associated with the `docker0` bridge, and the other will be the MAC
    address associated with the container. We can look at the `docker0` bridge information
    to determine what its MAC address is:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下，我们向`tcpdump`传递了`e`参数。这告诉`tcpdump`显示每个帧的源和目的MAC地址。在这种情况下，我们可以看到我们有两个MAC地址。其中一个将是与`docker0`桥相关联的MAC地址，另一个将是与容器相关联的MAC地址。我们可以查看`docker0`桥信息来确定其MAC地址是什么：
- en: '[PRE7]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This leaves the address `02:42:ac:11:00:02`. Using the bridge command that
    comes as part of the `iproute2` toolset, we can determine on which interface this
    MAC address lives:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这将留下地址`02:42:ac:11:00:02`。使用作为`iproute2`工具集的一部分的bridge命令，我们可以确定这个MAC地址存在于哪个接口上：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here, we can see that the MAC address of the container is accessible through
    the interface named `vetha431055`. Doing a capture on that interface will confirm
    that we''re looking at the right interface:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到容器的MAC地址可以通过名为`vetha431055`的接口访问。在该接口上进行捕获将确认我们是否正在查看正确的接口：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`tcpdump` can be a vital tool in verifying container communication. It is wise
    to spend some time understanding the tool and the different ways you can filter
    on traffic using its different parameters.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`tcpdump`可以成为验证容器通信的重要工具。花一些时间了解该工具以及使用其不同参数过滤流量的不同方式是明智的。'
- en: Verifying VETH pairs
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证VETH对
- en: Of all the Linux network constructs we've reviewed in this book, VETH pairs
    are likely the most essential. Being namespace aware they allow you to connect
    a container in a unique namespace to any other namespace including the default.
    And while Docker handles all of this for you, it is useful to be able to determine
    where the ends of a VETH pair live and correlate them to determine what purpose
    a VETH pair is serving. In this recipe, we'll review in depth how to find and
    correlate the ends of a VETH pair.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中我们审查过的所有Linux网络构造中，VETH对可能是最重要的。它们是命名空间感知的，允许您将一个唯一命名空间中的容器连接到包括默认命名空间在内的任何其他命名空间。虽然Docker会为您处理所有这些，但能够确定VETH对的端点位于何处并将它们相关联以确定VETH对的用途是很有用的。在本教程中，我们将深入研究如何找到和相关VETH对的端点。
- en: Getting ready
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be using a single Docker host. It is assumed that Docker
    is installed and in its default configuration. You'll also need root-level access
    in order to inspect and change the hosts networking and firewall configuration.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用单个Docker主机。假定Docker已安装并处于默认配置。您还需要root级别访问权限，以便检查和更改主机的网络和防火墙配置。
- en: How to do it…
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: The main use case for VETH pairs in Docker is to connect a containers network
    namespace back to the default network namespace. It does this by placing one of
    the VETH pair on the `docker0` bridge and the other end in the container. The
    container side of the VETH pair gets an IP address assigned to it and then renamed
    to `eth0`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Docker中VETH对的主要用例是将容器的网络命名空间连接回默认网络命名空间。它通过将VETH对中的一个放置在`docker0`桥上，另一个放置在容器中来实现这一点。VETH对的容器端被分配了一个IP地址，然后重命名为`eth0`。
- en: When looking to match up ends of a VETH pair for a container, there are two
    scenarios. The first is when you start with the end in the default namespace,
    and the second is when you start the end in the container namespace. Let's walk
    through each case and how to correlate them together.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 当寻找匹配容器的VETH对端时，有两种情况。第一种是当你从默认命名空间开始，第二种是当你从容器命名空间开始。让我们逐步讨论每种情况以及如何将它们联系在一起。
- en: 'Let''s first start with knowing the host end of the interface. For instance,
    let''s say we''re looking for the container end of this interface:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先从了解接口的主机端开始。例如，假设我们正在寻找这个接口的容器端：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'There are a couple things to point out here. First, passing the `-d` parameter
    to the `ip link` subcommand displays extra detail about the interface. In this
    case, it confirms that the interface is a VETH pair. Second, VETH pair naming
    generally follows the `<end1>@<end2>` naming convention. In this case, we can
    see that the end `vetha431055` is the local interface and the `if5` is the other
    end. `if5` stands for interface 5 or the index ID of the 5th interface on the
    host. Since VETH interfaces are always created in pairs, it''s fair to assume
    that the end of this VETH pair with index 6 is very likely index 5 or 7\. In this
    case, the naming is indicating that it''s 5, but we can confirm that using the
    `ethtool` command:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几件事情需要指出。首先，将`-d`参数传递给`ip link`子命令会显示有关接口的额外详细信息。在这种情况下，它确认了接口是一个VETH对。其次，VETH对的命名通常遵循`<end1>@<end2>`的命名约定。在这种情况下，我们可以看到`vetha431055`端是本地接口，而`if5`是另一端。`if5`代表接口5或主机上第5个接口的索引ID。由于VETH接口总是成对创建的，可以合理地假设具有索引6的VETH对端很可能是索引5或7。在这种情况下，命名表明它是5，但我们可以使用`ethtool`命令来确认：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'As you can see, the other end of this VETH pair has an interface index of 5
    as the name indicated. Now finding which container has 5 is the hard part. To
    do this, we need to inspect each container for a specific interface number. If
    you''re running a lot of containers, this can be a challenge. Instead of inspecting
    each container manually, you can loop through them using Linux `xargs`. For instance,
    look at this command:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这个VETH对的另一端具有接口索引5，正如名称所示。现在找到具有5的容器是困难的部分。为了做到这一点，我们需要检查每个容器的特定接口号。如果你运行了很多容器，这可能是一个挑战。你可以使用Linux的`xargs`循环遍历它们，而不是手动检查每个容器。例如，看看这个命令：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'What we''re doing here is returning a list of the container IDs for all running
    containers and then passing that list to `xargs`. In turn, `xargs` is using those
    container IDs to run a command inside the container with `docker exec`. That command
    happens to be the `ip link` command, which will return a list of all interfaces
    and their associated index numbers. If any of that information returned starts
    with a `5:`, indicating an interface index of 5, we''ll print it to the screen.
    In order to see which container has the interface in question, we have to run
    the `xargs` command in verbose mode (`--verb`), which will show us each command
    as it runs. The output will look like this:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里要做的是返回所有正在运行的容器的容器ID列表，然后将该列表传递给`xargs`。反过来，`xargs`正在使用这些容器ID在容器内部运行`docker
    exec`命令。该命令恰好是`ip link`命令，它将返回所有接口及其关联的索引号的列表。如果返回的任何信息以`5:`开头，表示接口索引为5，我们将把它打印到屏幕上。为了查看哪个容器具有相关接口，我们必须以详细模式（`--verb`）运行`xargs`命令，这将显示每个命令的运行情况。输出将如下所示：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see, there were six containers running on this host. We didn't find
    the interface ID we were looking for until the last container. Given the container
    ID, we can tell which container has the other end of the VETH interface.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，此主机上有六个容器正在运行。直到最后一个容器，我们才找到了我们要找的接口ID。有了容器ID，我们就可以知道哪个容器具有VETH接口的另一端。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: You could confirm this by running the `docker exec -it` `ea32565ece0c ip link`
    command.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行`docker exec -it` `ea32565ece0c ip link`命令来确认这一点。
- en: 'Now, let''s try another example of starting with the container end of the VETH
    pair. This is slightly easier since the naming of the interface tells us the index
    of the host-side matching interface:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试另一个例子，从VETH对的容器端开始。这稍微容易一些，因为接口的命名告诉我们主机端匹配接口的索引：
- en: '[PRE14]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can then validate that the interface on the host with index 6 is a match
    to the interface with an index 5 in the container by once again using the `ethtool`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过再次使用`ethtool`来验证主机上索引为6的接口是否与容器中索引为5的接口匹配：
- en: '[PRE15]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Verifying published ports and outbound masquerading
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证已发布的端口和出站伪装
- en: One of the more difficult pieces involved in Docker networking is `iptables`.
    The `iptables`/netfilter integration plays a key role in providing functionality
    like port publication and outbound masquerading. However, `iptables` can be difficult
    to understand and troubleshoot if you're not already familiar with it. In this
    recipe, we'll review how to examine the `iptables` configuration in detail and
    verify that connectivity is working as expected.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Docker网络中涉及的较困难的部分之一是`iptables`。`iptables`/netfilter集成在提供端口发布和出站伪装等功能方面发挥着关键作用。然而，如果您对其不熟悉，`iptables`可能很难理解和排除故障。在本教程中，我们将审查如何详细检查`iptables`配置，并验证连接是否按预期工作。
- en: Getting ready
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be using a single Docker host. It is assumed that Docker
    is installed and in its default configuration. You'll also need root-level access
    in order to inspect the `iptables` rule set.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用单个Docker主机。假设Docker已安装并处于默认配置中。您还需要root级别的访问权限才能检查`iptables`规则集。
- en: How to do it…
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: As we've seen in earlier chapters, Docker does an outstanding job of managing
    host firewall rules on your behalf. There will likely be very few instances in
    which you need to view or modify the `iptables` rules as they relate to Docker.
    However, it's always a good idea to be able to validate the configuration to rule
    out `iptables` as a possible issue when you're troubleshooting container networking.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前几章中看到的，Docker在代表您管理主机防火墙规则方面做得非常出色。您可能很少需要查看或修改与Docker相关的`iptables`规则。然而，能够验证配置以排除`iptables`可能是容器网络故障的一个好主意。
- en: 'To demonstrate walking through the `iptables` rule set, we''ll examine an example
    container that''s publishing a port. The steps we perform to do this are easily
    transferable to examining rules for any other Docker-integrated `iptables` use
    cases. To do this, we''ll run a simple container that exposes port `80` for publishing:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示遍历`iptables`规则集，我们将检查一个发布端口的示例容器。我们执行这些步骤很容易转移到检查任何其他Docker集成`iptables`用例的规则。为此，我们将运行一个简单的容器，该容器公开端口`80`以进行发布：
- en: '[PRE16]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Since we told Docker to publish any exposed ports, we know that this container
    should have its exposed port of `80` published to the host. To verify that the
    port is actually being published, we can check the `iptables` rule set. The first
    thing we''d want to do is to make sure that the destination NAT required for port
    publication is in place. To examine an `iptables` table, we can use the `iptables`
    command and pass the following parameters:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们告诉Docker发布任何公开的端口，我们知道该容器应该将其公开的端口`80`发布到主机。为了验证端口是否真的被发布，我们可以检查`iptables`规则集。我们想要做的第一件事是确保端口发布所需的目标NAT已经就位。为了检查`iptables`表，我们可以使用`iptables`命令并传递以下参数：
- en: '`n`: Tells `iptables` to use numeric information in the output for things such
    as addresses and ports'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n`：告诉`iptables`在输出中使用数值信息，如地址和端口'
- en: '`L`: Tells `iptables` that you want to output a list of rules'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`L`：告诉`iptables`你想输出一个规则列表'
- en: '`v`: Tells `iptables` to provide verbose output, so we can see all of the rule
    information as well as rule counters'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`v`：告诉`iptables`提供详细输出，这样我们就可以看到所有的规则信息以及规则计数器'
- en: '`t`: Tells `iptables` to only show information from a specific table'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`t`：告诉`iptables`仅显示特定表的信息'
- en: 'Putting that all together, we can use the command `sudo iptables –nL –t nat`
    to view the rules in the NAT table of the host:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，我们可以使用命令`sudo iptables -nL -t nat`来查看主机NAT表中的规则：
- en: '![How to do it…](graphics/B05453_11_01.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](graphics/B05453_11_01.jpg)'
- en: Note
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Note that all the default table and chain policies we'll examine in this recipe
    are `ACCEPT`. If the default chain policy is `ACCEPT`, it means that even if we
    don't get a rule match, the flow will still be allowed. Docker will create the
    rules regardless of what the default policy is set to.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们将在本教程中检查的所有默认表和链策略都是“接受”。如果默认链策略是“接受”，这意味着即使我们没有匹配规则，流量仍将被允许。无论默认策略设置为什么，Docker都将创建规则。
- en: 'If you''re not comfortable with `iptables`, interpreting this output can be
    a bit daunting. Even though we''re looking at the NAT table, we need to know what
    chain is being processed for inbound communication to the host. In our case, since
    the traffic is coming into the host, the chain we''re interested with is the `PREROUTING`
    chain. Let''s walk through how the table is processed:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对`iptables`不太熟悉，解释这个输出可能有点令人生畏。即使我们正在查看NAT表，我们也需要知道哪个链正在处理进入主机的通信。在我们的情况下，由于流量进入主机，我们感兴趣的链是`PREROUTING`链。让我们来看一下表是如何处理的：
- en: The first line in the `PREROUTING` chain looks for traffic destined for `LOCAL`
    or the host itself. Since the traffic is destined to an IP address on one of the
    host's interfaces, we match on this rule and perform the action that references
    jumping to a new chain named `DOCKER`.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PREROUTING`链中的第一行寻找目的地为`LOCAL`或主机本身的流量。由于流量的目的地是主机接口之一的IP地址，我们匹配了这条规则并执行了引用跳转到一个名为`DOCKER`的新链的动作。'
- en: In the `DOCKER` chain, we hit the first rule that is looking for traffic coming
    into the `docker0` bridge. Since this traffic isn't coming into the `docker0`
    bridge, the rule is passed over and we move to the next rule in the chain.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`DOCKER`链中，我们命中了第一条规则，该规则正在寻找进入`docker0`桥的流量。由于这个流量并没有进入`docker0`桥，所以规则被跳过，我们继续移动到链中的下一条规则。
- en: The second rule in the `DOCKER` chain is looking for traffic that's not coming
    into the `docker0` bridge and has a destination port of TCP `32768`. We match
    this rule and perform the action to perform a destination NAT to `172.17.0.2`
    port `80`.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DOCKER`链中的第二条规则正在寻找并非进入`docker0`桥且目的端口为TCP `32768`的流量。我们匹配了这条规则并执行了将目的NAT转换为`172.17.0.2`端口`80`的动作。'
- en: 'The processing in the table looks like this:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的处理看起来是这样的：
- en: '![How to do it…](graphics/B05453_11_02.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](graphics/B05453_11_02.jpg)'
- en: The arrows in the preceding image indicate the traffic flow as the traffic traverses
    the NAT table. In this example, we only have one container running on the host,
    so it's pretty easy to see which rules are being processed.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的图像中的箭头表示流量在穿过NAT表时的流动。在这个例子中，我们只有一个运行在主机上的容器，所以很容易看出哪些规则正在被处理。
- en: Note
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'You can couple this sort of output with the `watch` command to get a live output
    of the counters, for instance:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将这种输出与`watch`命令配合使用，以获得计数器的实时输出，例如：
- en: '[PRE17]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now that we''ve traversed the NAT table, the next thing we need to worry about
    is the filter table. We can view the filter table in much the same way that we
    viewed the NAT table:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经穿过了NAT表，接下来我们需要担心的是过滤表。我们可以以与查看NAT表相同的方式查看过滤表：
- en: '![How to do it…](graphics/B05453_11_03.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](graphics/B05453_11_03.jpg)'
- en: 'At first glance, we can see that this table is laid out slightly different
    than the NAT table was. For instance, we have different chains in this table than
    we did with the NAT table. In our case, the chain we''re interested in for inbound
    published port communication would be the forward chain. This is because the host
    is forwarding, or routing, the traffic to the container. The traffic will traverse
    this table as follows:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 乍一看，我们可以看到这个表的布局与NAT表略有不同。例如，这个表中的链与NAT表中的不同。在我们的情况下，我们对入站发布端口通信感兴趣的链是forward链。这是因为主机正在转发或路由流量到容器。流量将按以下方式穿过这个表：
- en: The first line in the forward chain sends the traffic directly to the `DOCKER-ISOLATION`
    chain.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发链中的第一行直接将流量发送到`DOCKER-ISOLATION`链。
- en: In this case, the only rule in the `DOCKER-ISOLATION` chain is a rule to send
    the traffic back, so we resume reviewing rules in the `FORWARD` table.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，`DOCKER-ISOLATION`链中唯一的规则是将流量发送回来，所以我们继续审查`FORWARD`表中的规则。
- en: The second rule in the forward table says that if the traffic is going out the
    `docker0` bridge to send the traffic to the `DOCKER` chain. Since our destination
    (`172.17.0.20`) lives out the `docker0` bridge, we match on this rule and jump
    to the `DOCKER` chain.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发表中的第二条规则表示，如果流量要离开`docker0`桥，则将流量发送到`DOCKER`链。由于我们的目的地（`172.17.0.20`）位于`docker0`桥外，我们匹配了这条规则并跳转到`DOCKER`链。
- en: In the `DOCKER` chain, we inspect the first rule and determine that it's looking
    for traffic that is destined to the container IP address on port TCP `80` and
    is going out, but not in, the `docker0` bridge. We match on this rule and the
    flow is accepted.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`DOCKER`链中，我们检查第一条规则，并确定它正在寻找目的地为容器IP地址，端口为TCP `80`的流量，且是从`docker0`桥接口出去而不是进来的。我们匹配到了这条规则，流量被接受了。
- en: 'The processing in the table looks like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的处理如下：
- en: '![How to do it…](graphics/B05453_11_04.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](graphics/B05453_11_04.jpg)'
- en: Passing the filter table is the last step published port traffic has to take
    in order to reach the container. However, we've now only reached the container.
    We still need to account for the return traffic from the container back to the
    host talking to the published port. So now, we need to talk about how traffic
    originated from the container is handled by `iptables`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通过过滤表是发布端口流量必须经过的最后一步，以便到达容器。然而，我们现在只是到达了容器。我们仍然需要考虑从容器返回到与发布端口通信的主机的返回流量。因此，现在，我们需要讨论容器发起的流量如何由`iptables`处理。
- en: 'The first table we''ll encounter with outbound traffic is the filter table.
    Traffic originating from the container will once again use the forward chain of
    the filter table. The flow would look something like this:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将遇到的第一个表是出站流量的过滤表。再次，来自容器的流量将使用过滤表的转发链。流程大致如下：
- en: The first line in the forward chain sends the traffic directly to the `DOCKER-ISOLATION`
    chain.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发链中的第一条规则直接将流量发送到`DOCKER-ISOLATION`链。
- en: In this case, the only rule in the `DOCKER-ISOLATION` chain is a rule to send
    the traffic back, so we resume reviewing rules in the FORWARD table.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这种情况下，`DOCKER-ISOLATION`链中唯一的规则是将流量发送回去，所以我们继续查看转发表中的规则。
- en: The second rule in the forward table says that if the traffic is going from
    the `docker0` bridge, send the traffic to the `DOCKER` chain. Since our traffic
    is going into the `docker0` bridge rather than out, this rule is passed over and
    we move to the next rule in the chain.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发表中的第二条规则表示，如果流量是从`docker0`桥接口出去的，就将流量发送到`DOCKER`链。由于我们的流量是进入`docker0`桥接口而不是出去，所以这条规则被跳过，我们继续查看链中的下一条规则。
- en: The third rule in the forward table says that if the traffic is going out from
    the `docker0` bridge and its connection state is `RELATED` or `ESTABLISHED` that
    the flow should be accepted. This traffic is going into the `docker0` bridge,
    so we won't match this rule either. However, it is worth pointing out that this
    rule is used to allow return traffic for flows initiated from the container. It's
    just not hit as part of the initial outbound connection since that represents
    a new flow.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发表中的第三条规则表示，如果流量是从`docker0`桥接口出去，并且连接状态是`RELATED`或`ESTABLISHED`，则应该接受该流量。这个流量是进入`docker0`桥接口的，所以我们也不会匹配到这条规则。然而，值得指出的是，这条规则用于允许容器发起的流量的返回流量。它只是作为初始出站连接的一部分而没有被命中，因为那代表了一个新的流量。
- en: The fourth rule in the forward table says that if the traffic is going in the
    `docker0` bridge, but not out the `docker0` bridge, to accept it. Because our
    traffic is going into the `docker0` bridge, we match on this rule and the traffic
    is accepted.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 转发表中的第四条规则表示，如果流量经过`docker0`桥接口，但不是从`docker0`桥接口出去，就接受它。因为我们的流量是进入`docker0`桥接口的，所以我们匹配到了这条规则，流量被接受了。
- en: 'The processing in the table looks like this:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表中的处理如下：
- en: '![How to do it…](graphics/B05453_11_05.jpg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤...](graphics/B05453_11_05.jpg)'
- en: 'The next table we''d hit for outbound traffic is the NAT table. This time,
    we want to look at the `POSTROUTING` chain. In this case, we match the first rule
    of the chain which is looking for traffic that is not going out the `docker0`
    bridge and is sourced from the `docker0` bridge subnet (`172.17.0.0/16`):'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将命中的下一个表是NAT表。这一次，我们要查看`POSTROUTING`链。在这种情况下，我们匹配链的第一条规则，该规则寻找不是从`docker0`桥出去的流量，并且源自`docker0`桥子网（`172.17.0.0/16`）的流量。
- en: '![How to do it…](graphics/B05453_11_06.jpg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作…](graphics/B05453_11_06.jpg)'
- en: The action for this rule is to `MASQUERADE`, which will hide the traffic behind
    one of the hosts interfaces based on the hosts routing table.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这条规则的操作是`MASQUERADE`，它将根据主机的路由表隐藏流量在主机接口之一后面。
- en: Taking this same approach, you can easily validate other `iptables` flows related
    to Docker. Granted, as the number of containers scale, this becomes a harder task.
    However, since the majority of rules are written on a per container basis, the
    hit counters will be unique to each container, making it easier to narrow the
    scope.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 采用相同的方法，您可以轻松验证与Docker相关的其他`iptables`流。当然，随着容器数量的增加，这变得更加困难。然而，由于大多数规则是按照每个容器的基础编写的，命中计数器将对每个容器都是唯一的，这使得缩小范围变得更容易。
- en: Note
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: For more information on the order in which `iptables` tables and chains are
    processed, take a look at this `iptables` web page and the associated flow charts
    at [http://www.iptables.info/en/structure-of-iptables.html](http://www.iptables.info/en/structure-of-iptables.html).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 有关`iptables`表和链的处理顺序的更多信息，请查看这个`iptables`网页和相关的流程图[http://www.iptables.info/en/structure-of-iptables.html](http://www.iptables.info/en/structure-of-iptables.html)。
- en: Verifying name resolution
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 验证名称解析
- en: DNS resolution for containers has always been rather straightforward. The container
    received the same DNS configuration as the host. However, with the advent of user-defined
    networks and the embedded DNS server, this has now become a little trickier. A
    common problem in many of the DNS issues I've seen is not understanding how the
    embedded DNS server works and how to validate that it's working correctly. In
    this recipe, we'll step through a container DNS configuration to validate which
    DNS server it is using to resolve specific namespaces.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 容器的DNS解析一直都很简单。容器接收与主机相同的DNS配置。然而，随着用户定义网络和嵌入式DNS服务器的出现，这现在变得有点棘手。我见过的许多DNS问题中的一个常见问题是不理解嵌入式DNS服务器的工作原理以及如何验证它是否正常工作。在这个教程中，我们将逐步介绍容器DNS配置，以验证它使用哪个DNS服务器来解析特定的命名空间。
- en: Getting ready
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be using a single Docker host. It is assumed that Docker
    is installed and in its default configuration. You'll also need root-level access
    in order to inspect and change the host's networking and firewall configuration.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将使用一个单独的Docker主机。假设Docker已安装并处于默认配置。您还需要root级别的访问权限，以便检查和更改主机的网络和防火墙配置。
- en: How to do it…
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'The standard DNS configuration for Docker without user-defined networks is
    to simply copy the DNS configuration from the host into the container. In these
    cases, the DNS resolution is straightforward:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 没有用户定义网络的情况下，Docker的标准DNS配置是将主机的DNS配置简单地复制到容器中。在这些情况下，DNS解析很简单：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In these cases, all DNS requests will go straight to the defined DNS server.
    This means that our container can resolve any DNS records that our host can:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，所有的DNS请求都会直接发送到定义的DNS服务器。这意味着我们的容器可以解析任何我们的主机可以解析的DNS记录：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Coupled with the fact that Docker will masquerade this traffic to the IP address
    of the host itself makes this a simple and easily maintainable solution.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 再加上Docker将这些流量伪装成主机本身的IP地址，这就成为了一个简单且易于维护的解决方案。
- en: 'However, this gets a little trickier when we start using user-defined networks.
    This is because user-defined networks provide for container name resolution. That
    is, one container can resolve the name of another container without the use of
    static or manual host file entries and linking. This is a great feature, but it
    can cause some confusion if you don''t understand how the container receives its
    DNS configuration. For instance, let''s now create a new user-defined network:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们开始使用用户定义的网络时，情况就会变得有些棘手。这是因为用户定义的网络提供了容器名称解析。也就是说，一个容器可以解析另一个容器的名称，而无需使用静态或手动主机文件条目和链接。这是一个很棒的功能，但如果您不了解容器如何接收其DNS配置，可能会导致一些混乱。例如，现在让我们创建一个新的用户定义网络：
- en: '[PRE20]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let''s now start a new container named `web2` on this network:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们在这个网络上启动一个名为`web2`的新容器：
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now if we connect our existing `web1` container to this bridge, we should find
    that `web1` can resolve the container `web2` by name:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们将现有的`web1`容器连接到这个桥接器，我们应该会发现`web1`可以通过名称解析容器`web2`：
- en: '[PRE22]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The problem here is that in order to facilitate this, Docker had to change
    the DNS configuration of the `web1` container. In doing so, it injects the embedded
    DNS server in the middle of a containers DNS request. So before, when we were
    talking directly to the hosts DNS server, we are now talking to the embedded DNS
    server:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，为了实现这一点，Docker必须更改`web1`容器的DNS配置。这样做会在容器的DNS请求中间注入嵌入式DNS服务器。因此，在此之前，当我们直接与主机的DNS服务器通信时，现在我们是在与嵌入式DNS服务器通信：
- en: '[PRE23]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: This is required for DNS resolution to containers to work, but it has an interesting
    side effect. The embedded DNS server reads the host's `/etc/resolv.conf` file
    and uses any name servers defined in that file as forwarders for the embedded
    DNS server. The net effect of this is that you don't notice the embedded DNS server
    since it's still forwarding requests it can't answer to the host's DNS server.
    However, it only programs these forwarders if they are defined. If they don't
    exist or are set to `127.0.0.1`, then Docker programs the forwarders to be Google's
    public DNS server (`8.8.8.8` and `8.4.4.4`).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于容器的DNS解析是必需的，但它有一个有趣的副作用。嵌入式DNS服务器会读取主机的`/etc/resolv.conf`文件，并使用该文件中定义的任何名称服务器作为嵌入式DNS服务器的转发器。这样做的净效果是，您不会注意到嵌入式DNS服务器，因为它仍然将无法回答的请求转发给主机的DNS服务器。但是，它只会在这些转发器被定义时进行编程。如果它们不存在或设置为`127.0.0.1`，那么Docker会将转发器设置为Google的公共DNS服务器（`8.8.8.8`和`8.4.4.4`）。
- en: 'Although this makes good sense, there are rare circumstances in which your
    local DNS server happens to be `127.0.0.1`. For instance, you happen to be running
    some type of local DNS resolver on the same host or using a DNS forwarder application
    such as **DNSMasq**. In those cases, there are some complications that can be
    caused by Docker forwarding the container''s DNS requests off to the aforementioned
    external DNS servers instead of the one locally defined. Namely, internal DNS
    zones will no longer be resolvable:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是有道理的，但在某些罕见情况下，您的本地DNS服务器恰好是`127.0.0.1`。例如，您可能在同一台主机上运行某种类型的本地DNS解析器，或者使用DNS转发应用程序，比如**DNSMasq**。在这些情况下，Docker将容器的DNS请求转发到前面提到的外部DNS服务器，而不是本地定义的DNS服务器，可能会引起一些复杂情况。换句话说，内部DNS区域将不再可解析：
- en: '[PRE24]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This can also cause general resolution issues because it is common to block
    DNS traffic to external DNS servers preferring instead to force internal endpoints
    to use internal DNS servers.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这也可能导致一般的解析问题，因为通常会阻止DNS流量到外部DNS服务器，而是更倾向于强制内部端点使用内部DNS服务器。
- en: 'In these scenarios, there are a couple of ways to address this. You can either
    run the container with a specific DNS server by passing the DNS flag at container
    runtime:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情景中，有几种方法可以解决这个问题。您可以在容器运行时通过传递DNS标志来指定运行容器的特定DNS服务器：
- en: '[PRE25]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Otherwise, you can set the DNS server at the Docker service level, which the
    embedded DNS server will then use as the forwarder:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，您可以在Docker服务级别设置DNS服务器，然后嵌入式DNS服务器将使用它作为转发器：
- en: '[PRE26]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: In either case, if you're having container resolution issues, always check and
    see what the container has configured in its `/etc/resolv.conf` file. If it's
    `127.0.0.11`, that indicates you're using the Docker embedded DNS server. If you
    are, and you're still having issues, make sure that you validate the host DNS
    configuration to determine what the embedded DNS server is consuming for a forwarder.
    If there isn't one defined or it's `127.0.0.1`, then make sure that you tell the
    Docker service what DNS server it should be passing to containers in one of the
    two ways defined earlier.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 无论哪种情况，如果您遇到容器解析问题，请始终检查并查看容器在其`/etc/resolv.conf`文件中配置了什么。如果是`127.0.0.11`，那表明您正在使用Docker嵌入式DNS服务器。如果是这样，并且您仍然遇到问题，请确保验证主机DNS配置，以确定嵌入式DNS服务器正在使用什么作为转发器。如果没有定义或者是`127.0.0.1`，那么请确保告诉Docker服务应该将哪个DNS服务器传递给容器，可以使用前面定义的两种方式之一。
- en: Building a test container
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个测试容器
- en: One of the tenants of building Docker containers is to keep them small and lean.
    In some cases, this can limit your troubleshooting options as the containers won't
    have many of the common Linux networking tools as part of their image. While not
    ideal, it is sometimes nice to have a container image that has these tools installed
    so that you can troubleshoot the network from the container perspective. In this
    chapter, we'll review how to build a Docker image specifically for this purpose.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 构建Docker容器的原则之一是保持它们小巧精悍。在某些情况下，这可能会限制您的故障排除选项，因为容器的镜像中可能没有许多常见的Linux网络工具。虽然不是理想的情况，但有时候有一个安装了这些工具的容器镜像是很好的，这样您就可以从容器的角度来排查网络问题。在本章中，我们将讨论如何专门为此目的构建Docker镜像。
- en: Getting ready
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be using a single Docker network host. It is assumed that
    Docker is installed and in its default configuration. You'll also need root-level
    access in order to inspect and change the hosts networking and firewall configuration.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在本示例中，我们将使用单个Docker网络主机。假设Docker已安装并处于默认配置状态。您还需要root级别访问权限，以便检查和更改主机的网络和防火墙配置。
- en: How to do it…
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'A Docker image is built by defining a Dockerfile. The Dockerfile defines what
    base image to use as well as commands to run inside of the container. In my example,
    I''ll define the Dockerfile as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Docker镜像是通过定义Dockerfile来构建的。Dockerfile定义了要使用的基础镜像以及容器内部要运行的命令。在我的示例中，我将定义Dockerfile如下：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The goal of this image is twofold. First, I wanted to be able to run the container
    in detached mode and have it offer a service. This would allow me to define the
    container and verify that things such as port publishing were working off the
    host. This container image provides me with a known good container that will publish
    a service on port `80`. For this purpose, we're using Apache to host a simple
    index page.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这个镜像的目标是双重的。首先，我希望能够以分离模式运行容器，并且让它提供一个服务。这将允许我定义容器并验证诸如端口发布之类的功能是否在主机上正常工作。这个容器镜像为我提供了一个已知良好的容器，将在端口`80`上发布一个服务。为此，我们使用Apache来托管一个简单的索引页面。
- en: 'The index file is pulled into the image at build time and can be customized
    by you. I use a simple HTML page, `index.html`, that shows big red font such as
    this:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 索引文件在构建时被拉入镜像中，并且可以由您自定义。我使用一个简单的HTML页面`index.html`，显示大红色的字体，如下所示：
- en: '[PRE28]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Second, the image has a lot of network tools installed as part of the image.
    You''ll notice that I''m installing the following packages:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，镜像中安装了许多网络工具。您会注意到我正在安装以下软件包：
- en: '`net-tools`: This provides network utilities to view and configure interfaces'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`net-tools`：提供网络实用程序以查看和配置接口'
- en: '`inetutils-ping`: This provides ping functionality'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inetutils-ping`：提供ping功能'
- en: '`curl`: This is to pull files from other network endpoints'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`curl`：这是从其他网络端点拉取文件'
- en: '`dnsutils`: This is to resolve DNS names and other DNS tracing'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`dnsutils`：这是用于解析DNS名称和其他DNS跟踪'
- en: '`ethtool`: This is to get information and stats from interfaces'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ethtool`：这是从接口获取信息和统计信息'
- en: '`tcpdump`: This is to do packet capture from within the container'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tcpdump`：这是从容器内进行数据包捕获'
- en: 'If you define this Dockerfile, as well as it''s required supporting files (an
    index page), you can build the image as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您定义了这个Dockerfile，以及它所需的支持文件（一个索引页面），您可以按以下方式构建图像：
- en: '[PRE29]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Note
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: There are a lot of options you can define when building an image. Take a look
    at `docker build --help` for more information.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建图像时，您可以定义很多选项。查看`docker build --help`以获取更多信息。
- en: Docker will then process the Dockerfile and, if successful, it will generate
    a `docker image` file, which you can then push to your container registry of choice
    for consumption on other hosts with `docker pull`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然后Docker将处理Dockerfile，如果成功，它将生成一个`docker image`文件，然后您可以将其推送到您选择的容器注册表，以便在其他主机上使用`docker
    pull`进行消费。
- en: 'Once built, you can run it and verify that the tools are working as expected.
    Having `ethtool` within the container means that we can easily determine the host-side
    VETH end of the VETH pair:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 构建完成后，您可以运行它并验证工具是否按预期工作。在容器内有`ethtool`意味着我们可以轻松确定VETH对的主机端VETH端：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can also perform local `tcpdump` actions to verify traffic reaching the
    container:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以执行本地的`tcpdump`操作来验证到达容器的流量：
- en: '[PRE31]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: As your use cases change, you can modify the Dockerfile to make it more specific
    to your own use cases. Being able to troubleshoot from within the container can
    be a big help when diagnosing connectivity issues.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您的用例的改变，您可以修改Dockerfile，使其更符合您自己的用例。在容器内进行故障排除时，能够进行故障排除可能会在诊断连接问题时提供很大帮助。
- en: Note
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: This image is just an example. There are many ways that this can be made more
    lightweight. I decided to use Ubuntu as the base image just for the sake of familiarity.
    The image described earlier is fairly heavy because of this.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个图像只是一个例子。有很多方法可以使它更加轻量级。我决定使用Ubuntu作为基础图像，只是为了熟悉起见。前面描述的图像因此相当沉重。
- en: Resetting the local Docker network database
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 重置本地Docker网络数据库
- en: With the advent of user-defined networks, users are able to define custom network
    types for their containers. Once defined, these networks persist through system
    reboots until they are deleted by an administrator. In order for this persistence
    to work, Docker needs some place to store information related to your user-defined
    networks. The answer is a database file that's local to the host. In some rare
    cases, this database can get out of sync with the current state of the containers
    on the host or become corrupt. This can cause issues related to deleting containers,
    deleting networks, and starting the Docker service. In this recipe, we'll show
    you how to remove the database to restore Docker back to its default network configuration.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 随着用户定义网络的出现，用户可以为其容器定义自定义网络类型。一旦定义，这些网络将在系统重新启动时持久存在，直到被管理员删除。为了使这种持久性工作，Docker需要一些地方来存储与您的用户定义网络相关的信息。答案是一个本地主机的数据库文件。在一些罕见的情况下，这个数据库可能与主机上容器的当前状态不同步，或者变得损坏。这可能会导致与删除容器、删除网络和启动Docker服务相关的问题。在这个教程中，我们将向您展示如何删除数据库以将Docker恢复到其默认网络配置。
- en: Getting ready
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: In this recipe, we'll be using a single Docker network host. It is assumed that
    Docker is installed and in its default configuration. You'll also need root-level
    access in order to inspect and change the host's networking and firewall configuration.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将使用单个Docker网络主机。假设Docker已安装并处于默认配置状态。您还需要root级别访问权限，以便检查和更改主机的网络和防火墙配置。
- en: How to do it…
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: Docker stores information related to user-defined networks in a database stored
    on the local host. This database is written to when networks are defined and read
    from when the service starts. In the rare case that this database gets out of
    sync or becomes corrupt, you can delete the database and restart the Docker service
    in order to reset the Docker user-defined networks and restore the three default
    network types (bridge, host, and none).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Docker将与用户定义网络相关的信息存储在本地主机上的数据库中。当定义网络时，会将数据写入该数据库，并在服务启动时从中读取。在极少数情况下，如果该数据库不同步或损坏，您可以删除数据库并重新启动Docker服务，以重置Docker用户定义网络并恢复三种默认网络类型（桥接、主机和无）。
- en: Note
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: 'Warning: Deleting this database deletes any and all Docker user-defined networks
    on the host. It is wise to only do this as a last resort and if you have the capability
    of recreating the networks that were previously defined. All other troubleshooting
    options should be pursued before attempting this and you should create a backup
    of the file before deleting it.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 警告：删除此数据库会删除主机上的任何Docker用户定义网络。最好只在万不得已且有能力重新创建先前定义的网络时才这样做。在尝试此操作之前，应该追求所有其他故障排除选项，并在删除之前创建文件的备份。
- en: 'The database is named `local-kv.db` and is stored in the path `/var/lib/network/files/`.
    Accessing and or deleting the file requires root-level access. For the purpose
    of this example, we''ll switch to the root user in order to make browsing this
    protected directory easier:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据库的名称为`local-kv.db`，存储在路径`/var/lib/network/files/`中。访问或删除该文件需要root级别访问权限。为了方便浏览这个受保护的目录，我们将切换到root用户：
- en: '[PRE32]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'To demonstrate what happens when we delete this file, let''s first create a
    new user-defined network and attach a container to it:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示删除此文件时会发生什么，让我们首先创建一个新的用户定义网络并将一个容器连接到它：
- en: '[PRE33]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let''s now delete the file `local-db.kv`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们删除文件`local-db.kv`：
- en: '[PRE34]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'While this has no immediate effect on the running container, it does prevent
    us from adding, removing, or starting new containers associated with this user-defined
    network:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这对正在运行的容器没有立即影响，但它阻止我们向与此用户定义网络关联的新容器添加、删除或启动：
- en: '[PRE35]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'After deleting the `boltdb` database file, `local-kv.db`, you''ll need to restart
    the Docker service in order for Docker to recreate it with the default settings:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 删除`boltdb`数据库文件`local-kv.db`后，您需要重新启动Docker服务，以便Docker使用默认设置重新创建它：
- en: '[PRE36]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now that the file is recreated, you''ll once again be able to create user-defined
    networks. However, any containers that were attached to previously configure user-defined
    network will now fail to start:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在文件已重新创建，您将再次能够创建用户定义网络。但是，以前连接到先前配置的用户定义网络的任何容器现在将无法启动：
- en: '[PRE37]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'This is expected behavior since Docker still believes that the container should
    have an interface on that network:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这是预期行为，因为Docker仍然认为容器应该在该网络上有一个接口：
- en: '[PRE38]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: To remedy this problem, you have two options. First, you can recreate the user-defined
    network named `mybridge` using the same configuration options from when it was
    initially provisioned. If this doesn't work, your only alternative is to delete
    the container and restart a new instance referencing a newly created or default
    network.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，你有两个选择。首先，你可以使用与最初配置时相同的配置选项重新创建名为`mybridge`的用户定义网络。如果这不起作用，你唯一的选择就是删除容器并重新启动一个新实例，引用新创建的或默认网络。
- en: Note
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意：…
- en: There has been some discussion on GitHub of newer versions of Docker supporting
    a `--force` flag when using the `docker network disconnect` subcommand. In version
    1.10, this parameter exists, but still doesn't like that the user-defined network
    does not exist. If you're running a newer version, this might be worth trying
    as well.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: ：GitHub上已经讨论过Docker的新版本是否支持在使用`docker network disconnect`子命令时使用`--force`标志。在1.10版本中，存在这个参数，但仍然不喜欢用户定义的网络不存在。如果你正在运行一个更新的版本，这也许值得一试。
