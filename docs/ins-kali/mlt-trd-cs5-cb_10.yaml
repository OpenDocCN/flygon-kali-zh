- en: Chapter 10. Parallel Programming Patterns
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章 并行编程模式
- en: 'In this chapter, we will review the common problems that a programmer often
    faces while trying to implement parallel workflow. You will learn about:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将回顾程序员在尝试实现并行工作流时经常面临的常见问题。您将学习以下内容：
- en: Implementing Lazy-evaluated shared states
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现延迟共享状态
- en: Implementing Parallel Pipeline with BlockingCollection
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用BlockingCollection实现并行管道
- en: Implementing Parallel Pipeline with TPL DataFlow
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用TPL DataFlow实现并行管道
- en: Implementing Map/Reduce with PLINQ
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用PLINQ实现Map/Reduce
- en: Introduction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Patterns in programming mean a concrete and standard solution to a given problem.
    Usually, programming patterns are the result of people gathering experience, analyzing
    the common problems, and providing solutions to these problems.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 编程中的模式意味着针对特定问题的具体和标准解决方案。通常，编程模式是人们积累经验、分析常见问题并提供解决方案的结果。
- en: Since parallel programming has existed for quite a long time, there are many
    different patterns for programming parallel applications. There are even special
    programming languages to make programming of specific parallel algorithms easier.
    However, this is where things start to become increasingly complicated. In this
    book, I will provide a starting point from where you will be able to study parallel
    programming further. We will review very basic, yet very useful, patterns that
    are quite helpful for many common situations in parallel programming.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于并行编程已经存在了很长时间，因此有许多不同的模式用于编程并行应用程序。甚至有专门的编程语言来使特定并行算法的编程更容易。然而，事情开始变得越来越复杂。在本书中，我将提供一个起点，让您能够进一步学习并行编程。我们将回顾一些非常基本但非常有用的模式，这些模式对并行编程中的许多常见情况非常有帮助。
- en: First is about using a **shared-state object** from multiple threads. I would
    like to emphasize that you should avoid it as much as possible. As we have discussed
    in previous chapters, shared state is really bad when you write parallel algorithms,
    but in many occasions it is inevitable. We will find out how to delay an actual
    computation of an object until it is needed, and how to implement different scenarios
    to achieve thread safety.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先是关于从多个线程使用**共享状态对象**。我想强调的是，尽量避免这样做。正如我们在之前的章节中讨论过的，当您编写并行算法时，共享状态真的很糟糕，但在许多情况下是不可避免的。我们将找出如何延迟对象的实际计算直到需要它，并且如何实现不同的场景以实现线程安全。
- en: The next two recipes will show how to create a structured parallel data flow.
    We will review a concrete case of a producer/consumer pattern, which is called
    as **Parallel Pipeline**. We are going to implement it by just blocking the collection
    first, and then see how helpful is another library from Microsoft for parallel
    programming—**TPL DataFlow**.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的两个示例将展示如何创建结构化的并行数据流。我们将回顾一个生产者/消费者模式的具体案例，称为**并行管道**。我们将首先通过阻塞集合来实现它，然后看看微软为并行编程提供的另一个库**TPL
    DataFlow**有多么有用。
- en: The last pattern that we will study is the **Map/Reduce** pattern. In the modern
    world, this name could mean very different things. Some people consider map/reduce
    not as a common approach to any problem but as a concrete implementation for large,
    distributed cluster computations. We will find out the meaning behind the name
    of this pattern and review some examples of how it might work in case of small
    parallel applications.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习的最后一个模式是**Map/Reduce**模式。在现代世界中，这个名字可能意味着非常不同的东西。有些人认为map/reduce不是解决任何问题的常见方法，而是大型分布式集群计算的具体实现。我们将找出这个模式背后的含义，并回顾一些例子，说明它在小型并行应用程序的情况下如何工作。
- en: Implementing Lazy-evaluated shared states
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现延迟共享状态
- en: This recipe shows how to program a Lazy-evaluated thread-safe shared state object.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例展示了如何编写一个延迟共享状态对象。
- en: Getting ready
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To start with this recipe, you will need a running Visual Studio 2012\. There
    are no other prerequisites. The source code for this recipe can be found at `BookSamples`
    `\Chapter10\Recipe1`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用这个示例，您需要运行Visual Studio 2012。没有其他先决条件。此示例的源代码可以在`BookSamples`的`Chapter10\Recipe1`中找到。
- en: How to do it...
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'For implementing Lazy-evaluated shared states, perform the following steps:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现延迟共享状态，请执行以下步骤：
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2012。创建一个新的C#**控制台应用程序**项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下面添加以下代码片段：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法中添加以下代码片段：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Run the program.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: The first example show why it is not safe to use the `UnsafeState` object with
    multiple accessing threads. We see that the `Construct` method was called several
    times, and different threads use different values, which is obviously not right.
    To fix this, we can use a lock when reading the value, and if it is not initialized,
    create it first. It will work, but using a lock with every read operation is not
    efficient. To avoid using locks every time, there is a traditional approach called
    the **double-checked locking** pattern. We check the value for the first time,
    and if is not null, we avoid unnecessary locking and just use the shared object.
    However, if it was not constructed yet, we use the lock and then check the value
    for the second time, because it could be initialized between our first check and
    the lock operation. If it is still not initialized, only then we compute the value.
    We can clearly see that this approach works with the second example—there is only
    one call to the `Construct` method, and the first-called thread defines the shared
    object state.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个示例展示了为什么不能在多个访问线程中使用`UnsafeState`对象是不安全的。我们看到`Construct`方法被多次调用，不同的线程使用不同的值，这显然是不正确的。为了解决这个问题，我们可以在读取值时使用锁定，如果它尚未初始化，则首先创建它。这样做是有效的，但是在每次读取操作时使用锁定并不高效。为了避免每次使用锁定，有一种传统的方法叫做**双重检查锁定**模式。我们首次检查值，如果不为空，我们避免不必要的锁定，直接使用共享对象。然而，如果尚未构造，我们使用锁定，然后第二次检查值，因为在我们的第一次检查和锁定操作之间它可能已经初始化。如果它仍未初始化，那么我们才计算值。我们可以清楚地看到这种方法适用于第二个示例——只有一次对`Construct`方法的调用，第一个调用的线程定义了共享对象的状态。
- en: Note
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that if the lazy- evaluated object implementation is thread-safe,
    it does not automatically mean that all its properties are thread-safe as well.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果延迟评估对象的实现是线程安全的，这并不意味着它的所有属性也是线程安全的。
- en: If you add, for example, an **int** public property to the `ValueToAccess` object,
    it will not be thread-safe; you still have to use interlocked constructs or locking
    to ensure thread safety.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果向`ValueToAccess`对象添加一个**int**公共属性，它将不是线程安全的；您仍然需要使用交错构造或锁定来确保线程安全。
- en: This pattern is very common, and that is why there are several classes in the
    Base Class Library to help us. First, we can use the `LazyInitializer.EnsureInitialized`
    method, which implements the double-checked locking pattern inside. However, the
    most comfortable option is to use the `Lazy<T>` class that allows us to have thread-safe
    Lazy-evaluated, shared state, out of the box. The next two examples show us that
    they are equivalent to the second one, and the program behaves the same. The only
    difference is that since `LazyInitializer` is a static class, we do not have to
    create a new instance of a class as we do in the case of `Lazy<T>`, and therefore
    the performance in the first case will be better in some scenarios.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式非常常见，这就是为什么基类库中有几个类来帮助我们。首先，我们可以使用`LazyInitializer.EnsureInitialized`方法，它在内部实现了双重检查锁定模式。然而，最舒适的选项是使用`Lazy<T>`类，它允许我们拥有开箱即用的线程安全的延迟评估、共享状态。接下来的两个示例向我们展示它们等同于第二个示例，程序的行为也是相同的。唯一的区别是，由于`LazyInitializer`是一个静态类，我们不必像在`Lazy<T>`的情况下创建一个新的类的实例，因此在某些情况下第一种情况的性能会更好。
- en: The last option is to avoid locking at all, if we do not care about the `Construct`
    method. If it is thread-safe and has no side effects and/or serious performance
    impacts, we can just run it several times but use only the first constructed value.
    The last example shows the described behavior, and we can achieve this result
    by using another `LazyInitializer.EnsureInitialized` method overload.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的选择是完全避免锁定，如果我们不关心`Construct`方法。如果它是线程安全的，没有副作用和/或严重的性能影响，我们可以多次运行它，但只使用第一次构造的值。最后一个示例展示了所描述的行为，我们可以通过使用另一个`LazyInitializer.EnsureInitialized`方法重载来实现这个结果。
- en: Implementing Parallel Pipeline with BlockingCollection
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用BlockingCollection实现并行管道
- en: This recipe will describe how to implement a specific scenario of a producer/consumer
    pattern, which is called Parallel Pipeline, using the standard `BlockingCollection`
    data structure.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本篇将描述如何使用标准的`BlockingCollection`数据结构实现生产者/消费者模式的特定场景，称为并行管道。
- en: Getting ready
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To begin this recipe, you will need a running Visual Studio 2012\. There are
    no other prerequisites. The source code for this recipe can be found at `7644_Code\Chapter10\Recipe2`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始本篇，您需要运行Visual Studio 2012。没有其他先决条件。本篇的源代码可以在`7644_Code\Chapter10\Recipe2`中找到。
- en: How to do it...
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤如下：
- en: 'To understand how to implement Parallel Pipeline using `BlockingCollection`,
    perform the following steps:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用`BlockingCollection`实现并行管道，请执行以下步骤：
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2012。创建一个新的C# **控制台应用程序**项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下面添加以下代码片段：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法内部添加以下代码片段：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Run the program.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: In the preceding example, we implement one of the most common parallel programming
    scenarios. Imagine that we have some data that has to pass through several computation
    stages, which take a significant amount of time. The latter computation requires
    the results of the former, so we cannot run them in parallel.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们实现了最常见的并行编程场景之一。想象一下，我们有一些数据必须通过几个计算阶段，这些阶段需要相当长的时间。后面的计算需要前面的结果，所以我们不能并行运行它们。
- en: If we had only one item to process, there would not be many possibilities to
    enhance the performance. However, if we run many items through the set of same
    computation stages, we can use a Parallel Pipeline technique. This means that
    we do not have to wait until all items pass through the first computation stage
    to go to the next one. It is enough to have just one item that finishes the stage,
    we move it to the next stage, and meanwhile the next item is being processed by
    the previous stage, and so on. As a result, we almost have parallel processing
    shifted by a time required for the first item to pass through the first computation
    stage.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们只有一个项目要处理，那么提高性能的可能性就不多。但是，如果我们通过相同的计算阶段运行许多项目，我们可以使用并行管道技术。这意味着我们不必等到所有项目通过第一个计算阶段才进入下一个阶段。只要有一个项目完成了阶段，我们就将其移动到下一个阶段，同时前一个阶段正在处理下一个项目，依此类推。结果几乎是并行处理，只是需要第一个项目通过第一个计算阶段所需的时间。
- en: Here, we use four collections for each processing stage, illustrating that we
    can process every stage in parallel as well. The first step that we do is to provide
    a possibility to cancel the whole process by pressing the *C* key. We create a
    cancellation token and run a separate task to monitor the *C* key. Then, we define
    our pipeline. It consists of three main stages. The first stage is where we put
    the initial numbers on the first four collections that serve as the item source
    to the latter pipeline. This code is inside the `Parallel.For` loop, which in
    turn is inside the `Parallel.Invoke` statement, as we run all the stages in parallel;
    the initial stage runs in parallel as well.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为每个处理阶段使用了四个集合，说明我们也可以并行处理每个阶段。我们做的第一步是通过按*C*键提供取消整个过程的可能性。我们创建一个取消令牌并运行一个单独的任务来监视*C*键。然后，我们定义我们的管道。它由三个主要阶段组成。第一个阶段是我们将初始数字放在作为后续管道的项目来源的前四个集合中。这段代码在`Parallel.For`循环内，而`Parallel.Invoke`语句内部，因为我们并行运行所有阶段；初始阶段也是并行运行的。
- en: The next stage is defining our pipeline elements. The logic is defined inside
    the `PipelineWorker` class. We initialize the worker with the input collection,
    provide a transformation function, and then run the worker in parallel with the
    other workers. This way we define two workers, or filters, because they filter
    the initial sequence. One of them turns an integer into a decimal value, and the
    second one turns a decimal to a string. Finally, the last worker just prints every
    incoming string to the console. Everywhere we provide a running thread ID to see
    how everything works. Besides this, we added artificial delays, so the items processing
    will be more natural, as we really use heavy computations.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一阶段是定义我们的管道元素。逻辑在`PipelineWorker`类中定义。我们使用输入集合初始化工作程序，提供转换函数，然后并行运行工作程序与其他工作程序。这样我们定义了两个工作程序，或者过滤器，因为它们过滤初始序列。其中一个将整数转换为十进制值，另一个将十进制转换为字符串。最后，最后一个工作程序只是将每个传入的字符串打印到控制台。我们在每个地方都提供了运行线程ID以查看一切是如何工作的。除此之外，我们添加了人为的延迟，以便项目处理更加自然，因为我们真的使用了繁重的计算。
- en: As a result, we see the exact expected behavior. First, some items are being
    created on the initial collections. Then, we see that the first filter starts
    to process them, and as they are being processed, the second filter starts to
    work, and finally the item goes to the last worker that prints it to the console.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，我们看到了确切的预期行为。首先，一些项目被创建在初始集合上。然后，我们看到第一个过滤器开始处理它们，随着它们被处理，第二个过滤器开始工作，最后项目进入最后一个工作程序，将其打印到控制台。
- en: Implementing Parallel Pipeline with TPL DataFlow
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用TPL DataFlow实现并行管道
- en: This recipe shows how to implement a Parallel Pipeline pattern with the help
    of TPL DataFlow library.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这个教程展示了如何使用TPL DataFlow库实现并行管道模式。
- en: Getting ready
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: To start with this recipe, you will need a running Visual Studio 2012\. There
    are no other prerequisites. The source code for this recipe could be found at
    `7644_Code\Chapter10\Recipe3`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个教程，你需要一个运行的Visual Studio 2012\. 没有其他先决条件。这个教程的源代码可以在`7644_Code\Chapter10\Recipe3`中找到。
- en: How to do it...
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'To understand how to implement Parallel Pipeline with TPL DataFlow, perform
    the following steps:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用TPL DataFlow实现并行管道，执行以下步骤：
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2012\. 创建一个新的C# **控制台应用程序**项目。
- en: Add references to the **Microsoft TPL DataFlow** NuGet package.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加对**Microsoft TPL DataFlow** NuGet包的引用。
- en: Right-click on the **References** folder in the project and select the **Manage
    NuGet Packages...** menu option.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 右键单击项目中的**References**文件夹，选择**管理NuGet包...**菜单选项。
- en: 'Now add your preferred references to the **Microsoft TPL DataFlow** NuGet package.
    You can use the search option in the **Manage NuGet Packages** dialog as follows:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在添加你喜欢的**Microsoft TPL DataFlow** NuGet包的引用。你可以使用**管理NuGet包**对话框中的搜索选项，如下所示：
- en: '![How to do it...](img/7644OT_10_01.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![如何做...](img/7644OT_10_01.jpg)'
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下面添加以下代码片段：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法中添加以下代码片段：
- en: '[PRE8]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Run the program.
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In the previous recipe, we have implemented a Parallel Pipeline pattern to process
    items through sequential stages. It is quite a common problem, and one of the
    proposed ways to program such algorithms is using a TPL DataFlow library from
    Microsoft. It is distributed via **NuGet**, and is easy to install and use in
    your application.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个教程中，我们已经实现了一个并行管道模式，通过顺序阶段处理项目。这是一个很常见的问题，而且编写这样的算法的一种提议的方法是使用微软的TPL DataFlow库。它通过**NuGet**分发，很容易在你的应用程序中安装和使用。
- en: The TPL DataFlow library contains different type of blocks that can be connected
    with each other in different ways and form complicated processes that can be partially
    parallel and sequential where needed. To see some of the available infrastructure,
    let's implement the previous scenario with the help of the TPL DataFlow library.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: TPL DataFlow库包含不同类型的块，可以以不同的方式连接在一起，形成可以部分并行和顺序执行的复杂过程。要查看一些可用的基础设施，让我们使用TPL
    DataFlow库来实现前面的场景。
- en: First, we define the different blocks that will be processing our data. Please
    note that these blocks have different options that can be specified during their
    construction; they can be very important. For example, we pass the cancellation
    token into every block we define, and when we signal the cancellation, all of
    them will stop working.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们定义将处理我们的数据的不同块。请注意，这些块在构建过程中可以指定不同的选项，这些选项可能非常重要。例如，我们将取消标记传递给我们定义的每个块，并且当我们发出取消信号时，所有这些块都将停止工作。
- en: We start our process with `BufferBlock`. This block holds items to pass it to
    the next blocks in the flow. We restrict it to the five-items capacity, specifying
    the `BoundedCapacity` option value. This means that when there will be five items
    in this block, it will stop accepting new items until one of the existing items
    pass to the next blocks.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`BufferBlock`开始我们的过程。这个块保存项目以便将其传递给流中的下一个块。我们将其限制为五个项目的容量，指定`BoundedCapacity`选项值。这意味着当这个块中有五个项目时，它将停止接受新项目，直到现有项目中的一个传递到下一个块。
- en: The next block type is `TransformBlock`. This block is intended for a data transformation
    step. Here we define two transformation blocks, one of them creates decimals from
    integers, and the second one creates a string from a decimal value. There is a
    `MaxDegreeOfParallelism` option for this block, specifying the maximum simultaneous
    worker threads.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个块类型是`TransformBlock`。这个块用于数据转换步骤。在这里，我们定义了两个转换块，其中一个从整数创建十进制数，另一个从十进制值创建一个字符串。对于这个块，有一个`MaxDegreeOfParallelism`选项，指定最大同时工作线程数。
- en: The last block is the `ActionBlock` type. This block will run a specified action
    on every incoming item. We use this block to print our items to the console.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个块是`ActionBlock`类型。这个块将在每个传入的项目上运行指定的操作。我们使用这个块将我们的项目打印到控制台上。
- en: Now, we link these blocks together with the help of the `LinkTo` methods. Here
    we have an easy sequential data flow, but it is possible to create schemes that
    are more complicated. Here we also provide `DataflowLinkOptions` with the `PropagateCompletion`
    property set to `true`. This means that when the step completes, it will automatically
    propagate its results and exceptions to the next stage. Then we start adding items
    to the buffer block in parallel, calling the block's `Complete` method, when we
    finish adding new items. Then we wait for the last block to complete. In case
    of a cancellation, we handle `OperationCancelledException` and cancel the whole
    process.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们使用`LinkTo`方法将这些块连接在一起。在这里，我们有一个简单的顺序数据流，但也可以创建更复杂的方案。在这里，我们还提供了`DataflowLinkOptions`，其中`PropagateCompletion`属性设置为`true`。这意味着当步骤完成时，它将自动传播其结果和异常到下一个阶段。然后我们并行地开始向缓冲块添加项目，当完成添加新项目时，调用块的`Complete`方法。然后我们等待最后一个块完成。在取消的情况下，我们处理`OperationCancelledException`并取消整个过程。
- en: Implementing Map/Reduce with PLINQ
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PLINQ实现Map/Reduce
- en: This recipe will describe how to implement the **Map**/**Reduce** pattern while
    using PLINQ.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例将描述如何在使用PLINQ时实现**Map**/**Reduce**模式。
- en: Getting ready
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: To begin with this recipe, you will need a running Visual Studio 2012\. There
    are no other prerequisites. The source code for this recipe can be found at `7644_Code\Chapter10\Recipe4`.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始这个示例，您需要运行Visual Studio 2012。没有其他先决条件。此示例的源代码可以在`7644_Code\Chapter10\Recipe4`中找到。
- en: How to do it...
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'To understand how to implement Map/Reduce with PLINQ, perform the following
    steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何使用PLINQ实现Map/Reduce，请执行以下步骤：
- en: Start Visual Studio 2012\. Create a new C# **Console Application** project.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动Visual Studio 2012。创建一个新的C# **控制台应用程序**项目。
- en: 'In the `Program.cs` file, add the following `using` directives:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program.cs`文件中，添加以下`using`指令：
- en: '[PRE9]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Add the following code snippet below the `Main` method:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法下面添加以下代码片段：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the following code snippet inside the `Main` method:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Main`方法中添加以下代码片段：
- en: '[PRE11]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Add the following code snippet after the `Program` class definition:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`Program`类定义之后添加以下代码片段：
- en: '[PRE12]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Run the program.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行程序。
- en: How it works...
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The `Map`/`Reduce` functions are another important parallel programming pattern.
    It is suitable for a small program and large multi-server computations. The meaning
    of this pattern is that you have two special functions to apply to your data.
    The first of them is the `Map` function. It takes a set of initial data in a key/value
    list form and produces another key/value sequence, transforming the data to the
    comfortable format for further processing. Then we use another function called
    `Reduce`**.** The `Reduce` function takes the result of the `Map` function and
    transforms it to a smallest possible set of data that we actually need. To understand
    how this algorithm works, let's look through the recipe.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`Map`/`Reduce`函数是另一种重要的并行编程模式。它适用于小型程序和大型多服务器计算。这种模式的含义是你有两个特殊的函数来应用于你的数据。其中一个是`Map`函数。它以键/值列表形式的一组初始数据，并产生另一个键/值序列，将数据转换为进一步处理的舒适格式。然后我们使用另一个名为`Reduce`的函数。`Reduce`函数接受`Map`函数的结果，并将其转换为我们实际需要的最小可能数据集。要了解这个算法是如何工作的，让我们通过这个示例来看一下。'
- en: 'First, we define a relatively large text in the string variable: `textToParse`.
    We need this text to run our queries on. Then we define our `Map`/`Reduce` implementation
    as a PLINQ extension method in the `PLINQExtensions` class. We use `SelectMany`
    to transform the initial sequence to the sequence we need by applying the `Map`
    function. This function produces several new elements from one sequence element.
    Then we choose how we group the new sequence with the `keySelector` function,
    and we use `GroupBy` with this key to produce an intermediate key/value sequence.
    The last thing we do is applying `Reduce` to the resulting grouped sequence to
    get the result.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们在字符串变量`textToParse`中定义了一个相对较大的文本。我们需要这个文本来运行我们的查询。然后我们将我们的`Map`/`Reduce`实现定义为`PLINQExtensions`类中的PLINQ扩展方法。我们使用`SelectMany`将初始序列转换为我们需要的序列，通过应用`Map`函数。这个函数从一个序列元素中产生几个新元素。然后我们选择如何使用`keySelector`函数对新序列进行分组，并使用`GroupBy`与这个键来产生一个中间键/值序列。我们做的最后一件事就是对产生的分组序列应用`Reduce`来得到结果。
- en: In our first example, we split the text into separate words, and then we chop
    each word into character sequences with the help of the `Map` function, and group
    the result by the character value. The `Reduce` function finally transforms the
    sequence into a key value pair, where we have a character and a number for the
    times it was used in the text ordered by the usage. Therefore, we are able to
    count each character appearance in the text in parallel (since we use PLINQ to
    query the initial data).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一个例子中，我们将文本分割成单独的单词，然后我们使用`Map`函数将每个单词切割成字符序列，并按字符值对结果进行分组。`Reduce`函数最终将序列转换为键值对，其中我们有一个字符和一个数字，表示它在文本中被使用的次数，按使用次数排序。因此，我们能够并行计算文本中每个字符的出现次数（因为我们使用PLINQ来查询初始数据）。
- en: The next example is quite similar, but now we use PLINQ to filter the sequence
    leaving only the words containing our search pattern, and we then get all those
    words sorted by their usage in the text.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个例子非常相似，但现在我们使用PLINQ来过滤序列，只留下包含我们搜索模式的单词，然后按它们在文本中的使用情况对所有这些单词进行排序。
- en: Finally, the last example uses file I/O. We save the sample text on the disk,
    splitting it into two files. Then we define the `Map` function as producing a
    number of strings from the directory name, which are all the words from all the
    lines in all text files in the initial directory. Then we group those words by
    the first letter (filtering out the empty strings) and use reduce to see which
    letter is most often used as the first word letter in the text. What is nice is
    that we can easily change this program to be distributed by just using other implementations
    of map and reduce functions, and we still are able to use PLINQ with them to make
    our program easy to read and maintain.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个例子使用文件I/O。我们将示例文本保存在磁盘上，将其分成两个文件。然后我们将`Map`函数定义为从目录名称生成多个字符串，这些字符串都是初始目录中所有文本文件中所有行中的所有单词。然后我们通过第一个字母对这些单词进行分组（过滤掉空字符串），并使用reduce来查看哪个字母在文本中最常用作第一个单词的字母。好处在于我们可以很容易地通过使用其他map和reduce函数的实现来将此程序分布，并且我们仍然能够使用PLINQ来使我们的程序易于阅读和维护。
