- en: Reactive Microservices
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式微服务
- en: In this chapter, we'll implement reactive microservices using Spring Boot, Spring
    Stream, Apache Kafka, and Apache Avro. We'll make use of the existing Booking
    microservice to implement the message producer, or in other words, generate the
    event. We'll also create a new microservice (Billing) for consuming the messages
    produced by the updated Booking microservice, or we can say, for consuming the
    event generated by the Booking microservice. We'll also discuss the tradeoffs
    between REST-based microservice and event-based microservice.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用Spring Boot、Spring Stream、Apache Kafka和Apache Avro来实现响应式微服务。我们将利用现有的预订微服务来实现消息生产者，或者换句话说，生成事件。我们还将创建一个新的微服务（结算）来消费更新的预订微服务产生的消息，或者可以说，来消费预订微服务生成的事件。我们还将讨论基于REST的微服务和基于事件的微服务之间的权衡。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An overview of the reactive microservice architecture
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应式微服务架构概述
- en: Producing an event
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成事件
- en: Consuming the event
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 消费事件
- en: An overview of the reactive microservice architecture
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应式微服务架构概述
- en: So far, the microservices we have developed are based on REST. We have used
    REST for both internal (inter-microservice, where one microservice communicates
    with another microservice in the same system) and external (through the public
    API) communication. At present, REST fits best for the public API. Are there other
    alternatives for inter-microservices communication? Is it the best approach to
    implement the REST for inter-microservices communication? We'll discuss all this
    in this section.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们开发的微服务都是基于REST的。我们已经在内部（微服务之间的通信，在同一系统中一个微服务与另一个微服务通信）和外部（通过公共API）通信中使用了REST。目前，REST
    最适合公共API。在微服务之间的通信中是否有其他替代方案？实现REST用于微服务之间的通信是否是最佳方法？我们将在本节中讨论所有这些问题。
- en: You can build microservices that are purely asynchronous. You can build microservice-based
    systems that would communicate based on events. There is a tradeoff between REST
    and event-based microservices. REST provides synchronous communication, whereas
    reactive microservices are based on asynchronous communication (asynchronous message
    passing).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以构建纯异步的微服务。您可以构建基于事件通信的微服务系统。REST和基于事件的微服务之间存在权衡。REST提供同步通信，而响应式微服务基于异步通信（异步消息传递）。
- en: We can use asynchronous communication for inter-microservice communication.
    Based on the requirement and functionality, we can choose REST or asynchronous
    message passing. Consider the example case of a user placing an order, which makes
    a very good case for implementing reactive microservices. On successful order
    placement, the inventory service would recalculate the available items; account
    service would maintain the transaction, correspondence service would send the
    messages (SMS, emails, and so on) to all involved users such as a customer and
    a supplier. In this case, more than one microservice may perform distinct operations
    (inventory, accounts, messaging, and so on) based on an operation (order placement)
    performed in one microservice. Now, just think if all these communications were
    synchronous. Instead, reactive communication, with asynchronous message passing,
    provides efficient use of hardware resources, non-blocking, low latency, and high
    throughput operations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用异步通信进行微服务之间的通信。根据需求和功能，我们可以选择REST或异步消息传递。考虑用户下订单的案例，这是一个非常适合实现响应式微服务的案例。在成功下订单后，库存服务将重新计算可用物品；账户服务将维护交易；通讯服务将向所有涉及用户发送消息（短信、电子邮件等），如客户和供应商。在这种情况下，一个以上的微服务可能根据一个微服务中的操作（下订单）执行不同的操作（库存、账户、消息等）。现在，想象一下如果所有这些通信都是同步的。相反，响应式通信，通过异步消息传递，提供了对硬件资源的高效利用，非阻塞，低延迟和高吞吐量的操作。
- en: We can primarily divide the microservice implementations into two groups—REST-based
    microservices and event-based/message-driven microservices. Reactive microservices
    are event-based.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将微服务实现主要分为两组——基于REST的微服务和基于事件/消息驱动的微服务。响应式微服务是基于事件的。
- en: '![](img/42dd3919-b165-4b8a-b0d2-ec2cf4aacd8b.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](img/42dd3919-b165-4b8a-b0d2-ec2cf4aacd8b.png)'
- en: Reactive manifesto
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式宣言
- en: Reactive microservices are based on the Reactive Manifesto ([https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/)).
    The Reactive Manifesto comprises of four principles, which we will now discuss.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式微服务基于响应式宣言（[https://www.reactivemanifesto.org/](https://www.reactivemanifesto.org/)）。响应式宣言包括四个原则，我们现在将讨论这些原则。
- en: Responsive
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 响应性
- en: Responsiveness is the characteristic of serving a request in a timely manner.
    It is measured by the latency. The producer should provide the response in time
    and the consumer should receive the response in time. A failure in the chain of
    operations performed for a request should not cause a delay in response or failure.
    Therefore, it is very important for availability of services.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 响应性是及时提供请求的特征。它由延迟来衡量。生产者应该及时提供响应，消费者应该及时接收响应。对于请求执行的操作链中的故障不应导致响应延迟或失败。因此，服务的可用性非常重要。
- en: Resilient
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性
- en: A resilient system is a robust system. The resilient principle is in line with
    the responsive principle. A microservice, despite failures, should provide the
    response, and if one instance of the microservice gets down, the request should
    be served by another node of the same microservice. A resilient microservice system
    is capable of handling all kinds of failures. All services should be monitored
    for detecting failures and all failures should be handled. We have used the service
    discovery eureka for monitoring and Hystrix for circuit breaker pattern implementation
    in the last chapter.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一个具有弹性的系统是一个强大的系统。弹性原则与响应原则一致。一个微服务应该在发生故障时提供响应，如果一个微服务实例宕机，请求应该由同一微服务的另一个节点提供服务。一个具有弹性的微服务系统能够处理各种故障。所有服务都应该被监视以检测故障，并且所有故障都应该被处理。在上一章中，我们已经使用了服务发现eureka进行监控，以及Hystrix进行断路器模式的实现。
- en: Elastic
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性
- en: A reactive system is elastic if it reacts to the load by utilizing the hardware
    and other resources optimally. It can bring up new instances of a microservice
    or microservices if the demand increases and vice versa. On special sales days,
    such as Black Friday, Christmas, Diwali, and so on, a reactive shopping application
    would instantiate a greater number of microservice nodes in order to share the
    load of increased requests. On normal days, the shopping application may not require
    a bigger number of resources than on average, hence it can reduce the number of
    nodes. Therefore, for effectively using the hardware, a reactive system should
    be elastic in nature.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个响应式系统能够根据负载情况充分利用硬件和其他资源，那么它就是弹性的。如果需求增加，它可以启动新的微服务实例，反之亦然。在特殊的促销日，如黑色星期五、圣诞节、排灯节等，一个响应式的购物应用将实例化更多的微服务节点，以分担增加的请求负载。在正常日子里，购物应用可能不需要比平均水平更多的资源，因此它可以减少节点数量。因此，为了有效利用硬件，一个响应式系统应该具有弹性。
- en: Message driven
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消息驱动
- en: A reactive system would sit idle if it has nothing to do; it would not use the
    resources unnecessarily if it was not supposed to do anything. An event or a message
    may make a reactive microservice active and then start working (reacting) on the
    received event/message (request). Ideally, communication should be asynchronous
    and non-blocking by nature. A reactive system uses messages for communication—asynchronous
    message passing. In this chapter, we'll use the Apache Kafka for messaging.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个响应式系统没有任务要执行，它将保持空闲；如果它没有要执行的任务，它将不会不必要地使用资源。一个事件或消息可能会使一个响应式微服务变得活跃，然后开始对接收到的事件/消息（请求）进行工作（响应）。理想情况下，通信应该是异步的，并且天生非阻塞。响应式系统使用消息进行通信——异步消息传递。在本章中，我们将使用Apache
    Kafka进行消息传递。
- en: Ideally, a reactive programming language is the best way to implement the reactive
    microservices. A reactive programming language provides asynchronous and non-blocking
    calls. Java could also be used for developing the reactive microservices with
    the use of Java streaming feature. Kafka would be used for messaging with Kafka's
    Java libraries and plugins. We have already implemented service discovery and
    registry service (Eureka Server-monitoring), the proxy server (Zuul) with Eureka
    for elasticity, and Hystrix with Eureka for Circuit Breaker (resilient and responsive).
    In the next section, we will implement the message-driven microservices.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，响应式编程语言是实现响应式微服务的最佳方式。响应式编程语言提供异步和非阻塞调用。Java也可以用于开发响应式微服务，利用Java流特性。Kafka将使用Kafka的Java库和插件进行消息传递。我们已经实现了服务发现和注册服务（Eureka
    Server-监控），代理服务器（Zuul）与Eureka实现弹性，以及Hystrix与Eureka实现断路器（弹性和响应）。在下一节中，我们将实现消息驱动的微服务。
- en: Implementing reactive microservices
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施响应式微服务
- en: Reactive microservice performs operations in response to events. We'll make
    changes in our code to produce and consume events for our sample implementation.
    Although we'll create a single event, a microservice can have multiple producers
    or consumer events. Also, a microservice can have both producer and consumer events.
    We'll make use of the existing functionality in the Booking microservice that
    creates the new booking (`POST /v1/booking`). This will be our event source and
    would make use of Apache Kafka for sending this event. Other microservices can
    consume this event by listening to the event. On successful booking call, the
    Booking microservice will produce the Kafka topic (event) `amp.bookingOrdered`.
    We'll create a new microservice Billing (in the same way in which we created the
    other microservices like Booking) for consuming this event (`amp.bookingOrdered`).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 响应式微服务根据事件执行操作。我们将对我们的代码进行更改，以便为我们的示例实现产生和消费事件。虽然我们将创建一个单一事件，但微服务可以有多个生产者或消费者事件。此外，微服务可以同时具有生产者和消费者事件。我们将利用Booking微服务中创建新预订（`POST
    /v1/booking`）的现有功能。这将是我们的事件源，并将利用Apache Kafka发送此事件。其他微服务可以通过监听事件来消费此事件。在成功预订调用时，Booking微服务将产生Kafka主题（事件）`amp.bookingOrdered`。我们将创建一个新的微服务Billing（与我们创建Booking等其他微服务的方式相同）来消费此事件（`amp.bookingOrdered`）。
- en: Producing an event
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产生事件
- en: An object would be sent to Kafka once an event is produced. Similarly, Kafka
    would send this produced object to all listeners (microservices). In short, the
    produced object travels over the network. Therefore, we need serialization support
    for these objects. We'll make use of Apache Avro for data serialization. It defines
    the data structure (schema) in the JSON format and also provides a plugin for
    both Maven and Gradle to generate Java classes using JSON schema. Avro works well
    with Kafka because both Avro and Kafka are Apache products and align well with
    each other for integration.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦事件被产生，一个对象将被发送到Kafka。同样，Kafka将把这个产生的对象发送给所有的监听者（微服务）。简而言之，产生的对象在网络上传输。因此，我们需要对这些对象进行序列化支持。我们将利用Apache
    Avro进行数据序列化。它以JSON格式定义数据结构（模式），并为Maven和Gradle提供插件，以使用JSON模式生成Java类。Avro与Kafka配合良好，因为Avro和Kafka都是Apache产品，并且它们在集成方面相互契合。
- en: Let's start with defining the schema that represents the object sent over the
    network when a new booking is created. As shared earlier for producing the event,
    we'll make use of the existing Booking microservice. We'll create the Avro schema
    file `bookingOrder.avro` in `src/main/resources/avro` directory in Booking microservice.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从定义代表创建新预订时通过网络发送的对象的模式开始。如前所述，为了生成事件，我们将利用现有的预订微服务。我们将在预订微服务的`src/main/resources/avro`目录中创建Avro模式文件`bookingOrder.avro`。
- en: 'The `bookingOrder.avro` file will look something like this:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`bookingOrder.avro`文件看起来会像这样：'
- en: '[PRE0]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Here, `namespace` represents the package `type` which is `record` represents
    the class, `name` represents the name of the class, and `fields` represent the
    properties of the class. When we generate the Java class using this schema, it
    would create the new Java class `BookingOrder.java` in the `com.packtpub.mmj.booking.domain.valueobject.avro
    package`, with all properties defined in `fields`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`namespace`表示`type`的包`type`，它表示类，`name`表示类的名称，`fields`表示类的属性。当我们使用这个模式生成Java类时，它会在`com.packtpub.mmj.booking.domain.valueobject.avro`包中创建新的Java类`BookingOrder.java`，其中包含`fields`中定义的所有属性。
- en: In `fields` too, we have `name` and `type` that represent the name and type
    of the property. For all fields, we have used the input `type` as `string`. You
    could also use other primitive types such as `boolean`, `int`, and `double`. Also,
    you can use complex types such as `record` (used in the preceding code snippet),
    `enum`, `array`, and `map`. The `default` type represents the default value of
    the property.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在`fields`中，我们也有`name`和`type`，它们表示属性的名称和类型。对于所有字段，我们都使用了`string`作为输入`type`。您还可以使用其他原始类型，如`boolean`、`int`和`double`。您还可以使用复杂类型，如`record`（在前面的代码片段中使用）、`enum`、`array`和`map`。`default`类型表示属性的默认值。
- en: 'The preceding schema would be used to generate the Java code. We''ll make use
    of the `avro-maven-plugin` to generate the Java source files from the preceding
    Avro schema. We''ll add this plugin in the plugins section of the child `pom`
    files (service''s `pom.xml`):'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 上述模式将用于生成Java代码。我们将利用`avro-maven-plugin`从前面的Avro模式生成Java源文件。我们将在子`pom`文件（服务的`pom.xml`）的插件部分中添加此插件：
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can see that in the `configuration` section, `sourceDirectory` and `outputDirectory`
    are configured. Therefore, when we run `mvn package`, it would create the `BookingOrder.java`
    file in the `com.packtpub.mmj.booking.domain.valueobject.avro` package located
    inside the configured `outputDirectory`.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，在`configuration`部分，配置了`sourceDirectory`和`outputDirectory`。因此，当我们运行`mvn
    package`时，它会在配置的`outputDirectory`内的`com.packtpub.mmj.booking.domain.valueobject.avro`包中创建`BookingOrder.java`文件。
- en: Now that our Avro schema and the generated Java source is available to us, we'll
    add Maven dependencies that are required for producing the event.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了Avro模式和生成的Java源代码，我们将添加所需用于生成事件的Maven依赖项。
- en: 'Adding dependency in the Booking microservice `pom.xml` file:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在预订微服务的`pom.xml`文件中添加依赖项：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Here, we have added the three main dependencies: `avro`, `spring-cloud-stream`,
    and `kafka-clients`. Also, we have added stream integration with Kafka (`spring-cloud-starter-stream-kafka`)
    and stream support schema (`spring-cloud-stream-schema`).'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们添加了三个主要依赖项：`avro`、`spring-cloud-stream`和`kafka-clients`。此外，我们还添加了与Kafka的流集成（`spring-cloud-starter-stream-kafka`）和流支持模式（`spring-cloud-stream-schema`）。
- en: Now, since our dependencies are in place, we can start writing producer implementation.
    Booking microservice would send the `amp.bookingOrdered` event to the Kafka stream.
    We'll declare the message channel for this purpose. It can be done either using
    `Source.OUTPUT` with the `@InboundChannelAdapter` annotation or by declaring the
    Java interface. We'll use the interface approach because it is easier to understand
    and correlate.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的依赖关系已经就位，我们可以开始编写生产者实现。预订微服务将向Kafka流发送`amp.bookingOrdered`事件。我们将为此声明消息通道。可以使用`Source.OUTPUT`与`@InboundChannelAdapter`注解或声明Java接口来完成。我们将使用接口方法，因为它更容易理解和相关联。
- en: We'll create the `BookingMessageChannels.java` message channel in the `com.packtpub.mmj.booking.domain.service.message`
    package. Here, we can add all the message channels that are required. Since we
    are using the single event for sample implementation, we have to just declare
    the `bookingOrderOutput`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在`com.packtpub.mmj.booking.domain.service.message`包中创建`BookingMessageChannels.java`消息通道。在这里，我们可以添加所有需要的消息通道。由于我们只是使用单个事件进行示例实现，我们只需要声明`bookingOrderOutput`。
- en: 'The `BookingMessageChannels.java` file will look something like this:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingMessageChannels.java`文件看起来会像这样：'
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Here, we have just defined the name of the message channel, `bookingOrderOutput`,
    using the `@Output annotation`. We also need to configure this message channel
    in `application.yaml`. We''ll use this name to define the Kafka topic in the `application.yaml`
    file:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们刚刚使用`@Output`注解定义了消息通道的名称`bookingOrderOutput`。我们还需要在`application.yaml`中配置这个消息通道。我们将使用这个名称在`application.yaml`文件中定义Kafka主题：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the Kafka topic name `amp.bookingOrdered` is given that is bound to the
    `bookingOrderOutput` message channel. (Kafka topic name could be any string. We
    prefix `amp` to denote asynchronous message passing; you can use Kafka topic name
    with or without prefix.)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，给出了Kafka主题名称`amp.bookingOrdered`，它绑定到`bookingOrderOutput`消息通道。(Kafka主题名称可以是任何字符串。我们使用`amp`前缀来表示异步消息传递；您可以使用带有或不带有前缀的Kafka主题名称。)
- en: We also need a message converter that would send the `BookingOrder` object to
    Kafka. For this purpose, we'll create an `@Bean` annotation that would return
    the Spring `MessageConverter` in the Booking service main class.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个消息转换器，它将`BookingOrder`对象发送到Kafka。为此，我们将在预订服务的主类中创建一个`@Bean`注解，该注解将返回Spring`MessageConverter`。
- en: 'The `@Bean` annotation in `BookingApp.class` file will look something like
    this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingApp.class`文件中的`@Bean`注解看起来会像这样：'
- en: '[PRE5]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You may add more beans based on required schemas for respective schemas. We
    have not yet configured the Kafka server in `application.yaml`, which is set to
    `localhost`. Let's do it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 根据所需模式添加更多bean。我们尚未在`application.yaml`中配置Kafka服务器，该服务器设置为`localhost`。让我们来做吧。
- en: 'Configuring the Kafka server in the `application.yaml` file:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在`application.yaml`文件中配置Kafka服务器：
- en: '[PRE6]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Here, we have configured `localhost` for both `zkNodes` and `brokers`; you can
    change it to the host where Kafka is hosted.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们为`zkNodes`和`brokers`都配置了`localhost`；您可以将其更改为托管Kafka的主机。
- en: We are ready for sending the `amp.bookingOrdered` Kafka topic to the Kafka server.
    For simplicity, we'll directly add a `produceBookingOrderEvent` method that takes
    the `Booking` class as a parameter in the `BookingServiceImpl.java` class (you
    need to add the same method signature in `BookingService.java`). Let's see the
    code first.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已准备好将`amp.bookingOrdered` Kafka主题发送到Kafka服务器。为简单起见，我们将直接在`BookingServiceImpl.java`类中添加一个接受`Booking`类作为参数的`produceBookingOrderEvent`方法（您需要在`BookingService.java`中添加相同的方法签名）。让我们先看看代码。
- en: 'The `BookingServiceImpl.java` file is as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`BookingServiceImpl.java`文件如下：'
- en: '[PRE7]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here, we have declared the `bookingMessageChannel` object that is autowired
    using the `setter` method. The Spring cloud stream annotation `@EnableBinding`
    binds the `bookingOrderOutput` message channel declared in the `BookingMessageChannels`
    class.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们声明了`bookingMessageChannel`对象，该对象使用`setter`方法进行自动装配。Spring Cloud Stream注释`@EnableBinding`绑定了在`BookingMessageChannels`类中声明的`bookingOrderOutput`消息通道。
- en: The `produceBookingOrderEvent` method is added, which takes the `booking` object.
    Inside the `produceBookingOrderEvent` method, the `BookingOrder` object properties
    are set using the `booking` object. Then the message is built using the `bookingOrder`
    object. At the end, the message is sent to Kafka using `bookingMessageChannels`.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 添加了`produceBookingOrderEvent`方法，该方法接受`booking`对象。在`produceBookingOrderEvent`方法内部，使用`booking`对象设置了`BookingOrder`对象的属性。然后使用`bookingOrder`对象构建消息。最后，使用`bookingMessageChannels`将消息发送到Kafka。
- en: The `produceBookingOrderEvent` method is called after the booking is successfully
    persisted in DB.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在成功将预订持久化到数据库后，将调用`produceBookingOrderEvent`方法。
- en: 'To test this functionality, you can run the Booking microservice with the following
    command:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要测试此功能，您可以使用以下命令运行预订微服务：
- en: '[PRE8]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Ensure that the Kafka and Zookeeper applications are running properly on hosts
    and ports defined in the `application.yaml` file for performing successful testing.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Kafka和Zookeeper应用程序在`application.yaml`文件中定义的主机和端口上正常运行，以执行成功的测试。
- en: 'Then, fire a post request (`http://<host>:<port>/v1/booking`) for a booking
    through any REST client with the following payload:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过任何REST客户端使用以下有效负载对预订进行预订后，发送POST请求（`http://<host>:<port>/v1/booking`）。
- en: '[PRE9]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'It would produce the `amp.bookingOrdered` Kafka topic (event) as shown in following
    logs published on the Booking microservice console:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 它将生成如下日志所示的`amp.bookingOrdered` Kafka主题（事件）：
- en: '[PRE10]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Similarly, the Kafka console would display the following message that confirms
    that the message is received successfully by Kafka:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，Kafka控制台将显示以下消息，以确认Kafka已成功接收消息：
- en: '[PRE11]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can now move to code the consumer of the previously generated event.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以转到编写先前生成的事件的消费者代码。
- en: Consuming the event
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 消费事件
- en: First, we'll add the new module `billing-service` in the parent `pom.xml` file
    and create the Billing microservice the way other microservices are created in
    [Chapter 5](b1f93b4e-3475-4d8a-8c9f-697b0fd4410c.xhtml), *Deployment and Testing*.
    Most of the reactive code we have written for the Booking microservice will be
    reused for a Billing microservice, such as Avro schema and `pom.xml` entries.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将在父`pom.xml`文件中添加新模块`billing-service`，并按照[第5章](b1f93b4e-3475-4d8a-8c9f-697b0fd4410c.xhtml)中其他微服务的创建方式创建计费微服务，*部署和测试*。我们为预订微服务编写的大部分响应式代码将被重用于计费微服务，例如Avro模式和`pom.xml`条目。
- en: We'll add the Avro schema in Billing microservice in same way we have added
    it in Booking microservice. Since schema namespace (package name) would be the
    same `booking` package in Billing microservice, we need to add value `com.packtpub.mmj.booking`
    in the `scanBasePackages` property of `@SpringBootApplication` annotation in `BillingApp.java`.
    It would allow the spring context to scan booking package also.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将以与在预订微服务中添加的方式相同的方式在计费微服务中添加Avro模式。由于模式命名空间（包名）将在计费微服务中与预订包相同，因此我们需要在`BillingApp.java`的`@SpringBootApplication`注释的`scanBasePackages`属性中添加值`com.packtpub.mmj.booking`。这将允许Spring上下文扫描预订包。
- en: We'll add following dependencies in the Billing microservice `pom.xml`, which
    is the same as we have added in Booking microservice.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在计费微服务的`pom.xml`中添加以下依赖项，这与我们在预订微服务中添加的相同。
- en: 'The `pom.xml` file for Billing microservice is as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 计费微服务的`pom.xml`文件如下：
- en: '[PRE12]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can refer to the booking service dependency paragraph for the reason behind
    the addition of these dependencies.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考预订服务依赖段落，了解添加这些依赖项的原因。
- en: 'Next, we''ll add the message channel in the Billing microservice, as shown
    here:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将在计费微服务中添加消息通道，如下所示：
- en: '[PRE13]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Here, we are adding the input message channel opposite to the message channel
    in the booking service where we have added the output message channel. Note that
    `bookingOrderInput` is an input message channel marked with the `@input` annotation.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们正在添加输入消息通道，与我们在预订服务中添加输出消息通道相反。请注意，`bookingOrderInput`是一个带有`@input`注释的输入消息通道。
- en: 'Next, we want to configure the `bookingOrderInput` channel to the Kafka topic
    `amp.BookingOrdered`. We''ll modify the `application.yaml` for this purpose:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要将`bookingOrderInput`通道配置到Kafka主题`amp.BookingOrdered`。我们将修改`application.yaml`以实现此目的：
- en: '[PRE14]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Here, the Kafka topic is added to the `bookingOrderInput` channel using the
    destination property. We''ll also configure Kafka in the Billing microservice
    (`application.yaml`) the way we have configured it in the Booking microservice:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用destination属性将Kafka主题添加到`bookingOrderInput`通道。我们还将在计费微服务（`application.yaml`）中配置Kafka，方式与我们在预订微服务中配置的方式相同：
- en: '[PRE15]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, we'll add the event listener that would listen to the stream bound to the
    `bookingOrderInput` message channel using the `@StreamListener` annotation available
    in the Spring Cloud Steam library.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将添加事件监听器，该监听器将使用Spring Cloud Steam库中的`@StreamListener`注解监听绑定到`bookingOrderInput`消息通道的流。
- en: 'The `EventListener.java` file is as follows:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`EventListener.java`文件如下：'
- en: '[PRE16]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here, you can also add other event listeners. For example, we'll simply log
    the received object. You may add an additional functionality based on the requirement;
    you can even produce a new event again for further processing if required. For
    example, you can produce the event to a restaurant for which a new booking is
    requested, and so on, through a service that manages restaurant communication.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您还可以添加其他事件监听器。例如，我们将简单记录接收到的对象。根据需求，您可以添加额外的功能；如果需要，甚至可以再次产生新的事件进行进一步处理。例如，您可以为请求新预订的餐厅产生事件，并通过管理餐厅通信的服务等等。
- en: 'Finally, we can enable the binding of the `bookingOrderInput` message channel
    to stream using the `@EnableBinding` annotation of the Spring Cloud Stream library
    and create the bean of the `EventListener` class created in `BillingApp.java`
    (the main class of the `billing-service` module) as shown here:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以使用Spring Cloud Stream库的`@EnableBinding`注解启用`bookingOrderInput`消息通道的绑定，并在`BillingApp.java`（`billing-service`模块的主类）中创建`EventListener`类的bean，如下所示：
- en: 'The `BillingApp.java` will look something like this:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`BillingApp.java`将如下所示：'
- en: '[PRE17]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, you can start the Billing microservice and raise a new `POST/v1/booking`
    REST call. You can find the received object in the Billing microservice log, as
    shown here:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以启动计费微服务并发起新的`POST/v1/booking` REST调用。您可以在计费微服务日志中找到接收到的对象，如下所示：
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: References
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: 'The following links will give you more information:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 以下链接将为您提供更多信息：
- en: '**Apache Kafka**: [https://kafka.apache.org/](https://kafka.apache.org/)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Kafka**：[https://kafka.apache.org/](https://kafka.apache.org/)'
- en: '**Apache Avro**: [https://avro.apache.org/](https://avro.apache.org/)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Avro**：[https://avro.apache.org/](https://avro.apache.org/)'
- en: '**Avro Specs**: [https://avro.apache.org/docs/current/spec.html](https://avro.apache.org/docs/current/spec.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Avro规范**：[https://avro.apache.org/docs/current/spec.html](https://avro.apache.org/docs/current/spec.html)'
- en: '**Spring Cloud Stream**: [https://cloud.spring.io/spring-cloud-stream/](https://cloud.spring.io/spring-cloud-stream/)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Spring Cloud Stream**：[https://cloud.spring.io/spring-cloud-stream/](https://cloud.spring.io/spring-cloud-stream/)'
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you learned about reactive microservices or event-based microservices.
    These services work on messages/events rather than REST calls over HTTP. They
    provide asynchronous communication among services, which provide non-blocking
    communication and allow better usage of resources and failure handling.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您了解了响应式微服务或基于事件的微服务。这些服务使用消息/事件而不是HTTP上的REST调用。它们提供服务之间的异步通信，提供非阻塞通信，并允许更好地利用资源和处理故障。
- en: We have made use of Apache Avro and Apache Kafka with Spring Cloud Stream libraries
    for implementing the reactive microservices. We have added the code in the existing
    `booking-service` module for producing the `amp.bookingOrdered` messages under
    the Kafka topic and added new module `billing-service` for consuming the same
    event.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们利用Apache Avro和Apache Kafka与Spring Cloud Stream库来实现响应式微服务。我们在现有的`booking-service`模块中添加了代码，用于在Kafka主题下生成`amp.bookingOrdered`消息，并添加了新模块`billing-service`来消费相同的事件。
- en: You may want to add a new event for producers and consumers. You can add multiple
    consumers for an event or create a chain of events as exercise.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望为生产者和消费者添加新事件。您可以为一个事件添加多个消费者，或者创建一系列事件作为练习。
- en: In the next chapter, you will learn to secure the microservices with respect
    to authentication and authorization. We will also explore the other aspects of
    microservice securities.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何在身份验证和授权方面保护微服务。我们还将探讨微服务安全的其他方面。
