- en: Getting Started with Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 Kubernetes
- en: 'We''ve learned the benefits that containers can bring us, but what if we need
    to scale out our services for business needs? Is there a way to build services
    across multiple machines without dealing with cumbersome network and storage settings?
    Also, is there any other easy way to manage and roll out our microservices by
    different service cycle? That''s how Kubernetes comes into play. In this chapter,
    we''ll learn:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了容器可以为我们带来的好处，但是如果我们需要根据业务需求扩展我们的服务怎么办？有没有一种方法可以在多台机器上构建服务，而不必处理繁琐的网络和存储设置？此外，是否有其他简单的方法来管理和推出我们的微服务，以适应不同的服务周期？这就是
    Kubernetes 的作用。在本章中，我们将学习：
- en: Kubernetes concept
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 概念
- en: Kubernetes components
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 组件
- en: Kubernetes resources and their configuration file
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 资源及其配置文件
- en: How to launch the kiosk application by Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何通过 Kubernetes 启动 kiosk 应用程序
- en: Understanding Kubernetes
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Kubernetes
- en: Kubernetes is a platform for managing application containers across multiple
    hosts. It provides lots of management features for container-oriented applications,
    such as auto scaling, rolling deployment, compute resource, and volume management.
    Same as the nature of containers, it's designed to run anywhere, so we're able
    to run it on a bare metal, in our data center, on the public cloud, or even hybrid
    cloud.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是一个用于管理跨多台主机的应用容器的平台。它为面向容器的应用程序提供了许多管理功能，例如自动扩展、滚动部署、计算资源和卷管理。与容器的本质相同，它被设计为可以在任何地方运行，因此我们可以在裸机上、在我们的数据中心、在公共云上，甚至是混合云上运行它。
- en: 'Kubernetes considers most of the operational needs for application containers.
    The highlights are:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 考虑了应用容器的大部分操作需求。重点是：
- en: Container deployment
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器部署
- en: Persistent storage
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久存储
- en: Container health monitoring
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器健康监控
- en: Compute resource management
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算资源管理
- en: Auto-scaling
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展
- en: High availability by cluster federation
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过集群联邦实现高可用性
- en: Kubernetes is a perfect match for microservices. With Kubernetes, we can create
    a `Deployment` to rollout, rollover, or roll back selected containers ([Chapter
    7](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e), *Continous Delivery*).
    Containers are considered as ephemeral. We can mount the volume into a container
    to preserve the data in a single host world. In the cluster world, a container
    might be scheduled to run on any host. How do we make the volume mounting work
    as permanent storage seamlessly? Kubernetes **Volumes** and **Persistent Volumes**
    are introduced to solve that problem ([Chapter 4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Working with Storage and Resources*). The lifetime of containers might be short.
    They may be killed or stopped anytime when they exceed the limit of resource,
    how do we ensure our services always serve a certain number of containers? **ReplicationController**
    or **ReplicaSet** in Kubernetes will ensure a certain number of group of containers
    are up. Kubernetes even supports **liveness probe** to help you define your application
    health. For better resource management, we can also define the maximum capacity
    on Kubernetes nodes and the resource limit for each group of containers (a.k.a
    **pod**). Kubernetes scheduler will then select a node that fulfills the resource
    criteria to run the containers. We'll learn this in [Chapter 4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Working with Storage and Resources*. Kubernetes provides an optional horizontal
    pod auto-scaling feature. With this feature, we could scale a pod horizontally
    by resource or custom metrics. For those advanced readers, Kubernetes is designed
    with high availability (**HA**). We are able to create multiple master nodes from
    preventing single point of failure.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes非常适合微服务。使用Kubernetes，我们可以创建“Deployment”来部署、滚动或回滚选定的容器（[第7章](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e)，*持续交付*）。容器被视为临时的。我们可以将卷挂载到容器中，以在单个主机世界中保留数据。在集群世界中，容器可能被调度在任何主机上运行。我们如何使卷挂载作为永久存储无缝工作？Kubernetes引入了**Volumes**和**Persistent
    Volumes**来解决这个问题（[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)，*使用存储和资源*）。容器的生命周期可能很短。当它们超出资源限制时，它们可能随时被杀死或停止，我们如何确保我们的服务始终为一定数量的容器提供服务？Kubernetes中的**ReplicationController**或**ReplicaSet**将确保一定数量的容器组处于运行状态。Kubernetes甚至支持**liveness
    probe**来帮助您定义应用程序的健康状况。为了更好地管理资源，我们还可以为Kubernetes节点定义最大容量和每组容器（即**pod**）的资源限制。Kubernetes调度程序将选择满足资源标准的节点来运行容器。我们将在[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)，*使用存储和资源*中学习这一点。Kubernetes提供了一个可选的水平pod自动缩放功能。使用此功能，我们可以按资源或自定义指标水平扩展pod。对于那些高级读者，Kubernetes设计了高可用性（**HA**）。我们可以创建多个主节点来防止单点故障。
- en: Kubernetes components
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes组件
- en: 'Kubernetes includes two major players:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes包括两个主要组件：
- en: '**Masters**: The Master is the heart of Kubernetes, which controls and schedules
    all the activities in the cluster'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主节点**：主节点是Kubernetes的核心，它控制和调度集群中的所有活动'
- en: '**Nodes**: Nodes are the workers that run our containers'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点**：节点是运行我们的容器的工作节点'
- en: Master components
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Master组件
- en: The master includes the API server, Controller Manager, scheduler, and etcd.
    All the components can run on different hosts with clustering. However, from a
    learning perspective, we'll make all the components run on the same node.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Master包括API服务器、控制器管理器、调度程序和etcd。所有组件都可以在不同的主机上进行集群运行。然而，从学习的角度来看，我们将使所有组件在同一节点上运行。
- en: '![](../images/00032.jpeg)Master components'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00032.jpeg)Master组件'
- en: API server (kube-apiserver)
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: API服务器（kube-apiserver）
- en: The API server provides an HTTP/HTTPS server, which provides a RESTful API for
    all the components in the Kubernetes master. For example, we could GET resource
    status, such as pod, POST to create a new resource and also watch a resource.
    API server reads and updates etcd, which is Kubernetes' backend data store.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: API服务器提供HTTP/HTTPS服务器，为Kubernetes主节点中的所有组件提供RESTful API。例如，我们可以获取资源状态，如pod，POST来创建新资源，还可以观察资源。API服务器读取和更新etcd，这是Kubernetes的后端数据存储。
- en: Controller Manager (kube-controller-manager)
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制器管理器（kube-controller-manager）
- en: The Controller Manager controls lots of different things in the cluster. Replication
    Controller Manager ensures all the ReplicationControllers run on the desired container
    amount. Node Controller Manager responds when the nodes go down, it will then
    evict the pods. Endpoint Controller is used to associate the relationship between
    services and pods. Service Account and Token Controller are used to control default
    account and API access tokens.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器管理器在集群中控制许多不同的事物。复制控制器管理器确保所有复制控制器在所需的容器数量上运行。节点控制器管理器在节点宕机时做出响应，然后会驱逐pod。端点控制器用于关联服务和pod之间的关系。服务账户和令牌控制器用于控制默认账户和API访问令牌。
- en: etcd
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: etcd
- en: etcd is an open source distributed key-value store ([https://coreos.com/etcd](https://coreos.com/etcd)).
    Kubernetes stores all the RESTful API objects here. etcd is responsible for storing
    and replicating data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: etcd是一个开源的分布式键值存储（[https://coreos.com/etcd](https://coreos.com/etcd)）。Kubernetes将所有RESTful
    API对象存储在这里。etcd负责存储和复制数据。
- en: Scheduler (kube-scheduler)
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调度器（kube-scheduler）
- en: Scheduler decides which node is suitable for pods to run on, according to the
    resource capacity or the balance of the resource utilization on the node. It also
    considers spreading the pods in the same set to different nodes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 调度器根据节点的资源容量或节点上资源利用的平衡来决定适合pod运行的节点。它还考虑将相同集合中的pod分散到不同的节点。
- en: Node components
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点组件
- en: Node components need to be provisioned and run on every node, which report the
    runtime status of the pod to the master.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 节点组件需要在每个节点上进行配置和运行，向主节点报告pod的运行时状态。
- en: '![](../images/00033.jpeg)Node components'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00033.jpeg)节点组件'
- en: Kubelet
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubelet
- en: Kubelet is a major process in the nodes, which reports node activities back
    to kube-apiserver periodically, such as pod health, node health, and liveness
    probe. As the preceding graph shows, it runs containers via container runtimes,
    such as Docker or rkt.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Kubelet是节点中的一个重要进程，定期向kube-apiserver报告节点活动，如pod健康、节点健康和活动探测。正如前面的图表所示，它通过容器运行时（如Docker或rkt）运行容器。
- en: Proxy (kube-proxy)
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理（kube-proxy）
- en: Proxy handles the routing between pod load balancer (a.k.a. **service**) and
    pods, it also provides the routing from outside to service. There are two proxy
    modes, userspace and iptables. Userspace mode creates large overhead by switching
    kernel space and user space. Iptables mode, on the other hand, is the latest default
    proxy mode. It changes iptables **NAT** in Linux to achieve routing TCP and UDP
    packets across all containers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 代理处理pod负载均衡器（也称为**服务**）和pod之间的路由，它还提供了从外部到服务的路由。有两种代理模式，用户空间和iptables。用户空间模式通过在内核空间和用户空间之间切换来创建大量开销。另一方面，iptables模式是最新的默认代理模式。它改变Linux中的iptables
    **NAT**以实现在所有容器之间路由TCP和UDP数据包。
- en: Docker
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker
- en: As described in [Chapter 2](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *DevOps with Container*, Docker is a container implementation. Kubernetes uses
    Docker as a default container engine.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如[第2章](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e)中所述，*使用容器进行DevOps*，Docker是一个容器实现。Kubernetes使用Docker作为默认的容器引擎。
- en: Interaction between Kubernetes master and nodes
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes主节点与节点之间的交互
- en: In the following graph, the client uses **kubectl** to send requests to the
    API server; API server responds to the request, pushes and pulls the object information
    from etcd. Scheduler determines which node should be assigned to do the tasks
    (for example, run pods). **Controller Manager** monitors the running tasks and
    responds if any undesired state occurs. On the other hand, the **API server**
    fetches the logs from pods by kubelet, and is also a hub between other master
    components.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，客户端使用**kubectl**向API服务器发送请求；API服务器响应请求，从etcd中推送和拉取对象信息。调度器确定应该分配给哪个节点执行任务（例如，运行pod）。**控制器管理器**监视运行的任务，并在发生任何不良状态时做出响应。另一方面，**API服务器**通过kubelet从pod中获取日志，并且还是其他主节点组件之间的中心。
- en: '![](../images/00034.jpeg)Interaction between master and nodes'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与主节点和节点之间的交互
- en: Getting started with Kubernetes
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Kubernetes
- en: In this section, we will learn how to set up a small single-node cluster at
    the start. Then we'll get to learn how to interact with Kubernetes via its command-line
    tool--kubectl. We will go through all the important Kubernetes API objects and
    their expression in YAML format, which is the input to kubectl, then kubectl will
    send the request to the API server accordingly.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何在开始时设置一个小型单节点集群。然后我们将学习如何通过其命令行工具--kubectl与Kubernetes进行交互。我们将学习所有重要的Kubernetes
    API对象及其在YAML格式中的表达，这是kubectl的输入，然后kubectl将相应地向API服务器发送请求。
- en: Preparing the environment
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备环境
- en: The easiest way to start is running minikube ([https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)),
    which is a tool to run Kubernetes on a single node locally. It supports to run
    on Windows, Linux, and macOS. In the following example, we'll run on macOS. Minikube
    will launch a VM with Kubernetes installed. Then we'll be able to interact with
    it via kubectl.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 开始的最简单方法是运行minikube ([https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube))，这是一个在本地单节点上运行Kubernetes的工具。它支持在Windows、Linux和macOS上运行。在下面的示例中，我们将在macOS上运行。Minikube将启动一个安装了Kubernetes的虚拟机。然后我们将能够通过kubectl与其交互。
- en: Note that minikube is not suitable for production or any heavy load environment.
    There are some limitations by its single node nature. We'll learn how to run a
    real cluster in [Chapter 9](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on AWS* and [Chapter 10](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on GCP* instead.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，minikube不适用于生产环境或任何重负载环境。由于其单节点特性，存在一些限制。我们将在[第9章](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e)
    *在AWS上运行Kubernetes*和[第10章](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e)
    *在GCP上运行Kubernetes*中学习如何运行一个真正的集群。
- en: Before installing minikube, we'll have to install Homebrew ([https://brew.sh/](https://brew.sh/))
    and VirtualBox ([https://www.virtualbox.org/](https://www.virtualbox.org/)) first.
    Homebrew is a useful package manager in macOS. We can easily install Homebrew
    via the `/usr/bin/ruby -e "$(curl -fsSL [https://raw.githubusercontent.com/Homebrew/install/master/install)](https://raw.githubusercontent.com/Homebrew/install/master/install))"`
    command, and download VirtualBox from the Oracle website and click to install
    it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装minikube之前，我们必须先安装Homebrew ([https://brew.sh/](https://brew.sh/))和VirtualBox
    ([https://www.virtualbox.org/](https://www.virtualbox.org/))。Homebrew是macOS中一个有用的软件包管理器。我们可以通过`/usr/bin/ruby
    -e "$(curl -fsSL [https://raw.githubusercontent.com/Homebrew/install/master/install)](https://raw.githubusercontent.com/Homebrew/install/master/install))"`命令轻松安装Homebrew，并从Oracle网站下载VirtualBox并点击安装。
- en: 'Then it''s time to start! We can install minikube via `brew cask install minikube`:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是启动的时间！我们可以通过`brew cask install minikube`来安装minikube：
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'After minikube is installed, we now can start the cluster:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完minikube后，我们现在可以启动集群了：
- en: '[PRE1]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This will launch a Kubernetes cluster locally. At the time of writing, the latest
    version is `v.1.6.4` minikube. Proceed to start a VM named minikube in VirtualBox.
    Then it will be setting up `kubeconfig`, which is a configuration file to define
    the context and authentication settings of the cluster.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在本地启动一个Kubernetes集群。在撰写时，最新版本是`v.1.6.4` minikube。继续在VirtualBox中启动名为minikube的VM。然后将设置`kubeconfig`，这是一个用于定义集群上下文和认证设置的配置文件。
- en: 'With `kubeconfig`, we''re able to switch to different clusters via the `kubectl`
    command. We could use the `kubectl config view` command to see current settings
    in `kubeconfig`:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`kubeconfig`，我们能够通过`kubectl`命令切换到不同的集群。我们可以使用`kubectl config view`命令来查看`kubeconfig`中的当前设置：
- en: '[PRE2]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here we know we're currently using minikube context with the same name of cluster
    and user. Context is a combination of authentication information and cluster connection
    information. You could use `kubectl config use-context $context` to force switch
    the context if you have more than one context.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们知道我们当前正在使用与集群和用户名称相同的minikube上下文。上下文是认证信息和集群连接信息的组合。如果您有多个上下文，可以使用`kubectl
    config use-context $context`来强制切换上下文。
- en: 'In the end, we''ll need to enable `kube-dns` addon in minikube. `kube-dns`
    is a DNS service in Kuberentes:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们需要在minikube中启用`kube-dns`插件。`kube-dns`是Kuberentes中的DNS服务：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: kubectl
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: kubectl
- en: '`kubectl` is the command to control Kubernetes cluster manager. The most general
    usage is to check the version of cluster:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`是控制Kubernetes集群管理器的命令。最常见的用法是检查集群的版本：'
- en: '[PRE4]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We then know our server version is up to date, which is the latest at the time
    of writing—version 1.6.4\. The general syntax of `kubectl` is:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后知道我们的服务器版本是最新的，在撰写时是最新的版本1.6.4。 `kubectl`的一般语法是：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `command` indicates the operation you want to perform. If you just type
    `kubectl help` in the Terminal, it will show the supported commands. `type` means
    the resource type. We'll learn major resource types in the next section. `name`
    is how we name our resources. It's always good practice to have clear and informational
    naming along the way. For the `flags`, if you type `kubectl options`, it will
    show all the flags you could pass on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '`command`表示您要执行的操作。如果您只在终端中键入`kubectl help`，它将显示支持的命令。`type`表示资源类型。我们将在下一节中学习主要的资源类型。`name`是我们命名资源的方式。沿途始终保持清晰和信息丰富的命名是一个好习惯。对于`flags`，如果您键入`kubectl
    options`，它将显示您可以传递的所有标志。'
- en: '`kubectl` comes in handy and we could always add `--help` to get more detailed
    information for the specific command. For example:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`非常方便，我们总是可以添加`--help`来获取特定命令的更详细信息。例如：'
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We then get the full supported option in the `kubectl logs` command.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们得到了`kubectl logs`命令中的完整支持选项。
- en: Kubernetes resources
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes资源
- en: Kubernetes objects are the entries in the cluster, which are stored in etcd.
    They represent the desired state of your cluster. When we create an object, we
    send the request to API Server by kubectl or RESTful API. API Server will store
    the state into etcd and interact with other master components to ensure the object
    exists. Kubernetes uses namespace to isolate the objects virtually, according
    to different teams, usages, projects, or environments. Every object has its own
    name and unique ID. Kubernetes also supports labels and annotation to let us tag
    our objects. Labels especially could be used to group the objects together.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes对象是集群中的条目，存储在etcd中。它们代表了集群的期望状态。当我们创建一个对象时，我们通过kubectl或RESTful API向API服务器发送请求。API服务器将状态存储到etcd中，并与其他主要组件交互，以确保对象存在。Kubernetes使用命名空间在虚拟上隔离对象，根据不同的团队、用途、项目或环境。每个对象都有自己的名称和唯一ID。Kubernetes还支持标签和注释，让我们对对象进行标记。标签尤其可以用于将对象分组在一起。
- en: Kubernetes objects
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes对象
- en: Object spec describes the desired state of Kubernetes objects. Most of the time,
    we write an object spec, and send the spec to the API Server via kubectl. Kubernetes
    will try to fulfill that desired state and update object status.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 对象规范描述了Kubernetes对象的期望状态。大多数情况下，我们编写对象规范，并通过kubectl将规范发送到API服务器。Kubernetes将尝试实现该期望状态并更新对象状态。
- en: 'Object spec could be written in YAML ([http://www.yaml.org/](http://www.yaml.org/))
    or JSON ([http://www.json.org/](http://www.json.org/)[)](http://www.json.org/)).
    YAML is more common in the Kubernetes world. We''ll use YAML format to write object
    specs in the rest of this book. The following code block shows a YAML-formatted
    spec fragment:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 对象规范可以用YAML（[http://www.yaml.org/](http://www.yaml.org/)）或JSON（[http://www.json.org/](http://www.json.org/)）编写。在Kubernetes世界中，YAML更常见。在本书的其余部分中，我们将使用YAML格式来编写对象规范。以下代码块显示了一个YAML格式的规范片段：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Namespace
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名空间
- en: 'Kubernetes namespace is considered to be an isolation as multiple virtual clusters.
    Objects in different namespaces are invisible to each other. This is useful when
    different teams or projects are sharing the same cluster. Most of the resources
    are under a namespace (a.k.a. namespaced resources); however, some generic resources,
    such as nodes or namespace itself, don''t belong to any namespace. Kubernetes
    has three namespaces by default:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes命名空间被视为多个虚拟集群的隔离。不同命名空间中的对象对彼此是不可见的。当不同团队或项目共享同一个集群时，这是非常有用的。大多数资源都在一个命名空间下（也称为命名空间资源）；然而，一些通用资源，如节点或命名空间本身，不属于任何命名空间。Kubernetes默认有三个命名空间：
- en: default
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: default
- en: kube-system
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-system
- en: kube-public
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kube-public
- en: Without explicitly assigning namespace to the namespaced resource, it will be
    located in the namespace under current context. If we never add a new namespace,
    a default namespace will be used.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有明确地为命名空间资源分配命名空间，它将位于当前上下文下的命名空间中。如果我们从未添加新的命名空间，将使用默认命名空间。
- en: Kube-system namespaces are used by the objects created by the Kubernetes system,
    such as addon, which are the pods or services that implement cluster features,
    such as dashboard. Kube-public namespaces are newly introduced in Kubernetes 1.6,
    which is used by a beta controller manager (BootstrapSigner [https://kubernetes.io/docs/admin/bootstrap-tokens](https://kubernetes.io/docs/admin/bootstrap-tokens)),
    putting the signed cluster location information into the `kube-public` namespace,
    so this information could be visible to authenticated/unauthenticated users.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: kube-system命名空间被Kubernetes系统创建的对象使用，例如插件，这些插件是实现集群功能的pod或服务，例如仪表板。kube-public命名空间是在Kubernetes
    1.6中新引入的，它被一个beta控制器管理器（BootstrapSigner [https://kubernetes.io/docs/admin/bootstrap-tokens](https://kubernetes.io/docs/admin/bootstrap-tokens)）使用，将签名的集群位置信息放入`kube-public`命名空间，以便认证/未认证用户可以看到这些信息。
- en: In the following sections, all the namespaced resources will be located in a
    default namespace. Namespace is also very important for resource management and
    role. We'll introduce more in [Chapter 8](part0188.html#5J99O0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Cluster Administration*.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，所有的命名空间资源都将位于默认命名空间中。命名空间对于资源管理和角色也非常重要。我们将在第8章《集群管理》中介绍更多内容。
- en: Name
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 名称
- en: Every object in Kubernetes owns its own name. Object name in one resource is
    uniquely identified within the same namespace. Kubernetes uses object name as
    part of a resource URL to API Server, so it must be the combination of lower case
    of alphanumeric characters, dash and dot, less than 254 characters. Besides object
    name, Kubernetes also assigns a unique ID (UID) to every object to distinguish
    historical occurrences of similar entities.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的每个对象都拥有自己的名称。一个资源中的对象名称在同一命名空间内是唯一标识的。Kubernetes使用对象名称作为资源URL到API服务器的一部分，因此它必须是小写字母、数字字符、破折号和点的组合，长度不超过254个字符。除了对象名称，Kubernetes还为每个对象分配一个唯一的ID（UID），以区分类似实体的历史发生。
- en: Label and selector
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 标签和选择器
- en: 'Labels are a set of key/pair values, used to attach to objects. Labels are
    designed to specify meaningful, identifying information for the object. Common
    usage is micro-service name, tier, environment, and software version. Users could
    define meaningful labels that could be used with selector later. Labels syntax
    in object spec is:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 标签是一组键/值对，用于附加到对象。标签旨在为对象指定有意义的标识信息。常见用法是微服务名称、层级、环境和软件版本。用户可以定义有意义的标签，以便稍后与选择器一起使用。对象规范中的标签语法是：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Along with label, label selector is used to filter the set of objects. Separated
    by commas, multiple requirements will be joined by the `AND` logical operator.
    There are two ways to filter:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标签，标签选择器用于过滤对象集。用逗号分隔，多个要求将由`AND`逻辑运算符连接。有两种过滤方式：
- en: Equality-based requirement
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于相等性的要求
- en: Set-based requirement
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于集合的要求
- en: 'Equality-based requirement supports the operator of `=`, `==`, and `!=`. For
    example, if selector is `chapter=2,version!=0.1`, the result will be **object
    C**. If requirement is `version=0.1`, the result will be **object A** and **object
    B**. If we write the requirement in supported object spec, it''ll be as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 基于相等性的要求支持`=`，`==`和`!=`运算符。例如，如果选择器是`chapter=2,version!=0.1`，结果将是**对象C**。如果要求是`version=0.1`，结果将是**对象A**和**对象B**。如果我们在支持的对象规范中写入要求，将如下所示：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../images/00035.jpeg)Selector example'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00035.jpeg)选择器示例'
- en: 'Set-based requirement supports `in`, `notin`, and `exists` (for key only).
    For example, if requirement is `chapter in (3, 4),version`, then object A will
    be returned. If requirement is `version notin (0.2), !author_info`, the result
    will be **object A** and **object B**. The following is an example if we write
    to the object spec that supports set-based requirement:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基于集合的要求支持`in`，`notin`和`exists`（仅针对键）。例如，如果要求是`chapter in (3, 4),version`，那么对象A将被返回。如果要求是`version
    notin (0.2), !author_info`，结果将是**对象A**和**对象B**。以下是一个示例，如果我们写入支持基于集合的要求的对象规范：
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The requirements of `matchLabels` and `matchExpressions` are combined together.
    It means the filtered objects need to be true on both requirements.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '`matchLabels`和`matchExpressions`的要求被合并在一起。这意味着过滤后的对象需要在两个要求上都为真。'
- en: We will learn along the way in this chapter with ReplicationController, Service,
    ReplicaSet, and Deployment.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中学习使用ReplicationController、Service、ReplicaSet和Deployment。
- en: Annotation
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注释
- en: 'Annotation is a set of user-specified key/value pairs, used for specifying
    non-identifying metadata. With annotation acts such as normal tagging, for example,
    a user could add timestamp, commit hash, or build number to annotation. Some of
    the kubectl commands support the `--record` option to record the commands that
    make the changes to the objects to the annotation. Another use case of annotation
    is storing the configuration, such as Kubernetes Deployments ([https://kubernetes.io/docs/concepts/workloads/controllers/deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment))
    or Critical Add-On pods ([https://coreos.com/kubernetes/docs/latest/deploy-addons.html](https://coreos.com/kubernetes/docs/latest/deploy-addons.html)).
    Annotation syntax is as follows in the metadata section:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 注释是一组用户指定的键/值对，用于指定非标识性元数据。使用注释可以像普通标记一样，例如，用户可以向注释中添加时间戳、提交哈希或构建编号。一些 kubectl
    命令支持 `--record` 选项，以记录对注释对象进行更改的命令。注释的另一个用例是存储配置，例如 Kubernetes 部署（[https://kubernetes.io/docs/concepts/workloads/controllers/deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment)）或关键附加组件
    pods（[https://coreos.com/kubernetes/docs/latest/deploy-addons.html](https://coreos.com/kubernetes/docs/latest/deploy-addons.html)）。注释语法如下所示，位于元数据部分：
- en: '[PRE11]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Namespace, name, label, and annotation are located in the metadata section of
    object spec. Selector is located in the spec section of selector-supported resources,
    such as ReplicationController, service, ReplicaSet, and Deployment.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间、名称、标签和注释位于对象规范的元数据部分。选择器位于支持选择器的资源的规范部分，例如 ReplicationController、service、ReplicaSet
    和 Deployment。
- en: Pods
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pods
- en: Pod is the smallest deployable unit in Kubernetes. It can contain one or more
    containers. Most of the time, we just need one container per pod. In some special
    cases, more than one container is included in the same pod, such as Sidecar containers
    ([http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html](http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html)).
    The containers in the same pod run in a shared context, on the same node, sharing
    the network namespace and shared volumes. Pod is also designed as mortal. When
    a pod dies for some reasons, such as getting killed by Kubernetes controller when
    lacking resources, it won't recover by itself. Instead, Kubernetes uses controllers
    to create and manage the desired state of pods for us.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 是 Kubernetes 中最小的可部署单元。它可以包含一个或多个容器。大多数情况下，我们只需要一个 pod 中的一个容器。在一些特殊情况下，同一个
    pod 中包含多个容器，例如 Sidecar 容器（[http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html](http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html)）。同一
    pod 中的容器在共享上下文中运行，在同一节点上共享网络命名空间和共享卷。Pod 也被设计为有生命周期的。当 pod 因某些原因死亡时，例如由于缺乏资源而被
    Kubernetes 控制器杀死时，它不会自行恢复。相反，Kubernetes 使用控制器为我们创建和管理 pod 的期望状态。
- en: 'We could use `kubectl explain <resource>` to get the detailed description for
    the resource by command line. It will show up the fields that the resource supports:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubectl explain <resource>` 命令来获取资源的详细描述。它将显示资源支持的字段：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'In the following example, we''ll show how to create two containers in a pod,
    and demonstrate how they access each other. Please note that it''s neither a meaningful
    nor classic Sidecar pattern example. Those are used in very specific scenarios.
    The following is just an example of how we access other containers within a pod:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们将展示如何在一个 pod 中创建两个容器，并演示它们如何相互访问。请注意，这既不是一个有意义的经典的 Sidecar 模式示例。这些模式只在非常特定的场景中使用。以下只是一个示例，演示了如何在
    pod 中访问其他容器：
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '![](../images/00036.jpeg)Containers inside a Pod are visible via localhost'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00036.jpeg)Pod 中的容器可以通过 localhost 进行访问'
- en: This spec will create two containers, `web` and `centos`. Web is a nginx container
    ([https://hub.docker.com/_/nginx/](https://hub.docker.com/_/nginx/)). Expose container
    port `80` by default, since centos shares the same context with nginx, when doing
    curl in [http://localhost:80/](http://localhost:80/), it should be able to access
    nginx.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此规范将创建两个容器，`web` 和 `centos`。Web 是一个 nginx 容器 ([https://hub.docker.com/_/nginx/](https://hub.docker.com/_/nginx/))。默认情况下，通过暴露容器端口
    `80`，因为 centos 与 nginx 共享相同的上下文，当在 [http://localhost:80/](http://localhost:80/)
    中进行 curl 时，应该能够访问 nginx。
- en: 'Next, using the `kubectl create` command to launch the pod `-f` option lets
    kubectl know using the data in the file:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，使用 `kubectl create` 命令启动 pod，`-f` 选项让 kubectl 知道使用文件中的数据：
- en: '[PRE14]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Adding `--record=true` at the end of the `kubectl` command when we create the
    resources. Kubernetes will add the latest command while creating or updating this
    resource. Therefore, we won't forget which resources are created by which spec.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建资源时，在 `kubectl` 命令的末尾添加 `--record=true`。Kubernetes 将在创建或更新此资源时添加最新的命令。因此，我们不会忘记哪些资源是由哪个规范创建的。
- en: We could use the `kubectl get <resource>` command to get the current status
    of the object. In this case, we use the `kubectl get pods` command.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `kubectl get <resource>` 命令获取对象的当前状态。在这种情况下，我们使用 `kubectl get pods` 命令。
- en: '[PRE15]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Add `--namespace=$namespace_name` could access the object in different namespaces.
    The following is an example to check the pods in the `kube-system` namespace,
    which is used by system-type pods:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `kubectl` 命令的末尾添加 `--namespace=$namespace_name` 可以访问不同命名空间中的对象。以下是一个示例，用于检查
    `kube-system` 命名空间中的 pod，该命名空间由系统类型的 pod 使用：
- en: '`# kubectl get pods --namespace=kube-system`'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`# kubectl get pods --namespace=kube-system`'
- en: '`NAME READY STATUS RESTARTS AGE`'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`NAME READY STATUS RESTARTS AGE`'
- en: '`kube-addon-manager-minikube 1/1 Running 2 3d`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-addon-manager-minikube 1/1 Running 2 3d`'
- en: '`kube-dns-196007617-jkk4k 3/3 Running 3 3d`'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-dns-196007617-jkk4k 3/3 Running 3 3d`'
- en: '`kubernetes-dashboard-3szrf 1/1 Running 1 3d`'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubernetes-dashboard-3szrf 1/1 Running 1 3d`'
- en: Most of the objects have their short names, which come in handy when we use
    `kubectl get <object>` to list their status. For example, pods could be called
    po, services could be called svc, and deployment could be called deploy. Type
    `kubectl get` to know more.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数对象都有它们的简称，在我们使用 `kubectl get <object>` 列出它们的状态时非常方便。例如，pod 可以称为 po，服务可以称为
    svc，部署可以称为 deploy。输入 `kubectl get` 了解更多信息。
- en: 'The status of our example pod is `ContainerCreating`. In this phase, Kubernetes
    has accepted the request, trying to schedule the pod and pulling down the image.
    Zero containers are currently running. After waiting a moment, we could get the
    status again:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们示例 pod 的状态是 `ContainerCreating`。在这个阶段，Kubernetes 已经接受了请求，尝试调度 pod 并拉取镜像。当前没有容器正在运行。等待片刻后，我们可以再次获取状态：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'We can see two containers are currently running. Uptime is three seconds. Using
    `kubectl logs <pod_name> -c <container_name>` could get `stdout` for the container,
    similar to `docker logs <container_name>`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到当前有两个容器正在运行。正常运行时间为三秒。使用 `kubectl logs <pod_name> -c <container_name>`
    可以获取容器的 `stdout`，类似于 `docker logs <container_name>`：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Centos in the pod shares the same networking with nginx via localhost! Kubernetes
    creates a network container along with the pod. One of the functions in the network
    container is to forward the traffic between containers within a pod. We'll learn
    more in [Chapter 5](part0126.html#3O56S0-6c8359cae3d4492eb9973d94ec3e4f1e), *Network
    and Security*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: pod 中的 centos 通过 localhost 与 nginx 共享相同的网络！Kubernetes 会在 pod 中创建一个网络容器。网络容器的功能之一是在
    pod 内部的容器之间转发流量。我们将在 [第 5 章](part0126.html#3O56S0-6c8359cae3d4492eb9973d94ec3e4f1e)
    中了解更多，*网络和安全*。
- en: If we specify labels in pod spec, we could use the `kubectl get pods -l <requirement>`
    command to get the pods that are satisfying the requirements. For example, `kubectl
    get pods -l 'tier in (frontend, backend)'`. Additionally, if we use `kubectl pods
    -owide`, it will list down which pod is running on which nodes.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在pod规范中指定了标签，我们可以使用`kubectl get pods -l <requirement>`命令来获取满足要求的pod。例如，`kubectl
    get pods -l 'tier in (frontend, backend)'`。另外，如果我们使用`kubectl pods -owide`，它将列出哪个pod运行在哪个节点上。
- en: 'We could use `kubectl describe <resource> <resource_name>` to get the detailed
    information of a resource:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl describe <resource> <resource_name>`来获取资源的详细信息：
- en: '[PRE18]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'At this point, we know which node this pod is running on, in minikube we only
    get a single node so it won''t make any difference. In the real cluster environment,
    knowing which node is useful for troubleshooting. We didn''t associate any labels,
    annotations, and controllers for it:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们知道这个pod正在哪个节点上运行，在minikube中我们只有一个节点，所以不会有任何区别。在真实的集群环境中，知道哪个节点对故障排除很有用。我们没有为它关联任何标签、注释和控制器：
- en: '[PRE19]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the containers section, we''ll see there are two containers included in
    this pod. Their states, images, and restart count:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器部分，我们将看到这个pod中包含了两个容器。它们的状态、镜像和重启计数：
- en: '[PRE20]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'A pod has a `PodStatus`, which including a map of array represents as `PodConditions`.
    The possible key for `PodConditions` are `PodScheduled`, `Ready`, `Initialized`,
    and `Unschedulable`. Value will be true, false, or unknown. If the pod is not
    created accordingly, `PodStatus` will give us a brief view of which part failed:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一个pod有一个`PodStatus`，其中包括一个表示为`PodConditions`的数组映射。`PodConditions`的可能键是`PodScheduled`、`Ready`、`Initialized`和`Unschedulable`。值可以是true、false或unknown。如果pod没有按预期创建，`PodStatus`将为我们提供哪个部分失败的简要视图：
- en: '[PRE21]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Pod is associated with a service account that provides an identity for processes
    that are running a pod. It's controlled by service account and token controller
    in API Server.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Pod关联了一个service account，为运行在pod中的进程提供身份。它由API Server中的service account和token
    controller控制。
- en: 'It will mount a read only volume to each container under `/var/run/secrets/kubernetes.io/serviceaccount`
    in a pod that contains a token for API access. Kubernetes creates a default service
    account. We could use the `kubectl get serviceaccounts` command to list them:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 它将在包含用于API访问令牌的pod中，为每个容器挂载一个只读卷到`/var/run/secrets/kubernetes.io/serviceaccount`下。Kubernetes创建了一个默认的service
    account。我们可以使用`kubectl get serviceaccounts`命令来列出它们：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We don't assign any selectors to this pod yet. QoS means Resource Quality of
    Service. Toleration is used to restrict how many pods that can use a node. We
    will learn more in [Chapter 8](part0188.html#5J99O0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Cluster Administration:*
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有为这个pod分配任何选择器。QoS表示资源服务质量。Toleration用于限制可以使用节点的pod数量。我们将在[第8章](part0188.html#5J99O0-6c8359cae3d4492eb9973d94ec3e4f1e)中学到更多，*集群管理*：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: By seeing events, we could know what the steps are for Kubernetes to run a node.
    First, scheduler assigns the task to a node, here it is named minikube. Then kubelet
    on minikube starts pulling the first image and creates a container accordingly.
    Then kubelet pulls down the second container and runs.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看事件，我们可以了解Kubernetes在运行节点时的步骤。首先，调度器将任务分配给一个节点，这里它被命名为minikube。然后minikube上的kubelet开始拉取第一个镜像并相应地创建一个容器。然后kubelet拉取第二个容器并运行。
- en: ReplicaSet (RS) and ReplicationController (RC)
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ReplicaSet (RS) 和 ReplicationController (RC)
- en: A pod is not self-healing. When a pod encounters failure, it won't recover on
    its own. **ReplicaSet** (**RS**) and **ReplicationController** (**RC**) therefore
    come into play. Both ReplicaSet and ReplicationController will ensure a specified
    number of replica pods are always up and running in the cluster. If a pod crashes
    for any reason, ReplicaSet and ReplicationController will request to spin up a
    new Pod.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 一个pod不会自我修复。当一个pod遇到故障时，它不会自行恢复。因此，**ReplicaSet**（**RS**）和**ReplicationController**（**RC**）就发挥作用了。ReplicaSet和ReplicationController都将确保集群中始终有指定数量的副本pod在运行。如果一个pod因任何原因崩溃，ReplicaSet和ReplicationController将请求启动一个新的Pod。
- en: After the latest Kubernetes, ReplicationController is replaced by ReplicaSet
    gradually. They share the same concept, just using different requirements for
    the pod selector. ReplicationController uses equality-based selector requirements
    while ReplicaSet uses set-based selector requirements. ReplicaSet usually is not
    created by users, but by Kubernetes Deployments objects, while ReplicationController
    is created by users ourselves. In this section, we'll explain the concept for
    RC first by walking through examples, which is much easier to understand. Then
    we'll bring in ReplicaSet at the end.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在最新的Kubernetes版本中，ReplicationController逐渐被ReplicaSet取代。它们共享相同的概念，只是使用不同的pod选择器要求。ReplicationController使用基于相等性的选择器要求，而ReplicaSet使用基于集合的选择器要求。ReplicaSet通常不是由用户创建的，而是由Kubernetes部署对象创建，而ReplicationController是由用户自己创建的。在本节中，我们将通过示例逐步解释RC的概念，这样更容易理解。然后我们将在最后介绍ReplicaSet。
- en: '![](../images/00037.jpeg)ReplicationController with desired count 2'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00037.jpeg)带有期望数量2的ReplicationController'
- en: Let's say we'd like to create a `ReplicationController` object, with desired
    count two. It means we will always have two pods in service. Before we write the
    spec for ReplicationController, we'll have to decide pod template first. Pod template
    is similar to the spec of pod. In ReplicationController, labels in the metadata
    section are required. ReplicationController uses pod selector to select which
    pods it manages. Labels allow ReplicationController to distinguish whether all
    the pods matching the selectors are all on track.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想创建一个`ReplicationController`对象，期望数量为两个。这意味着我们将始终有两个pod在服务中。在编写ReplicationController的规范之前，我们必须先决定pod模板。Pod模板类似于pod的规范。在ReplicationController中，元数据部分中的标签是必需的。ReplicationController使用pod选择器来选择它管理的哪些pod。标签允许ReplicationController区分是否所有与选择器匹配的pod都处于正常状态。
- en: 'In this example, we''ll create two pods with the labels `project`, `service`,
    and `version`, as shown in the preceding figure:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将创建两个带有标签`project`，`service`和`version`的pod，如前图所示：
- en: '[PRE24]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Then we can use `kubectl` to get current RC status:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用`kubectl`来获取当前的RC状态：
- en: '[PRE25]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: It shows we have two desired pods, we currently have two pods and two pods are
    ready. How many pods do we have now?
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示我们有两个期望的pod，我们目前有两个pod并且两个pod已经准备就绪。现在我们有多少个pod？
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'It shows we have two pods up and running. As described previously, ReplicationController
    manages all the pods matching the selector. If we create a pod with the same label
    manually, in theory, it should match the pod selector of the RC we just created.
    Let''s try it out:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示我们有两个正在运行的pod。如前所述，ReplicationController管理所有与选择器匹配的pod。如果我们手动创建一个具有相同标签的pod，理论上它应该与我们刚刚创建的RC的pod选择器匹配。让我们试一试：
- en: '[PRE27]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Let''s see if it''s up and running:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看它是否正在运行：
- en: '[PRE28]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'It''s scheduled, and ReplicationController catches it. The amount of pods becomes
    three, which exceeds our desired count. The pod is eventually killed:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 它已经被调度，ReplicationController捕捉到了它。pod的数量变成了三个，超过了我们的期望数量。最终该pod被杀死：
- en: '[PRE29]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '![](../images/00038.jpeg)ReplicationController makes sure pods are in desired
    state'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00038.jpeg)ReplicationController确保pod处于期望的状态。'
- en: 'If we want to scale on demand, we could simply use `kubectl edit <resource>
    <resource_name>` to update the spec. Here we''ll change replica count from `2`
    to `5`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要按需扩展，我们可以简单地使用 `kubectl edit <resource> <resource_name>` 来更新规范。在这里，我们将将副本数从
    `2` 更改为 `5`：
- en: '[PRE30]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Let''s check RC information:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来检查 RC 信息：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We have five pods now. Let''s check how RC works:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有五个 pods。让我们来看看 RC 是如何工作的：
- en: '[PRE32]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: By describing the command; we can learn the spec of RC, also the events. At
    the time we created `nginx` RC, it launched two containers by spec. Then we created
    another pod manually by another spec, named `our-nginx`. RC detected that pod
    matches its pod selector. Then the amount exceeded our desired count, so it evicted
    it. Then we scaled out the replicas to five. RC detected that it didn't fulfill
    our desired state, launching three pods to fill the gap.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 通过描述命令，我们可以了解 RC 的规范，也可以了解事件。在我们创建 `nginx` RC 时，它按规范启动了两个容器。然后我们通过另一个规范手动创建了另一个
    pod，名为 `our-nginx`。RC 检测到该 pod 与其 pod 选择器匹配。然后数量超过了我们期望的数量，所以它将其驱逐。然后我们将副本扩展到了五个。RC
    检测到它没有满足我们的期望状态，于是启动了三个 pods 来填补空缺。
- en: 'If we want to delete an RC, simply use the `kubectl` command by `kubectl delete
    <resource> <resource_name>`. Since we have a configuration file on hand, we could
    also use `kubectl delete -f <configuration_file>` to delete the resources listing
    in the file:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要删除一个 RC，只需使用 `kubectl` 命令 `kubectl delete <resource> <resource_name>`。由于我们手头上有一个配置文件，我们也可以使用
    `kubectl delete -f <configuration_file>` 来删除文件中列出的资源：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The same concept is brought to ReplicaSet. The following is RS version of `3-2-2.rc.yaml`.
    Two major differences are:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 相同的概念也适用于 ReplicaSet。以下是 `3-2-2.rc.yaml` 的 RS 版本。两个主要的区别是：
- en: The `apiVersion` is `extensions/v1beta1` at the time of writing
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在撰写时，`apiVersion` 是 `extensions/v1beta1`
- en: Selector requirement is changed set-based requirement, with `matchLabels` and
    `matchExpressions` syntax
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择器要求更改为基于集合的要求，使用 `matchLabels` 和 `matchExpressions` 语法。
- en: 'Following the same steps with the preceding example should work exactly the
    same between RC and RS. This is just an example; however, we shouldn''t create
    RS on our own, while it should be always managed by Kubernetes `deployment` object.
    We''ll learn more in the next section:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 按照前面示例的相同步骤，RC 和 RS 之间应该完全相同。这只是一个例子；然而，我们不应该自己创建 RS，而应该始终由 Kubernetes `deployment`
    对象管理。我们将在下一节中学到更多：
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Deployments
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Deployment is the best primitive to manage and deploy our software in Kubernetes
    after version 1.2\. It supports gracefully deploying, rolling updating, and rolling
    back pods and ReplicaSets. We define our desired update of the software by deployment
    declaratively, and then deployment will do it for us progressively.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 1.2 版本之后，部署是管理和部署我们的软件的最佳原语。它支持优雅地部署、滚动更新和回滚 pods 和 ReplicaSets。我们通过声明性地定义我们对软件的期望更新，然后部署将逐渐为我们完成。
- en: Before deployment, ReplicationController and kubectl rolling-update were the
    major way to implement rolling-update for the software, which is more imperative
    and slower. Deployment now becomes the major high-level object to manage our application.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署之前，ReplicationController 和 kubectl rolling-update 是实现软件滚动更新的主要方式，这更加命令式和较慢。现在部署成为了管理我们应用的主要高级对象。
- en: Let's have a glimpse of how it works. In this section, we'll get a taste of
    how deployment is created, how to perform rolling-update and rollback. [Chapter
    7](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e), *Continuous Delivery*
    has more information with practical examples about how we integrate with deployments
    into our continuous delivery pipeline.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看它是如何工作的。在这一部分，我们将体验到部署是如何创建的，如何执行滚动更新和回滚。[第7章](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e)，*持续交付*有更多关于如何将部署集成到我们的持续交付流水线中的实际示例信息。
- en: 'First, we could use the `kubectl run` command to create a `deployment` for
    us:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以使用`kubectl run`命令为我们创建一个`deployment`：
- en: '[PRE35]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Before Kubernetes 1.2, the `kubectl run` command would create pods instead.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes 1.2之前，`kubectl run`命令将创建pod。
- en: 'There are two pods that are deployed by deployment:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 部署时部署了两个pod：
- en: '[PRE36]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: '![](../images/00039.jpeg)The relationship in deployments, ReplicaSets, and
    pods'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00039.jpeg)部署、ReplicaSets和pod之间的关系'
- en: 'If we delete one of the pods, the replaced pod will be scheduled and launched
    immediately. That''s because deployments creates a ReplicaSet behind the scenes,
    which will ensure the number of replicas is matched with our desired count. In
    general, deployments manage ReplicaSets, ReplicaSets manage pods. Note that we
    shouldn''t manually manipulate ReplicaSets that deployments managed, just like
    there is no sense to change pods directly if they''re managed by ReplicaSets:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们删除一个pod，替换的pod将立即被调度和启动。这是因为部署在幕后创建了一个ReplicaSet，它将确保副本的数量与我们的期望数量匹配。一般来说，部署管理ReplicaSets，ReplicaSets管理pod。请注意，我们不应该手动操作部署管理的ReplicaSets，就像如果它们由ReplicaSets管理，直接更改pod也是没有意义的：
- en: '[PRE37]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'We could also expose the port for deployment by the `kubectl` command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以通过`kubectl`命令为部署公开端口：
- en: '[PRE38]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Deployments can be created by spec as well. The previous deployments and service
    launched by kubectl can be converted to the following spec:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 部署也可以通过spec创建。之前由kubectl启动的部署和服务可以转换为以下spec：
- en: '[PRE39]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'For performing rolling update, we''ll have to add rolling update strategy.
    There are three parameters used to control the process:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为执行滚动更新，我们将不得不添加滚动更新策略。有三个参数用于控制该过程：
- en: '| **Parameters** | **Description** | **Default value** |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| **参数** | **描述** | **默认值** |'
- en: '| `minReadySeconds` | Warm-up time. How long a newly created pod is considered
    to be available. By default, Kubernetes assumes the application will be available
    once it is successfully launched. | 0 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| `minReadySeconds` | 热身时间。新创建的pod被认为可用的时间。默认情况下，Kubernetes假定应用程序一旦成功启动就可用。
    | 0 |'
- en: '| `maxSurge` | How many pods can be surged when doing rolling update process.
    | 25% |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| `maxSurge` | 在执行滚动更新过程时可以增加的pod数量。 | 25% |'
- en: '| `maxUnavailable` | How many pods can be unavailable when doing rolling update
    process. | 25% |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| `maxUnavailable` | 在执行滚动更新过程时可以不可用的pod数量。 | 25% |'
- en: 'The `minReadySecond` is an important setting. If our application is not available
    immediately when the pod is up, pods are rolling too fast without proper waiting.
    Although all the new pods are up, the application might be still warming up; there
    are chances a service outage might occur. In the following example, we''ll add
    the configuration into the `Deployment.spec` section:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`minReadySeconds`是一个重要的设置。如果我们的应用程序在pod启动时不能立即使用，那么没有适当的等待，pod将滚动得太快。尽管所有新的pod都已经启动，但应用程序可能仍在热身；有可能会发生服务中断。在下面的示例中，我们将把配置添加到`Deployment.spec`部分：'
- en: '[PRE40]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: It indicates that we allow one of the pods to be unavailable at a time and one
    more pod could be launched when rolling the pods. The warm-up time before proceeding
    to the next operation will be three seconds. We can use either `kubectl edit deployments
    nginx` (edit directly) or `kubectl replace -f 3-2-3_deployments_rollingupdate.yaml`
    to update the strategy.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示我们允许一个pod每次不可用，并且在滚动pod时可以启动一个额外的pod。在进行下一个操作之前的热身时间将为三秒。我们可以使用`kubectl edit
    deployments nginx`（直接编辑）或`kubectl replace -f 3-2-3_deployments_rollingupdate.yaml`来更新策略。
- en: 'Let''s say we want to simulate new software rollout, from nginx 1.12.0 to 1.13.1\.
    We still could use the preceding two commands to change image version, or use
    `kubectl set image deployment nginx nginx=nginx``:1.13.1` to trigger the update.
    If we use `kubectl describe` to check what''s going on, we will see deployments
    have triggered rolling updates on ReplicaSets by deleting/creating pods:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要模拟新软件的升级，从nginx 1.12.0到1.13.1。我们仍然可以使用前面的两个命令来更改镜像版本，或者使用`kubectl set
    image deployment nginx nginx=nginx:1.13.1`来触发更新。如果我们使用`kubectl describe`来检查发生了什么，我们将看到部署已经通过删除/创建pod来触发了ReplicaSets的滚动更新：
- en: '[PRE41]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](../images/00040.jpeg)Illustration of deployments'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00040.jpeg)部署的示例'
- en: The preceding figure shows the illustration of the deployment. At a certain
    point of time, we have two (desired count) and one (`maxSurge`) pods. After launching
    each new pod, Kubernetes will wait three (`minReadySeconds`) seconds and then
    performs the next action.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 上图显示了部署的示例。在某个时间点，我们有两个（期望数量）和一个（`maxSurge`）pod。在启动每个新的pod后，Kubernetes将等待三个（`minReadySeconds`）秒，然后执行下一个操作。
- en: If we use the command `kubectl set image deployment nginx nginx=nginx:1.12.0
    to previous version 1.12.0`, deployments will do the rollback for us.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用命令`kubectl set image deployment nginx nginx=nginx:1.12.0 to previous version
    1.12.0`，部署将为我们执行回滚。
- en: Services
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务
- en: Service in Kubernetes is an abstraction layer for routing traffic to a logical
    set of pods. With service, we don't need to trace the IP address of each pod.
    Service usually uses label selector to select the pods that it needs to route
    to (in some cases service is created without selector in purpose). The service
    abstraction is powerful. It enables the decoupling and makes communication between
    micro-services possible. Currently Kubernetes service supports TCP and UDP.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes中的服务是将流量路由到一组逻辑pod的抽象层。有了服务，我们就不需要追踪每个pod的IP地址。服务通常使用标签选择器来选择它需要路由到的pod（在某些情况下，服务是有意地创建而不带选择器）。服务抽象是强大的。它实现了解耦，并使微服务之间的通信成为可能。目前，Kubernetes服务支持TCP和UDP。
- en: 'Service doesn''t care how we create the pod. Just like ReplicationController,
    it only cares that the pods match its label selectors, so the pods could belong
    to different ReplicationControllers. The following is an illustration:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 服务不关心我们如何创建pod。就像ReplicationController一样，它只关心pod是否匹配其标签选择器，因此pod可以属于不同的ReplicationControllers。以下是一个示例：
- en: '![](../images/00041.jpeg)Service maps pods via label selector'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00041.jpeg)服务通过标签选择器映射pod'
- en: In the graph, all the pods match the service selector, so service will be responsible
    to distribute the traffic into all the pods without explicit assignment.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在图中，所有的pod都匹配服务选择器，因此服务将负责将流量分发到所有的pod，而无需显式分配。
- en: '**Service types**'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务类型**'
- en: 'There are four types of services: ClusterIP, NodePort, LoadBalancer, and ExternalName.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 服务有四种类型：ClusterIP、NodePort、LoadBalancer和ExternalName。
- en: '![](../images/00042.jpeg)LoadBalancer includes the features of NodePort and
    ClusterIP'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00042.jpeg)LoadBalancer包括NodePort和ClusterIP的功能'
- en: '**ClusterIP**'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**ClusterIP**'
- en: ClusterIP is the default service type. It exposes the service on a cluster-internal
    IP. Pods in the cluster could reach the service via the IP address, environment
    variables, or DNS. In the following example, we'll learn how to use both native
    service environment variables and DNS to access the pods behind services in the
    cluster.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterIP是默认的服务类型。它在集群内部IP上公开服务。集群中的pod可以通过IP地址、环境变量或DNS访问服务。在下面的示例中，我们将学习如何使用本地服务环境变量和DNS来访问集群中服务后面的pod。
- en: 'Before starting a service, we''d like to create two sets of RC shown in the
    figure:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动服务之前，我们想要创建图中显示的两组RC：
- en: '[PRE42]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Then we could make our pod selector, targeting project and service labels:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以制定我们的pod选择器，以定位项目和服务标签：
- en: '[PRE43]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Since `service` object might create a DNS label, service name must follow the
    combination of characters a-z, 0-9, or - (hyphen). A hyphen at the beginning or
    end of a label is not allowed.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`service`对象可能创建一个DNS标签，因此服务名称必须遵循字符a-z、0-9或-（连字符）的组合。标签开头或结尾的连字符是不允许的。
- en: 'Then we could use `kubectl describe service <service_name>` to check the service
    information:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用`kubectl describe service <service_name>`来检查服务信息：
- en: '[PRE44]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: One service could expose multiple ports. Just extend `.spec.ports` list in the
    service spec.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 一个服务可以公开多个端口。只需在服务规范中扩展`.spec.ports`列表。
- en: We can see it's a ClusterIP type service, assigned internal IP is 10.0.0.188\.
    Endpoints show we have four IPs behind the service. Pod IP could be found by the
    `kubectl describe pods <pod_name>` command. Kubernetes creates an `endpoints`
    object along with a `service` object for routing the traffic to matching pods.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以看到这是一个ClusterIP类型的服务，分配的内部IP是10.0.0.188。端点显示我们在服务后面有四个IP。可以通过`kubectl describe
    pods <pod_name>`命令找到pod IP。Kubernetes为匹配的pod创建了一个`endpoints`对象以及一个`service`对象来路由流量。 '
- en: 'When the service is created with selectors, Kubernetes will create corresponding
    endpoints entries and keep updating, which will tell the destination that service
    routes into:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用选择器创建服务时，Kubernetes将创建相应的端点条目并进行更新，这将告诉目标服务路由到哪里：
- en: '[PRE45]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: ClusterIP could be defined within your cluster, though most of the time we don't
    explicitly use IP address to access clusters. Using `.spec.clusterIP` could do
    the work.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ClusterIP可以在集群内定义，尽管大多数情况下我们不会显式使用IP地址来访问集群。使用`.spec.clusterIP`可以完成工作。
- en: 'By default, Kubernetes will expose seven environment variables for each service.
    In most cases, the first two will be used for using `kube-dns` addon to do service
    discovery for us:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes将为每个服务公开七个环境变量。在大多数情况下，前两个将用于使用`kube-dns`插件来为我们进行服务发现：
- en: '`${SVCNAME}_SERVICE_HOST`'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_SERVICE_HOST`'
- en: '`${SVCNAME}_SERVICE_PORT`'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_SERVICE_PORT`'
- en: '`${SVCNAME}_PORT`'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_PORT`'
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}`'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}`'
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PROTO`'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PROTO`'
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PORT`'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PORT`'
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_ADDR`'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_ADDR`'
- en: 'In the following example, we''ll use `${SVCNAME}_SERVICE_HOST` in another pod
    to check if we could access our nginx pods:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们将在另一个pod中使用`${SVCNAME}_SERVICE_HOST`来检查是否可以访问我们的nginx pods：
- en: '![](../images/00043.jpeg)The illustration of accessing ClusterIP via environment
    variables and DNS names'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00043.jpeg)通过环境变量和DNS名称访问ClusterIP的示意图'
- en: 'We''ll then create a pod called `clusterip-chk` to access nginx containers
    via `nginx-service`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将创建一个名为`clusterip-chk`的pod，通过`nginx-service`访问nginx容器：
- en: '[PRE46]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We could check the `stdout` of `cluserip-chk` pod via the `kubectl logs` command:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`kubectl logs`命令来检查`cluserip-chk` pod的`stdout`：
- en: '[PRE47]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: This abstraction level decouples the communication between pods. Pods are mortal.
    With RC and service, we can build robust services without caring whether one pod
    might influence all micro-services.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这种抽象级别解耦了pod之间的通信。Pod是有寿命的。有了RC和service，我们可以构建健壮的服务，而不必担心一个pod可能影响所有微服务。
- en: With `kube-dns` addon enabled, the pods in the same cluster and same namespace
    with services could access services via services DNS records. Kube-dns creates
    DNS records for newly created services by watching the Kubernetes API. The DNS
    format for the cluster IP is `$servicename.$namespace`, and the port is `_$portname_$protocal.$servicename.$namespace`.
    The spec of the `clusterip_chk` pod will be similar with environment variables
    one. Just changing the URL to [`http://nginx-service.default:_http_tcp.nginx-service.default/`](http://nginx-service.default:_http_tcp.nginx-service.default/)
    in our previous example, and they should work exactly the same!
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 启用`kube-dns`插件后，同一集群和相同命名空间中的pod可以通过服务的DNS记录访问服务。Kube-dns通过监视Kubernetes API来为新创建的服务创建DNS记录。集群IP的DNS格式是`$servicename.$namespace`，端口是`_$portname_$protocal.$servicename.$namespace`。`clusterip_chk`
    pod的规范将与环境变量相似。只需在我们之前的例子中将URL更改为[`http://nginx-service.default:_http_tcp.nginx-service.default/`](http://nginx-service.default:_http_tcp.nginx-service.default/)，它们应该完全相同地工作！
- en: '**NodePort**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**NodePort**'
- en: 'If the service is set as NodePort, Kubernetes will allocate a port within a
    certain range on each node. Any traffic going to nodes on that port will be routed
    to the service port. Port number could be user-specified. If not specified, Kubernetes
    will randomly choose a port from range 30000 to 32767 without collision. On the
    other hand, if specified, the user should be responsible to manage the collision
    by themselves. NodePort includes the feature of ClusterIP. Kubernetes assigns
    an internal IP to the service. In the following example, we''ll see how we create
    a NodePort service and leverage it:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果服务设置为NodePort，Kubernetes将在每个节点上分配一个特定范围内的端口。任何发送到该端口的节点的流量将被路由到服务端口。端口号可以由用户指定。如果未指定，Kubernetes将在30000到32767范围内随机选择一个端口而不发生冲突。另一方面，如果指定了，用户应该自行负责管理冲突。NodePort包括ClusterIP的功能。Kubernetes为服务分配一个内部IP。在下面的例子中，我们将看到如何创建一个NodePort服务并利用它：
- en: '[PRE48]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Then you should be able to access the service via `http://${NODE_IP}:80`. Node
    could be any node. The `kube-proxy` watches any update of service and endpoints,
    and updates iptables rules accordingly (if using default iptables proxy-mode).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你应该能够通过`http://${NODE_IP}:80`访问服务。Node可以是任何节点。`kube-proxy`会监视服务和端点的任何更新，并相应地更新iptables规则（如果使用默认的iptables代理模式）。
- en: If you're using minikube, you could access the service via the `minikube service
    [-n NAMESPACE] [--url] NAME` command. In this example, it's `minikube service
    nginx-nodeport`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用minikube，你可以通过`minikube service [-n NAMESPACE] [--url] NAME`命令访问服务。在这个例子中，是`minikube
    service nginx-nodeport`。
- en: '**LoadBalancer**'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**LoadBalancer**'
- en: This type is only usable with cloud provider support, such as Google Cloud Platform
    ([Chapter 10](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e), *Kubernetes
    on GCP*) and Amazon Web Service ([Chapter 9](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on AWS*). By creating LoadBalancer service, Kubernetes will provision
    a load balancer by the Cloud provider to the service.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型只能在云提供商支持的情况下使用，比如谷歌云平台（[第10章](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e)，*GCP上的Kubernetes*）和亚马逊网络服务（[第9章](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e)，*AWS上的Kubernetes*）。通过创建LoadBalancer服务，Kubernetes将由云提供商为服务提供负载均衡器。
- en: '**ExternalName (kube-dns version >= 1.7)**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**ExternalName（kube-dns版本>=1.7）**'
- en: Sometimes we leverage different services in the cloud. Kubernetes is flexible
    enough to be hybrid. ExternalName is one of the bridges to create a **CNAME**
    for external endpoints into the cluster.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们会在云中利用不同的服务。Kubernetes足够灵活，可以是混合的。ExternalName是创建外部端点的**CNAME**的桥梁之一，将其引入集群中。
- en: '**Service without selectors**'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '**没有选择器的服务**'
- en: 'Service uses selectors to match the pods to direct the traffic. However, sometimes
    you need to implement a proxy to be the bridge between Kubernetes cluster and
    another namespace, another cluster, or external resources. In the following example,
    we''ll demonstrate how to implement a proxy for [http://www.google.com](http://www.google.com)
    in your cluster. It''s just an example while the source of the proxy might be
    the endpoint of your databases or other resources in the cloud:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 服务使用选择器来匹配pod以指导流量。然而，有时您需要实现代理来成为Kubernetes集群和另一个命名空间、另一个集群或外部资源之间的桥梁。在下面的示例中，我们将演示如何在您的集群中为[http://www.google.com](http://www.google.com)实现代理。这只是一个示例，代理的源可能是云中数据库或其他资源的终点：
- en: '![](../images/00044.jpeg)Illustration of how service without selector works'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00044.jpeg)无选择器的服务如何工作的示例'
- en: 'The configuration file is similar to the previous one, just without the selector
    section:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件与之前的类似，只是没有选择器部分：
- en: '[PRE49]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: No Kubernetes endpoint will be created since there is no selector. Kubernetes
    doesn't know where to route the traffic since no selector could match the pods.
    We'll have to create that on our own.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有选择器，将不会创建任何Kubernetes终点。Kubernetes不知道将流量路由到何处，因为没有选择器可以匹配pod。我们必须自己创建。
- en: 'In the `Endpoints` object, the source addresses can''t be DNS name, so we''ll
    use `nslookup` to find the current Google IP from the domain, and add them into
    `Endpoints.subsets.addresses.ip`:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Endpoints`对象中，源地址不能是DNS名称，因此我们将使用`nslookup`从域中查找当前的Google IP，并将其添加到`Endpoints.subsets.addresses.ip`中：
- en: '[PRE50]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Let''s create another pod in the cluster to access our Google proxy:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在集群中创建另一个pod来访问我们的Google代理：
- en: '[PRE51]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Let''s check the `stdout` from the pod:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下pod的`stdout`：
- en: '[PRE52]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Hurray! We can now confirm the proxy works. The traffic to the service will
    be routed to the endpoints we specified. If it doesn't work, make sure you add
    the proper inbound rules to the network of your external resources.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 万岁！我们现在可以确认代理起作用了。对服务的流量将被路由到我们指定的终点。如果不起作用，请确保您为外部资源的网络添加了适当的入站规则。
- en: Endpoints don't support DNS as source. Alternatively, we could use ExternalName,
    which doesn't have selectors either. It requires kube-dns version >= 1.7.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 终点不支持DNS作为源。或者，我们可以使用ExternalName，它也没有选择器。它需要kube-dns版本>= 1.7。
- en: In some use cases, users need neither load balancing nor proxy functionalities
    for the service. In that case, we can set `CluterIP = "None"` as so-called headless
    services. For more information, please refer to [https://kubernetes.io/docs/concepts/services-networking/service/#headless-services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些用例中，用户对服务既不需要负载平衡也不需要代理功能。在这种情况下，我们可以将`CluterIP = "None"`设置为所谓的无头服务。有关更多信息，请参阅[https://kubernetes.io/docs/concepts/services-networking/service/#headless-services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services)。
- en: Volumes
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卷
- en: A container is ephemeral, so is its disk. We either use the `docker commit [CONTAINER]`
    command or mount data volumes into a container ([Chapter 2](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *DevOps with Container*). In Kubernetes' world, volume management becomes critical,
    since pods might run on any node. Also, ensuring that containers in the same pod
    could share the same files becomes extremely hard. This is a large topic in Kubernetes.
    [Chapter 4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e), *Working with
    Storage and Resources* introduces volume management.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是短暂的，它的磁盘也是如此。我们要么使用`docker commit [CONTAINER]`命令，要么将数据卷挂载到容器中（[第2章](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e)，*使用容器进行DevOps*）。在Kubernetes的世界中，卷管理变得至关重要，因为pod可能在任何节点上运行。此外，确保同一pod中的容器可以共享相同的文件变得非常困难。这是Kubernetes中的一个重要主题。[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)，*存储和资源处理*介绍了卷管理。
- en: Secrets
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 秘密
- en: Secret, just like its name, is an object that stores the secrets in key-value
    format for providing sensitive information to pods, which could be a password,
    access key, or token. Secret is not landed to the disk; instead, it's stored in
    a per-node `tmpfs` filesystem. Kubelet on the mode will create a `tmpfs` filesystem
    to store secret. Secret is not designed to store large amounts of data due to
    storage management consideration. The current size limit of one secret is 1MB.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密，正如其名称，是以键值格式存储敏感信息以提供给pod的对象，这可能是密码、访问密钥或令牌。秘密不会落地到磁盘上；相反，它存储在每个节点的`tmpfs`文件系统中。模式上的Kubelet将创建一个`tmpfs`文件系统来存储秘密。由于存储管理的考虑，秘密并不设计用于存储大量数据。一个秘密的当前大小限制为1MB。
- en: 'We can create a secret based on a file, directory, or specified literal value
    by launching kubectl to create a secret command or by spec. There are three types
    of secret format: generic (or opaque, if encoded), docker registry, and TLS.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过启动kubectl创建秘密命令或通过spec来基于文件、目录或指定的文字值创建秘密。有三种类型的秘密格式：通用（或不透明，如果编码）、docker注册表和TLS。
- en: Generic/opaque is the text that we'll use in our application. Docker registry
    is used to store the credential of a private docker registry. TLS secret is used
    to store the CA certificate bundle for cluster administration.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 通用/不透明是我们将在应用程序中使用的文本。Docker注册表用于存储私有docker注册表的凭据。TLS秘密用于存储集群管理的CA证书包。
- en: The docker-registry type of secret is also called **imagePullSecrets**, which
    is used to pass the password of a private docker registry via kubelet when pulling
    the image. This comes in handy so that we don't need to do `docker login` for
    each provisioned node. The command is `kubectl create secret docker-registry`
    `<registry_name>` `--docker-server``=<docker_server> --docker-username=<docker_username>`
    `-``-docker-password=<docker_password> --docker-email=<docker_email>`
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: docker-registry类型的秘密也被称为**imagePullSecrets**，它用于在拉取镜像时通过kubelet传递私有docker注册表的密码。这非常方便，这样我们就不需要为每个提供的节点执行`docker
    login`。命令是`kubectl create secret docker-registry` `<registry_name>` `--docker-server``=<docker_server>
    --docker-username=<docker_username>` `-``-docker-password=<docker_password> --docker-email=<docker_email>`
- en: 'We''ll start with a generic-type of example to show how it works:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从一个通用类型的示例开始，以展示它是如何工作的：
- en: '[PRE53]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: The options for creating secrets based on directory and literal value are pretty
    similar with the file ones. If specifying a directory after `--from-file`, the
    files in the directory will be iterated, the file name will be the secret key
    if its a legal secret name, and other non-regular files will be ignored subdirectories,
    symlinks, devices, pipes. On the other hand, `--from-literal=<key>=<value>` is
    the option if you want to specify plain text directly from the command, for example,
    `--from-literal=username=root`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 基于目录和文字值创建秘密的选项与文件的选项非常相似。如果在`--from-file`后指定目录，那么目录中的文件将被迭代，文件名将成为秘密密钥（如果是合法的秘密名称），其他非常规文件将被忽略，如子目录、符号链接、设备、管道。另一方面，`--from-literal=<key>=<value>`是一个选项，如果你想直接从命令中指定纯文本，例如，`--from-literal=username=root`。
- en: 'Here, we create a secret name `mypassword` from the file `mypassword.txt`.
    By default, the key of the secret is the file name, which is equivalent to the
    `--from-file=mypassword=./mypassword.txt` option. We could append multiple `--from-file`
    as well. Using the `kubectl get secret` `<secret_name>` `-o yaml` command could
    check out the detailed information of the secret:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们从文件`mypassword.txt`创建一个名为`mypassword`的秘密。默认情况下，秘密的键是文件名，这相当于`--from-file=mypassword=./mypassword.txt`选项。我们也可以追加多个`--from-file`。使用`kubectl
    get secret` `<secret_name>` `-o yaml`命令可以查看秘密的详细信息：
- en: '[PRE54]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We can see the type of the secret becomes `Opaque` since the text has been
    encrypted by kubectl. It''s base64 encoded. We could use a simple bash command
    to decode it:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到秘密的类型变为`Opaque`，因为文本已被kubectl加密。它是base64编码的。我们可以使用一个简单的bash命令来解码它：
- en: '[PRE55]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: There are two ways for a pod to retrieve the secret. The first one is by file,
    and the second one is by environment variable. The first method is implemented
    by volume. The syntax is adding `containers.volumeMounts` in container specs,
    and adding a volumes section with secret configuration.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: Pod检索秘密有两种方式。第一种是通过文件，第二种是通过环境变量。第一种方法是通过卷实现的。语法是在容器规范中添加`containers.volumeMounts`，并在卷部分添加秘密配置。
- en: '**Retrieving secret via files**'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过文件检索秘密**'
- en: 'Let''s see how to read secrets from files inside a pod first:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看如何从Pod内的文件中读取秘密：
- en: '[PRE56]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'The secret file will be mounted in `/<mount_point>/<secret_name>` without specifying
    `items``key` and `path`, or `/<mount_point>/<path>` in the pod. In this case,
    it''s under `/secret/password-example`. If we describe the pod, we can find there
    are two mount points in this pod. First is the read-only volume storing our secret,
    the second one stores the credentials to communicate with API servers, which is
    created and managed by Kubernetes. We''ll learn more in [Chapter 5](part0126.html#3O56S0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Network and Security*:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密文件将被挂载在`/<mount_point>/<secret_name>`中，而不指定`items``key`和`path`，或者在Pod中的`/<mount_point>/<path>`中。在这种情况下，它位于`/secret/password-example`下。如果我们描述Pod，我们可以发现这个Pod中有两个挂载点。第一个是只读卷，存储我们的秘密，第二个存储与API服务器通信的凭据，这是由Kubernetes创建和管理的。我们将在[第5章](part0126.html#3O56S0-6c8359cae3d4492eb9973d94ec3e4f1e)中学到更多内容，*网络和安全*。
- en: '[PRE57]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: We can delete a secret by using the `kubectl delete secret` `<secret_name>`
    command.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl delete secret` `<secret_name>`命令删除秘密。
- en: 'After describing the pod, we can find a `FailedMount` event, since the volume
    no longer exists:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 描述完Pod后，我们可以找到`FailedMount`事件，因为卷不再存在：
- en: '[PRE58]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Same idea, if the pod is generated before a secret is created, the pod will
    encounter failure as well.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的想法，如果Pod在创建秘密之前生成，那么Pod也会遇到失败。
- en: 'We will now learn how to create a secret by command line. Next we''ll briefly
    introduce its spec format:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将学习如何通过命令行创建秘密。接下来我们将简要介绍其规范格式：
- en: '[PRE59]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Since the spec is plain text, we need to encode the secret by our own `echo
    -n <password>` `| base64`. Please note that the type here becomes `Opaque`. Following
    along it should work the same as the one we create via command line.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 由于规范是纯文本，我们需要通过自己的`echo -n <password>` `| base64`来对秘密进行编码。请注意，这里的类型变为`Opaque`。按照这样做，它应该与我们通过命令行创建的那个相同。
- en: '**Retrieving secret via environment variables**'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过环境变量检索秘密**'
- en: 'Alternatively, we could use environment variables to retrieve secret, which
    is more flexible to use for short credentials, such as a password. This way, applications
    are able to use environment variables to retrieve database passwords without tackling
    files and volumes:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用环境变量来检索秘密，这样更灵活，适用于短期凭据，比如密码。这样，应用程序可以使用环境变量来检索数据库密码，而无需处理文件和卷：
- en: Secret should always be created before the pods that need it. Otherwise the
    pods won't get launched successfully.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密应该始终在需要它的Pod之前创建。否则，Pod将无法成功启动。
- en: '[PRE60]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: The declaration is under `spec.containers[].env[]`. We'll need the secret name
    and the key name. Both are `mypassword` in this case. The example should work
    the same with the one retrieving via files.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 声明位于`spec.containers[].env[]`下。在这种情况下，我们需要秘密名称和密钥名称。两者都是`mypassword`。示例应该与通过文件检索的示例相同。
- en: ConfigMap
  id: totrans-296
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ConfigMap
- en: ConfigMap is a mean that is able to leave your configuration outside of a Docker
    image. It injects the configuration data as key-values pairs into pods. Its properties
    are similar to secret, more specifically, secret is used to store sensitive data,
    such as password, and ConfigMap is used to store insensitive configuration data.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap是一种能够将配置留在Docker镜像之外的方法。它将配置数据作为键值对注入到pod中。它的属性与secret类似，更具体地说，secret用于存储敏感数据，如密码，而ConfigMap用于存储不敏感的配置数据。
- en: 'Same as secret, ConfigMap could be based on a file, directory, or specified
    literal value. With similar syntax/command with secrets, ConfigMap uses `kubectl
    create configmap` instead:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 与secret相同，ConfigMap可以基于文件、目录或指定的文字值。与secret相似的语法/命令，ConfigMap使用`kubectl create
    configmap`而不是：
- en: '[PRE61]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Since two `config` files are located in the same folder name `config`, we could
    pass a `config` folder instead of specifying the files one by one. The equivalent
    command to create is `kubectl create configmap example --from-file=config` in
    this case.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 由于两个`config`文件位于同一个名为`config`的文件夹中，我们可以传递一个`config`文件夹，而不是逐个指定文件。在这种情况下，创建等效命令是`kubectl
    create configmap example --from-file=config`。
- en: 'If we describe the ConfigMap, it will show current information:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们描述ConfigMap，它将显示当前信息：
- en: '[PRE62]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: We could use `kubectl edit configmap` `<configmap_name>` to update the configuration
    after creation.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl edit configmap` `<configmap_name>`来更新创建后的配置。
- en: We also could use `literal` as the input. The equivalent commands for the preceding
    example will be `kubectl create configmap example --from-literal=app.properties.name=name=DevOps-with-Kubernetes`
    which is not always so practical when we have many configurations in an app.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`literal`作为输入。前面示例的等效命令将是`kubectl create configmap example --from-literal=app.properties.name=name=DevOps-with-Kubernetes`，当我们在应用程序中有许多配置时，这并不总是很实用。
- en: 'Let''s see how to leverage it inside a pod. There are two ways to use ConfigMap
    inside a pod too: by volume or environment variables.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何在pod内利用它。在pod内使用ConfigMap也有两种方式：通过卷或环境变量。
- en: Using ConfigMap via volume
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过卷使用ConfigMap
- en: 'Similar to previous examples in the secret section, we mount a volume with
    syntax `configmap`, and add `volumeMounts` inside a container template. The command
    in `centos` will loop to `cat ${MOUNTPOINT}/$CONFIG_FILENAME`:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 与secret部分中的先前示例类似，我们使用`configmap`语法挂载卷，并在容器模板中添加`volumeMounts`。在`centos`中，该命令将循环执行`cat
    ${MOUNTPOINT}/$CONFIG_FILENAME`。
- en: '[PRE63]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: We then could use this method to inject our non-sensitive configuration into
    the pod.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用这种方法将我们的非敏感配置注入到pod中。
- en: Using ConfigMap via environment variables
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过环境变量使用ConfigMap
- en: 'For using ConfigMap inside a pod, you''ll have to use `configMapKeyRef` as
    the value source in the `env` section. It will populate whole ConfigMap pairs
    to environment variables:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 要在pod内使用ConfigMap，您必须在`env`部分中使用`configMapKeyRef`作为值来源。它将将整个ConfigMap对填充到环境变量中：
- en: '[PRE64]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: The Kubernetes system itself also leverages ConfigMap for doing some authentication.
    For example, kube-dns uses it to put client CA files. You could check the system
    ConfigMap by adding `--namespace=kube-system` when describing ConfigMaps.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes系统本身也利用ConfigMap来进行一些认证。例如，kube-dns使用它来放置客户端CA文件。您可以通过在描述ConfigMaps时添加`--namespace=kube-system`来检查系统ConfigMap。
- en: Multi-containers orchestration
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多容器编排
- en: 'In this section, we''ll revisit our ticketing service: a kiosk web service
    as frontend, providing interface for get/put tickets. There is a Redis acting
    as cache, to manage how many tickets we have. Redis also acts as a publisher/subscriber
    channel. Once a ticket is sold, kiosk will publish an event into it. Subscriber
    is called recorder, which will write a timestamp and record it to the MySQL database.
    Please refer to the last section in [Chapter 2](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *DevOps with Container* for the detailed Dockerfile and Docker compose implementation.
    We''ll use `Deployment`, `Service`, `Secret`, `Volume`, and `ConfigMap` objects
    to implement this example in Kubernetes. Source code can be found at [https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk).'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将重新审视我们的售票服务：一个作为前端的售票机网络服务，提供接口来获取/放置票务。有一个作为缓存的Redis，用来管理我们有多少张票。Redis还充当发布者/订阅者通道。一旦一张票被售出，售票机将向其发布一个事件。订阅者被称为记录器，它将写入一个时间戳并将其记录到MySQL数据库中。请参考[第2章](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e)中的最后一节，*使用容器进行DevOps*，了解详细的Dockerfile和Docker
    compose实现。我们将使用`Deployment`、`Service`、`Secret`、`Volume`和`ConfigMap`对象在Kubernetes中实现这个例子。源代码可以在[https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk)找到。
- en: '![](../images/00045.jpeg)An example of kiosk in Kubernetes world'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00045.jpeg)Kubernetes世界中售票机的一个例子'
- en: We'll need four kinds of pods. Deployment is the best choice to manage/deploy
    the pods. It will reduce the pain when we do the deployment in the future by its
    deployment strategy feature. Since kiosk, Redis, and MySQL will be accessed by
    other components, we'll associate services to their pods. MySQL acts as a datastore,
    for the simplicity, we'll mount a local volume to it. Please note that Kubernetes
    offers a bunch of choices. Please check out the details and examples in [Chapter
    4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e), *Working with Storage
    and Resources*. Sensitive information such as our MySQL root and user password,
    we'll want them to be stored in secrets. The other insensitive configuration,
    such as DB name or DB username, we'll leave to ConfigMap.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将需要四种类型的pod。使用Deployment来管理/部署pod是最好的选择。它将通过部署策略功能减少我们在未来进行部署时的痛苦。由于售票机、Redis和MySQL将被其他组件访问，我们将为它们的pod关联服务。MySQL充当数据存储，为了简单起见，我们将为其挂载一个本地卷。请注意，Kubernetes提供了一堆选择。请查看[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)中的详细信息和示例，*使用存储和资源*。像MySQL的root和用户密码这样的敏感信息，我们希望它们存储在秘钥中。其他不敏感的配置，比如数据库名称或数据库用户名，我们将留给ConfigMap。
- en: 'We''ll launch MySQL first, as recorder depends on it. Before creating MySQL,
    we''ll have to create corresponding `secret` and `ConfigMap` first. To create
    `secret`, we need to generate base64 encrypted data:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先启动MySQL，因为记录器依赖于它。在创建MySQL之前，我们必须先创建相应的`secret`和`ConfigMap`。要创建`secret`，我们需要生成base64加密的数据：
- en: '[PRE65]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'Then we''re able to create the secret:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以创建秘钥：
- en: '[PRE66]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Then we come to our ConfigMap. Here, we put database user and database name
    as an example:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们来到我们的ConfigMap。在这里，我们将数据库用户和数据库名称作为示例放入：
- en: '[PRE67]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Then it''s time to launch MySQL and its service:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是启动MySQL及其服务的时候：
- en: '[PRE68]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: We can put more than one spec into a file by adding three dashes as separation.
    Here we mount `hostPath /mysql/data` into pods with the path `/var/lib/mysql`.
    In the environment section, we leverage the syntax of secret and ConfigMap by
    `secretKeyRef` and `configMapKeyRef`.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过添加三个破折号作为分隔，将多个规范放入一个文件中。在这里，我们将`hostPath /mysql/data`挂载到具有路径`/var/lib/mysql`的pod中。在环境部分，我们通过`secretKeyRef`和`configMapKeyRef`利用秘钥和ConfigMap的语法。
- en: 'After creating MySQL, Redis would be the next good candidate, since it is others''
    dependency, but it needs no prerequisite:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 创建MySQL后，Redis将是下一个很好的候选，因为它是其他的依赖，但它不需要先决条件：
- en: '[PRE69]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'Then it would be a good time to start kiosk:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 然后现在是启动kiosk的好时机：
- en: '[PRE70]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: Here, we expose `lcredis-service.default` to environment variables to kiosk
    pods, which is the DNS name that kube-dns creates for `Service` object (referred
    to as service in this chapter). Thus, kiosk could access Redis host via environment
    variables.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将`lcredis-service.default`暴露给kiosk pod的环境变量，这是kube-dns为`Service`对象（在本章中称为service）创建的DNS名称。因此，kiosk可以通过环境变量访问Redis主机。
- en: 'In the end, we''ll create recorder. Recorder doesn''t expose any interface
    to others, so it doesn''t need a `Service` object:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将创建录音机。录音机不向其他人公开任何接口，因此不需要`Service`对象：
- en: '[PRE71]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: Recorder needs to access both Redis and MySQL. It uses root credential that
    is injected via secret. Both endpoints for Redis and MySQL are accessed via service
    DNS name `<service_name>.<namespace>`.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 录音机需要访问Redis和MySQL。它使用通过秘密注入的根凭据。Redis和MySQL的两个端点通过服务DNS名称`<service_name>.<namespace>`访问。
- en: 'We then could check `deployment` objects:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以检查`deployment`对象：
- en: '[PRE72]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: As expected, we have four `deployment` objects with different desired count
    for pods.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 不出所料，我们有四个`deployment`对象，每个对象都有不同的期望pod数量。
- en: As we expose kiosk as NodePort, we should be able to access its service endpoint
    and see if it works properly. Assume we have a node, IP is `192.168.99.100`, and
    the NodePort that Kubernetes allocates is 30520.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将kiosk公开为NodePort，我们应该能够访问其服务端点，并查看它是否正常工作。假设我们有一个节点，IP是`192.168.99.100`，Kubernetes分配的NodePort是30520。
- en: 'If you''re using minikube, `minikube service [-n NAMESPACE] [--url] NAME` could
    help you access service NodePort via your default browser:'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在使用minikube，`minikube service [-n NAMESPACE] [--url] NAME`可以帮助您通过默认浏览器访问服务NodePort：
- en: '`// open kiosk console`'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '`//打开kiosk控制台`'
- en: '`# minikube service kiosk-service`'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`# minikube service kiosk-service`'
- en: '`Opening kubernetes service default/kiosk-service in default browser...`'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在默认浏览器中打开kubernetes服务默认/kiosk-service...
- en: Then we could know the IP and the port.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以知道IP和端口。
- en: 'We could then create and a get ticket by `POST` and `GET /tickets`:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以通过`POST`和`GET /tickets`创建和获取票据：
- en: '[PRE73]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Summary
  id: totrans-346
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned the basic concept of Kubernetes. We learned Kubernetes
    master has kube-apiserver to handle the requests, and controller managers are
    the control center of Kubernetes, for example, it ensures our desired container
    amount is fulfilled, controls the endpoint to associate pods and services, and
    controls API access token. We also have Kubernetes nodes, which are the workers
    to host the containers, receive the information from master, and route the traffic
    based on the configuration.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了Kubernetes的基本概念。我们了解到Kubernetes主节点有kube-apiserver来处理请求，控制器管理器是Kubernetes的控制中心，例如，它确保我们期望的容器数量得到满足，控制关联pod和服务的端点，并控制API访问令牌。我们还有Kubernetes节点，它们是承载容器的工作节点，接收来自主节点的信息，并根据配置路由流量。
- en: We then used minikube to demonstrate basic Kubernetes objects, including pod,
    ReplicaSets, ReplicationControllers, deployments, services, secrets, and ConfigMap.
    In the end, we demonstrated how to combine all the concepts we've learned into
    kiosk application deployment.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用minikube演示了基本的Kubernetes对象，包括pod、ReplicaSets、ReplicationControllers、deployments、services、secrets和ConfigMap。最后，我们演示了如何将我们学到的所有概念结合到kiosk应用程序部署中。
- en: As we mentioned previously, the data inside containers will be gone when a container
    is gone. Therefore, volume is extremely important to persist the data in container
    world. In the next chapter, we'll be learning how volume works and its options,
    how to use persistent volume, and so on.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，容器内的数据在容器消失时也会消失。因此，在容器世界中，卷是非常重要的，用来持久保存数据。在下一章中，我们将学习卷是如何工作的，以及它的选项，如何使用持久卷等等。
