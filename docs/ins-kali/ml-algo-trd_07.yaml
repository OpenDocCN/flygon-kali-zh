- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Linear Models – From Risk Factors to Return Forecasts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型 - 从风险因素到回报预测
- en: The family of linear models represents one of the most useful hypothesis classes.
    Many learning algorithms that are widely applied in algorithmic trading rely on
    linear predictors because they can be efficiently trained, are relatively robust
    to noisy financial data, and have strong links to the theory of finance. Linear
    predictors are also intuitive, easy to interpret, and often fit the data reasonably
    well or at least provide a good baseline.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型家族代表了最有用的假设类之一。许多广泛应用于算法交易的学习算法依赖于线性预测器，因为它们可以被有效地训练，相对于嘈杂的金融数据相对稳健，并且与金融理论有着密切的联系。线性预测器也直观、易于解释，并且通常能够很好地拟合数据，或者至少提供一个良好的基线。
- en: 'Linear regression has been known for over 200 years, since Legendre and Gauss
    applied it to  astronomy and began to analyze its statistical properties. Numerous
    extensions have since adapted the linear regression model and the baseline **ordinary
    least squares** (**OLS**) method to learn its parameters:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归已经被人们所熟知超过200年，自从Legendre和Gauss将其应用于天文学并开始分析其统计特性。自那时起，许多扩展已经改编了线性回归模型和基线**普通最小二乘法**（**OLS**）方法来学习其参数：
- en: '**Generalized linear models** (**GLM**) expand the scope of applications by
    allowing for response variables that imply an error distribution other than the
    normal distribution. GLMs include the probit or logistic models for **categorical
    response variables** that appear in classification problems.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义线性模型**（**GLM**）通过允许响应变量表示除正态分布以外的误差分布来扩展应用范围。GLM包括用于分类问题中出现的**分类响应变量**的概率或逻辑模型。'
- en: More **robust estimation methods** enable statistical inference where the data
    violates baseline assumptions due to, for example, correlation over time or across
    observations. This is often the case with panel data that contains repeated observations
    on the same units, such as historical returns on a universe of assets.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更**稳健的估计方法**使得在数据违反基线假设的情况下进行统计推断成为可能，例如，随时间或观察之间的相关性。这在包含对同一单位的重复观察的面板数据中经常发生，例如，资产组合的历史回报。
- en: '**Shrinkage methods** aim to improve the predictive performance of linear models.
    They use a complexity penalty that biases the coefficients learned by the model,
    with the goal of reducing the model''s variance and improving out-of-sample predictive
    performance.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收缩方法**旨在提高线性模型的预测性能。它们使用复杂度惩罚来偏置模型学习的系数，目的是减少模型的方差并提高样本外的预测性能。'
- en: In practice, linear models are applied to regression and classification problems
    with the goals of inference and prediction. Numerous asset pricing models have
    been developed by academic and industry researchers that leverage linear regression.
    Applications include the identification of significant factors that drive asset
    returns for better risk and performance management, as well as the prediction
    of returns over various time horizons. Classification problems, on the other hand,
    include directional price forecasts.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，线性模型被应用于回归和分类问题，目的是推断和预测。许多学术界和行业研究人员已经开发了许多利用线性回归的资产定价模型。应用包括确定推动资产回报的重要因素，以改善风险和绩效管理，以及在各种时间范围内预测回报。另一方面，分类问题包括方向性价格预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How linear regression works and which assumptions it makes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归的工作原理及其假设
- en: Training and diagnosing linear regression models
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练和诊断线性回归模型
- en: Using linear regression to predict stock returns
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用线性回归预测股票回报
- en: Use regularization to improve predictive performance
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用正则化来提高预测性能
- en: How logistic regression works
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归的工作原理
- en: Converting a regression into a classification problem
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将回归转化为分类问题
- en: You can find the code samples for this chapter and links to additional resources
    in the corresponding directory of the GitHub repository. The notebooks include
    color versions of the images.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在GitHub存储库的相应目录中找到本章的代码示例和其他资源的链接。笔记本包括图像的彩色版本。
- en: From inference to prediction
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从推断到预测
- en: As the name suggests, linear regression models assume that the output is the
    result of a linear combination of the inputs. The model also assumes a random
    error that allows for each observation to deviate from the expected linear relationship.
    The reasons that the model does not perfectly describe the relationship between
    inputs and output in a deterministic way include, for example, missing variables,
    measurement, or data collection issues.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，线性回归模型假设输出是输入的线性组合的结果。该模型还假设存在一个随机误差，允许每个观察结果偏离预期的线性关系。模型不能以确定性方式完美地描述输入和输出之间的关系的原因包括，例如，缺少变量、测量或数据收集问题。
- en: If we want to draw statistical conclusions about the true (but not observed)
    linear relationship in the population based on the regression parameters estimated
    from the sample, we need to add assumptions about the statistical nature of these
    errors. The baseline regression model makes the strong assumption that the distribution
    of the errors is identical across observations. It also assumes that errors are
    independent of each other—in other words, knowing one error does not help to forecast
    the next error. The assumption of **independent and identically distributed**
    (**IID**) errors implies that their covariance matrix is the identity matrix multiplied
    by a constant representing the error variance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要根据从样本估计的回归参数对总体中真实（但未观察到）的线性关系进行统计推断，我们需要增加关于这些误差的统计性质的假设。基线回归模型做出了一个强烈的假设，即误差的分布在观察中是相同的。它还假设误差是彼此独立的，换句话说，知道一个误差并不能帮助预测下一个误差。**独立同分布**（**IID**）误差的假设意味着它们的协方差矩阵是恒等矩阵乘以代表误差方差的常数。
- en: These assumptions guarantee that the OLS method delivers estimates that are
    not only unbiased but also efficient, which means that OLS estimates achieve the
    lowest sampling error among all linear learning algorithms. However, these assumptions
    are rarely met in practice.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设保证OLS方法提供的估计不仅是无偏的，而且是有效的，这意味着OLS估计在所有线性学习算法中实现了最低的抽样误差。然而，这些假设在实践中很少得到满足。
- en: In finance, we often encounter panel data with repeated observations on a given
    cross section. The attempt to estimate the systematic exposure of a universe of
    assets to a set of risk factors over time typically reveals correlation along
    the time axis, in the cross-sectional dimension, or both. Hence, alternative learning
    algorithms have emerged that assume error covariance matrices that are more complex
    than multiples of the identity matrix.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，我们经常遇到具有给定横截面上重复观察的面板数据。试图估计一组资产对一组风险因素的系统暴露随时间的变化通常会在时间轴上，横截面维度上或两者都会显示出相关性。因此，出现了假设误差协方差矩阵比单位矩阵更复杂的替代学习算法。
- en: On the other hand, methods that learn biased parameters for a linear model may
    yield estimates with lower variance and, hence, improve their predictive performance.
    Shrinkage methods reduce the model's complexity by applying regularization, which
    adds a penalty term to the linear objective function.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，学习线性模型的偏置参数的方法可能会产生方差较低的估计值，从而提高其预测性能。收缩方法通过应用正则化来减少模型的复杂性，这会向线性目标函数添加一个惩罚项。
- en: This penalty is positively related to the absolute size of the coefficients
    so that they are shrunk relative to the baseline case. Larger coefficients imply
    a more complex model that reacts more strongly to variations in the inputs. When
    properly calibrated, the penalty can limit the growth of the model's coefficients
    beyond what is optimal from a bias-variance perspective.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这种惩罚与系数的绝对大小正相关，因此它们相对于基线情况会收缩。较大的系数意味着更复杂的模型会更强烈地对输入的变化做出反应。当正确校准时，惩罚可以限制模型系数的增长，超出了从偏差-方差角度来看是最优的。
- en: First, we will introduce the baseline techniques for cross-section and panel
    data for linear models, as well as important enhancements that produce accurate
    estimates when key assumptions are violated. We will then illustrate these methods
    by estimating factor models that are ubiquitous in the development of algorithmic
    trading strategies. Finally, we will turn our attention to how shrinkage methods
    apply regularization and demonstrate how to use them to predict asset returns
    and generate trading signals.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将介绍用于线性模型的横截面和面板数据的基准技术，以及在关键假设被违反时产生准确估计的重要增强方法。然后，我们将通过估计因子模型来说明这些方法，在算法交易策略的发展中这些模型是无处不在的。最后，我们将把注意力转向收缩方法如何应用正则化，并演示如何使用它们来预测资产回报并生成交易信号。
- en: The baseline model – multiple linear regression
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基准模型 - 多元线性回归
- en: We will begin with the model's specification and objective function, the methods
    we can use to learn its parameters, and the statistical assumptions that allow
    the inference and diagnostics of these assumptions. Then, we will present extensions
    that we can use to adapt the model to situations that violate these assumptions.
    Useful references for additional background include *Wooldridge* (*2002* and *2008*).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从模型的规范和目标函数开始，学习其参数的方法，以及允许对这些假设进行推断和诊断的统计假设。然后，我们将介绍我们可以用来使模型适应违反这些假设的情况的扩展。额外背景的有用参考资料包括*Wooldridge*（2002年和2008年）。
- en: How to formulate the model
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何构建模型
- en: The multiple regression model defines a linear functional relationship between
    one continuous outcome variable and *p* input variables that can be of any type
    but may require preprocessing. Multivariate regression, in contrast, refers to
    the regression of multiple outputs on multiple input variables.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归模型定义了一个连续输出变量和*p*个输入变量之间的线性函数关系，这些输入变量可以是任何类型，但可能需要预处理。相比之下，多元回归是指多个输出变量对多个输入变量的回归。
- en: 'In the population, the linear regression model has the following form for a
    single instance of the output *y*, an input vector ![](img/B15439_07_001.png),
    and the error ![](img/B15439_07_002.png):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在总体中，线性回归模型对于输出*y*的单个实例，输入向量![](img/B15439_07_001.png)，和误差![](img/B15439_07_002.png)具有以下形式：
- en: '![](img/B15439_07_003.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_003.png)'
- en: 'The interpretation of the coefficients is straightforward: the value of a coefficient
    ![](img/B15439_07_093.png) is the partial, average effect of the variable *x*[i]
    on the output, holding all other variables constant.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的解释很简单：系数![](img/B15439_07_093.png)的值是变量*x*[i]对输出的部分平均影响，保持所有其他变量不变。
- en: 'We can also write the model more compactly in matrix form. In this case, *y*
    is a vector of *N* output observations, *X* is the design matrix with *N* rows
    of observations on the *p* variables plus a column of 1s for the intercept, and
    ![](img/B15439_07_004.png) is the vector containing the *P* = *p*+1 coefficients:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以以更紧凑的矩阵形式来表示模型。在这种情况下，*y*是*N*个输出观察值的向量，*X*是设计矩阵，具有*p*个变量的*N*行观察值，以及一个用于截距的1列，![](img/B15439_07_004.png)是包含*P*
    = *p*+1个系数的向量：
- en: '![](img/B15439_07_005.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_005.png)'
- en: The model is linear in its *p* +1 parameters but can represent nonlinear relationships
    if we choose or transform variables accordingly, for example, by including a polynomial
    basis expansion or logarithmic terms. You can also use categorical variables with
    dummy encoding, and include interactions between variables by creating new inputs
    of the form *x*[i]*x*[j].
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在其*p*+1个参数中是线性的，但如果我们选择或相应地转换变量，例如通过包括多项式基扩展或对数项，它可以表示非线性关系。您还可以使用具有虚拟编码的分类变量，并通过创建形式为*x*[i]*x*[j]的新输入来包含变量之间的交互。
- en: To complete the formulation of the model from a statistical point of view so
    that we can test hypotheses about its parameters, we need to make specific assumptions
    about the error term. We'll do this after introducing the most important methods
    to learn the parameters.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从统计角度完成模型的制定，以便我们可以测试关于其参数的假设，我们需要对误差项做出具体的假设。在介绍学习参数的最重要方法之后，我们将这样做。
- en: How to train the model
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何训练模型
- en: 'There are several methods we can use to learn the model parameters from the
    data: **ordinary least squares** (**OLS**), **maximum likelihood estimation**
    (**MLE**), and **stochastic gradient descent** (**SGD**). We will present each
    method in turn.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用几种方法从数据中学习模型参数：**普通最小二乘法**（**OLS**），**最大似然估计**（**MLE**）和**随机梯度下降**（**SGD**）。我们将依次介绍每种方法。
- en: Ordinary least squares – how to fit a hyperplane to the data
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 普通最小二乘法 - 如何拟合数据的超平面
- en: The method of least squares is the original method that learns the parameters
    of the hyperplane that best approximates the output from the input data. As the
    name suggests, it takes the best approximation to minimize the sum of the squared
    distances between the output value and the hyperplane represented by the model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法是学习最佳逼近输出的超平面的原始方法。顾名思义，它采用最佳逼近来最小化输出值与模型表示的超平面之间的平方距离的总和。
- en: 'The difference between the model''s prediction and the actual outcome for a
    given data point is the **residual** (whereas the deviation of the true model
    from the true output in the population is called **error**). Hence, in formal
    terms, the least-squares estimation method chooses the coefficient vector to minimize
    the **residual sum of squares** (**RSS**):'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数据点的模型预测与实际结果之间的差异是**残差**（而在总体中真实模型与真实输出的偏差称为**误差**）。因此，在正式术语中，最小二乘估计方法选择系数向量以最小化**残差平方和**（**RSS**）：
- en: '![](img/B15439_07_006.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_006.png)'
- en: 'Thus, the least-squares coefficients ![](img/B15439_07_007.png) are computed
    as:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最小二乘系数![](img/B15439_07_007.png)计算如下：
- en: '![](img/B15439_07_008.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_008.png)'
- en: 'The optimal parameter vector that minimizes the RSS results from setting the
    derivatives with respect to ![](img/B15439_07_009.png) of the preceding expression
    to zero. Assuming *X* has full column rank, which requires that the input variables
    are not linearly dependent, it is thus invertible, and we obtain a unique solution,
    as follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化残差平方和的最佳参数向量来自将前述表达式对![](img/B15439_07_009.png)的导数设为零。假设*X*具有完整的列秩，这要求输入变量不是线性相关的，因此可逆，我们得到一个唯一的解，如下所示：
- en: '![](img/B15439_07_010.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_010.png)'
- en: When *y* and *X* have means of zero, which can be achieved by subtracting their
    respective means, ![](img/B15439_07_009.png) represents the ratio of the covariance
    between the inputs and the outputs ![](img/B15439_07_012.png) and the output variance
    ![](img/B15439_07_013.png)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 当*y*和*X*的均值为零时，可以通过减去它们各自的均值来实现，![](img/B15439_07_009.png)表示输入和输出之间的协方差比上输出方差的比率。
- en: 'There is also a geometric interpretation: the coefficients that minimize RSS
    ensure that the vector of residuals ![](img/B15439_07_014.png) is orthogonal to
    the subspace of ![](img/B15439_07_015.png) spanned by the *P* columns of *X*,
    and the estimates ![](img/B15439_07_016.png) are orthogonal projections into that
    subspace.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个几何解释：最小化残差平方和的系数确保残差向量![](img/B15439_07_014.png)与由*X*的*P*列张成的子空间![](img/B15439_07_015.png)正交，并且估计值![](img/B15439_07_016.png)是该子空间的正交投影。
- en: Maximum likelihood estimation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: MLE is an important general method used to estimate the parameters of a statistical
    model. It relies on the likelihood function, which computes how likely it is to
    observe the sample of outputs when given the input data as a function of the model
    parameters. The likelihood differs from probabilities in that it is not normalized
    to a range from 0 to 1.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: MLE是用于估计统计模型参数的重要通用方法。它依赖于似然函数，该函数计算在给定模型参数的情况下观察输出样本的可能性。似然性与概率的不同之处在于它不会归一化到0到1的范围内。
- en: 'We can set up the likelihood function for the multiple linear regression example
    by assuming a distribution for the error term, such as the standard normal distribution:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过假设误差项的分布，如标准正态分布，为多元线性回归示例设置似然函数：
- en: '![](img/B15439_07_017.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_017.png)'
- en: 'This allows us to compute the conditional probability of observing a given
    output *y*[i] given the corresponding input vector *x*[i] and the parameters ![](img/B15439_07_009.png),
    ![](img/B15439_07_019.png):'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够计算在给定输入向量*x*[i]和参数![](img/B15439_07_009.png)，![](img/B15439_07_019.png)的条件概率观察到给定输出*y*[i]的概率：
- en: '![](img/B15439_07_020.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_020.png)'
- en: 'Assuming the output values are conditionally independent, given the inputs,
    the likelihood of the sample is proportional to the product of the conditional
    probabilities of the individual output data points. Since it is easier to work
    with sums than with products, we apply the logarithm to obtain the **log-likelihood
    function**:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输出值在给定输入的条件下是独立的，样本的似然性与各个输出数据点的条件概率的乘积成比例。由于使用总和比使用乘积更容易，我们应用对数得到**对数似然函数**：
- en: '![](img/B15439_07_021.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_021.png)'
- en: 'The goal of MLE is to choose the model parameters that maximize the probability
    of the observed output sample, taking the inputs as given. Hence, the MLE parameter
    estimate results from maximizing the log-likelihood function:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: MLE的目标是选择最大化观察到的输出样本的概率的模型参数，假设输入已知。因此，MLE参数估计结果来自最大化对数似然函数：
- en: '![](img/B15439_07_022.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_022.png)'
- en: Due to the assumption of normally distributed errors, maximizing the log-likelihood
    function produces the same parameter solution as least squares. This is because
    the only expression that depends on the parameters is the squared residual in
    the exponent.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 由于假设误差是正态分布的，最大化对数似然函数产生与最小二乘法相同的参数解。这是因为唯一依赖于参数的表达式是指数中的平方残差。
- en: For other distributional assumptions and models, MLE will produce different
    results, as we will see in the last section on binary classification, where the
    outcome follows a Bernoulli distribution. Furthermore, MLE is a more general estimation
    method because, in many cases, the least-squares method is not applicable, as
    we will see later for logistic regression.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他分布假设和模型，MLE将产生不同的结果，正如我们将在最后一节关于二元分类中看到的，那里的结果遵循伯努利分布。此外，MLE是一种更一般的估计方法，因为在许多情况下，最小二乘法是不适用的，正如我们稍后将在逻辑回归中看到的。
- en: Gradient descent
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 梯度下降
- en: Gradient descent is a general-purpose optimization algorithm that will find
    stationary points of smooth functions. The solution will be a global optimum if
    the objective function is convex. Variations of gradient descent are widely used
    in training complex neural networks, but also to compute solutions for MLE problems.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通用的优化算法，可以找到平滑函数的稳定点。如果目标函数是凸函数，解将是全局最优解。梯度下降的变种广泛用于训练复杂的神经网络，也用于计算MLE问题的解。
- en: The algorithm uses the gradient of the objective function. The gradient contains
    the partial derivatives of the objective with respect to the parameters. These
    derivatives indicate how much the objective changes for an infinitesimal (infinitely
    small) step in the direction of the corresponding parameters. It turns out that
    the maximal change of the function value results from a step in the direction
    of the gradient itself.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法使用目标函数的梯度。梯度包含目标函数对参数的偏导数。这些导数指示了在相应参数方向上进行微小（无限小）步骤时目标的变化量。结果表明，函数值的最大变化来自于沿着梯度方向的步骤。
- en: '*Figure 7.1* sketches the process for a single variable *x* and a convex function
    *f(x)*, where we are looking for the minimum, *x*[0] . Where the function has
    a negative slope, gradient descent increases the target value for *x*[0], and
    decreases the values otherwise:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.1*描述了单个变量*x*和凸函数*f(x)*的过程，我们在其中寻找最小值*x*[0]。当函数具有负斜率时，梯度下降会增加*x*[0]的目标值，并在其他情况下减小值：'
- en: '![](img/B15439_07_01.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_01.png)'
- en: 'Figure 7.1: Gradient descent'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.1：梯度下降
- en: When we minimize a function that describes, for example, the cost of a prediction
    error, the algorithm computes the gradient for the current parameter values using
    the training data. Then, it modifies each parameter in proportion to the negative
    value of its corresponding gradient component. As a result, the objective function
    will assume a lower value and move the parameters closer to the solution. The
    optimization stops when the gradient becomes small, and the parameter values change
    very little.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们最小化描述例如预测误差成本的函数时，算法使用训练数据计算当前参数值的梯度。然后，它按比例修改每个参数，以其相应梯度分量的负值。结果，目标函数将假定一个较低的值，并将参数移动到解决方案附近。优化在梯度变得很小且参数值变化很小时停止。
- en: The size of these steps is determined by the learning rate, which is a critical
    parameter that may require tuning. Many implementations include the option for
    this learning rate to gradually decrease with the number of iterations. Depending
    on the size of the data, the algorithm may iterate many times over the entire
    dataset. Each such iteration is called an **epoch**. The number of epochs and
    the tolerance used to stop further iterations are additional hyperparameters you
    can tune.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的大小由学习率确定，这是一个关键参数，可能需要调整。许多实现包括学习率随迭代次数逐渐减小的选项。根据数据的大小，算法可能会在整个数据集上进行多次迭代。每次迭代称为一个**epoch**。您可以调整的其他超参数包括迭代的次数和用于停止进一步迭代的容差。
- en: Stochastic gradient descent randomly selects a data point and computes the gradient
    for this data point, as opposed to an average over a larger sample to achieve
    a speedup. There are also batch versions that use a certain number of data points
    for each step.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降随机选择一个数据点并计算该数据点的梯度，而不是对较大样本进行平均以加快速度。还有使用一定数量的数据点进行每一步的批处理版本。
- en: The Gauss–Markov theorem
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高斯-马尔可夫定理
- en: To assess the statistical properties of the model and run inference, we need
    to make assumptions about the residuals that represent the part of the input data
    the model is unable to correctly fit or "explain."
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型的统计特性并进行推断，我们需要对表示模型无法正确拟合或“解释”的输入数据的残差做出假设。
- en: The **Gauss–Markov theorem** (**GMT**) defines the assumptions required for
    OLS to produce unbiased estimates of the model parameters ![](img/B15439_07_023.png),
    and for these estimates to have the lowest standard error among all linear models
    for cross-sectional data.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**高斯-马尔可夫定理**（**GMT**）定义了OLS产生模型参数![](img/B15439_07_023.png)无偏估计所需的假设，以及这些估计在横截面数据的所有线性模型中具有最低标准误差。'
- en: 'The baseline multiple regression model makes the following GMT assumptions
    (*Wooldridge 2008*):'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 基线多元回归模型做出了以下GMT假设（*Wooldridge 2008*）：
- en: In the population, linearity holds so that ![](img/B15439_07_024.png), where
    ![](img/B15439_07_025.png) are unknown but constant and ![](img/B15439_07_026.png)
    is a random error.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在人口中，线性关系成立，使得![](img/B15439_07_024.png)，其中![](img/B15439_07_025.png)是未知但恒定的，![](img/B15439_07_026.png)是随机误差。
- en: The data for the input variables ![](img/B15439_07_027.png) is a random sample
    from the population.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入变量![](img/B15439_07_027.png)的数据是来自人口的随机样本。
- en: No perfect collinearity—there are no exact linear relationships among the input
    variables.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有完美的共线性——输入变量之间没有精确的线性关系。
- en: 'The error ![](img/B15439_07_026.png) has a conditional mean of zero given any
    of the inputs: ![](img/B15439_07_029.png).'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 误差![](img/B15439_07_026.png)在给定任何输入时具有零的条件均值：![](img/B15439_07_029.png)。
- en: 'Homoskedasticity—the error term ![](img/B15439_07_030.png) has constant variance
    given the inputs: ![](img/B15439_07_031.png)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同方差性——误差项![](img/B15439_07_030.png)在给定输入时具有恒定方差：![](img/B15439_07_031.png)
- en: The fourth assumption implies that no missing variable exists that is correlated
    with any of the input variables.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个假设意味着不存在与任何输入变量相关的缺失变量。
- en: Under the first four assumptions (GMT 1-4), the OLS method delivers unbiased
    estimates. Including an irrelevant variable does not bias the intercept and slope
    estimates, but omitting a relevant variable will result in biased parameter estimates.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前四个假设（GMT 1-4）下，OLS方法提供无偏估计。包括一个不相关的变量不会使截距和斜率估计产生偏差，但省略一个相关变量将导致参数估计产生偏差。
- en: 'Under GMT 1-4, OLS is then also consistent: as the sample size increases, the
    estimates converge to the true value as the standard errors become arbitrary.
    The converse is, unfortunately, also true: if the conditional expectation of the
    error is not zero because the model misses a relevant variable or the functional
    form is wrong (for example, quadratic or log terms are missing), then all parameter
    estimates are biased. If the error is correlated with any of the input variables,
    then OLS is also not consistent and adding more data will not remove the bias.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在GMT 1-4下，OLS也是一致的：随着样本量的增加，估计值收敛于真实值，标准误差变得任意。不幸的是，反之亦然：如果误差的条件期望不为零，因为模型缺少相关变量或者函数形式错误（例如，缺少二次项或对数项），那么所有参数估计都是有偏的。如果误差与任何输入变量相关，那么OLS也不是一致的，增加更多数据也无法消除偏差。
- en: If we add the fifth assumption, then OLS also produces the **best linear unbiased
    estimates** (**BLUE**). Best means that the estimates have the lowest standard
    error among all linear estimators. Hence, if the five assumptions hold and the
    goal is statistical inference, then the OLS estimates are the way to go. If the
    goal, however, is to predict, then we will see that other estimators exist that
    trade some bias for a lower variance to achieve superior predictive performance
    in many settings.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们加入第五个假设，那么OLS也会产生**最佳线性无偏估计**（**BLUE**）。最佳意味着估计值在所有线性估计器中具有最低的标准误差。因此，如果五个假设成立并且目标是统计推断，那么OLS估计是最佳选择。然而，如果目标是预测，我们将看到存在其他估计器，它们在许多情况下通过交换一些偏差以获得更低的方差来实现更优越的预测性能。
- en: Now that we have introduced the basic OLS assumptions, we can take a look at
    inference in small and large samples.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了基本的OLS假设，我们可以看看小样本和大样本中的推断。
- en: How to conduct statistical inference
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何进行统计推断
- en: Inference in the linear regression context aims to draw conclusions from the
    sample data about the true relationship in the population. This includes testing
    hypotheses about the significance of the overall relationship or the values of
    particular coefficients, as well as estimates of confidence intervals.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归背景下的推断旨在从样本数据中得出关于总体真实关系的结论。这包括关于整体关系的显著性或特定系数值的假设检验，以及置信区间的估计。
- en: 'The key ingredient for statistical inference is a test statistic with a known
    distribution, typically computed from a quantity of interest like a regression
    coefficient. We can formulate a null hypothesis about this statistic and compute
    the probability of observing the actual value for this statistic, given the sample
    under the assumption that the hypothesis is correct. This probability is commonly
    referred to as the **p-value**: if it drops below a significance threshold (typically
    5 percent), then we reject the hypothesis because it makes the value that we observed
    for the test statistic in the sample very unlikely. On the flip side, the p-value
    reflects the probability that we are wrong in rejecting what is, in fact, a correct
    hypothesis.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 统计推断的关键要素是具有已知分布的检验统计量，通常是从感兴趣的数量（如回归系数）计算得出。我们可以对这个统计量制定一个关于零假设，并计算在假设成立的情况下，观察到实际统计量值的概率。这个概率通常被称为**p值**：如果它低于显著性阈值（通常为5%），那么我们拒绝零假设，因为它使我们在样本中观察到的测试统计量值非常不可能。另一方面，p值反映了我们在拒绝实际上是正确的假设时可能出错的概率。
- en: In addition to the five GMT assumptions, the **classical linear model** assumes
    **normality**—that the population error is normally distributed and independent
    of the input variables. This strong assumption implies that the output variable
    is normally distributed, conditional on the input variables. It allows for the
    derivation of the exact distribution of the coefficients, which, in turn, implies
    exact distributions of the test statistics that are needed for exact hypotheses
    tests in small samples. This assumption often fails in practice—asset returns,
    for instance, are not normally distributed.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 除了五个GMT假设外，**经典线性模型**还假设**正态性**——即总体误差服从正态分布，并且与输入变量独立。这个强假设意味着在输入变量条件下，输出变量服从正态分布。它允许推导出系数的精确分布，进而意味着小样本中精确假设检验所需的测试统计量的精确分布。这个假设在实践中经常失败——例如，资产收益并不服从正态分布。
- en: 'Fortunately, however, the test statistics used under normality are also approximately
    valid when normality does not hold. More specifically, the following distributional
    characteristics of the test statistics hold approximately under GMT assumptions
    1–5 and exactly when normality holds:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，当正态性不成立时，正态性下使用的检验统计量也近似有效。更具体地说，在GMT假设1-5下，这些检验统计量的分布特征近似成立，当正态性成立时则完全成立。
- en: 'The parameter estimates follow a multivariate normal distribution: ![](img/B15439_07_032.png).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数估计遵循多元正态分布：![](img/B15439_07_032.png)。
- en: Under GMT 1–5, the parameter estimates are unbiased, and we can get an unbiased
    estimate of ![](img/B15439_07_033.png), the constant error variance, using ![](img/B15439_07_034.png).
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GMT 1-5下，参数估计是无偏的，我们可以使用![](img/B15439_07_034.png)获得![](img/B15439_07_033.png)的无偏估计，即常数误差方差。
- en: The **t-statistic for a hypothesis test about an individual coefficient** ![](img/B15439_07_035.png)
    is ![](img/B15439_07_036.png) and follows a *t* distribution with *N*-*p*-1 degrees
    of freedom, where ![](img/B15439_07_037.png) is the *j*'s element of the diagonal
    of ![](img/B15439_07_038.png).
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于关于单个系数的假设检验的t统计量是![](img/B15439_07_036.png)，遵循自由度为N-p-1的t分布，其中![](img/B15439_07_037.png)是![](img/B15439_07_038.png)对角线的第j个元素。
- en: The *t* distribution converges to the normal distribution. Since the 97.5 quantile
    of the normal distribution is about 1.96, a useful rule of thumb for a **95 percent
    confidence interval around a parameter estimate** is ![](img/B15439_07_039.png),
    where *se* means **standard error**. An interval that includes zero implies that
    we can't reject the null hypothesis that the true parameter is zero and, hence,
    irrelevant for the model.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: t分布收敛于正态分布。由于正态分布的97.5分位数约为1.96，因此**参数估计的95%置信区间的一个有用的经验法则**是![](img/B15439_07_039.png)，其中se表示**标准误差**。包含零的区间意味着我们无法拒绝真实参数为零的零假设，因此对模型无关。
- en: The F-statistic allows for tests of restrictions on several parameters, including
    whether the entire regression is significant. It measures the change (reduction)
    in the RSS that results from additional variables.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: F统计量允许对多个参数的限制进行检验，包括整个回归是否显著。它衡量了由于额外变量而导致的残差平方和（RSS）的变化（减少）。
- en: Finally, the **Lagrange multiplier** (**LM**) test is an alternative to the
    F-test for testing multiple restrictions.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，**拉格朗日乘数**（**LM**）检验是测试多个限制的F检验的替代方法。
- en: How to diagnose and remedy problems
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何诊断和解决问题
- en: Diagnostics validate the model assumptions and help us prevent wrong conclusions
    when interpreting the result and conducting statistical inference. They include
    goodness of fit measures and various tests of the assumptions about the error
    term, including how closely the residuals match a normal distribution.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断验证了模型假设，并帮助我们在解释结果和进行统计推断时避免错误的结论。它们包括拟合度量和关于误差项的假设的各种检验，包括残差与正态分布的拟合程度。
- en: Furthermore, diagnostics evaluate whether the residual variance is indeed constant
    or exhibits heteroskedasticity (covered later in this section). They also test
    if the errors are conditionally uncorrelated or exhibit serial correlation, that
    is, if knowing one error helps to predict consecutive errors.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，诊断评估残差方差是否确实恒定或者是否存在异方差（稍后在本节中讨论）。它们还测试错误是否有条件相关或者是否存在串行相关，即知道一个错误是否有助于预测连续的错误。
- en: In addition to conducting the following diagnostic tests, you should always
    visually inspect the residuals. This helps to detect whether they reflect systematic
    patterns, as opposed to random noise that suggests the model is missing one or
    more factors that drive the outcome.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 除了进行以下诊断测试，您还应该始终直观地检查残差。这有助于检测它们是否反映了系统模式，而不是表明模型缺少一个或多个驱动结果的因素的随机噪声。
- en: Goodness of fit
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 拟合度
- en: '**Goodness-of-fit measures** assess how well a model explains the variation
    in the outcome. They help to evaluate the quality of the model specification,
    for instance, when selecting among different model designs.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**拟合度量**评估了模型解释结果变异程度的能力。它们有助于评估模型规范的质量，例如在选择不同的模型设计时。'
- en: Goodness-of-fit metrics differ in how they measure the fit. Here, we will focus
    on in-sample metrics; we will use out-of-sample testing and cross-validation when
    we focus on predictive models in the next section.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合度度量在衡量拟合程度方面有所不同。在这里，我们将专注于样本内度量；在下一节中，我们将在关注预测模型时使用样本外测试和交叉验证。
- en: 'Prominent goodness-of-fit measures include the **(adjusted) R2**, which should
    be maximized and is based on the least-squares estimate:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 突出的拟合度量包括（调整后的）R²，应该最大化，基于最小二乘估计：
- en: R² measures the share of the variation in the outcome data explained by the
    model and is computed as ![](img/B15439_07_040.png), where TSS is the sum of squared
    deviations of the outcome from its mean. It also corresponds to the squared correlation
    coefficient between the actual outcome values and those estimated by the model.
    The implicit goal is to maximize R². However, it never decreases as we add more
    variables. One of the shortcomings of R², therefore, is that it encourages overfitting.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²衡量了模型解释结果数据变异的比例，并计算为![](img/B15439_07_040.png)，其中TSS是结果与其均值的平方偏差之和。它还对应于实际结果值与模型估计值之间的平方相关系数。隐含的目标是最大化R²。然而，随着添加更多变量，它永远不会减少。因此，R²的一个缺点是它鼓励过度拟合。
- en: The adjusted R² penalizes R² for adding more variables; each additional variable
    needs to reduce the RSS significantly to produce better goodness of fit.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整后的R²对R²进行了惩罚，因为添加更多变量，每个额外变量都需要显著减少RSS才能产生更好的拟合度。
- en: 'Alternatively, the **Akaike information criterion** (**AIC**) and the **Bayesian
    information criterion** (**BIC**) are to be minimized and are based on the maximum-likelihood
    estimate:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，**赤池信息准则**（**AIC**）和**贝叶斯信息准则**（**BIC**）需要最小化，基于最大似然估计：
- en: '![](img/B15439_07_041.png), where ![](img/B15439_07_042.png) is the value of
    the maximized likelihood function and *k* is the number of parameters.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/B15439_07_041.png)，其中![](img/B15439_07_042.png)是最大化似然函数的值，k是参数的数量。'
- en: '![](img/B15439_07_043.png), where *N* is the sample size.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/B15439_07_043.png)，其中N是样本量。'
- en: Both metrics penalize for complexity. BIC imposes a higher penalty, so it might
    underfit relative to AIC and vice versa.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个度量都对复杂性进行了惩罚。BIC施加了更高的惩罚，因此相对于AIC可能会欠拟合，反之亦然。
- en: Conceptually, AIC aims to find the model that best describes an unknown data-generating
    process, whereas BIC tries to find the best model among the set of candidates.
    In practice, both criteria can be used jointly to guide model selection when the
    goal is an in-sample fit; otherwise, cross-validation and selection based on estimates
    of generalization error are preferable.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在概念上，AIC旨在找到最好描述未知数据生成过程的模型，而BIC试图在候选模型集合中找到最佳模型。在实践中，当目标是样本内拟合时，两个标准可以一起使用来指导模型选择；否则，交叉验证和基于泛化误差估计的选择更可取。
- en: Heteroskedasticity
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 异方差性
- en: GMT assumption 5 requires the residual covariance to take the shape ![](img/B15439_07_044.png),
    that is, a diagonal matrix with entries equal to the constant variance of the
    error term. **Heteroskedasticity** occurs when the residual variance is not constant
    but differs across observations. If the residual variance is positively correlated
    with an input variable, that is, when errors are larger for input values that
    are far from their mean, then OLS standard error estimates will be too low; consequently,
    the t-statistic will be inflated, leading to false discoveries of relationships
    where none actually exist.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: GMT假设5要求残差协方差采用形式![](img/B15439_07_044.png)，即对角线矩阵，其条目等于误差项的恒定方差。**异方差性**发生在残差方差不恒定，而是在观察中不同。如果残差方差与输入变量呈正相关，即对于远离其均值的输入值，误差较大，那么OLS标准误差估计将过低；因此，t统计量将被夸大，导致发现实际上不存在的关系。
- en: Diagnostics starts with a visual inspection of the residuals. Systematic patterns
    in the (supposedly random) residuals suggest statistical tests of the null hypothesis
    that errors are homoscedastic against various alternatives. These tests include
    the Breusch–Pagan and White tests.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断从对残差的视觉检查开始。在（假定为随机的）残差中出现系统性模式，表明对错误是同方差的零假设进行统计检验，检验包括Breusch-Pagan和White检验。
- en: 'There are several ways to correct OLS estimates for heteroskedasticity:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以纠正OLS估计的异方差性：
- en: '**Robust standard errors** (sometimes called *White standard errors*) take
    heteroskedasticity into account when computing the error variance using a so-called
    **sandwich estimator**.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**鲁棒标准误差**（有时称为*White标准误差*）在计算错误方差时考虑了异方差性，使用所谓的**三明治估计器**。'
- en: '**Clustered standard errors** assume that there are distinct groups in your
    data that are homoscedastic, but the error variance differs between groups. These
    groups could be different asset classes or equities from different industries.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类标准误差**假设数据中存在不同的组，这些组是同方差的，但是组之间的误差方差不同。这些组可以是不同的资产类别或来自不同行业的股票。'
- en: 'Several alternatives to OLS estimate the error covariance matrix using different
    assumptions when ![](img/B15439_07_045.png). The following are available in `statsmodels`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: OLS的几种替代方法使用不同的假设来估计错误协方差矩阵，这些方法在`statsmodels`中都可以找到：
- en: '**Weighted least squares (WLS)**: For heteroskedastic errors where the covariance
    matrix has only diagonal entries, as for OLS, but now the entries are allowed
    to vary.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权最小二乘法（WLS）：适用于异方差误差，其中协方差矩阵只有对角线条目，就像OLS一样，但现在允许条目变化。
- en: '**Feasible generalized least squares (GLSAR)**: For autocorrelated errors that
    follow an autoregressive AR(*p*) process (see *Chapter 9*, *Time-Series Models
    for Volatility Forecasts and Statistical Arbitrage*).'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可行广义最小二乘法（GLSAR）**：适用于遵循自回归AR(*p*)过程的自相关误差（见*第9章*，*波动率预测和统计套利的时间序列模型*）。'
- en: '**Generalized least squares (GLS)**: For arbitrary covariance matrix structure;
    yields efficient and unbiased estimates in the presence of heteroskedasticity
    or serial correlation.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义最小二乘法（GLS）：适用于任意协方差矩阵结构；在异方差性或序列相关存在时产生高效和无偏估计。
- en: Serial correlation
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 序列相关
- en: Serial correlation means that consecutive residuals produced by linear regression
    are correlated, which violates the fourth GMT assumption. Positive serial correlation
    implies that the standard errors are underestimated and that the t-statistics
    will be inflated, leading to false discoveries if ignored. However, there are
    procedures to correct for serial correlation when calculating standard errors.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 序列相关意味着线性回归产生的连续残差是相关的，这违反了第四个GMT假设。正序列相关意味着标准误差被低估，t统计量将被夸大，如果忽略，将导致虚假发现。然而，在计算标准误差时有纠正序列相关的程序。
- en: The **Durbin–Watson statistic** diagnoses serial correlation. It tests the hypothesis
    that the OLS residuals are not autocorrelated against the alternative that they
    follow an autoregressive process (which we will explore in the next chapter).
    The test statistic ranges from 0 to 4; values near 2 indicate non-autocorrelation,
    lower values suggest positive autocorrelation, and higher values indicate negative
    autocorrelation. The exact threshold values depend on the number of parameters
    and observations and need to be looked up in tables.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**Durbin-Watson统计量**用于诊断序列相关。它检验了OLS残差不自相关的假设，对抗它们遵循自回归过程的替代假设（我们将在下一章中探讨）。检验统计量的范围从0到4；接近2的值表示非自相关，较低的值暗示正自相关，较高的值表示负自相关。确切的阈值取决于参数和观测数，并需要在表中查找。'
- en: Multicollinearity
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多重共线性
- en: '**Multicollinearity** occurs when two or more independent variables are highly
    correlated. This poses several challenges:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 多重共线性发生在两个或更多个自变量高度相关的情况下。这带来了几个挑战：
- en: It is difficult to determine which factors influence the dependent variable.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难确定哪些因素影响因变量。
- en: The individual p-values can be misleading—a p-value can be high, even if the
    variable is, in fact, important.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个别p值可能会误导——即使变量实际上很重要，p值也可能很高。
- en: The confidence intervals for the regression coefficients will be too wide, possibly
    even including zero. This complicates the determination of an independent variable's
    effect on the outcome.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归系数的置信区间可能会过宽，甚至可能包括零。这使得确定自变量对结果的影响变得更加复杂。
- en: There is no formal or theory-based solution that corrects for multicollinearity.
    Instead, try to remove one or more of the correlated input variables, or increase
    the sample size.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正式的或基于理论的解决方案可以纠正多重共线性。相反，尝试去除一个或多个相关的输入变量，或增加样本量。
- en: How to run linear regression in practice
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在实践中运行线性回归
- en: 'The accompanying notebook, `linear_regression_intro.ipynb`, illustrates a simple
    and then a multiple linear regression, the latter using both OLS and gradient
    descent. For the multiple regression, we generate two random input variables *x*[1]
    and *x*[2] that range from -50 to +50, and an outcome variable that''s calculated
    as a linear combination of the inputs, plus random Gaussian noise, to meet the
    normality assumption GMT 6:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 附带的笔记本`linear_regression_intro.ipynb`演示了简单线性回归和多元线性回归，后者使用了OLS和梯度下降。对于多元回归，我们生成了两个范围从-50到+50的随机输入变量*x*[1]和*x*[2]，以及一个结果变量，它被计算为输入的线性组合，再加上随机的高斯噪声，以满足正态性假设GMT
    6：
- en: '![](img/B15439_07_046.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_046.png)'
- en: OLS with statsmodels
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: statsmodels中的OLS
- en: 'We use `statsmodels` to estimate a multiple regression model that accurately
    reflects the data-generating process, as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`statsmodels`来估计一个准确反映数据生成过程的多元回归模型，具体如下：
- en: '[PRE0]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following OLS Regression Results summary:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下OLS回归结果摘要：
- en: '![](img/B15439_07_02.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_02.png)'
- en: 'Figure 7.2: OLS Regression Results summary'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2：OLS回归结果摘要
- en: 'The upper part of the summary displays the dataset characteristics—namely,
    the estimation method and the number of observations and parameters—and indicates
    that standard error estimates do not account for heteroskedasticity. The middle
    panel shows the coefficient values that closely reflect the artificial data-generating
    process. We can confirm that the estimates displayed in the middle of the summary
    result can be obtained using the OLS formula derived previously:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的上部显示了数据集的特征，即估计方法和观测值和参数的数量，并指出标准误差估计不考虑异方差性。中间面板显示了系数值，这些系数值与人工数据生成过程密切相关。我们可以确认摘要结果中间显示的估计可以使用先前推导的OLS公式得到：
- en: '[PRE1]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following code visualizes how the model fitted by the model to the randomly
    generated data points:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码可视化了模型对随机生成的数据点进行拟合的过程：
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '*Figure 7.3* displays the resulting hyperplane and original data points:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.3*显示了生成的超平面和原始数据点：'
- en: '![](img/B15439_07_03.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_03.png)'
- en: 'Figure 7.3: Regression hyperplane'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3：回归超平面
- en: The upper right part of the panel displays the goodness-of-fit measures we just
    discussed, alongside the F-test, which rejects the hypothesis that all coefficients
    are zero and irrelevant. Similarly, the t-statistics indicate that intercept and
    both slope coefficients are, unsurprisingly, highly significant.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 面板的右上部显示了我们刚刚讨论的拟合度量，以及F检验，拒绝了所有系数都为零且不相关的假设。同样，t统计量表明截距和斜率系数都是非常显著的，这并不奇怪。
- en: The bottom part of the summary contains the residual diagnostics. The left panel
    displays skew and kurtosis, which are used to test the normality hypothesis. Both
    the Omnibus and the Jarque–Bera tests fail to reject the null hypothesis that
    the residuals are normally distributed. The Durbin–Watson statistic tests for
    serial correlation in the residuals and has a value near 2, which, given two parameters
    and 625 observations, fails to reject the hypothesis of no serial correlation,
    as outlined in the previous section on this topic.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的底部包含了残差诊断。左侧面板显示了偏度和峰度，用于检验正态性假设。Omnibus和Jarque–Bera测试都未能拒绝残差正态分布的零假设。Durbin–Watson统计量检验了残差的串行相关性，并且在接近2的值，考虑到两个参数和625个观测值，未能拒绝无串行相关性的假设，正如前一节关于这个主题的概述中所述。
- en: 'Lastly, the condition number provides evidence about multicollinearity: it
    is the ratio of the square roots of the largest and the smallest eigenvalue of
    the design matrix that contains the input data. A value above 30 suggests that
    the regression may have significant multicollinearity.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，条件数提供了关于多重共线性的证据：它是包含输入数据的设计矩阵的最大和最小特征值的平方根的比值。大于30的值表明回归可能存在显著的多重共线性。
- en: '`statsmodels` includes additional diagnostic tests that are linked in the notebook.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`包括了与笔记本相关的额外诊断测试。'
- en: Stochastic gradient descent with sklearn
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: sklearn中的随机梯度下降
- en: The sklearn library includes an `SGDRegressor` model in its `linear_models`
    module. To learn the parameters for the same model using this method, we need
    to standardize the data because the gradient is sensitive to the scale.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: sklearn库在其`linear_models`模块中包含了一个`SGDRegressor`模型。为了使用这种方法学习相同模型的参数，我们需要对数据进行标准化，因为梯度对尺度敏感。
- en: 'We use the `StandardScaler()` for this purpose: it computes the mean and the
    standard deviation for each input variable during the fit step, and then subtracts
    the mean and divides by the standard deviation during the transform step, which
    we can conveniently conduct in a single `fit_transform()` command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`StandardScaler()`来实现这一目的：它在拟合步骤中计算每个输入变量的均值和标准差，然后在转换步骤中减去均值并除以标准差，这可以方便地在单个`fit_transform()`命令中进行：
- en: '[PRE3]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we instantiate `SGDRegressor` using the default values except for a `random_state`
    setting to facilitate replication:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用默认值实例化`SGDRegressor`，除了`random_state`设置以便进行复制：
- en: '[PRE4]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we can fit the `sgd` model, create the in-sample predictions for both
    the OLS and the `sgd` models, and compute the root mean squared error for each:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以拟合`sgd`模型，为OLS和`sgd`模型创建样本内预测，并计算每个模型的均方根误差：
- en: '[PRE5]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As expected, both models yield the same result. We will now take on a more ambitious
    project using linear regression to estimate a multi-factor asset pricing model.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，这两个模型得出了相同的结果。我们现在将承担一个更有雄心的项目，使用线性回归来估计多因素资产定价模型。
- en: How to build a linear factor model
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建线性因子模型
- en: Algorithmic trading strategies use factor models to quantify the relationship
    between the return of an asset and the sources of risk that are the main drivers
    of these returns. Each factor risk carries a premium, and the total asset return
    can be expected to correspond to a weighted average of these risk premia.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 算法交易策略使用因子模型来量化资产回报与风险来源之间的关系，这些风险是这些回报的主要驱动因素。每个因子风险都带有一个溢价，总资产回报可以预期对应于这些风险溢价的加权平均。
- en: 'There are several practical applications of factor models across the portfolio
    management process, from construction and asset selection to risk management and
    performance evaluation. The importance of factor models continues to grow as common
    risk factors are now tradeable:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 因子模型在投资组合管理过程中有几个实际应用，从构建和资产选择到风险管理和绩效评估。随着常见风险因素现在可以交易，因子模型的重要性不断增长：
- en: A summary of the returns of many assets, by a much smaller number of factors,
    reduces the amount of data required to estimate the covariance matrix when optimizing
    a portfolio.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对许多资产的回报进行总结，通过更少数量的因素，可以减少在优化投资组合时估计协方差矩阵所需的数据量。
- en: An estimate of the exposure of an asset or a portfolio to these factors allows
    for the management of the resulting risk, for instance, by entering suitable hedges
    when risk factors are themselves traded or can be proxied.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对资产或投资组合暴露于这些因素的估计允许管理由此产生的风险，例如，当风险因素本身是可交易的或可以被代理时，可以进行适当的对冲。
- en: A factor model also permits the assessment of the incremental signal content
    of new alpha factors.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还允许评估新的阿尔法因子的增量信号内容。
- en: A factor model can also help assess whether a manager's performance, relative
    to a benchmark, is indeed due to skillful asset selection and market timing, or
    if the performance can instead be explained by portfolio tilts toward known return
    drivers. These drivers can, today, be replicated as low-cost, passively managed
    funds that do not incur active management fees.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还可以帮助评估一个经理相对于基准的绩效是否确实是由于技巧的资产选择和市场定时，还是绩效可以解释为投资组合倾向于已知回报驱动因素。今天，这些驱动因素可以作为低成本的被动管理基金进行复制，而不需要支付主动管理费用。
- en: The following examples apply to equities, but risk factors have been identified
    for all asset classes (Ang 2014).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于股票，但是所有资产类别都已确定了风险因素（Ang 2014）。
- en: From the CAPM to the Fama–French factor models
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从CAPM到法玛-法国因子模型
- en: 'Risk factors have been a key ingredient to quantitative models since the **capital
    asset pricing model** (**CAPM**) explained the expected returns of all *N* assets
    ![](img/B15439_07_047.png) using their respective exposure ![](img/B15439_07_048.png)
    to a single factor, the expected excess return of the overall market over the
    risk-free rate ![](img/B15439_07_049.png). The CAPM model takes the following
    linear form:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 自**资本资产定价模型**（**CAPM**）解释了所有*N*资产的预期回报 ![](img/B15439_07_047.png) 与它们各自暴露 ![](img/B15439_07_048.png)
    到单一因素，即整体市场超过无风险利率的预期超额回报 ![](img/B15439_07_049.png) 以来，风险因素一直是量化模型的关键组成部分。CAPM模型采用以下线性形式：
- en: '![](img/B15439_07_050.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_050.png)'
- en: This differs from the classic fundamental analysis, à la Dodd and Graham, where
    returns depend on firm characteristics. The rationale is that, in the aggregate,
    investors cannot eliminate this so-called systematic risk through diversification.
    Hence, in equilibrium, they require compensation for holding an asset commensurate
    with its systematic risk. The model implies that, given efficient markets where
    prices immediately reflect all public information, there should be no superior
    risk-adjusted returns. In other words, the value of ![](img/B15439_07_051.png)
    should be zero.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这与经典的基本面分析不同，如多德和格雷厄姆，其中回报取决于公司特征。其理论是，总体上，投资者无法通过分散化消除所谓的系统性风险。因此，在均衡状态下，他们要求持有资产的补偿与其系统性风险相称。该模型暗示，鉴于价格立即反映所有公共信息的有效市场，不应该存在优越的风险调整回报。换句话说，![](img/B15439_07_051.png)
    的价值应该为零。
- en: Empirical tests of the model use linear regression and have consistently failed,
    for example, by identifying anomalies in the form of superior risk-adjusted returns
    that do not depend on overall market exposure, such as higher returns for smaller
    firms (Goyal 2012).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的实证测试使用线性回归，并一直未能成功，例如，通过识别形式上不依赖于整体市场暴露的优越风险调整回报的异常，比如较小公司的更高回报（Goyal 2012）。
- en: 'These failures have prompted a lively debate about whether the efficient markets
    or the single factor aspect of the joint hypothesis is to blame. It turns out
    that both premises are probably wrong:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些失败引发了关于是有效市场还是联合假设的单一因素方面有问题的激烈讨论。结果表明，这两个前提可能都是错误的：
- en: 'Joseph Stiglitz earned the 2001 Nobel Prize in economics in part for showing
    that markets are generally not perfectly efficient: if markets are efficient,
    there is no value in collecting data because this information is already reflected
    in prices. However, if there is no incentive to gather information, it is hard
    to see how it should be already reflected in prices.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约瑟夫·斯蒂格利茨部分因为证明市场通常并非完全有效而获得了2001年的诺贝尔经济学奖：如果市场是有效的，那么收集数据就没有价值，因为这些信息已经反映在价格中。然而，如果没有收集信息的动机，很难看出它应该已经反映在价格中。
- en: On the other hand, theoretical and empirical improvements of the CAPM suggest
    that additional factors help explain some of the anomalies mentioned previously,
    which result in various multi-factor models.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，CAPM的理论和实证改进表明，额外的因素有助于解释先前提到的一些异常，这导致了各种多因素模型。
- en: Stephen Ross proposed the **arbitrage pricing theory** (**APT**) in 1976 as
    an alternative that allows for several risk factors while eschewing market efficiency.
    In contrast to the CAPM, it assumes that opportunities for superior returns due
    to mispricing may exist but will quickly be arbitraged away. The theory does not
    specify the factors, but research suggests that the most important are changes
    in inflation and industrial production, as well as changes in risk premia or the
    term structure of interest rates.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 斯蒂芬·罗斯于1976年提出了**套利定价理论**（**APT**），作为一种允许多个风险因子而避开市场效率的替代理论。与CAPM相反，它假设由于错定价而存在卓越回报的机会，但这些机会将很快被套利掉。该理论并未指定因子，但研究表明最重要的因素是通货膨胀和工业生产的变化，以及风险溢价或利率期限结构的变化。
- en: Kenneth French and Eugene Fama (who won the 2013 Nobel Prize) identified additional
    risk factors that depend on firm characteristics and are widely used today. In
    1993, the Fama–French three-factor model added the relative size and value of
    firms to the single CAPM source of risk. In 2015, the five-factor model further
    expanded the set to include firm profitability and level of investment, which
    had been shown to be significant in the intervening years. In addition, many factor
    models include a price momentum factor.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 肯尼斯·法rench和尤金·法玛（2013年诺贝尔奖得主）确定了依赖于公司特征并且今天被广泛使用的额外风险因子。1993年，法玛-法rench三因子模型将相对规模和公司价值添加到了单一CAPM风险来源中。2015年，五因子模型进一步扩展了该组合，包括公司盈利能力和投资水平，这在中间年份已被证明是显著的。此外，许多因子模型还包括价格动量因子。
- en: 'The Fama–French risk factors are computed as the return difference on diversified
    portfolios with high or low values, according to metrics that reflect a given
    risk factor. These returns are obtained by sorting stocks according to these metrics
    and then going long stocks above a certain percentile, while shorting stocks below
    a certain percentile. The metrics associated with the risk factors are defined
    as follows:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛-法rench风险因子是通过对高或低价值的多样化组合进行计算的，这些价值根据反映特定风险因子的指标进行排序。这些回报是通过根据这些指标对股票进行排序，然后做多高于某个百分位数的股票，同时做空低于某个百分位数的股票来获得的。与风险因子相关的指标定义如下：
- en: '**Size**: **Market equity** (**ME**)'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大小**：**市场权益**（**ME**）'
- en: '**Value**: **Book value of equity** (**BE**) divided by ME'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值**：**股权账面价值**（**BE**）除以ME'
- en: '**Operating profitability (OP)**: Revenue minus cost of goods sold/assets'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**营业利润率（OP）**：营业收入减去销售成本/资产'
- en: '**Investment**: Investment/assets'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资**：投资/资产'
- en: There are also unsupervised learning techniques for the data-driven discovery
    of risk factors that use factors and principal component analysis. We will explore
    this in *Chapter 13*, *Data-Driven Risk Factors and Asset Allocation with Unsupervised
    Learning*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些无监督学习技术，用于基于数据发现风险因子，使用因子和主成分分析。我们将在*第13章*，*基于数据的风险因子和无监督学习的资产配置*中探讨这一点。
- en: Obtaining the risk factors
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取风险因子
- en: Fama and French make updated risk factors and research portfolio data available
    through their website, and you can use the `pandas_datareader` library to obtain
    the data. For this application, refer to the `fama_macbeth.ipynb` notebook for
    the following code examples and additional detail.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和法rench通过他们的网站提供更新的风险因子和研究组合数据，并且您可以使用`pandas_datareader`库来获取数据。对于此应用，请参考`fama_macbeth.ipynb`笔记本，了解以下代码示例和更多细节。
- en: 'In particular, we will be using the five Fama–French factors that result from
    sorting stocks, first into three size groups and then into two, for each of the
    remaining three firm-specific factors. Hence, the factors involve three sets of
    value-weighted portfolios formed as ![](img/B15439_07_052.png) sorts on size and
    book-to-market, size and operating profitability, and size and investment. The
    risk factor values computed as the average returns of the **portfolios** (**PF**)
    are outlined in the following table:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将使用从股票排序中得出的五个法玛-法rench因子，首先分为三个大小组，然后分为两个，对于剩下的三个公司特定因子。因此，这些因子涉及三组价值加权组合，形成为大小和账面市值比、大小和营业利润率、大小和投资。计算为**组合**（**PF**）的风险因子值如下表所示：
- en: '| Concept | Label | Name | Risk factor calculation |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 概念 | 标签 | 名称 | 风险因子计算 |'
- en: '| Size | SMB | Small minus big | Nine small stock PF minus nine large stock
    PF. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 大小 | SMB | 小市值减大市值 | 九个小股票PF减去九个大股票PF。 |'
- en: '| Value | HML | High minus low | Two value PF minus two growth (with low BE/ME
    value) PF. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 价值 | HML | 高减低 | 两个价值PF减去两个成长（低BE/ME价值）PF。 |'
- en: '| Profitability | RMW | Robust minus weak | Two robust OP PF minus two weak
    OP PF. |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 盈利能力 | RMW | 强劲减弱 | 两个强劲OP PF减去两个弱OP PF。 |'
- en: '| Investment | CMA | Conservative minus aggressive | Two conservative investment
    portfolios, minus two aggressive investment portfolios. |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 投资 | CMA | 保守减激进 | 两个保守投资组合减去两个激进投资组合。 |'
- en: '| Market | Rm-Rf | Excess return on the market | Value-weight return of all
    firms incorporated in and listed on major US exchanges with good data, minus the
    one-month Treasury bill rate. |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | Rm-Rf | 市场的超额回报 | 所有在美国主要交易所上市并有良好数据的公司的价值加权回报，减去一个月期国库券利率。 |'
- en: 'We will use returns at a monthly frequency that we will obtain for the period
    2010–2017, as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用2010年至2017年期间获得的月度频率的回报：
- en: '[PRE6]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Fama and French also made numerous portfolios available that we can use to
    illustrate the estimation of the factor exposures, as well as the value of the
    risk premia available in the market for a given time period. We will use a panel
    of the 17 industry portfolios at a monthly frequency. We will subtract the risk-free
    rate from the returns because the factor model works with excess returns:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和法rench还提供了许多可用于说明因子敞口估计以及市场上某一特定时间段内可用的风险溢价价值的组合。我们将使用17个行业组合的面板以月度频率。我们将从回报中减去无风险利率，因为因子模型使用的是超额回报：
- en: '[PRE7]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We will now build a linear factor model based on this panel data using a method
    that addresses the failure of some basic linear regression assumptions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于这个面板数据构建一个线性因子模型，使用一种能够解决一些基本线性回归假设失败的方法。
- en: Fama–Macbeth regression
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fama-Macbeth回归
- en: Given data on risk factors and portfolio returns, it is useful to estimate the
    portfolio's exposure to these returns to learn how much they drive the portfolio's
    returns. It is also of interest to understand the premium that the market pays
    for the exposure to a given factor, that is, how much taking this risk is worth.
    The risk premium then permits to estimate the return for any portfolio provide
    we know or can assume its factor exposure.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 给定风险因子和投资组合回报的数据，估计投资组合对这些回报的暴露是有用的，以了解它们对投资组合回报的驱动程度。了解市场为暴露于特定因子支付的溢价也很有趣，也就是说，承担这种风险的价值有多大。然后，风险溢价允许我们估计任何投资组合的回报，只要我们知道或可以假设其因子暴露。
- en: More formally, we will have *i*=1, ..., *N* asset or portfolio returns over
    *t*=1, ..., *T* periods, and each asset's excess period return will be denoted.
    The goal is to test whether the *j*=1, ..., *M* factors explain the excess returns
    and the risk premium associated with each factor. In our case, we have *N*=17
    portfolios and *M*=5 factors, each with 96 periods of data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地，我们将有*i*=1，...，*N*资产或投资组合在*t*=1，...，*T*期间的回报，每个资产的超额期回报将被标记。目标是测试*j*=1，...，*M*因子是否解释了超额回报以及与每个因子相关的风险溢价。在我们的情况下，我们有*N*=17个投资组合和*M*=5个因子，每个因子有96个数据期。
- en: Factor models are estimated for many stocks in a given period. Inference problems
    will likely arise in such cross-sectional regressions because the fundamental
    assumptions of classical linear regression may not hold. Potential violations
    include measurement errors, covariation of residuals due to heteroskedasticity
    and serial correlation, and multicollinearity (Fama and MacBeth 1973).
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定时期内估计了许多股票的因子模型。在这样的横截面回归中可能会出现推断问题，因为经典线性回归的基本假设可能不成立。潜在的违规行为包括测量误差，由于异方差和串扰相关引起的残差协变，以及多重共线性（Fama和MacBeth
    1973）。
- en: 'To address the inference problem caused by the correlation of the residuals,
    Fama and MacBeth proposed a two-step methodology for a cross-sectional regression
    of returns on factors. The two-stage Fama–Macbeth regression is designed to estimate
    the premium rewarded for the exposure to a particular risk factor by the market.
    The two stages consist of:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决由残差相关引起的推断问题，Fama和MacBeth提出了一种用于对因子进行横截面回归的两步方法。Fama-Macbeth回归旨在估计市场对特定风险因子暴露所奖励的溢价。这两个阶段包括：
- en: 'First stage: *N* time-series regression, one for each asset or portfolio, of
    its excess returns on the factors to estimate the factor loadings. In matrix form,
    for each asset:![](img/B15439_07_053.png)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一阶段：*N*时间序列回归，每个资产或投资组合一个，其超额回报对因子的估计加载。以矩阵形式，对于每个资产：![](img/B15439_07_053.png)
- en: 'Second stage: *T* cross-sectional regression, one for each time period, to
    estimate the risk premium. In matrix form, we obtain a vector of risk premia for
    each period:![](img/B15439_07_054.png)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二阶段：*T*横截面回归，每个时间段一个，用于估计风险溢价。以矩阵形式，我们得到了每个时期的风险溢价向量！[](img/B15439_07_054.png)
- en: 'Now, we can compute the factor risk premia as the time average and get a t-statistic
    to assess their individual significance, using the assumption that the risk premia
    estimates are independent over time:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以计算因子风险溢价作为时间平均值，并获得t统计量来评估它们的个体显著性，使用风险溢价估计在时间上是独立的这一假设：
- en: '![](img/B15439_07_055.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_055.png)'
- en: If we had a very large and representative data sample on traded risk factors,
    we could use the sample mean as a risk premium estimate. However, we typically
    do not have a sufficiently long history to, and the margin of error around the
    sample mean could be quite large. The Fama–Macbeth methodology leverages the covariance
    of the factors with other assets to determine the factor premia.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个非常大且具有代表性的交易风险因子的数据样本，我们可以使用样本均值作为风险溢价估计。然而，我们通常没有足够长的历史数据，并且样本均值周围的误差边际可能相当大。Fama-Macbeth方法利用因子与其他资产的协方差来确定因子溢价。
- en: The second moment of asset returns is easier to estimate than the first moment,
    and obtaining more granular data improves estimation considerably, which is not
    true of mean estimation.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 资产回报的第二时刻比第一时刻更容易估计，获得更细粒度的数据显著改善了估计，这在均值估计中并不成立。
- en: 'We can implement the first stage to obtain the 17 factor loading estimates
    as follows:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以实施第一阶段，以获得17个因子加载估计，如下所示：
- en: '[PRE8]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'For the second stage, we run 96 regressions of the period returns for the cross
    section of portfolios on the factor loadings:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二阶段，我们对投资组合的横截面期回报进行了96次回归，回归的因子加载为：
- en: '[PRE9]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we compute the average for the 96 periods to obtain our factor risk
    premium estimates:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算96个期间的平均值，以获得我们的因子风险溢价估计：
- en: '[PRE10]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The linearmodels library extends `statsmodels` with various models for panel
    data and also implements the two-stage Fama–MacBeth procedure:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: linearmodels库通过各种面板数据模型扩展了`statsmodels`，并实施了两阶段Fama-MacBeth程序：
- en: '[PRE11]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'This provides us with the same result:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了相同的结果：
- en: '![](img/B15439_07_04.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_04.png)'
- en: 'Figure 7.4: LinearFactorModel estimation summary'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4：LinearFactorModel估计摘要
- en: The accompanying notebook illustrates the use of categorical variables by using
    industry dummies when estimating risk premia for a larger panel of individual
    stocks.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 随附的笔记本演示了在估计更大的个体股票面板的风险溢价时，使用行业虚拟变量的情况。
- en: Regularizing linear regression using shrinkage
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用收缩的正则化线性回归
- en: The least-squares method to train a linear regression model will produce the
    best linear and unbiased coefficient estimates when the Gauss–Markov assumptions
    are met. Variations like GLS fare similarly well, even when OLS assumptions about
    the error covariance matrix are violated. However, there are estimators that produce
    biased coefficients to reduce the variance and achieve a lower generalization
    error overall (Hastie, Tibshirani, and Friedman 2009).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 使用最小二乘法来训练线性回归模型，当满足高斯-马尔可夫假设时，将产生最佳的线性和无偏的系数估计。即使违反了关于误差协方差矩阵的OLS假设，GLS等变体也能表现得很好。然而，有一些估计器会产生偏差系数，以减少方差并在整体上实现更低的泛化误差（Hastie，Tibshirani和Friedman
    2009）。
- en: When a linear regression model contains many correlated variables, their coefficients
    will be poorly determined. This is because the effect of a large positive coefficient
    on the RSS can be canceled by a similarly large negative coefficient on a correlated
    variable. As a result, the risk of prediction errors due to high variance increases
    because this wiggle room for the coefficients makes the model more likely to overfit
    to the sample.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 当线性回归模型包含许多相关变量时，它们的系数将被较差地确定。这是因为大正系数对RSS的影响可能会被相关变量上同样大的负系数所抵消。因此，由于系数的这种摇摆空间使模型更有可能对样本过度拟合，导致了由于高方差而产生预测误差的风险增加。
- en: How to hedge against overfitting
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何对抗过度拟合
- en: One popular technique to control overfitting is that of **regularization**,
    which involves the addition of a penalty term to the error function to discourage
    the coefficients from reaching large values. In other words, size constraints
    on the coefficients can alleviate the potentially negative impact on out-of-sample
    predictions. We will encounter regularization methods for all models since overfitting
    is such a pervasive problem.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 控制过度拟合的一种流行技术是**正则化**，它涉及向误差函数添加惩罚项，以阻止系数达到较大的值。换句话说，对系数的大小施加约束可以减轻对样本外预测的潜在负面影响。由于过度拟合是如此普遍的问题，我们将为所有模型遇到正则化方法。
- en: 'In this section, we will introduce shrinkage methods that address two motivations
    to improve on the approaches to linear models discussed so far:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍收缩方法，以解决迄今为止讨论的线性模型的两个改进动机：
- en: '**Prediction accuracy**: The low bias but high variance of least-squares estimates
    suggests that the generalization error could be reduced by shrinking or setting
    some coefficients to zero, thereby trading off a slightly higher bias for a reduction
    in the variance of the model.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测准确性**：最小二乘估计的低偏差但高方差表明，通过缩小或将一些系数设为零，可以减少泛化误差，从而以略微更高的偏差换取模型方差的减少。'
- en: '**Interpretation**: A large number of predictors may complicate the interpretation
    or communication of the big picture of the results. It may be preferable to sacrifice
    some detail to limit the model to a smaller subset of parameters with the strongest
    effects.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释**：大量的预测变量可能会使结果的解释或传达变得复杂。牺牲一些细节以将模型限制在具有最强效果的较小参数子集可能更可取。'
- en: Shrinkage models restrict the regression coefficients by imposing a penalty
    on their size. They achieve this goal by adding a term ![](img/B15439_07_056.png)
    to the objective function. This term implies that the coefficients of a shrinkage
    model minimize the RSS, plus a penalty that is positively related to the (absolute)
    size of the coefficients.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过对系数的大小施加惩罚来限制回归系数。它们通过在目标函数中添加一个项![](img/B15439_07_056.png)来实现这一目标。这个项意味着收缩模型的系数最小化了RSS，再加上一个与系数的（绝对）大小正相关的惩罚。
- en: 'The added penalty thus turns the linear regression coefficients into the solution
    to a constrained minimization problem that, in general, takes the following Lagrangian
    form:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，添加的惩罚将线性回归系数转化为受约束的最小化问题的解，一般来说，采用以下的拉格朗日形式：
- en: '![](img/B15439_07_057.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_057.png)'
- en: The regularization parameter ![](img/B15439_07_058.png) determines the size
    of the penalty effect, that is, the strength of the regularization. As soon as
    ![](img/B15439_07_059.png) is positive, the coefficients will differ from the
    unconstrained least squared parameters, which implies a biased estimate. You should
    choose hyperparameter ![](img/B15439_07_059.png) adaptively via cross-validation
    to minimize an estimate of the expected prediction error. We will illustrate how
    to do so in the next section.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化参数![](img/B15439_07_058.png)决定了惩罚效应的大小，即正则化的强度。一旦![](img/B15439_07_059.png)为正，系数将与无约束的最小二乘参数不同，这意味着有偏估计。您应该通过交叉验证自适应地选择超参数![](img/B15439_07_059.png)，以最小化对预测误差的期望估计。我们将在下一节中说明如何做到这一点。
- en: Shrinkage models differ by how they calculate the penalty, that is, the functional
    form of *S*. The most common versions are the **ridge regression**, which uses
    the sum of the squared coefficients, and the **lasso model**, which bases the
    penalty on the sum of the absolute values of the coefficients.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过计算惩罚的方式不同，即*S*的函数形式。最常见的版本是**岭回归**，它使用了系数的平方和，以及**套索模型**，它基于系数的绝对值之和来进行惩罚。
- en: '**Elastic net regression**, which is not explicitly covered here, uses a combination
    of both. Scikit-learn includes an implementation that works very similarly to
    the examples we will demonstrate here.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性网络回归**，这里没有明确涵盖，使用了两者的组合。Scikit-learn包括了一个实现，其工作方式与我们将在这里演示的示例非常相似。'
- en: How ridge regression works
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 岭回归的工作原理
- en: 'Ridge regression shrinks the regression coefficients by adding a penalty to
    the objective function that equals the sum of the squared coefficients, which
    in turn corresponds to the L2 norm of the coefficient vector (Hoerl and Kennard
    1970):'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归通过在目标函数中添加一个惩罚项来缩小回归系数，该惩罚项等于系数的平方和，这又对应于系数向量的L2范数（Hoerl和Kennard 1970）：
- en: '![](img/B15439_07_061.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_061.png)'
- en: 'Hence, the ridge coefficients are defined as:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，岭系数被定义为：
- en: '![](img/B15439_07_062.png)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_062.png)'
- en: The intercept ![](img/B15439_07_063.png) has been excluded from the penalty
    to make the procedure independent of the origin chosen for the output variable—otherwise,
    adding a constant to all output values would change all slope parameters, as opposed
    to a parallel shift.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 拦截![](img/B15439_07_063.png)已从惩罚中排除，使得该程序独立于为输出变量选择的原点-否则，将常数添加到所有输出值将改变所有斜率参数，而不是平行移位。
- en: 'It is important to standardize the inputs by subtracting from each input the
    corresponding mean and dividing the result by the input''s standard deviation.
    This is because the ridge solution is sensitive to the scale of the inputs. There
    is also a closed solution for the ridge estimator that resembles the OLS case:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从每个输入中减去相应的均值并将结果除以输入的标准差来标准化输入是很重要的。这是因为岭解对输入的比例敏感。岭估计器也有一个类似OLS案例的封闭解：
- en: '![](img/B15439_07_064.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_064.png)'
- en: The solution adds the scaled identity matrix ![](img/B15439_07_065.png) to *X*^T*X*
    before inversion, which guarantees that the problem is non-singular, even if *X*^T*X*
    does not have full rank. This was one of the motivations for using this estimator
    when it was originally introduced.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在求逆之前，解决方案将缩放的单位矩阵![](img/B15439_07_065.png)添加到*X*^T*X*，这保证了即使*X*^T*X*没有完整的秩，问题也是非奇异的。这是最初引入此估计量时的动机之一。
- en: 'The ridge penalty results in the proportional shrinkage of all parameters.
    In the case of orthonormal inputs, the ridge estimates are just a scaled version
    of the least-squares estimates, that is:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚导致所有参数的比例收缩。在正交输入的情况下，岭估计只是最小二乘估计的缩放版本，即：
- en: '![](img/B15439_07_066.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_066.png)'
- en: Using the **singular value decomposition** (**SVD**) of the input matrix *X*,
    we can gain insight into how the shrinkage affects inputs in the more common case
    where they are not orthonormal. The SVD of a centered matrix represents the principal
    components of a matrix (see *Chapter 13*, *Data-Driven Risk Factors and Asset
    Allocation with Unsupervised Learning*) that capture uncorrelated directions in
    the column space of the data in descending order of variance.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 使用输入矩阵*X*的**奇异值分解**（**SVD**），我们可以深入了解收缩如何影响输入，更常见的情况是它们不是正交的。中心矩阵的奇异值分解代表矩阵的主要成分（参见*第13章*，*数据驱动的风险因素和无监督学习的资产配置*），以方差降序捕获数据的列空间中的不相关方向。
- en: Ridge regression shrinks the coefficients relative to the alignment of input
    variables with the directions in the data that exhibit most variance. More specifically,
    it shrinks those coefficients the most that represent inputs aligned with the
    principal components that capture less variance. Hence, the assumption that's
    implicit in ridge regression is that the directions in the data that vary the
    most will be most influential or most reliable when predicting the output.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归相对于输入变量与展现最大方差方向的数据的对齐来收缩系数。更具体地说，它最大程度地收缩那些代表与捕获较小方差的主成分对齐的输入的系数。因此，岭回归隐含的假设是，在数据中变化最大的方向在预测输出时最具影响力或最可靠。
- en: How lasso regression works
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 套索回归的工作原理
- en: 'The lasso (Hastie, Tibshirani, and Wainwright 2015), known as basis pursuit
    in signal processing, also shrinks the coefficients by adding a penalty to the
    sum of squares of the residuals, but the lasso penalty has a slightly different
    effect. The lasso penalty is the sum of the absolute values of the coefficient
    vector, which corresponds to its L1 norm. Hence, the lasso estimate is defined
    by:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 套索（Hastie，Tibshirani和Wainwright 2015），在信号处理中称为基础追踪，也通过向残差平方和添加惩罚来收缩系数，但套索惩罚的效果略有不同。套索惩罚是系数向量的绝对值之和，对应于其L1范数。因此，套索估计由以下定义：
- en: '![](img/B15439_07_067.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_067.png)'
- en: Similar to ridge regression, the inputs need to be standardized. The lasso penalty
    makes the solution nonlinear, and there is no closed-form expression for the coefficients,
    as in ridge regression. Instead, the lasso solution is a quadratic programming
    problem, and there are efficient algorithms that compute the entire path of coefficients,
    which results in different values of ![](img/B15439_07_059.png) with the same
    computational cost as ridge regression.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 与岭回归类似，输入需要标准化。套索惩罚使解决方案非线性，并且与岭回归不同，系数没有封闭形式的表达式。相反，套索解决方案是一个二次规划问题，有高效的算法可以计算系数的整个路径，这导致了与岭回归相同的计算成本的不同值![](img/B15439_07_059.png)。
- en: The lasso penalty had the effect of gradually reducing some coefficients to
    zero as the regularization increases. For this reason, the lasso can be used for
    the continuous selection of a subset of features.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 随着正则化的增加，套索惩罚逐渐将一些系数减少到零。因此，套索可以用于连续选择一部分特征。
- en: Let's now move on and put the various linear regression models to practical
    use and generate predictive stock trading signals.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续实际使用各种线性回归模型并生成预测股票交易信号。
- en: How to predict returns with linear regression
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何用线性回归预测回报
- en: In this section, we will use linear regression with and without shrinkage to
    predict returns and generate trading signals.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用带有和不带收缩的线性回归来预测回报并生成交易信号。
- en: First, we need to create the model inputs and outputs. To this end, we'll create
    features along the lines we discussed in *Chapter 4*, *Financial Feature Engineering
    – How to Research Alpha Factors*, as well as forward returns for various time
    horizons, which we will use as outcomes for the models.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要创建模型的输入和输出。为此，我们将创建特征，沿着我们在*第4章*，*金融特征工程-如何研究Alpha因子*中讨论的线路，以及各种时间范围的前瞻回报，我们将用作模型的结果。
- en: Then, we will apply the linear regression models discussed in the previous section
    to illustrate their usage with `statsmodels` and sklearn and evaluate their predictive
    performance. In the next chapter, we will use the results to develop a trading
    strategy and demonstrate the end-to-end process of backtesting a strategy driven
    by a machine learning model.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将应用上一节讨论的线性回归模型来说明它们在`statsmodels`和sklearn中的使用，并评估它们的预测性能。在下一章中，我们将使用结果来开发一个交易策略，并演示由机器学习模型驱动的策略的端到端回测过程。
- en: Preparing model features and forward returns
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备模型特征和正向回报
- en: 'To prepare the data for our predictive model, we need to:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备我们的预测模型的数据，我们需要：
- en: Select a universe of equities and a time horizon
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择股票池和时间范围
- en: Build and transform alpha factors that we will use as features
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建和转换我们将用作特征的alpha因子
- en: Calculate forward returns that we aim to predict
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算我们的目标预测的正向回报
- en: And (potentially) clean our data
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并（可能）清理我们的数据
- en: The notebook `preparing_the_model_data.ipynb` contains the code examples for
    this section.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本`preparing_the_model_data.ipynb`包含了本节的代码示例。
- en: Creating the investment universe
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建投资范围
- en: We will use daily equity data from the Quandl Wiki US Stock Prices dataset for
    the years 2013 to 2017\. See the instructions in the `data` directory in the root
    folder of the GitHub repository for this book on how to obtain the data.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用2013年至2017年的Quandl Wiki美国股票价格数据集的每日股票数据。请参阅GitHub存储库的根文件夹中的`data`目录中的说明，了解如何获取数据。
- en: 'We start by loading the daily (adjusted) **open, high, low, close, and volume**
    (**OHLCV**) prices and metadata, which includes sector information. Use the path
    to `DATA_STORE`, where you originally saved the Quandl Wiki data:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先加载每日（调整后的）**开盘、最高、最低、收盘和成交量**（**OHLCV**）价格和元数据，其中包括部门信息。使用`DATA_STORE`的路径，您最初保存Quandl
    Wiki数据的地方：
- en: '[PRE12]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We remove tickers that do not have at least 2 years of data:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除没有至少2年数据的股票：
- en: '[PRE13]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Next, we clean up the sector names and ensure that we only use equities with
    both price and sector information:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们清理部门名称，并确保我们只使用具有价格和部门信息的股票：
- en: '[PRE14]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'For now, we are left with 2,265 tickers with daily price data for at least
    2 years. First, there''s the `prices` DataFrame:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们剩下2,265个股票的每日价格数据至少有2年。首先，有`prices` DataFrame：
- en: '[PRE15]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Next, there''s the `stocks` DataFrame:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，有`stocks` DataFrame：
- en: '[PRE16]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We will use a 21-day rolling average of the (adjusted) dollar volume traded
    to select the most liquid stocks for our model. Limiting the number of stocks
    also has the benefit of reducing training and backtesting time; excluding stocks
    with low dollar volumes can also reduce the noise of price data.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用21天滚动平均（调整后）交易额来选择我们模型中最流动的股票。限制股票数量还有减少训练和回测时间的好处；排除低交易额的股票也可以减少价格数据的噪音。
- en: 'The computation requires us to multiply the daily close price with the corresponding
    volume and then apply a rolling mean to each ticker using `.groupby()`, as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 计算需要我们将每日收盘价与相应的交易量相乘，然后对每个股票使用`.groupby()`应用滚动平均，如下所示：
- en: '[PRE17]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We then use this value to rank stocks for each date so that we can select,
    for example, the 100 most-traded stocks for a given date:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用这个值来为每个日期对股票进行排名，这样我们就可以选择，例如，给定日期的最活跃的100支股票：
- en: '[PRE18]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Selecting and computing alpha factors using TA-Lib
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用TA-Lib选择和计算alpha因子
- en: We will create a few momentum and volatility factors using TA-Lib, as described
    in *Chapter 4*, *Financial Feature Engineering – How to Research Alpha Factors*.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用TA-Lib创建一些动量和波动率因子，如*第4章*，*金融特征工程-如何研究Alpha因子*中所述。
- en: 'First, we add the **relative strength index** (**RSI**), as follows:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们添加**相对强弱指数**（**RSI**），如下所示：
- en: '[PRE19]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'A quick evaluation shows that, for the 100 most-traded stocks, the mean and
    median 5-day forward returns are indeed decreasing in the RSI values, grouped
    to reflect the commonly 30/70 buy/sell thresholds:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 快速评估显示，对于最活跃的100支股票，平均和中位数的5天期正向回报确实随着RSI值的减小而减小，分组以反映通常的30/70买入/卖出阈值：
- en: '[PRE20]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '| rsi_signal | count | Mean | std | min | 25% | 50% | 75% | max |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| rsi_signal | count | Mean | std | min | 25% | 50% | 75% | max |'
- en: '| (0, 30] | 4,154 | 0.12% | 1.01% | -5.45% | -0.34% | 0.11% | 0.62% | 4.61%
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '|（0，30] | 4,154 | 0.12% | 1.01% | -5.45% | -0.34% | 0.11% | 0.62% | 4.61% |'
- en: '| (30, 70] | 107,329 | 0.05% | 0.76% | -16.48% | -0.30% | 0.06% | 0.42% | 7.57%
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '|（30，70] | 107,329 | 0.05% | 0.76% | -16.48% | -0.30% | 0.06% | 0.42% | 7.57%
    |'
- en: '| (70, 100] | 10,598 | 0.00% | 0.63% | -8.79% | -0.28% | 0.01% | 0.31% | 5.86%
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '|（70，100] | 10,598 | 0.00% | 0.63% | -8.79% | -0.28% | 0.01% | 0.31% | 5.86%
    |'
- en: 'Then, we compute **Bollinger Bands**. The TA-Lib `BBANDS` function returns
    three values so that we set up a function that returns a `DataFrame` with the
    higher and lower bands for use with `groupby()` and `apply()`:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们计算**布林带**。TA-Lib的`BBANDS`函数返回三个值，因此我们设置一个函数，返回一个`DataFrame`，其中包括更高和更低的带，以便与`groupby()`和`apply()`一起使用：
- en: '[PRE21]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We take the percentage difference between the stock price and the upper or
    lower Bollinger Band and take logs to compress the distribution. The goal is to
    reflect the current value, relative to the recent volatility trend:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 我们取股价与布林带上限或下限之间的百分比差，并取对数以压缩分布。目标是反映当前值相对于最近的波动趋势：
- en: '[PRE22]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Next, we compute the **average true range** (**ATR**), which takes three inputs,
    namely, the high, low, and close prices. We standardize the result to make the
    metric more comparable across stocks:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们计算**平均真实范围**（**ATR**），它需要三个输入，即最高、最低和收盘价格。我们标准化结果，使得指标在股票之间更具可比性：
- en: '[PRE23]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, we generate the **moving average convergence/divergence** (**MACD**)
    indicator, which reflects the difference between a shorter and a longer-term exponential
    moving average:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们生成**移动平均收敛/发散**（**MACD**）指标，它反映了短期和长期指数移动平均之间的差异：
- en: '[PRE24]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Adding lagged returns
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 添加滞后回报
- en: 'To capture the price trend for various historical lags, we compute the corresponding
    returns and transform the result into the daily geometric mean. We''ll use lags
    for 1 day; 1 and 1 weeks; and 1, 2, and 3 months. We''ll also winsorize the returns
    by clipping the values at the 0.01st and 99.99th percentile:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉各种历史滞后的价格趋势，我们计算相应的回报并将结果转换为日几何平均值。我们将使用1天、1周和1个月的滞后。我们还将通过将值剪切到第0.01和第99.99百分位数来对回报进行winsorize处理：
- en: '[PRE25]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We then shift the daily, (bi-)weekly, and monthly returns to use them as features
    for the current observations. In other words, in addition to the latest returns
    for these periods, we also use the prior five results. For example, we shift the
    weekly returns for the prior 5 weeks so that they align with the current observations
    and can be used to predict the current forward return:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将每日、（双）周和月度回报向前移动，以将其用作当前观察的特征。换句话说，除了这些期间的最新回报外，我们还使用了之前的五个结果。例如，我们将过去5周的周回报向前移动，以使其与当前观察对齐，并用于预测当前的前瞻回报：
- en: '[PRE26]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Generating target forward returns
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 生成目标前瞻回报
- en: We will test predictions for various lookahead periods. The goal is to identify
    the holding period that produces the best predictive accuracy, as measured by
    the **information coefficient** (**IC**).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试各种前瞻期的预测。目标是确定产生最佳预测准确性的持有期，由**信息系数**（**IC**）来衡量。
- en: 'More specifically, we shift returns for time horizon *t* back by *t* days to
    use them as forward returns. For instance, we shift the 5-day return from *t*[0]
    to *t*[5] back by 5 days so that this value becomes the model target for *t*[0].
    We can generate daily, (bi-)weekly, and monthly forward returns as follows:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们将时间* t *的回报向前移动*t*天，以将其用作前瞻回报。例如，我们将*t*[0]的5天回报向前移动5天，以便这个值成为*t*[0]的模型目标。我们可以生成每日、（双）周和月度前瞻回报，如下所示：
- en: '[PRE27]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Dummy encoding of categorical variables
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分类变量的虚拟编码
- en: 'We need to convert any categorical variable into a numeric format so that the
    linear regression can process it. For this purpose, we will use a dummy encoding
    that creates individual columns for each category level and flags the presence
    of this level in the original categorical column with an entry of 1, and 0 otherwise.
    The pandas function `get_dummies()` automates dummy encoding. It detects and properly
    converts columns of type objects, as illustrated here. If you need dummy variables
    for columns containing integers, for instance, you can identify them using the
    keyword columns:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将任何分类变量转换为数字格式，以便线性回归可以处理它。为此，我们将使用一个虚拟编码，为每个类别级别创建单独的列，并使用1来标记原始分类列中该级别的存在，否则使用0。pandas函数`get_dummies()`自动进行虚拟编码。它检测并正确转换对象类型的列，如本例所示。如果您需要包含整数的列的虚拟变量，例如，您可以使用关键字列来识别它们：
- en: '[PRE28]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'When converting all categories into dummy variables and estimating the model
    with an intercept (as you typically would), you inadvertently create multicollinearity:
    the matrix now contains redundant information, no longer has full rank, and instead
    becomes singular.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 当将所有类别转换为虚拟变量并估计带有截距的模型时（通常会这样做），您无意中创建了多重共线性：矩阵现在包含冗余信息，不再具有完整秩，而是变得奇异。
- en: It is simple to avoid this by removing one of the new indicator columns. The
    coefficient on the missing category level will now be captured by the intercept
    (which is always 1, including when every remaining category dummy is 0).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 通过删除新的指示变量列之一来避免这种情况是很简单的。缺失类别级别的系数现在将被截距捕获（当每个剩余类别虚拟为0时，截距始终为1）。
- en: 'Use the `drop_first` keyword to correct the dummy variables accordingly:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`drop_first`关键字来正确地纠正虚拟变量：
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'To capture seasonal effects and changing market conditions, we create time
    indictor variables for the year and month:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉季节性效应和不断变化的市场状况，我们为年份和月份创建时间指示变量：
- en: '[PRE30]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Then, we combine our price data with the sector information and create dummy
    variables for the time and sector categories:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将价格数据与部门信息结合起来，并为时间和部门类别创建虚拟变量：
- en: '[PRE31]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We obtain some 50 features as a result that we can now use with the various
    regression models discussed in the previous section.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了大约50个特征，现在可以与前一节讨论的各种回归模型一起使用。
- en: Linear OLS regression using statsmodels
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用statsmodels进行线性OLS回归
- en: In this section, we will demonstrate how to run statistical inference with stock
    return data using `statsmodels` and interpret the results. The notebook `04_statistical_inference_of_stock_returns_with_statsmodels.ipynb`
    contains the code examples for this section.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将演示如何使用`statsmodels`对股票回报数据进行统计推断并解释结果。笔记本`04_statistical_inference_of_stock_returns_with_statsmodels.ipynb`包含了本节的代码示例。
- en: Selecting the relevant universe
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择相关的宇宙
- en: 'Based on our ranked rolling average of the dollar volume, we select the top
    100 stocks for any given trading day in our sample:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 基于我们排名的美元成交量滚动平均值，我们选择样本中任何交易日的前100支股票：
- en: '[PRE32]'
  id: totrans-321
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'We then create our outcome variables and features, as follows:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们创建我们的结果变量和特征，如下所示：
- en: '[PRE33]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Estimating the vanilla OLS regression
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 估计普通最小二乘回归
- en: 'We can estimate a linear regression model using OLS with `statsmodels`, as
    demonstrated previously. We select a forward return, for example, for a 5-day
    holding period, and fit the model accordingly:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`statsmodels`估计线性回归模型，如之前所示。例如，我们选择一个前瞻期为5天的前瞻回报，并相应地拟合模型：
- en: '[PRE34]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Diagnostic statistics
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 诊断统计
- en: 'You can view the full summary output in the notebook. We will omit it here
    to save some space, given the large number of features, and only display the diagnostic
    statistics:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本中可以查看完整的摘要输出。我们将在这里省略它以节省一些空间，因为特征数量很大，并且只显示诊断统计信息：
- en: '[PRE35]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The diagnostic statistics show a low p-value for the Jarque–Bera statistic,
    suggesting that the residuals are not normally distributed: they exhibit negative
    skew and high kurtosis. The left panel of *Figure 7.5* plots the residual distribution
    versus the normal distribution and highlights this shortcoming. In practice, this
    implies that the model is making more large errors than "normal":'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断统计数据显示Jarque–Bera统计的p值很低，表明残差不是正态分布的：它们呈现负偏斜和高峰度。*图7.5*的左侧面板绘制了残差分布与正态分布，并突出了这一缺点。实际上，这意味着模型产生的大误差比“正常”情况下要多：
- en: '![](img/B15439_07_05.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_05.png)'
- en: 'Figure 7.5: Residual distribution and autocorrelation plots'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.5：残差分布和自相关图
- en: 'Furthermore, the Durbin–Watson statistic is low at 0.43 so that we comfortably
    reject the null hypothesis of "no autocorrelation" at the 5 percent level. Hence,
    the residuals are likely positively correlated. The right panel of the preceding
    figure plots the autocorrelation coefficients for the first 10 lags, pointing
    to a significant positive correlation up to lag 4\. This result is due to the
    overlap in our outcomes: we are predicting 5-day returns for each day so that
    outcomes for consecutive days contain four identical returns.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Durbin–Watson统计值为0.43，因此我们可以在5%的水平上舒适地拒绝“无自相关”的零假设。因此，残差很可能是正相关的。前述图的右侧面板绘制了前10个滞后的自相关系数，指出了直到滞后4的显著正相关。这个结果是由于我们结果的重叠造成的：我们在每一天都在预测5天的回报，因此连续几天的结果包含四个相同的回报。
- en: If our goal were to understand which factors are significantly associated with
    forward returns, we would need to rerun the regression using robust standard errors
    (a parameter in statsmodels' `.fit()` method) or use a different method altogether,
    such as a panel model that allows for more complex error covariance.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的目标是了解哪些因素与未来回报显著相关，我们需要使用健壮标准误差（statsmodels的`.fit()`方法中的一个参数）重新运行回归，或者完全使用不同的方法，比如允许更复杂的误差协方差的面板模型。
- en: Linear regression using scikit-learn
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用scikit-learn进行线性回归
- en: Since sklearn is tailored toward prediction, we will evaluate the linear regression
    model based on its predictive performance using cross-validation. You can find
    the code samples for this section in the notebook `05_predicting_stock_returns_with_linear_regression.ipynb`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 由于sklearn专注于预测，我们将根据其预测性能评估线性回归模型的表现，使用交叉验证。您可以在笔记本`05_predicting_stock_returns_with_linear_regression.ipynb`中找到本节的代码示例。
- en: Selecting features and targets
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择特征和目标
- en: We will select the universe for our experiment, as we did previously in the
    OLS case, limiting tickers to the 100 most traded in terms of the dollar value
    on any given date. The sample still contains 5 years of data from 2013-2017.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将选择我们实验的宇宙，就像我们在OLS案例中做的那样，将股票代码限制在任何给定日期按美元价值交易量最高的100个。样本仍然包含2013年至2017年的5年数据。
- en: Cross-validating the model
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证模型
- en: Our data consists of numerous time series, one for each security. As discussed
    in *Chapter 6*, *The Machine Learning Process*, sequential data like time series
    requires careful cross-validation to be set up so that we do not inadvertently
    introduce look-ahead bias or leakage.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据包括许多时间序列，每个证券对应一个时间序列。正如在《第6章 机器学习过程》中讨论的那样，像时间序列这样的顺序数据需要谨慎地设置交叉验证，以便我们不会无意中引入前瞻性偏差或泄漏。
- en: We can achieve this using the `MultipleTimeSeriesCV` class that we introduced
    in *Chapter 6*, *The Machine Learning Process*. We initialize it with the desired
    lengths for the train and test periods, the number of test periods that we would
    like to run, and the number of periods in our forecasting horizon. The `split()`
    method returns a generator yielding pairs of train and test indices, which we
    can then use to select outcomes and features. The number of pairs depends on the
    parameter `n_splits`.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用在《第6章 机器学习过程》中介绍的`MultipleTimeSeriesCV`类来实现这一点。我们可以使用所需的训练和测试期长度、我们想要运行的测试期数量以及我们预测的时间段的周期数来初始化它。`split()`方法返回一个生成器，产生训练和测试索引的对，然后我们可以用它们来选择结果和特征。对数的对数取决于参数`n_splits`。
- en: The test periods do not overlap and are located at the end of the period available
    in the data. After a test period is used, it becomes part of the training data
    that rolls forward and remains constant in size.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 测试期不重叠，并且位于数据中可用期间的末尾。测试期使用后，它将成为向前滚动并保持恒定大小的训练数据的一部分。
- en: 'We will test this using 63 trading days, or 3 months, to train the model and
    then predict 1-day returns for the following 10 days. As a result, we can use
    around 75 10-day splits during the 3 years, starting in 2015\. We will begin by
    defining the basic parameters and data structures, as follows:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用63个交易日，或者3个月，来训练模型，然后预测接下来10天的1天回报。因此，在3年内，从2015年开始，我们可以使用大约75个10天的拆分。我们将首先定义基本参数和数据结构，如下所示：
- en: '[PRE36]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The cross-validation loop iterates over the train and test indices provided
    by `TimeSeriesCV`, selects features and outcomes, trains the model, and predicts
    the returns for the test features. We also capture the root mean squared error
    and the Spearman rank correlation between the actual and predicted values:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证循环遍历`TimeSeriesCV`提供的训练和测试索引，选择特征和结果，训练模型，并预测测试特征的回报。我们还捕获了实际值和预测值之间的均方根误差和Spearman秩相关：
- en: '[PRE37]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The cross-validation process takes 2 seconds. We'll evaluate the results in
    the next section.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证过程需要2秒。我们将在下一节中评估结果。
- en: Evaluating the results – information coefficient and RMSE
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果-信息系数和RMSE
- en: We have captured 3 years of daily test predictions for our universe. To evaluate
    the model's predictive performance, we can compute the information coefficient
    for each trading day, as well as for the entire period by pooling all forecasts.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经捕获了我们的宇宙中3年的每日测试预测。为了评估模型的预测性能，我们可以计算每个交易日的信息系数，以及通过汇总所有预测来计算整个时期的信息系数。
- en: The left panel of *Figure 7.6* (see the code in the notebook) shows the distribution
    of the rank correlation coefficients computed for each day and displays their
    mean and median, which are close to 1.95 and 2.56, respectively.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.6*的左面板（请参阅笔记本中的代码）显示了为每一天计算的秩相关系数的分布，并显示了它们的均值和中位数，它们分别接近1.95和2.56。'
- en: 'The figure''s right panel shows a scatterplot of the predicted and actual 1-day
    returns across all test periods. The seaborn `jointplot` estimates a robust regression
    that assigns lower weights to outliers and shows a small positive relationship.
    The rank correlation of actual and predicted returns for the entire 3-year test
    period is positive but low at 0.017 and statistically significant:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 图的右面板显示了在所有测试期间内预测和实际1天收益的散点图。seaborn的`jointplot`估计了一个健壮的回归，对异常值分配较低的权重，并显示了一个小的正相关关系。整个3年测试期间的实际和预测收益的秩相关性为0.017，具有统计学意义上的低正相关性：
- en: '![](img/B15439_07_06.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_06.png)'
- en: 'Figure 7.6: Daily and pooled IC for linear regression'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.6：线性回归的每日和汇总IC
- en: 'In addition, we can track how predictions performed in terms of the IC on a
    daily basis. *Figure 7.7* displays a 21-day rolling average for both the daily
    information coefficient and the RMSE, as well as their respective means for the
    validation period. This perspective highlights that the small positive IC for
    the entire period hides substantial variation that ranges from -10 to +10:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以跟踪预测在IC方面的表现。*图7.7*显示了每日信息系数和RMSE的21天滚动平均，以及验证期间它们各自的均值。这个视角突出了整个期间的小正IC隐藏了从-10到+10的巨大变化：
- en: '![](img/B15439_07_07.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_07.png)'
- en: 'Figure 7.7: 21-day rolling average for the daily IC and RMSE for the linear
    regression model'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.7：线性回归模型的21天滚动平均每日IC和RMSE
- en: Ridge regression using scikit-learn
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用scikit-learn进行岭回归
- en: 'We will now move on to the regularized ridge model, which we will use to evaluate
    whether parameter constraints improve on the linear regression''s predictive performance.
    Using the ridge model allows us to select the hyperparameter that determines the
    weight of the penalty term in the model''s objective function, as discussed previously
    in the section *Shrinkage methods: regularization for linear regression*.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将转向正则化的岭模型，我们将使用它来评估参数约束是否改善了线性回归的预测性能。使用岭模型可以让我们选择确定模型目标函数中惩罚项权重的超参数，如前面在*线性回归的正则化缩减方法*部分中讨论的。
- en: Tuning the regularization parameters using cross-validation
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用交叉验证调整正则化参数
- en: 'For ridge regression, we need to tune the regularization parameter with the
    keyword `alpha`, which corresponds to the ![](img/B15439_07_058.png) we used previously.
    We will try 18 values from 10^(-4) to 10⁴, where larger values imply stronger
    regularization:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 对于岭回归，我们需要使用关键字`alpha`来调整正则化参数，这对应于我们之前使用的![](img/B15439_07_058.png)。我们将尝试从10^(-4)到10⁴的18个值，其中较大的值意味着更强的正则化：
- en: '[PRE38]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We will apply the same cross-validation parameters as in the linear regression
    case, training for 3 months to predict 10 days of daily returns.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将应用与线性回归情况相同的交叉验证参数，训练3个月以预测10天的每日收益。
- en: 'The scale sensitivity of the ridge penalty requires us to standardize the inputs
    using `StandardScaler`. Note that we always learn the mean and the standard deviation
    from the training set using the `.fit_transform()` method and then apply these
    learned parameters to the test set using the `.transform()` method. To automate
    the preprocessing, we create a `Pipeline`, as illustrated in the following code
    example. We also collect the ridge coefficients. Otherwise, cross-validation resembles
    the linear regression process:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚的尺度敏感性要求我们使用`StandardScaler`对输入进行标准化。请注意，我们总是使用`.fit_transform()`方法从训练集中学习均值和标准差，然后使用这些学习到的参数来对测试集使用`.transform()`方法。为了自动化预处理，我们创建一个`Pipeline`，如下面的代码示例所示。我们还收集岭系数。否则，交叉验证类似于线性回归过程：
- en: '[PRE39]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭系数路径
- en: We can now plot the IC for each hyperparameter value to visualize how it evolves
    as the regularization increases. The results show that we get the highest mean
    and median IC value for ![](img/B15439_07_070.png).
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以绘制每个超参数值的IC，以可视化正则化增加时它是如何变化的。结果显示，我们得到了![](img/B15439_07_070.png)的最高均值和中位数IC值。
- en: 'For these levels of regularization, the right panel of *Figure 7.8* shows that
    the coefficients have been slightly shrunk compared to the (almost) unconstrained
    model with ![](img/B15439_07_071.png):'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些正则化水平，*图7.8*的右面板显示，与（几乎）无约束模型相比，系数略微收缩了：
- en: '![](img/B15439_07_08.png)'
  id: totrans-368
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_08.png)'
- en: 'Figure 7.8: Ridge regression cross-validation results'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.8：岭回归交叉验证结果
- en: The left panel of the figure shows that the predictive accuracy increases only
    slightly in terms of the mean and median IC values for optimal regularization
    values.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图的左面板显示，对于最佳正则化值，预测准确性仅略微提高了均值和中位数IC值。
- en: Top 10 coefficients
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前10个系数
- en: 'The standardization of the coefficients allows us to draw conclusions about
    their relative importance by comparing their absolute magnitude. *Figure 7.9*
    displays the 10 most relevant coefficients for regularization using ![](img/B15439_07_072.png),
    averaged over all trained models:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的标准化使我们能够通过比较它们的绝对大小来得出关于它们相对重要性的结论。*图7.9*显示了使用![](img/B15439_07_072.png)进行正则化的最相关的10个系数，这些系数是在所有训练模型上平均的：
- en: '![](img/B15439_07_09.png)'
  id: totrans-373
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_09.png)'
- en: 'Figure 7.9: Daily IC distribution and most important coefficients'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.9：每日IC分布和最重要的系数
- en: For this simple model and sample period, lagged monthly returns and various
    sector indicators played the most important role.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个简单的模型和样本期间，滞后的月度收益和各种部门指标起到了最重要的作用。
- en: Lasso regression using sklearn
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用sklearn进行Lasso回归
- en: The lasso implementation looks very similar to the ridge model we just ran.
    The main difference is that lasso needs to arrive at a solution using iterative
    coordinate descent, whereas ridge regression can rely on a closed-form solution.
    This can lead to longer training times.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 套索实现看起来与我们刚刚运行的岭模型非常相似。主要区别在于，套索需要使用迭代坐标下降来得出解决方案，而岭回归可以依赖封闭形式的解决方案。这可能导致更长的训练时间。
- en: Cross-validating the lasso model
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证套索模型
- en: The cross-validation code only differs with respect to the `Pipeline` setup.
    The `Lasso` object lets you set the tolerance and the maximum number of iterations
    it uses to determine whether it has converged or should abort, respectively. You
    can also rely on a `warm_start` so that the next training starts from the last
    optimal coefficient values. Please refer to the sklearn documentation and the
    notebook for additional detail.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证代码只在`Pipeline`设置方面有所不同。`Lasso`对象允许您设置容差和它用于确定是否已收敛或应中止的最大迭代次数。您还可以依靠`warm_start`，以便下一次训练从上次的最佳系数值开始。请参考sklearn文档和笔记本以获取更多细节。
- en: 'We will use eight `alpha` values in the range 10^(-10) to 10^(-3):'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在10^(-10)到10^(-3)的范围内使用八个`alpha`值：
- en: '[PRE40]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Evaluating the results – IC and lasso path
  id: totrans-382
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估结果-IC和套索路径
- en: As we did previously, we can plot the average information coefficient for all
    test sets used during cross-validation. We can see once more that regularization
    improves the IC over the unconstrained model, delivering the best out-of-sample
    result at a level of ![](img/B15439_07_073.png).
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，我们可以绘制所有交叉验证中使用的测试集的平均信息系数。我们可以再次看到，正则化可以提高IC，从而在无约束模型上提供最佳的样本外结果，达到![](img/B15439_07_073.png)的水平。
- en: 'The optimal regularization value is different from ridge regression because
    the penalty consists of the sum of the absolute, not the squared values of the
    relatively small coefficient values. We can also see in *Figure 7.10* that for
    this regularization level, the coefficients have been similarly shrunk, as in
    the ridge regression case:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳的正则化值与岭回归不同，因为惩罚由相对较小的系数值的绝对值的总和组成，而不是平方值。我们还可以在*图7.10*中看到，对于这个正则化水平，系数已经被类似地缩小，就像岭回归的情况一样：
- en: '![](img/B15439_07_10.png)'
  id: totrans-385
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_10.png)'
- en: 'Figure 7.10: Lasso cross-validation results'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.10：套索交叉验证结果
- en: 'The mean and median IC coefficients are slightly higher for lasso regression
    in this case, and the best-performing models use, on average, a different set
    of coefficients:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，套索回归的均值和中位数IC系数略高，表现最佳的模型平均使用不同的系数集：
- en: '![](img/B15439_07_11.png)'
  id: totrans-388
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_11.png)'
- en: 'Figure 7.11: Lasso daily IC distribution and top 10 coefficients'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.11：套索每日IC分布和前10个系数
- en: Comparing the quality of the predictive signals
  id: totrans-390
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较预测信号的质量
- en: In sum, ridge and lasso regression often produce similar results. Ridge regression
    often computes faster, but lasso regression also offers continuous feature subset
    selection by gradually reducing coefficients to zero, hence eliminating features.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，岭回归和套索回归通常产生类似的结果。岭回归通常计算速度更快，但套索回归也通过逐渐将系数减少到零来提供连续的特征子集选择，从而消除特征。
- en: 'In this particular setting, lasso regression produces the best mean and median
    IC values, as displayed in *Figure 7.12*:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种特定设置中，套索回归产生了最佳的平均和中位数IC值，如*图7.12*所示：
- en: '![](img/B15439_07_12.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_12.png)'
- en: 'Figure 7.12: Mean and median daily IC for the three models'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.12：三个模型的平均和中位数每日IC
- en: Furthermore, we can use Alphalens to compute various metrics and visualizations
    that reflect the signal quality of the model's predictions, as introduced in *Chapter
    4*, *Financial Feature Engineering – How to Research Alpha Factors*. The notebook
    `06_evaluating_signals_using_alphalens.ipynb` contains the code examples that
    combine the model predictions with price information to generate the alpha factor
    input needed by Alphalens.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以使用Alphalens计算各种指标和反映模型预测信号质量的可视化，如*第4章*中介绍的*金融特征工程-如何研究Alpha因子*。笔记本`06_evaluating_signals_using_alphalens.ipynb`包含将模型预测与价格信息相结合以生成Alphalens所需的Alpha因子输入的代码示例。
- en: 'The following table shows the alpha and beta values for portfolios invested
    in, according to different quintiles of the model predictions. In this simple
    example, the differences in performance are very small:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 下表显示了根据模型预测的不同五分位数投资组合的alpha和beta值。在这个简单的例子中，性能差异非常小：
- en: '| Metric | Alpha |  | Beta |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 指标 | Alpha |  | Beta |'
- en: '| Model | 1D | 5D | 10D | 21D |  | 1D | 5D | 10D | 21D |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 模型 | 1D | 5D | 10D | 21D |  | 1D | 5D | 10D | 21D |'
- en: '| Linear regression | 0.03 | 0.02 | 0.007 | 0.004 |  | -0.012 | -0.081 | -0.059
    | 0.019 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 线性回归 | 0.03 | 0.02 | 0.007 | 0.004 |  | -0.012 | -0.081 | -0.059 | 0.019
    |'
- en: '| Ridge regression | 0.029 | 0.022 | 0.012 | 0.008 |  | -0.01 | -0.083 | -0.060
    | 0.021 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 岭回归 | 0.029 | 0.022 | 0.012 | 0.008 |  | -0.01 | -0.083 | -0.060 | 0.021
    |'
- en: '| Lasso regression | 0.03 | 0.021 | 0.009 | 0.006 |  | -0.011 | -0.081 | -0.057
    | 0.02 |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 套索回归 | 0.03 | 0.021 | 0.009 | 0.006 |  | -0.011 | -0.081 | -0.057 | 0.02
    |'
- en: Linear classification
  id: totrans-402
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类
- en: The linear regression model discussed so far assumes a quantitative response
    variable. In this section, we will focus on approaches to modeling qualitative
    output variables for inference and prediction, a process that is known as **classification**
    and that occurs even more frequently than regression in practice.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，讨论的线性回归模型假设定量响应变量。在本节中，我们将专注于对推断和预测建模定性输出变量的方法，这个过程被称为**分类**，在实践中比回归更频繁地发生。
- en: Predicting a qualitative response for a data point is called classifying that
    observation because it involves assigning the observation to a category, or class.
    In practice, classification methods often predict probabilities for each of the
    categories of a qualitative variable and then use this probability to decide on
    the proper classification.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 预测数据点的定性响应被称为对观察结果进行分类，因为它涉及将观察结果分配到一个类别或类别中。在实践中，分类方法通常预测定性变量的每个类别的概率，然后使用这个概率来决定适当的分类。
- en: We could approach this classification problem by ignoring the fact that the
    output variable assumes discrete values, and then applying the linear regression
    model to try to predict a categorical output using multiple input variables. However,
    it is easy to construct examples where this method performs very poorly. Furthermore,
    it doesn't make intuitive sense for the model to produce values larger than 1
    or smaller than 0 when we know that ![](img/B15439_07_074.png).
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过忽略输出变量取离散值的事实来解决这个分类问题，然后应用线性回归模型来尝试使用多个输入变量预测分类输出。然而，很容易构造出这种方法表现非常糟糕的例子。此外，当我们知道![](img/B15439_07_074.png)时，模型产生大于1或小于0的值并不直观。
- en: There are many different classification techniques, or classifiers, that are
    available to predict a qualitative response. In this section, we will introduce
    the widely used logistic regression, which is closely related to linear regression.
    We will address more complex methods in the following chapters on generalized
    additive models, which includes decision trees and random forests, as well as
    gradient boosting machines and neural networks.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的分类技术或分类器可用于预测定性响应。在本节中，我们将介绍广泛使用的逻辑回归，它与线性回归密切相关。我们将在下一章中介绍更复杂的方法，包括决策树和随机森林的广义加法模型，以及梯度提升机和神经网络。
- en: The logistic regression model
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逻辑回归模型
- en: The logistic regression model arises from the desire to model the probabilities
    of the output classes, given a function that is linear in *x*, just like the linear
    regression model, while at the same time ensuring that they sum to one and remain
    in [0, 1], as we would expect from probabilities.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型源于希望对输出类别的概率进行建模，给定一个在x中是线性的函数，就像线性回归模型一样，同时确保它们总和为1，并保持在[0, 1]，这是我们从概率中期望的。
- en: In this section, we will introduce the objective and functional form of the
    logistic regression model and describe the training method. We will then illustrate
    how to use logistic regression for statistical inference with macro data using
    `statsmodels`, as well as how to predict price movements using the regularized
    logistic regression implemented by sklearn.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍逻辑回归模型的目标和函数形式，并描述训练方法。然后，我们将说明如何使用`statsmodels`对宏观数据进行统计推断，以及如何使用sklearn实现的正则化逻辑回归来预测价格变动。
- en: The objective function
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 目标函数
- en: 'To illustrate the **objective function**, we''ll use the output variable *y*,
    which takes on the value 1 if a stock return is positive over a given time horizon
    *d*, and 0 otherwise:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明**目标函数**，我们将使用输出变量y，如果股票回报在给定时间范围d内为正，则取值为1，否则为0。
- en: '![](img/B15439_07_075.png)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_075.png)'
- en: We could easily extend *y* to three categories, where 0 and 2 reflect negative
    and positive price moves beyond a certain threshold, and 1 otherwise.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地将y扩展到三个类别，其中0和2反映了某个阈值之外的负面和正面价格变动，否则为1。
- en: 'Rather than modeling the output variable *y* directly, logistic regression
    models the probability that *y* belongs to either of the categories, given a vector
    of alpha factors or features *x*[t]. In other words, logistic regression models
    the probability that the stock price goes up, depending on the values of the variables
    included in the model:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归不是直接对输出变量y进行建模，而是对y属于任一类别的概率进行建模，给定一组alpha因子或特征x[t]。换句话说，逻辑回归模型了股价上涨的概率，取决于模型中包含的变量的值：
- en: '![](img/B15439_07_076.png)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_076.png)'
- en: The logistic function
  id: totrans-416
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: 'To prevent the model from producing values outside the [0, 1] interval, we
    must model *p*(*x*) using a function that only gives outputs between 0 and 1 over
    the entire domain of *x*. The **logistic function** meets this requirement and
    always produces an S-shaped curve and so, regardless of the value of *x*, we will
    obtain a prediction that makes sense in probability terms:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型产生超出[0, 1]区间的值，我们必须使用一个函数来对p(x)进行建模，该函数在整个x的定义域上只产生0和1之间的输出。**逻辑函数**满足这一要求，并且总是产生S形曲线，因此无论x的值如何，我们都将得到一个在概率术语中有意义的预测：
- en: '![](img/B15439_07_077.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_077.png)'
- en: 'Here, the vector *x* includes a 1 for the intercept captured by the first component
    of ![](img/B15439_07_078.png). We can transform this expression to isolate the
    part that looks like a linear regression to arrive at:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，向量x包括一个拦截器，由![](img/B15439_07_078.png)的第一个分量捕获。我们可以转换这个表达式，以隔离看起来像线性回归的部分，得到：
- en: '![](img/B15439_07_079.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_079.png)'
- en: The quantity *p*(*x*)/[1−*p*(*x*)] is called the **odds**, an alternative way
    to express probabilities that may be familiar from gambling. This can take on
    any value odds between 0 and ![](img/B15439_07_080.png), where low values also
    imply low probabilities and high values imply high probabilities.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 将p(x)/[1−p(x)]的数量称为**赔率**，这是一种从赌博中可能熟悉的表达概率的替代方式。这可以取任何值，介于0和之间的赔率！[](img/B15439_07_080.png)，其中低值也意味着低概率，高值意味着高概率。
- en: The logit is also called **log-odds** (since it is the logarithm of the odds).
    Hence, logistic regression represents a logit that is linear in *x* and looks
    a lot like the preceding linear regression.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 对数几率也称为**对数几率**（因为它是赔率的对数）。因此，逻辑回归表示一个在x中是线性的对数，并且看起来很像前面的线性回归。
- en: Maximum likelihood estimation
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: 'The coefficient vector ![](img/B15439_07_081.png) must be estimated using the
    available training data. Although we could use (nonlinear) least squares to fit
    the logistic regression model, the more general method of maximum likelihood is
    preferred, since it has better statistical properties. As we have just discussed,
    the basic intuition behind using maximum likelihood to fit a logistic regression
    model is to seek estimates for ![](img/B15439_07_081.png) such that the predicted
    probability ![](img/B15439_07_083.png) corresponds as closely as possible to the
    actual outcome. In other words, we try to find ![](img/B15439_07_084.png) such
    that these estimates yield a number close to 1 for all cases where the stock price
    went up, and a number close to 0 otherwise. More formally, we are seeking to maximize
    the likelihood function:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: '必须使用可用的训练数据来估计系数向量![](img/B15439_07_081.png)。虽然我们可以使用（非线性）最小二乘法来拟合逻辑回归模型，但更一般的最大似然方法更可取，因为它具有更好的统计特性。正如我们刚刚讨论的，使用最大似然拟合逻辑回归模型的基本直觉是寻找估计值![](img/B15439_07_081.png)，使得预测概率![](img/B15439_07_083.png)尽可能接近实际结果。换句话说，我们试图找到![](img/B15439_07_084.png)，使得这些估计在股价上涨的所有情况下产生接近1的数字，否则接近0。更正式地说，我们正在寻求最大化似然函数： '
- en: '![](img/B15439_07_085.png)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_085.png)'
- en: 'It is easier to work with sums than with products, so let''s take logs on both
    sides to get the log-likelihood function and the corresponding definition of the
    logistic regression coefficients:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 使用总和比使用乘积更容易，因此让我们两边取对数，得到对数似然函数和相应的逻辑回归系数的定义：
- en: '![](img/B15439_07_086.png)'
  id: totrans-427
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_086.png)'
- en: To maximize this equation, we set the derivatives of ![](img/B15439_07_087.png)
    with respect to ![](img/B15439_07_081.png) to zero. This yields *p*+1 so-called
    score equations, which are nonlinear in the parameters and can be solved using
    iterative numerical methods.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最大化这个方程，我们将![](img/B15439_07_087.png)对![](img/B15439_07_081.png)的导数设为零。这产生了*p*+1个所谓的得分方程，这些方程在参数中是非线性的，可以使用迭代数值方法来解决。
- en: How to conduct inference with statsmodels
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何使用statsmodels进行推断
- en: We will illustrate how to use logistic regression with `statsmodels` based on
    a simple built-in dataset containing quarterly US macro data from 1959 to 2009
    (see the notebook `logistic_regression_macro_data` for details).
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何使用`statsmodels`进行逻辑回归，基于一个包含1959年至2009年美国宏观数据的简单内置数据集（有关详细信息，请参见笔记本`logistic_regression_macro_data`）。
- en: 'The variables and their transformations are listed in the following table:'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是变量及其转换的列表：
- en: '| Variable | Description | Transformation |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 变量 | 描述 | 转换 |'
- en: '| `realgdp` | Real gross domestic product | Annual Growth Rate |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| `realgdp` | 实际国内生产总值 | 年增长率 |'
- en: '| `realcons` | Real personal consumption expenditures | Annual Growth Rate
    |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| `realcons` | 实际个人消费支出 | 年增长率 |'
- en: '| `realinv` | Real gross private domestic investment | Annual Growth Rate |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| `realinv` | 实际国内私人投资总额 | 年增长率 |'
- en: '| `realgovt` | Real federal expenditures and gross investment | Annual Growth
    Rate |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
  zh: '| `realgovt` | 实际联邦支出和总投资 | 年增长率 |'
- en: '| `realdpi` | Real private disposable income | Annual Growth Rate |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
  zh: '| `realdpi` | 实际私人可支配收入 | 年增长率 |'
- en: '| `m1` | M1 nominal money stock | Annual Growth Rate |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
  zh: '| `m1` | M1名义货币存量 | 年增长率 |'
- en: '| `tbilrate` | Monthly Treasury bill rate | Level |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
  zh: '| `tbilrate` | 月度国库券利率 | 水平 |'
- en: '| `unemp` | Seasonally adjusted unemployment rate (%) | Level |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
  zh: '| `unemp` | 季节调整后的失业率（%） | 水平 |'
- en: '| `infl` | Inflation rate | Level |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
  zh: '| `infl` | 通货膨胀率 | 水平 |'
- en: '| `realint` | Real interest rate | Level |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
  zh: '| `realint` | 实际利率 | 水平 |'
- en: To obtain a binary target variable, we compute the 20-quarter rolling average
    of the annual growth rate of quarterly real GDP. We then assign 1 if the current
    growth exceeds the moving average and 0 otherwise. Finally, we shift the indicator
    variables to align the next quarter's outcome with the current quarter.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得二元目标变量，我们计算季度实际GDP年增长率的20个季度滚动平均值。然后，如果当前增长超过移动平均值，则分配1，否则分配0。最后，我们将指示变量移位，以使下一个季度的结果与当前季度对齐。
- en: 'We use an intercept and convert the quarter values into dummy variables and
    train the logistic regression model, as follows:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个截距，并将季度值转换为虚拟变量，并训练逻辑回归模型，如下所示：
- en: '[PRE41]'
  id: totrans-445
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This produces the following summary for our model, which shows 198 observations
    and 13 variables, including an intercept:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们的模型产生了以下摘要，显示了198个观测值和13个变量，包括一个截距：
- en: '![](img/B15439_07_13.png)'
  id: totrans-447
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_13.png)'
- en: 'Figure 7.13: Logit regression results'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.13：Logit回归结果
- en: The summary indicates that the model has been trained using maximum likelihood
    and provides the maximized value of the log-likelihood function at -67.9.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要表明，该模型已经使用最大似然进行了训练，并提供了对数似然函数的最大化值为-67.9。
- en: The LL-Null value of -136.42 is the result of the maximized log-likelihood function
    when only an intercept is included. It forms the basis for the **pseudo-R2 statistic**
    and the **log-likelihood ratio** (**LLR**) test.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: LL-Null值为-136.42是仅包括截距时最大化对数似然函数的结果。它构成了**伪R2统计量**和**对数似然比**（**LLR**）检验的基础。
- en: 'The pseudo-R² statistic is a substitute for the familiar R² available under
    least squares. It is computed based on the ratio of the maximized log-likelihood
    function for the null model *m*[0] and the full model *m*[1], as follows:'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: 伪R²统计量是最小二乘法下可用的熟悉R²的替代品。它是基于空模型*m*[0]和完整模型*m*[1]的最大化对数似然函数的比率计算的，如下所示：
- en: '![](img/B15439_07_089.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_089.png)'
- en: The values vary from 0 (when the model does not improve the likelihood) to 1,
    where the model fits perfectly and the log-likelihood is maximized at 0\. Consequently,
    higher values indicate a better fit.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值的变化范围为0（当模型不改善似然时）到1，其中模型完全适合且对数似然在0处最大化。因此，较高的值表示更好的拟合。
- en: 'The LLR test generally compares a more restricted model and is computed as:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: LLR检验通常比较更受限制的模型，并计算如下：
- en: '![](img/B15439_07_090.png)'
  id: totrans-455
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_090.png)'
- en: The null hypothesis is that the restricted model performs better, but the low
    p-value suggests that we can reject this hypothesis and prefer the full model
    over the null model. This is similar to the F-test for linear regression (where
    we can also use the LLR test when we estimate the model using MLE).
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 零假设是受限模型表现更好，但低p值表明我们可以拒绝这个假设，更喜欢完整模型而不是零模型。这类似于线性回归的F检验（当我们使用MLE估计模型时，我们也可以使用LLR检验）。
- en: The z-statistic plays the same role as the t-statistic in the linear regression
    output and is equally computed as the ratio of the coefficient estimate and its
    standard error. The p-values also indicate the probability of observing the test
    statistic, assuming the null hypothesis ![](img/B15439_07_091.png) that the population
    coefficient is zero. We can reject this hypothesis for the `intercept`, `realcons`,
    `realinv`, `realgovt`, `realdpi`, and `unemp`.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: z统计量在线性回归输出中扮演与t统计量相同的角色，并且与系数估计值及其标准误差的比率一样计算。p值也指示了在假设零假设![](img/B15439_07_091.png)下观察到检验统计量的概率，即总体系数为零的概率。我们可以拒绝这个假设，对于`intercept`、`realcons`、`realinv`、`realgovt`、`realdpi`和`unemp`。
- en: Predicting price movements with logistic regression
  id: totrans-458
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用逻辑回归预测价格走势
- en: The lasso L1 penalty and the ridge L2 penalty can both be used with logistic
    regression. They have the same shrinkage effect that we have just discussed, and
    the lasso can again be used for variable selection with any linear regression
    model.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 套索L1惩罚和岭L2惩罚都可以与逻辑回归一起使用。它们具有我们刚刚讨论的相同的收缩效应，套索可以再次用于任何线性回归模型的变量选择。
- en: Just as with linear regression, it is important to standardize the input variables
    as the regularized models are scale sensitive. The regularization hyperparameter
    also requires tuning using cross-validation, as in the case of linear regression.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归一样，对输入变量进行标准化非常重要，因为正则化模型对尺度敏感。正则化超参数也需要使用交叉验证进行调整，就像线性回归一样。
- en: How to convert a regression into a classification problem
  id: totrans-461
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何将回归转化为分类问题
- en: 'We will continue with the price prediction example, but now we will binarize
    the outcome variable so that it takes on the value 1 whenever the 1-day return
    is positive and 0 otherwise (see the notebook `predicting_price_movements_with_logistic_regression.ipynb`
    for the code examples given in this section):'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将继续使用价格预测示例，但现在我们将使结果变量二值化，以便在1天回报为正时取值为1，否则为0（请参阅笔记本`predicting_price_movements_with_logistic_regression.ipynb`中给出的代码示例）：
- en: '[PRE42]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'The outcomes are slightly unbalanced, with more positive than negative moves:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 结果略微不平衡，正向移动比负向移动多：
- en: '[PRE43]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: With this new categorical outcome variable, we can now train a logistic regression
    using the default L2 regularization.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个新的分类结果变量，我们现在可以使用默认的L2正则化训练逻辑回归。
- en: Cross-validating the logistic regression hyperparameters
  id: totrans-467
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 交叉验证逻辑回归超参数
- en: 'For logistic regression, the regularization is formulated inversely to linear
    regression: higher values for ![](img/B15439_07_059.png) imply less regularization
    and vice versa.'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 对于逻辑回归，正则化与线性回归相反：较高的值表示较少的正则化，反之亦然。
- en: 'We will cross-validate 11 options for the regularization hyperparameter using
    our custom `TimeSeriesCV`, as follows:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们自定义的`TimeSeriesCV`交叉验证正则化超参数的11个选项，如下所示：
- en: '[PRE44]'
  id: totrans-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The `train-test` loop now uses sklearn''s `LogisticRegression` and computes
    the `roc_auc_score` (see the notebook for details):'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`train-test`循环使用sklearn的`LogisticRegression`并计算`roc_auc_score`（有关详细信息，请参阅笔记本）：
- en: '[PRE45]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'In addition, we can also compute the IC based on the predicted probabilities
    and the actual returns:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以基于预测概率和实际回报计算IC：
- en: '[PRE46]'
  id: totrans-474
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: Evaluating the results using AUC and IC
  id: totrans-475
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用AUC和IC评估结果
- en: 'We can again plot the AUC result for the range of hyperparameter values. In
    *Figure 7.14*, the left panel shows that the best median AUC results for *C*=0.1,
    whereas the best mean AUC corresponds to *C*=10^(-3). The right panel displays
    the distribution of the information coefficients for the model with *C*=10⁴. This
    also highlights that we obtain somewhat higher values for the mean and the median
    compared to the regression models shown previously:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次绘制超参数值范围内的AUC结果。在*图7.14*中，左侧面板显示了*C*=0.1时最佳的中位数AUC结果，而最佳均值AUC对应于*C*=10^(-3)。右侧面板显示了*C*=10⁴的模型的信息系数分布。这也突显出，与先前显示的回归模型相比，我们获得了略高的均值和中位数数值：
- en: '![](img/B15439_07_14.png)'
  id: totrans-477
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B15439_07_14.png)'
- en: 'Figure 7.14: Logistic regression'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.14：逻辑回归
- en: In the next chapter, we will use the predictions produced by these basic models
    to generate signals for trading strategies and demonstrate how to backtest their
    performance.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将使用这些基本模型产生的预测来生成交易策略的信号，并演示如何对其性能进行回测。
- en: Summary
  id: totrans-480
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced the first of our machine learning models using
    the important baseline case of linear models for regression and classification.
    We explored the formulation of the objective functions for both tasks, learned
    about various training methods, and learned how to use the model for both inference
    and prediction.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了我们的第一个机器学习模型，使用了线性模型作为回归和分类的重要基线案例。我们探讨了两个任务的目标函数的制定，学习了各种训练方法，并学习了如何将模型用于推断和预测。
- en: We applied these new machine learning techniques to estimate linear factor models
    that are very useful to manage risks, assess new alpha factors, and attribute
    performance. We also applied linear regression and classification to accomplish
    the first predictive task of predicting stock returns in absolute and directional
    terms.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些新的机器学习技术应用于估计线性因子模型，这些模型对于管理风险、评估新的alpha因子和归因绩效非常有用。我们还应用线性回归和分类来完成第一个预测任务，即在绝对和方向性方面预测股票回报。
- en: In the next chapter, we will put together what we have covered so far in the
    form of the machine learning for trading workflow. This process starts with sourcing
    and preparing the data about a specific investment universe and the computation
    of useful features, continues with the design and evaluation of machine learning
    models to extract actionable signals from these features, and culminates in the
    simulated execution and evaluation of a strategy that translates these signals
    into optimized portfolios.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将把迄今为止所涵盖的内容以机器学习交易工作流的形式整合起来。这个过程从收集和准备特定投资领域的数据开始，计算出有用的特征，然后设计和评估机器学习模型，从这些特征中提取可操作的信号，最终在模拟执行和评估策略中，将这些信号转化为优化的投资组合。
