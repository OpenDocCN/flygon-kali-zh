["```\n 1  cd k8s-specs\n 2\n 3  git pull\n```", "```\n 1  GD5_ADDR=go-demo-5.$LB_IP.nip.io\n 2\n 3  echo $GD5_ADDR\n 4\n 5  helm upgrade -i go-demo-5 \\\n 6      https://github.com/vfarcic/go-demo-5/releases/download/\n    0.0.1/go-demo-5-0.0.1.tgz \\\n 7      --namespace go-demo-5 \\\n 8      --set ingress.host=$GD5_ADDR\n 9\n10  kubectl -n go-demo-5 \\\n11    rollout status deployment go-demo-5\n12\n13  curl \"http://$GD5_ADDR/demo/hello\"\n```", "```\n 1  kubectl -n go-demo-5 \\\n 2    describe sts go-demo-5-db\n```", "```\n...\nEvents:\n... Message\n... -------\n... create Claim go-demo-5-db-go-demo-5-db-0 Pod go-demo-5-db-0 in StatefulSet go-demo-5-db success\n... create Pod go-demo-5-db-0 in StatefulSet go-demo-5-db successful\n... create Claim go-demo-5-db-go-demo-5-db-1 Pod go-demo-5-db-1 in StatefulSet go-demo-5-db success\n... create Pod go-demo-5-db-1 in StatefulSet go-demo-5-db successful\n... create Claim go-demo-5-db-go-demo-5-db-2 Pod go-demo-5-db-2 in StatefulSet go-demo-5-db success\n... create Pod go-demo-5-db-2 in StatefulSet go-demo-5-db successful\n```", "```\n 1  kubectl -n go-demo-5 \\\n 2      logs go-demo-5-db-0 -c db\n```", "```\n 1  kubectl -n go-demo-5 \\\n 2      logs -l app=go-demo-5\n```", "```\n 1  open \"https://papertrailapp.com/\"\n```", "```\n 1  open \"https://papertrailapp.com/start\"\n```", "```\n 1  PT_HOST=[...]\n 2\n 3  PT_PORT=[...]\n```", "```\n 1  cat logging/fluentd-papertrail.yml\n```", "```\n 1  cat logging/fluentd-papertrail.yml \\\n 2      | sed -e \\\n 3      \"s@logsN.papertrailapp.com@$PT_HOST@g\" \\\n 4      | sed -e \\\n 5      \"s@NNNNN@$PT_PORT@g\" \\\n 6      | kubectl apply -f - --record\n 7\n 8  kubectl -n logging \\\n 9    rollout status ds fluentd-papertrail\n```", "```\n 1  cat logging/logger.yml\n 2  apiVersion: v1\n 3  kind: Pod\n 4  metadata:\n 5    name: random-logger\n 6  spec:\n 7    containers:\n 8    - name: random-logger\n 9      image: chentex/random-logger\n```", "```\n 1  kubectl create -f logging/logger.yml\n```", "```\n 1  kubectl logs random-logger\n```", "```\n...\n2018-12-06T17:21:15+0000 ERROR something happened in this execution.\n2018-12-06T17:21:20+0000 DEBUG first loop completed.\n2018-12-06T17:21:24+0000 ERROR something happened in this execution.\n2018-12-06T17:21:27+0000 ERROR something happened in this execution.\n2018-12-06T17:21:29+0000 WARN variable not in use.\n2018-12-06T17:21:31+0000 ERROR something happened in this execution.\n2018-12-06T17:21:33+0000 DEBUG first loop completed.\n2018-12-06T17:21:35+0000 WARN variable not in use.\n2018-12-06T17:21:40+0000 WARN variable not in use.\n2018-12-06T17:21:43+0000 INFO takes the value and converts it to string.\n2018-12-06T17:21:44+0000 INFO takes the value and converts it to string.\n2018-12-06T17:21:47+0000 DEBUG first loop completed.\n```", "```\n 1  kubectl delete \\\n 2    -f logging/fluentd-papertrail.yml\n```", "```\n 1  kubectl -n kube-system \\\n 2    describe ds -l k8s-app=fluentd-gcp\n```", "```\n...\nPod Template:\n  Labels:     k8s-app=fluentd-gcp\n              kubernetes.io/cluster-service=true\n              version=v3.1.0\n...\n  Containers:\n   fluentd-gcp:\n    Image: gcr.io/stackdriver-agents/stackdriver-logging-agent:0.3-1.5.34-1-k8s-1\n    ...\n```", "```\n 1  kubectl -n kube-system \\\n 2    logs -l k8s-app=fluentd-gcp \\\n 3    -c fluentd-gcp\n```", "```\n...\n18-12-12 21:36:41 +0000 [warn]: Dropping 1 log message(s) error=\"7:Stackdriver Logging API has not been used in project 152824630010 before or it is disabled. Enable it by visiting https://console.developers.google.com/apis/api/logging.googleapis.com/overview?project=152824630010 then retry. If you enabled this API recently, wait a few minutes for the action to propagate to our systems and retry.\" error_code=\"7\"\n```", "```\n 1  open \"https://console.cloud.google.com/logs/viewer\"\n```", "```\n 1  PROFILE=$(aws iam \\\n 2    list-instance-profiles \\\n 3    | jq -r \\\n 4    \".InstanceProfiles[]\\\n 5    .InstanceProfileName\" \\\n 6    | grep eksctl-$NAME-nodegroup-0)\n 7\n 8  echo $PROFILE\n```", "```\neksctl-devops25-nodegroup-0-NodeInstanceProfile-SBTFOBLRAKJF\n```", "```\n 1  ROLE=$(aws iam get-instance-profile \\\n 2    --instance-profile-name $PROFILE \\\n 3    | jq -r \".InstanceProfile.Roles[] \\\n 4    | .RoleName\")\n 5\n 6  echo $ROLE\n```", "```\n 1  cat logging/eks-logs-policy.json\n```", "```\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Action\": [\n        \"logs:DescribeLogGroups\",\n        \"logs:DescribeLogStreams\",\n        \"logs:CreateLogGroup\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": \"*\",\n      \"Effect\": \"Allow\"\n    }\n  ]\n}\n```", "```\n 1  aws iam put-role-policy \\\n 2    --role-name $ROLE \\\n 3    --policy-name eks-logs \\\n 4    --policy-document file://logging/eks-logs-policy.json\n```", "```\n 1  aws iam get-role-policy \\\n 2    --role-name $ROLE \\\n 3    --policy-name eks-logs\n```", "```\n 1  cat logging/fluentd-eks.yml\n```", "```\n 1  kubectl apply \\\n 2    -f logging/fluentd-eks.yml\n```", "```\n 1  kubectl -n logging get pods\n```", "```\nNAME                       READY   STATUS    RESTARTS   AGE\nfluentd-cloudwatch-7dp5b   1/1     Running   0          19s\nfluentd-cloudwatch-zq98z   1/1     Running   0          19s\nfluentd-cloudwatch-zrrk7   1/1     Running   0          19s\n```", "```\n 1  open \"https://$AWS_DEFAULT_REGION.console.aws.amazon.com/\n    cloudwatch/home?#logStream:group=/eks/$NAME/containers\"\n```", "```\n 1  kubectl delete \\\n 2    -f logging/fluentd-eks.yml\n 3\n 4  aws iam delete-role-policy \\\n 5      --role-name $ROLE \\\n 6      --policy-name eks-logs\n 7\n 8  aws logs delete-log-group \\\n 9    --log-group-name \\\n10    \"/eks/devops25/containers\"\n```", "```\n 1  az aks enable-addons \\\n 2    -a monitoring \\\n 3    -n devops25-cluster \\\n 4    -g devops25-group\n```", "```\n 1  kubectl -n kube-system get deployments\n```", "```\nNAME                 DESIRED CURRENT UP-TO-DATE AVAILABLE AGE\nheapster             1       1       1          1         1m\nkube-dns-v20         2       2       2          2         1h\nkubernetes-dashboard 1       1       1          1         1h\nmetrics-server       1       1       1          1         1h\nomsagent-rs          1       1       1          1         1m\ntiller-deploy        1       1       1          1         59m\ntunnelfront          1       1       1          1         1h\n```", "```\n 1  open \"https://portal.azure.com\"\n```", "```\n 1  ContainerLog | where Name contains \"random-logger\"\n```", "```\n 1  az aks disable-addons \\\n 2    -a monitoring \\\n 3    -n devops25-cluster \\\n 4    -g devops25-group\n```", "```\n 1  cat logging/es-values.yml\n```", "```\nclient:\n  resources:\n    limits:\n      cpu: 1\n      memory: 1500Mi\n    requests:\n      cpu: 25m\n      memory: 750Mi\nmaster:\n  resources:\n    limits:\n      cpu: 1\n      memory: 1500Mi\n    requests:\n      cpu: 25m\n      memory: 750Mi\ndata:\n  resources:\n    limits:\n      cpu: 1\n      memory: 3Gi\n    requests:\n      cpu: 100m\n      memory: 1500Mi\n```", "```\n 1  helm upgrade -i elasticsearch \\\n 2      stable/elasticsearch \\\n 3      --version 1.14.1 \\\n 4      --namespace logging \\\n 5      --values logging/es-values.yml\n 6 \n 7  kubectl -n logging \\\n 8    rollout status \\\n 9    deployment elasticsearch-client\n```", "```\n 1  helm upgrade -i fluentd \\\n 2      stable/fluentd-elasticsearch \\\n 3      --version 1.4.0 \\\n 4      --namespace logging \\\n 5      --values logging/fluentd-values.yml\n 6\n 7  kubectl -n logging \\\n 8      rollout status \\\n 9     ds fluentd-fluentd-elasticsearch\n```", "```\n 1  kubectl -n logging logs \\\n 2      -l app=fluentd-fluentd-elasticsearch\n```", "```\n... Connection opened to Elasticsearch cluster => {:host=>\"elasticsearch-client\", :port=>9200, :scheme=>\"http\"}\n... Detected ES 6.x: ES 7.x will only accept `_doc` in type_name.\n```", "```\n 1  cat logging/kibana-values.yml\n```", "```\ningress:\n  enabled: true\n  hosts:\n  - acme.com\nenv:\n  ELASTICSEARCH_URL: http://elasticsearch-client:9200\nresources:\n  limits:\n    cpu: 50m\n    memory: 300Mi\n  requests:\n    cpu: 5m\n    memory: 150Mi\n```", "```\n 1  KIBANA_ADDR=kibana.$LB_IP.nip.io\n```", "```\n 1  helm upgrade -i kibana \\\n 2      stable/kibana \\\n 3      --version 0.20.0 \\\n 4      --namespace logging \\\n 5      --set ingress.hosts=\"{$KIBANA_ADDR}\" \\\n 6     --values logging/kibana-values.yml\n 7\n 8  kubectl -n logging \\\n 9      rollout status \\\n10      deployment kibana\n```", "```\n 1  open \"http://$KIBANA_ADDR\"\n```", "```\n 1  helm delete kibana --purge\n 2\n 3  helm delete fluentd --purge\n 4\n 5  helm delete elasticsearch --purge\n 6\n 7  kubectl -n logging \\\n 8      delete pvc \\\n 9      -l release=elasticsearch,component=data\n10\n11  kubectl -n logging \\\n12      delete pvc \\\n13      -l release=elasticsearch,component=master\n```"]