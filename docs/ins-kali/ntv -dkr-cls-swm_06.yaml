- en: Chapter 6. Deploy Real Applications on Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章 在Swarm上部署真实应用
- en: 'With a Swarm infrastructure we can put up various types of load to deploy.
    We''ll work on the application stack in this and the next chapter. In this chapter
    we''ll:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm基础设施上，我们可以部署各种类型的负载。在本章和下一章中，我们将处理应用程序堆栈。在本章中，我们将：
- en: Discover Swarm's services and tasks
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现Swarm的服务和任务
- en: Deploy Nginx containers
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Nginx容器
- en: Deploy a complete WordPress
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署一个完整的WordPress
- en: Deploy a tiny scale Apache Spark architecture.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署一个小规模的Apache Spark架构。
- en: Microservices
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务
- en: The IT industry has always been keen on decoupling and reusing its creations,
    either source code or applications. Modeling applications at the architectural
    level is not an exception. Modularization was earlier called **service-oriented
    architecture** (**SOA**) and was kept glued by open source protocols based on
    XML. However, with the advent of containers, everyone is now speaking of micro
    services.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: IT行业一直热衷于解耦和重用其创造物，无论是源代码还是应用程序。在架构层面对应用程序进行建模也不例外。模块化早期被称为**面向服务的架构**（**SOA**），并且是基于XML的开源协议粘合在一起。然而，随着容器的出现，现在每个人都在谈论微服务。
- en: Micro services are small and self-contained autonomous modules that work together
    to accomplish an architectural goal.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是小型的、自包含的自治模块，它们共同工作以实现架构目标。
- en: The most inflated example of a micro service architecture is a web-application
    stack, for example WordPress, where web server might be one service, others being
    the database, cache engine, and the service containing the application itself.
    Modeling micro services through Docker containers can be done immediately and
    that's how the industry is moving ahead right now.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构的最夸张的例子是Web应用程序堆栈，例如WordPress，其中Web服务器可能是一个服务，其他服务包括数据库、缓存引擎和包含应用程序本身的服务。通过Docker容器对微服务进行建模可以立即完成，这就是目前行业的发展方向。
- en: '![Microservices](images/image_06_001.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![微服务](images/image_06_001.jpg)'
- en: 'There are many advantages of using microservices and they are as follows:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用微服务有许多优势，如下所示：
- en: '**Reusability**: You just pull the images of services you want (nginx, MySQL)
    in case you customize them'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可重用性**：您只需拉取您想要的服务的镜像（nginx、MySQL），以防需要自定义它们。'
- en: '**Heterogeneity**: You link existing modules embracing the different technologies.
    If, sometime later in the future, you decide to switch from MySQL to MariaDB,
    you plug off MySQL and plug in MariaDB'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**异构性**：您可以链接现有的模块，包括不同的技术。如果将来某个时候决定从MySQL切换到MariaDB，您可以拔掉MySQL并插入MariaDB'
- en: '**Focus on small**: Detached modules are easy to troubleshoot separately'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注于小规模**：独立模块易于单独进行故障排除'
- en: '**Scale**: You can easily scale the web servers to 10 front ends, the cache
    servers to three, and architect the database replicas on five nodes, and one day
    scale-up or scale-down depending on the application load and needs'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模**：您可以轻松地将Web服务器扩展到10个前端，将缓存服务器扩展到3个，并在5个节点上设计数据库副本，并且可以根据应用程序的负载和需求进行扩展或缩减'
- en: '**Resilience**: If you have three memcached servers and one fails, you can
    have mechanisms that try to resurrect it or just forget it and immediately fire
    up another one'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性**：如果你有三个memcached服务器，其中一个失败了，你可以有机制来尝试恢复它，或者直接忘记它并立即启动另一个'
- en: Deploy a replicated nginx
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署一个复制的nginx
- en: 'We get in touch with how to use services on Swarm by starting with a simple
    sample: Deploy and scale Nginx.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过一个简单的示例来了解如何在Swarm上使用服务：部署和扩展Nginx。
- en: A minimal Swarm
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最小的Swarm
- en: 'To make this chapter self-sufficient and useful for developers who are reading
    it as a stand-alone chapter. Let''s quickly create a minimal Swarm Mode architecture
    locally, made of one manager and three workers:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本章自给自足并对正在阅读它的开发人员有用，让我们快速在本地创建一个最小的Swarm模式架构，由一个管理者和三个工作者组成：
- en: 'We spawn up four Docker hosts:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们启动了四个Docker主机：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We then take control of `node-1`, which we elect as our static manager, and
    initialize it on a Swarm:'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们接管了`node-1`，我们选举它作为我们的静态管理器，并在Swarm上初始化它：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Docker generates a token, for us, to join our three workers. So we just copy-paste
    that output to iterate through the other three workers to join them to the nodes:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Docker为我们生成一个令牌，以加入我们的三个工作节点。因此，我们只需复制粘贴该输出以迭代其他三个工作节点，将它们加入节点：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Swarm Mode architecture is always connected to `node-1` by Docker Machine-shell
    environment variables that are filled by the previous `eval` command. We need
    to check whether all the nodes, including the leader manager, are active and successfully
    joined to the Swarm:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式架构始终通过Docker Machine-shell环境变量连接到`node-1`，这些变量由先前的`eval`命令填充。我们需要检查所有节点，包括领导管理器，是否都处于活动状态并成功加入了Swarm：
- en: '![A minimal Swarm](images/image_06_002.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![一个最小的Swarm](images/image_06_002.jpg)'
- en: 'Now, we can check the status of this Swarm cluster using `docker info` command:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`docker info`命令来检查这个Swarm集群的状态：
- en: '![A minimal Swarm](images/image_06_003.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![一个最小的Swarm](images/image_06_003.jpg)'
- en: The important information here is that Swarm is active, and then some Raft details
    follow.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重要信息是Swarm处于活动状态，然后是一些Raft的细节。
- en: Docker service
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker服务
- en: A new command introduced in Docker 1.12 is `docker service` and that's what
    we're going to see now. Service is the primary way by which you'll operate applications
    on Docker Swarm mode; it's how you will create, destroy, scale and roll update
    services.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 1.12中引入的一个新命令是`docker service`，这就是我们现在要看到的。服务是在Docker Swarm模式上操作应用程序的主要方式；这是您将创建、销毁、扩展和滚动更新服务的方式。
- en: Services are made of tasks. An nginx service is made-up of nginx container tasks.
    The service mechanism spins-up the tasks on (typically) worker nodes. So, when
    you create a service, you have to mandatorily specify, among its options, a service
    name and the container that will be the base of the service.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 服务由任务组成。一个nginx服务由nginx容器任务组成。服务机制在（通常）工作节点上启动任务。因此，当您创建一个服务时，您必须强制指定服务名称和将成为服务基础的容器等选项。
- en: .
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: '![Docker service](images/image_06_004.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_004.jpg)'
- en: 'The syntax to create the services is very immediate: You just use the `docker
    service create` command, specifying options, such as the exposed ports, and select
    the container to use. Here we execute'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 创建服务的语法非常直接：只需使用`docker service create`命令，指定选项，如暴露的端口，并选择要使用的容器。在这里我们执行
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Docker service](images/image_06_005.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_005.jpg)'
- en: This command starts nginx, exposes the container's port `80` to the host's port
    `80`, so that they can be reached from outside, and specifies a replica factor
    of three.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令启动了nginx，将容器的端口`80`暴露给主机的端口`80`，以便可以从外部访问，并指定了三个副本因子。
- en: Replica factor is the way you scale containers on Swarm. If you specify three,
    Swarm will create three nginx tasks (containers) on three nodes and try to preserve
    this number, in case one or more of these containers die, by rescheduling nginx
    on other available hosts (where possible).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 副本因子是在Swarm上扩展容器的方式。如果指定为三个，Swarm将在三个节点上创建三个nginx任务（容器），并尝试保留这个数量，以防其中一个或多个容器死掉，通过在其他可用主机上重新调度nginx来实现。
- en: If a no `--replicas` option is given, then the default replica factor is `1`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有给出`--replicas`选项，则默认的副本因子是`1`。
- en: 'After some time, Swarm needs to pull the image from the hub, or any registry
    locally, to the hosts and create the appropriate container (and exposing the port);
    we see that three nginx are in place on our infrastructure with the command:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，Swarm需要从hub或任何本地注册表中将镜像拉到主机并创建适当的容器（并暴露端口）；我们看到三个nginx已经在我们的基础设施上就位了，使用命令：
- en: '[PRE4]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '![Docker service](images/image_06_006.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_006.jpg)'
- en: 'These tasks are actually scheduled on three nodes, as shown using the following
    command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这些任务实际上是在三个节点上调度的，如下命令所示：
- en: '[PRE5]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Docker service](images/image_06_007.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_007.jpg)'
- en: The `fsoppelsa/swarm-nginx` container used here is a trivial modification of
    `richarvey/nginx-php-fpm`, which is a nginx image empowered by PHP. We used PHP
    to output on the Nginx welcome page the address of the current server, by adding
    a PHP command with the purpose of showing the load balancing mechanism.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的`fsoppelsa/swarm-nginx`容器是对`richarvey/nginx-php-fpm`的微小修改，后者是一个由PHP增强的nginx镜像。我们使用PHP在Nginx欢迎页面上输出当前服务器的地址，通过添加一个PHP命令来显示负载均衡机制的目的。
- en: '[PRE6]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Docker service](images/image_06_008.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_008.jpg)'
- en: Now if you point your browser to the manager IP and reload several times, you'll
    see that a load balancer is actually redirecting you to different containers sometimes.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你将浏览器指向管理器IP并多次重新加载，你会发现负载均衡器有时会将你重定向到不同的容器。
- en: 'First page that will load will be similar to the following screenshot:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '第一个加载的页面将类似于以下截图： '
- en: '![Docker service](images/image_06_009.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_009.jpg)'
- en: 'The following screenshot shows another page loaded, with a different node selected
    by the load balancer, 10.255.0.9:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了另一个加载的页面，由负载均衡器选择了不同的节点，即10.255.0.9：
- en: '![Docker service](images/image_06_010.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_010.jpg)'
- en: 'The following screenshot is of another page loaded when the load balancer redirects
    to node 10.255.0.10:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是当负载均衡器重定向到节点10.255.0.10时加载的另一个页面：
- en: '![Docker service](images/image_06_011.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![Docker服务](images/image_06_011.jpg)'
- en: Overlay networks
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 覆盖网络
- en: If instead of just replicating, you want to connect containers running on different
    hosts to your Swarm infrastructure, you have to use networks. For example, you
    need to connect your web servers to your database containers so that they can
    communicate.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不仅仅是要复制，而是要连接运行在不同主机上的容器到你的Swarm基础设施，你必须使用网络。例如，你需要将你的web服务器连接到你的数据库容器，以便它们可以通信。
- en: The answer to this, in Swarm Mode, is to use overlay networks. They are implemented
    with Docker's libnetwork and libkv. These networks are VxLAN networks built on
    top of another network (in the standard setup, the physical host network).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm模式下，解决这个问题的方法是使用覆盖网络。它们是使用Docker的libnetwork和libkv实现的。这些网络是建立在另一个网络之上的VxLAN网络（在标准设置中，是物理主机网络）。
- en: VxLAN is an extension of the VLAN protocol, aiming at increasing its scalability.
    Containers on different hosts, connected to Docker VxLAN networks, can communicate
    as if they are on the same host.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: VxLAN是VLAN协议的扩展，旨在增加其可扩展性。连接到Docker VxLAN网络的不同主机上的容器可以像它们在同一主机上一样进行通信。
- en: Docker Swarm Mode includes a routing mesh table that enables this multi-host
    networking, by default, called **ingress**.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm模式包括一个路由网格表，通过默认情况下称为**ingress**，实现了这种多主机网络。
- en: Integrated load balancing
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成负载均衡
- en: How does the load balancing work on Swarm Mode 1.12? The routing works in two
    different ways. Firstly, it works through the port exposed by the Virtual IP service.
    Any requests to the port are distributed among the hosts hosting the service tasks.
    Secondly, the service is given a Virtual IP address that is routable only inside
    the Docker Network. When requests are made to this VIP address, they are distributed
    to the underlying containers. This Virtual IP is registered inside the DNS server
    included in Docker Swarm. When a DNS query is done on the service name (for example
    nslookup mysql), the Virtual IP is returned.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm Mode 1.12上的负载平衡是如何工作的？路由有两种不同的方式。首先，它通过虚拟IP服务公开的端口工作。对端口的任何请求都会分布在承载服务任务的主机之间。其次，服务被赋予一个仅在Docker网络内可路由的虚拟IP地址。当对此VIP地址进行请求时，它们将分布到底层容器。这个虚拟IP被注册在Docker
    Swarm中包含的DNS服务器中。当对服务名称进行DNS查询时（例如nslookup mysql），将返回虚拟IP。
- en: 'Connecting services: A WordPress example'
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 连接服务：WordPress示例
- en: The possibility of launching a bunch of replicated and load balanced containers
    is already a good start, but how about more complex application stacks, made of
    different interconnected containers?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 启动一堆复制和负载平衡的容器已经是一个不错的开始，但是如何处理由不同相互连接的容器组成的更复杂的应用程序堆栈呢？
- en: In this case, you can link containers by calling them by name. As we just saw,
    the internal Swarm DNS server will guarantee a reliable name resolution mechanism.
    If you instantiate a service called `nginx`, you can just reference it as `nginx`
    and other services will resolve to the `nginx` Virtual IP (load balanced), hence
    accessing the distributed containers.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，您可以通过名称调用容器进行链接。正如我们刚才看到的，内部Swarm DNS服务器将保证可靠的名称解析机制。如果您实例化一个名为`nginx`的服务，您只需将其引用为`nginx`，其他服务将解析为`nginx`虚拟IP（负载平衡），从而访问分布式容器。
- en: 'To demonstrate this with an example, we''re now going to deploy the more classical
    of classics on Swarm: WordPress. You can run WordPress as a container, in fact
    a ready image is available on the Docker Hub, however it requires an external
    database (in this case MySQL) to store its data.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了以示例演示这一点，我们现在将在Swarm上部署经典中的经典：WordPress。您可以将WordPress作为容器运行，实际上Docker Hub上有一个准备好的镜像，但是它需要一个外部数据库（在本例中是MySQL）来存储其数据。
- en: So, as a start, we'll create a new dedicated overlay network on Swarm, called
    WordPress, and run one MySQL container on top of it as a Swarm service and three
    load balanced WordPress containers (web containers) also as a Swarm service. MySQL
    will expose port 3306, while WordPress will expose port `80`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，首先，我们将在Swarm上创建一个名为WordPress的新专用覆盖网络，并将一个MySQL容器作为Swarm服务运行在其上，并将三个负载平衡的WordPress容器（Web容器）也作为Swarm服务运行。MySQL将公开端口3306，而WordPress将公开端口`80`。
- en: 'Let''s start by defining our overlay network. When connected to the Swarm manager,
    we issue the following command:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先定义我们的覆盖网络。连接到Swarm管理器时，我们发出以下命令：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![Connecting services: A WordPress example](images/image_06_012.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![连接服务：WordPress示例](images/image_06_012.jpg)'
- en: So, what happens behind the curtain? The command creates an overlay network
    with libnetwork, which becomes available on the Swarm nodes when they get scheduled
    tasks requiring it. It will always be present if you connect to `node-2` and list
    networks.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，幕后发生了什么？该命令使用libnetwork创建了一个覆盖网络，在需要时在Swarm节点上可用。如果连接到`node-2`并列出网络，它将始终存在。
- en: 'We now create a MySQL service, made of just one container (no MySQL native
    replicas nor Galera or other replication mechanisms) with the following command:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在创建一个MySQL服务，只由一个容器组成（没有MySQL本地副本，也没有Galera或其他复制机制），使用以下命令：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We want to pull MySQL 5.6 from the hub, call the service (later accessible
    via resolved name pointing to its VIP) `mysql`, set replicas to one for clarity,
    expose port `3306`, specify the dedicated network WordPress, and the root password,
    in our case it''s `dockerswarm`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要从hub上拉取MySQL 5.6，调用服务（稍后可以通过解析的名称访问其VIP）`mysql`，为了清晰起见，将副本设置为1，暴露端口`3306`，指定专用网络WordPress，并指定根密码，在我们的情况下是`dockerswarm`：
- en: '![Connecting services: A WordPress example](images/image_06_013.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![连接服务：WordPress示例](images/image_06_013.jpg)'
- en: 'It is necessary to pull the MySQL image from the hub after a few seconds, we
    can check and see that in our case a `mysql` container was downloaded and placed
    on `node-1` (actually, masters can run containers if not specified differently),
    and the VIP is `10.255.0.2`, on the WordPress network. We can get this information
    with the following command:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 必须从hub上拉取MySQL镜像，几秒钟后，我们可以检查并看到在我们的情况下，一个`mysql`容器被下载并放置在`node-1`上（实际上，如果没有另行指定，主节点也可以运行容器），VIP是`10.255.0.2`，在WordPress网络上。我们可以使用以下命令获取此信息：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Connecting services: A WordPress example](images/image_06_014.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![连接服务：WordPress示例](images/image_06_014.jpg)'
- en: We now have a running MySQL, we just need to launch and connect it to WordPress.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在有一个正在运行的MySQL，我们只需要启动并将其连接到WordPress。
- en: Swarm scheduling strategies
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swarm调度策略
- en: 'It just happened that we started a service and Swarm scheduled the container
    to be run on `node-1`. Swarm mode (as of now, at the time of writing Docker 1.12,
    and 1.13-dev) has only one possible strategy: spread. Spread counts the number
    of containers on each host and attempts to place newly created containers on the
    less loaded hosts (that is, hosts with less containers). Despite the fact that
    there is only one spread strategy available on this day, Swarm comes with options
    that allow us to filter the hosts, on which the tasks will be launched, with good
    precision.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 碰巧我们启动了一个服务，Swarm将容器调度到`node-1`上运行。Swarm模式（截至目前，在编写Docker 1.12和1.13-dev时）只有一种可能的策略：spread。Spread计算每个主机上的容器数量，并尝试将新创建的容器放置在负载较轻的主机上（即，容器较少的主机）。尽管在当天只有一种可用的spread策略，但Swarm提供了选项，允许我们以很高的精度过滤将启动任务的主机。
- en: These options are called **constraints** and may be passed as an optional argument
    when services are instantiated with `--constraint`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选项称为**约束条件**，可以在实例化服务时作为可选参数传递，使用`--constraint`。
- en: We now want to start WordPress. We decide that we want to forcibly execute three
    containers on the three workers and not on the master, so we specify a constraint.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想要启动WordPress。我们决定要强制在三个工作者上执行三个容器，而不是在主节点上，因此我们指定了一个约束条件。
- en: Constraints are of the form of `--constraint``node.KEY == VALUE` or `--constraint``node.KEY
    != VALUE` and there are several variants. An operator can filter by node id, role,
    and hostname. More interesting, as we saw in [Chapter 5](ch04.html "Chapter 4. Creating
    a Production-Grade Swarm"), *Administer a Swarm Cluster*, is the possibility to
    specify custom labels by adding it to the node attributes with the `docker node
    update --label-add` command.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 约束条件的形式为`--constraint``node.KEY == VALUE`或`--constraint``node.KEY != VALUE`，有几种变体。操作员可以按节点ID、角色和主机名进行过滤。更有趣的是，正如我们在[第5章](ch04.html
    "第4章。创建生产级Swarm")中看到的那样，*管理Swarm集群*，可以通过使用`docker node update --label-add`命令将自定义标签添加到节点属性中来指定自定义标签。
- en: '| **Key** | **Meaning** | **Example** |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| **键** | **含义** | **示例** |'
- en: '| `node.id` | ID of node | `node.id == 3tqtddj8wfyd1dl92o1l1bniq` |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| `node.id` | 节点ID | `node.id == 3tqtddj8wfyd1dl92o1l1bniq` |'
- en: '| `node.role` | Node role (manager, worker) | `node.role != manager` |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| `node.role` | 节点角色（管理器，工作者） | `node.role != manager` |'
- en: '| `node.hostname` | Node hostname | `node.hostname == node-1` |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| `node.hostname` | 节点主机名 | `node.hostname == node-1` |'
- en: '| `node.labels` | Labels | `node.labels.type == database` |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| `node.labels` | 标签 | `node.labels.type == database` |'
- en: Now, WordPress
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 现在，WordPress
- en: 'Here we want to start `wordpress` on all workers, so we say that the constraint
    is `node.role != manager` (or `node.role == worker`). Also, we call the service,
    just `wordpress,` set the replica factor to `3`, expose port `80,` and say to
    WordPress that MySQL is located on host mysql (this is resolved internally in
    Swarm and points to the MySQL VIP):'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们希望在所有工作节点上启动`wordpress`，因此我们说约束条件是`node.role != manager`（或`node.role ==
    worker`）。此外，我们将服务命名为`wordpress`，将副本因子设置为`3`，暴露端口`80`，并告诉WordPress MySQL位于主机mysql上（这在Swarm内部解析并指向MySQL
    VIP）：
- en: '[PRE10]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Now, WordPress](images/image_06_015.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![现在，WordPress](images/image_06_015.jpg)'
- en: After some time, we need to download WordPress images to the workers so that
    we can check if everything is up and running.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一段时间，我们需要将WordPress图像下载到工作节点，以便我们可以检查一切是否正常运行。
- en: '![Now, WordPress](images/image_06_016.jpg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![现在，WordPress](images/image_06_016.jpg)'
- en: We now connect to one of the hosts on port `80` and we're welcomed by the WordPress
    installer.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过端口`80`连接到主机之一，并受到WordPress安装程序的欢迎。
- en: '![Now, WordPress](images/image_06_017.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![现在，WordPress](images/image_06_017.jpg)'
- en: 'WordPress is ready after a few steps, such as selecting an admin username and
    a password, are performed in the browser:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: WordPress在浏览器中执行一些步骤后就准备好了，比如选择管理员用户名和密码：
- en: '![Now, WordPress](images/image_06_018.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![现在，WordPress](images/image_06_018.jpg)'
- en: Docker Compose and Swarm mode
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Compose和Swarm模式
- en: Many developers enjoy using Compose to model their applications, for example
    applications similar to WordPress. We do the same and think that it's a fantastic
    way to describe and manage micro services on Docker. However, at the time of writing
    this book, no support for Docker Swarm Mode is available in Compose yet and all
    containers are scheduled on the current node. To deploy an application across
    the swarm, we need to use the new bundle feature of stacks.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 许多开发人员喜欢使用Compose来模拟他们的应用程序，例如类似WordPress的应用程序。我们也这样做，并认为这是描述和管理Docker上的微服务的一种绝妙方式。然而，在撰写本书时，Compose尚未支持Docker
    Swarm模式，所有容器都被安排在当前节点上。要在整个Swarm上部署应用程序，我们需要使用堆栈的新捆绑功能。
- en: At the time of writing, stacks are available only experimentally, but we're
    showing them here just to give you a taste of what it will be like to deploy microservices
    on Docker in the (near) future.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，堆栈仅以实验性方式提供，但我们在这里展示它们，只是为了让您体验在（不久的）将来在Docker上部署微服务的感觉。
- en: Introducing Docker stacks
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Docker堆栈
- en: 'For Docker, stacks will be the standard way of packaging applications made
    by multiple containers. Consider the hyper inflated WordPress example: You need
    a minimum of one web server and one database.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Docker，堆栈将成为打包由多个容器组成的应用程序的标准方式。考虑到庞大的WordPress示例：您至少需要一个Web服务器和一个数据库。
- en: 'Developers usually describe these applications with Compose, by creating a
    YAML, as shown:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员通常通过创建一个YAML文件来使用Compose描述这些应用程序，如下所示：
- en: '[PRE11]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, they launch this application with a command such as:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，他们使用类似以下的命令启动此应用：
- en: '[PRE12]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, `mysql` and `wordpress` containers are scheduled, pulled, and started
    as daemons on the host to which the developer is connected. Starting from Docker
    1.12 (experimental in 1.12), it will be possible to package `mysql + wordpress`
    in a single file package, called **Distributed Application Bundle** (**DAB**).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`mysql`和`wordpress`容器被安排、拉取并作为守护进程在开发者连接的主机上启动。从Docker 1.12开始（在1.12中是实验性的），将有可能将`mysql
    + wordpress`打包成一个单一文件包，称为**分布式应用程序包**（**DAB**）。
- en: Distributed Application Bundles
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分布式应用程序包
- en: 'So, instead of `docker-compose up` command, you will run:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您将运行`docker-compose up`命令，而不是：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This command will output another JSON, called `wordpress.dab`, which will be
    the starting point for deploying services described as Swarm services by Compose
    on Swarm.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令将输出另一个名为`wordpress.dab`的JSON，它将成为通过Compose在Swarm上描述为Swarm服务的服务部署的起点。
- en: 'For this example, the content of `wordpress.dab` looks similar to:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，`wordpress.dab`的内容看起来类似于：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Docker deploy
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker部署
- en: 'Starting from the generated `wordpress.dab` file, when connected to a Swarm
    manager, the developer can start a stack with the deploy command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 从生成的`wordpress.dab`文件开始，当连接到Swarm管理器时，开发者可以使用deploy命令启动一个堆栈：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now you will have two services called `wordpress1_wordpress` and `wordpress1_db`,
    conventionally following the syntax traditions of Compose.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你将有两个名为`wordpress1_wordpress`和`wordpress1_db`的服务，传统上遵循Compose的语法传统。
- en: '![Docker deploy](images/image_06_019.jpg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![Docker部署](images/image_06_019.jpg)'
- en: This is a very primitive demo of what it will be. As an experimental feature,
    the support features in Compose are still not completely defined, but we expect
    it to change (even radically) in the future to meet the developer, Swarm, and
    Compose needs.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个非常原始的演示。作为一个实验性功能，Compose中的支持功能仍然没有完全定义，但我们期望它会改变（甚至根本改变）以满足开发者、Swarm和Compose的需求。
- en: 'Another app: Apache Spark'
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 另一个应用程序：Apache Spark
- en: Now that we have acquired some practice using services, we step up to the next
    level. We'll deploy Apache Spark on Swarm. Spark is an open source cluster computing
    framework from the Apache foundation, which is mainly used for data processing.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经通过使用服务获得了一些实践经验，我们将迈向下一个级别。我们将在Swarm上部署Apache Spark。Spark是Apache基金会的开源集群计算框架，主要用于数据处理。
- en: 'Spark may be (but not limited to) used for things, such as:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以用于诸如以下的事情：
- en: Analysis of big data (Spark Core)
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大数据分析（Spark Core）
- en: Fast and scalable data structured console (Spark SQL)
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速可扩展的数据结构化控制台（Spark SQL）
- en: Streaming analytics (Spark Streaming)
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流式分析（Spark Streaming）
- en: Graph processing (Spark GraphX)
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形处理（Spark GraphX）
- en: Here we will focus mainly on the infrastructural part of Swarm. If you want
    to learn how to program or use Spark in detail, read Packt's selection of books
    on Spark. We suggest starting with *Fast Data Processing with Spark 2.0 - Third
    Edition*.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们主要关注Swarm的基础设施部分。如果你想详细了解如何编程或使用Spark，可以阅读Packt关于Spark的图书选择。我们建议从*Fast
    Data Processing with Spark 2.0 - Third Edition*开始。
- en: Spark is a neat and clear alternative for Hadoop, it is a more agile and efficient
    substitute for the complexity and magnitude of Hadoop.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Spark是Hadoop的一个整洁而清晰的替代方案，它是Hadoop复杂性和规模的更敏捷和高效的替代品。
- en: The theoretical topology of Spark is immediate and can reckon the Swarm mode
    on one or more managers leading the cluster operations and a certain number of
    workers who are executing real tasks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Spark的理论拓扑是立即的，可以在一个或多个管理器上计算集群操作，并有一定数量的执行实际任务的工作节点。
- en: As for managers, Spark can use its own managers called standalone managers (as
    we'll do here) or use Hadoop YARN or even exploit Mesos features.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管理器，Spark可以使用自己的独立管理器（就像我们在这里做的那样），也可以使用Hadoop YARN，甚至利用Mesos的特性。
- en: Then, Spark can delegate storage to an internal HDFS (Hadoop Distributed Filesystem)
    or to external storage services, such as Amazon S3, OpenStack Swift, or Cassandra.
    Storage is used by Spark to get data to elaborate and then to save the elaborated
    results.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，Spark可以将存储委托给内部HDFS（Hadoop分布式文件系统）或外部存储服务，如Amazon S3、OpenStack Swift或Cassandra。存储由Spark用于获取数据进行处理，然后保存处理后的结果。
- en: Why Spark on Docker
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么在Docker上使用Spark
- en: 'We''ll show you how to start a Spark cluster on a Docker Swarm cluster, as
    an alternative to start Spark with virtual machines. The example defined in this
    chapter can get many benefits from containers:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将向您展示如何在Docker Swarm集群上启动Spark集群，作为使用虚拟机启动Spark的替代方法。本章中定义的示例可以从容器中获得许多好处：
- en: Starting containers is much more quicker
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动容器更快
- en: Scaling containers in a pet model is more immediate
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在宠物模型中扩展容器更为直接。
- en: You can get Spark images without having to create VMs, to write custom scripts,
    adapt Ansible Playbooks. Just `docker pull`
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以获取Spark镜像，而无需创建虚拟机，编写自定义脚本，调整Ansible Playbooks。只需`docker pull`
- en: You can create a dedicated overlay network with Docker Networking features,
    without physically compromising or invoking a networking team
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用Docker Networking功能创建专用的覆盖网络，而无需在物理上损害或调用网络团队
- en: Spark standalone without Swarm
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spark独立模式无Swarm
- en: Let's start defining a tiny Apache Spark cluster built with the classical Docker
    tools, which are basically Docker commands on a Docker host. Before understanding
    the big picture, we need to start familiarizing ourselves with Swarm concepts
    and terminologies on the field.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始定义一个使用经典Docker工具构建的小型Apache Spark集群，这些工具基本上是Docker主机上的Docker命令。在了解整体情况之前，我们需要开始熟悉Swarm概念和术语。
- en: 'In this chapter, we''ll work with the `google_container` images, specifically
    with Swarm version 1.5.2\. Many improvements are included in the 2.0 version,
    but these images are proven to be very stable and reliable. So, we can start by
    pulling them for the master and the workers from the Google repository:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用`google_container`镜像，特别是Swarm版本1.5.2。2.0版本中包含了许多改进，但这些镜像被证明非常稳定可靠。因此，我们可以从Google仓库中开始拉取它们，用于主节点和工作节点：
- en: '[PRE16]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Spark can run on the top of YARN, Mesos, or Hadoop. In the following examples
    and chapters, we're going to use its standalone mode, because it is the easiest
    and requires no additional prerequisites. In a standalone Spark cluster mode,
    Spark allocates resources based on cores. By default, an application will grab
    all the cores in the cluster, so we're going to limit the resources dedicated
    to the workers.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Spark可以在YARN、Mesos或Hadoop的顶部运行。在接下来的示例和章节中，我们将使用它的独立模式，因为这是最简单的，不需要额外的先决条件。在独立的Spark集群模式中，Spark根据核心分配资源。默认情况下，应用程序将占用集群中的所有核心，因此我们将限制专用于工作节点的资源。
- en: 'Our architecture will be very straightforward: one master, which will be responsible
    for managing the cluster, and three workers for the nodes running Spark jobs.
    For our purpose, the master has to publish port `8080` (the Web UI we''ll use
    for convenience) and we''ll call it spark-master. By default, the worker containers
    attempt to connect to the URL `spark://spark-master:7077`, so apart from linking
    them to the master, no further customization are required.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的架构将非常简单：一个负责管理集群的主节点，以及三个负责运行Spark作业的节点。对于我们的目的，主节点必须发布端口`8080`（我们将用于方便的Web
    UI），我们将其称为spark-master。默认情况下，工作节点容器尝试连接到URL `spark://spark-master:7077`，因此除了将它们链接到主节点外，不需要进一步的定制。
- en: 'So, let''s pass it to the practical part and initialize a Spark master with
    the following code:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们将其传递给实际部分，并使用以下代码初始化Spark主节点：
- en: '[PRE17]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This runs in the daemon mode (`-d`), a container from the `gcr.io/google_containers/spark-master`
    image, assigns the name (`--name`) spark-master to the container and configures
    its hostname (`-h`) to spark-master.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这在守护程序模式（`-d`）中运行，从`gcr.io/google_containers/spark-master`镜像中创建一个容器，将名称（`--name`）spark-master分配给容器，并将其主机名（`-h`）配置为spark-master。
- en: We can connect now a browser to the Docker host, at port `8080,` to verify that
    Spark is up and running.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以连接浏览器到Docker主机，端口`8080`，以验证Spark是否正在运行。
- en: '![Spark standalone without Swarm](images/image_06_020.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![没有Swarm的Spark独立运行](images/image_06_020.jpg)'
- en: 'It still has no Alive Workers, which we''re going to spawn now. We start the
    workers with the following commands just before we take note of the ID of the
    Spark master container:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 它仍然没有活动的工作节点，我们现在要生成。在我们注意到Spark主容器的ID之前，我们使用以下命令启动工作节点：
- en: '[PRE18]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This starts a container in the daemon mode, links it to the master, limits
    the memory-in-use to a maximum of 256M, exposes port 8081 to web (worker) management,
    and assigns it to the container name `worker-1`. Similarly, we start the other
    two workers:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以守护进程模式启动一个容器，将其链接到主节点，将内存使用限制为最大256M，将端口8081暴露给Web（工作节点）管理，并将其分配给容器名称`worker-1`。类似地，我们启动其他两个工作节点：
- en: '[PRE19]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We can check on the master if everything is connected and running:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在主节点上检查一切是否连接并运行：
- en: '![Spark standalone without Swarm](images/image_06_021.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![没有Swarm的Spark独立运行](images/image_06_021.jpg)'
- en: Spark standalone on Swarm
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swarm上的独立Spark
- en: So far, we have discussed the not so important part. We're now going now to
    transfer the concepts already discussed to Swarm architecture, so we'll instantiate
    the Spark master and workers as Swarm services, instead of single containers.
    We'll create an architecture with a replica factor of one for the master, and
    a replica factor of three for the workers.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了不那么重要的部分。我们现在将已经讨论的概念转移到Swarm架构，所以我们将实例化Spark主节点和工作节点作为Swarm服务，而不是单个容器。我们将创建一个主节点的副本因子为1的架构，以及工作节点的副本因子为3。
- en: Spark topology
  id: totrans-162
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Spark拓扑
- en: In this example, we'll create a Spark cluster made of one master and three workers.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将创建一个由一个主节点和三个工作节点组成的Spark集群。
- en: Storage
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 存储
- en: We'll define a real storage and start some real Spark tasks in [Chapter 7](ch07.html
    "Chapter 7. Scaling Up Your Platform"), S*caling Up Your Platform*.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第7章](ch07.html "第7章 扩展您的平台")中定义真实的存储并启动一些真实的Spark任务，扩展您的平台。
- en: Prerequisites
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 先决条件
- en: 'We begin by creating a new dedicated overlay network for Spark:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先为Spark创建一个新的专用覆盖网络：
- en: '[PRE20]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Then, we set some labels onto nodes to be able to filter later. We want to
    host the Spark master on the Swarm manager (`node-1`) and Spark workers on Swarm
    workers (node-2, 3 and 4):'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们在节点上设置一些标签，以便以后能够过滤。我们希望将Spark主节点托管在Swarm管理器（`node-1`）上，将Spark工作节点托管在Swarm工作节点（节点2、3和4）上：
- en: '[PRE21]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Tip
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: 'We''re adding here the ''sparkworker'' type tags for extreme clarity. With
    only two variants, it''s possible in fact to write the same constraint as:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里添加了“sparkworker”类型标签以确保极端清晰。实际上，只有两种变体，事实上可以写成相同的约束：
- en: '**--constraint ''node.labels.type == sparkworker''**'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**--constraint ''node.labels.type == sparkworker''**'
- en: 'Or:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 或者：
- en: '**--constraint ''node.labels.type != sparkmaster''**'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**--constraint ''node.labels.type != sparkmaster''**'
- en: Start Spark on Swarm
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Swarm上启动Spark
- en: We will now define our Spark services in Swarm, similar to what we did for Wordpress
    in the preceding section, but this time we will drive the scheduling strategy
    by defining where to start the Spark master and the Spark workers with the maximum
    precision.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将在Swarm中定义我们的Spark服务，类似于我们在前一节为Wordpress所做的操作，但这次我们将通过定义在哪里启动Spark主节点和Spark工作节点来驱动调度策略，以最大程度地精确地进行。
- en: 'We begin with the master as shown:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从主节点开始，如下所示：
- en: '[PRE22]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'A Spark master exposes port `8080` (the web UI) and optionally, for the clarity
    of the example, here we also expose port `7077` used by the Spark workers to connect
    to the master and port 6066, the Spark API port. Also, we limit the memory to
    1G with --limit-memory. Once the Spark master is up, we can create the service
    hosting the workers, sparkworker:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Spark主节点暴露端口`8080`（Web UI），并且可选地，为了示例的清晰度，这里我们还暴露了端口`7077`，Spark工作节点用于连接到主节点的端口，以及端口6066，Spark
    API端口。此外，我们使用--limit-memory将内存限制为1G。一旦Spark主节点启动，我们可以创建托管工作节点的服务，sparkworker：
- en: '[PRE23]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Similarly, we expose port `8081` (the workers web UI), but it''s optional.
    Here, all the Spark containers are scheduled on spark worker nodes, as we defined
    earlier. It will take some time to pull the images to the hosts. As a result,
    we have the minimal Spark infrastructure:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们暴露端口`8081`（工作节点的Web UI），但这是可选的。在这里，所有的Spark容器都被调度到了之前我们定义的spark工作节点上。将镜像拉到主机上需要一些时间。结果，我们有了最小的Spark基础设施：
- en: '![Start Spark on Swarm](images/image_06_022.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![在Swarm上启动Spark](images/image_06_022.jpg)'
- en: 'The Spark cluster is up and running, even if there is a little note to add:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Spark集群正在运行，即使有一点需要补充的地方：
- en: '![Start Spark on Swarm](images/image_06_023.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![在Swarm上启动Spark](images/image_06_023.jpg)'
- en: 'Despite the fact that we limited the memory to 256M for each worker, in the
    UI we still see that Spark reads 1024M. This is because of the Spark internal
    default configuration. If we connect to any of the hosts, where one of the workers
    is running, and check its statistics with the `docker stats a7a2b5bb3024` command,
    we see that the container is actually limited:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们将每个worker的内存限制为256M，但在UI中我们仍然看到Spark读取了1024M。这是因为Spark内部的默认配置。如果我们连接到任何一个正在运行其中一个worker的主机，并使用`docker
    stats a7a2b5bb3024`命令检查其统计信息，我们会看到容器实际上是受限制的。
- en: '![Start Spark on Swarm](images/image_06_024.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![在Swarm上启动Spark](images/image_06_024.jpg)'
- en: Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this chapter, we started working on the application stack and deploying
    real things on Swarm. We did some practice in defining Swarm services and we launched
    a cluster of nginx, as well as a load-balanced WordPress on a dedicated overlay
    network. Then, we moved on to something more real: Apache Spark. We deployed Spark
    on Swarm at a small scale, by defining our own scheduling strategies. We are going
    to expand Swarm and scale it to a bigger size, with more real storage and networking
    options, in [Chapter 7](ch07.html "Chapter 7. Scaling Up Your Platform"), S*caling
    Up Your Platform*.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们开始在应用程序堆栈上工作，并在Swarm上部署真实的东西。我们练习了定义Swarm服务，并在专用覆盖网络上启动了一组nginx，以及一个负载均衡的WordPress。然后，我们转向了更真实的东西：Apache
    Spark。我们通过定义自己的调度策略，在Swarm上以小规模部署了Spark。在[第7章](ch07.html "第7章。扩展您的平台")中，我们将扩展Swarm并将其扩展到更大规模，具有更多真实的存储和网络选项。
