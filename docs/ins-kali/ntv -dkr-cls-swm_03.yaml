- en: Chapter 3. Meeting Docker Swarm Mode
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章。了解Docker Swarm模式
- en: At Dockercon 16, the Docker team presented a new way of operating Swarm clusters,
    called Swarm Mode. The announcement was slightly anticipated by the introduction
    of a new set of tools, said to *operate distributed systems at any scale* called
    **Swarmkit**.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在Dockercon 16上，Docker团队提出了一种操作Swarm集群的新方式，称为Swarm模式。这一宣布略有预期，因为引入了一套新的工具，被称为*在任何规模上操作分布式系统*的**Swarmkit**。
- en: 'In this chapter, we will:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将：
- en: Introduce Swarmkit
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Swarmkit
- en: Introduce Swarm Mode
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Swarm模式
- en: Compare Swarm v1, Swarmkit, and Swarm Mode
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较Swarm v1、Swarmkit和Swarm模式
- en: Create a test Swarmkit cluster, and launch services on it
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个测试Swarmkit集群，并在其上启动服务。
- en: Do not skip reading the Swarmkit section, because Swarmkit acts as a foundation
    for Swarm mode. Seeing Swarmkit is the way we chose to introduce Swarm Mode concepts,
    such as nodes, services, tasks.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 不要跳过阅读Swarmkit部分，因为Swarmkit作为Swarm模式的基础。看到Swarmkit是我们选择介绍Swarm模式概念的方式，比如节点、服务、任务。
- en: We'll show how to create production-level big Swarm Mode clusters in [Chapter
    4](ch04.html "Chapter 4. Creating a Production-Grade Swarm"), *Creating a Production-Grade
    Swarm*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将展示如何在[第4章](ch04.html "第4章。创建生产级别的Swarm")中创建生产级别的大型Swarm模式集群，*创建生产级别的Swarm*。
- en: Swarmkit
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarmkit
- en: 'Alongside with Swarm Mode, the Docker team at DockerCon16 released Swarmkit,
    defined as a:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Swarm模式，Docker团队在DockerCon16发布了Swarmkit，被定义为：
- en: '*"Toolkit for orchestrating distributed systems at any scale. It includes primitives
    for node discovery, raft-based consensus, task scheduling, and more."*'
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“用于在任何规模上编排分布式系统的工具包。它包括节点发现、基于raft的共识、任务调度等基元。”*'
- en: '**Swarms** clusters are made of active nodes, that can either act as managers
    or workers.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarms**集群由活动节点组成，可以充当管理者或工作者。'
- en: Managers, that coordinate via Raft (that is, they elect leaders when quorum
    is available, as described in [Chapter 2](ch02.html "Chapter 2. Discover the Discovery
    Services"), *Discover the Discovery Services*), are responsible for allocating
    resources, orchestrating services, and dispatching tasks along the cluster. Workers
    run tasks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 管理者通过Raft进行协调（也就是说，当达成法定人数时，他们会选举领导者，如[第2章](ch02.html "第2章。发现发现服务")中所述，*发现发现服务*），负责分配资源、编排服务和在集群中分发任务。工作者运行任务。
- en: The cluster goal is to execute *services*, so what's required to be run is defined
    at high level. For example, a service could be "web". Work units assigned to nodes
    are instead called **tasks**. A task allocated for a "web" service could be, for
    example, a container running the nginx container, and may be named as web.5.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 集群的目标是执行*服务*，因此需要在高层次上定义要运行的内容。例如，一个服务可以是“web”。分配给节点的工作单元称为**任务**。分配给“web”服务的任务可能是运行nginx容器的容器，可能被命名为web.5。
- en: It's very important to notice that we are speaking of services and that a service
    may be containers. May be, it's not necessary. In this book, our focus will be
    of course on containers, but the intention of Swarmkit is to theoretically abstract
    orchestration of any object.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的是要注意我们正在谈论服务，而服务可能是容器。可能不是必要的。在本书中，我们的重点当然是容器，但Swarmkit的意图理论上是抽象编排任何对象。
- en: Versions and support
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 版本和支持
- en: A note on versions. Docker Swarm mode, which we'll introduce in the upcoming
    sections, is compatible only with Docker 1.12+. With Swarmkit, instead, you can
    orchestrate even previous versions of Docker Engines, for example, 1.11 or 1.10.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 关于版本的说明。我们将在接下来的章节中介绍的Docker Swarm模式，只与Docker 1.12+兼容。而Swarmkit可以编排甚至是以前版本的Docker引擎，例如1.11或1.10。
- en: Swarmkit architecture
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swarmkit架构
- en: '**Swarmkit** is the orchestration mechanism released to handle clusters of
    services of any size.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swarmkit**是发布的编排机制，用于处理任何规模的服务集群。'
- en: In a Swarmkit cluster, nodes can be either **managers** (of the cluster) or
    **workers** (the workhorses of cluster, nodes that execute compute operations).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarmkit集群中，节点可以是**管理者**（集群的管理者）或**工作节点**（集群的工作马，执行计算操作的节点）。
- en: There should be an odd number of managers, preferably 3 or 5, so that if there
    will be no split brains (as explained in [Chapter 2](ch02.html "Chapter 2. Discover
    the Discovery Services"), *Discover the Discovery Services*), and a majority of
    managers will drive the cluster. A quorum is always required by the Raft consensus
    algorithm.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最好有奇数个管理者，最好是3或5个，这样就不会出现分裂的情况（如[第2章](ch02.html "第2章。发现发现服务")中所解释的，*发现发现服务*），并且大多数管理者将驱动集群。Raft一致性算法始终需要法定人数。
- en: 'A Swarmkit cluster can host any arbitrary number of workers: 1, 10, 100, or
    2,000.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Swarmkit集群可以承载任意数量的工作节点：1、10、100或2000。
- en: On managers, **services** may be defined and load balanced. For example, a service
    may be "web". A "web" service will be physically made of several **tasks**, running
    on the cluster nodes, including the managers, for example, one task can be a single
    nginx Docker container.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理者上，**服务**可以被定义和负载平衡。例如，一个服务可以是“web”。一个“web”服务将由运行在集群节点上的多个**任务**组成，包括管理者，例如，一个任务可以是一个单独的nginx
    Docker容器。
- en: '![Swarmkit architecture](images/image_03_001.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![Swarmkit架构](images/image_03_001.jpg)'
- en: In Swarmkit, an operator uses a **Swarmctl** binary to interact with the system
    remotely, invoking operations on the leader master. Masters, that run a binary
    called **Swarmd**, agree on a leader via Raft, keep the status of services and
    tasks, and schedule jobs on workers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarmkit中，操作员使用**Swarmctl**二进制文件远程与系统交互，在领导主节点上调用操作。运行名为**Swarmd**的主节点通过Raft同意领导者，保持服务和任务的状态，并在工作节点上调度作业。
- en: Workers run the Docker Engine, and take jobs running them as separate containers.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点运行Docker引擎，并将作业作为单独的容器运行。
- en: The Swarmkit architecture can be subject to a redraw, but the core components
    (masters and workers) are going to stay. Rather, new objects can possibly be added
    with plugins, for allocating resources such as networks and volumes.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Swarmkit架构可能会被重新绘制，但核心组件（主节点和工作节点）将保持不变。相反，可能会通过插件添加新对象，用于分配资源，如网络和卷。
- en: How a manager chooses the best node for a task
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理者如何选择最佳节点执行任务
- en: The way that Swarmkit spawns tasks over the cluster is called **scheduling**.
    The scheduler is an algorithm that uses criteria such as filters to decide where
    to physically start a task.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Swarmkit在集群上生成任务的方式称为**调度**。调度程序是一个使用诸如过滤器之类的标准来决定在哪里物理启动任务的算法。
- en: '![How a manager chooses the best node for a task](images/image_03_002.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![管理者如何选择最佳节点执行任务](images/image_03_002.jpg)'
- en: 'The heart of SwarmKit: swarmd'
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SwarmKit的核心：swarmd
- en: The core binary to start a SwarmKit service is called `swarmd`, and that's the
    daemon to create both the master and join slaves.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 启动SwarmKit服务的核心二进制文件称为`swarmd`，这是创建主节点和加入从节点的守护程序。
- en: It can bind itself either to a local UNIX socket and to a TCP socket, but in
    both cases, is manageable by the `swarmctl` utility by connecting to (another)
    dedicated UNIX local socket.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以绑定到本地UNIX套接字和TCP套接字，但无论哪种情况，都可以通过连接到（另一个）专用的本地UNIX套接字来由`swarmctl`实用程序管理。
- en: In the example that follows in the next section, we'll use `swarmd` to create
    a first manager listening on port `4242/tcp`, and then again we'll use `swarmd`
    on the other worker nodes, to make them join the manager, and finally we'll use
    `swarmctl` to check some facts about our cluster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们将使用`swarmd`在端口`4242/tcp`上创建一个第一个管理者，并再次使用`swarmd`在其他工作节点上，使它们加入管理者，最后我们将使用`swarmctl`来检查我们集群的一些情况。
- en: These binaries are encapsulated into the `fsoppelsa/swarmkit` image that's available
    on the Docker Hub, and that we're going to use here to simplify the explanation
    and avoid Go code compilation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些二进制文件被封装到`fsoppelsa/swarmkit`镜像中，该镜像可在Docker Hub上获得，并且我们将在这里使用它来简化说明并避免Go代码编译。
- en: This is the online help for swarmd. It's rather self-explanatory in its tunables,
    so we're not going to cover all options in detail. For our practical purposes,
    the most important options are `--listen-remote-api`, defining the `address:port`
    for `swarmd` to bind on, and `--join-addr`, used from other nodes to join the
    cluster.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是swarmd的在线帮助。它在其可调整项中相当自解释，因此我们不会详细介绍所有选项。对于我们的实际目的，最重要的选项是`--listen-remote-api`，定义`swarmd`绑定的`address:port`，以及`--join-addr`，用于其他节点加入集群。
- en: '![The heart of SwarmKit: swarmd](images/image_03_003.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![SwarmKit的核心：swarmd](images/image_03_003.jpg)'
- en: 'The controller of SwarmKit: swarmctl'
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SwarmKit的控制器：swarmctl
- en: '`swarmctl` is the client part of SwarmKit. It''s the tool to use for operating
    SwarmKit clusters, as it is capable of showing the list of joined nodes, the list
    of services and tasks, and other information. Here, again from `fsoppelsa/swarmkit`,
    the `swarmctl` online help:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`swarmctl`是SwarmKit的客户端部分。这是用于操作SwarmKit集群的工具，它能够显示已加入节点的列表、服务和任务的列表，以及其他信息。这里，再次来自`fsoppelsa/swarmkit`，`swarmctl`的在线帮助：'
- en: '![The controller of SwarmKit: swarmctl](images/image_03_004.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![SwarmKit的控制器：swarmctl](images/image_03_004.jpg)'
- en: Provisioning a SwarmKit cluster with Ansible
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Ansible创建SwarmKit集群
- en: In this section, we'll provision a SwarmKit cluster initially made of a single
    manager and an arbitrary number of slaves.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将首先创建一个由单个管理节点和任意数量的从节点组成的SwarmKit集群。
- en: To create such a setup, we'll use Ansible to make operations repeatable and
    more robust and, besides illustrating the commands, we'll proceed by examining
    the playbooks structure. You can easily adapt those playbooks to run on your provider
    or locally, but here we'll go on Amazon EC2.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '为了创建这样的设置，我们将使用Ansible来使操作可重复和更加健壮，并且除了说明命令，我们还将通过检查playbooks结构来进行。您可以轻松地调整这些playbooks以在您的提供商或本地运行，但在这里我们将在Amazon
    EC2上进行。 '
- en: To make this example run, there are some basic requirements.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个示例运行，有一些基本要求。
- en: 'If you want to follow the example on AWS, of course you must have an AWS account
    and have the access keys configured. Keys are retrievable from the AWS Console
    under your **Account Name** | **Security Credentials**. You will need to copy
    the following key''s values:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在AWS上跟随示例，当然您必须拥有AWS账户并配置访问密钥。密钥可从AWS控制台中的**账户名称** | **安全凭据**下检索。您需要复制以下密钥的值：
- en: Access Key ID
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问密钥ID
- en: Secret Access Key
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 秘密访问密钥
- en: 'I use `awsctl` to set those keys. Just install it from *brew* (Mac) or from
    your packaging system if you''re using Linux or Windows, and configure it:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用`awsctl`来设置这些密钥。只需从*brew*（Mac）安装它，或者如果您使用Linux或Windows，则从您的打包系统安装它，并进行配置：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Answer the prompt questions by pasting the keys when required. Configuration,
    where you can specify, for example, a favorite AWS region (such as `us-west-1`)
    is stored in `~/.aws/config`, while credentials are in `~/.aws/credentials`. In
    this way, keys are configured and read automatically by Docker Machine.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要时通过粘贴密钥来回答提示问题。配置中，您可以指定例如一个喜爱的AWS区域（如`us-west-1`）存储在`~/.aws/config`中，而凭据存储在`~/.aws/credentials`中。这样，密钥会被Docker
    Machine自动配置和读取。
- en: 'If you want to run the Ansible example instead of the commands, these are the
    software requirements:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想运行Ansible示例而不是命令，这些是软件要求：
- en: Ansible 2.2+
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ansible 2.2+
- en: A Docker client compatible with the image that docker-machine will install on
    EC2 (in our case, the default one is Ubuntu 15.04 LTS), at the time of writing,
    the Docker Client 1.11.2
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与docker-machine将在EC2上安装的镜像兼容的Docker客户端（在我们的情况下，默认的是Ubuntu 15.04 LTS）一起使用，写作时，Docker
    Client 1.11.2
- en: Docker-machine
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker-machine
- en: Docker-py client (that's used by Ansible), can be installed with `pip install
    docker-py`
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker-py客户端（由Ansible使用）可以通过`pip install docker-py`安装
- en: Moreover, the example is using the standard port `4242/tcp`, to make the cluster
    nodes interact with each other. So it's required to open that port in a security
    group.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，示例使用标准端口`4242/tcp`，以使集群节点相互交互。因此，需要在安全组中打开该端口。
- en: 'Clone the repository at [https://github.com/fsoppelsa/ansible-swarmkit](https://github.com/fsoppelsa/ansible-swarmkit)
    and begin by setting up the SwarmKit Manager node:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 克隆存储库[https://github.com/fsoppelsa/ansible-swarmkit](https://github.com/fsoppelsa/ansible-swarmkit)，并开始设置SwarmKit
    Manager节点：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Provisioning a SwarmKit cluster with Ansible](images/image_03_005.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![使用Ansible配置SwarmKit集群](images/image_03_005.jpg)'
- en: 'After some docker-machine setup, the playbook will start a container on the
    Manager host, acting as a SwarmKit Manager. Here is the play snippet:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些docker-machine的设置后，playbook将在Manager主机上启动一个容器，充当SwarmKit Manager。以下是play片段：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: On host, a container named `swarmkit-master` from the image `fsoppelsa/swarmkit`
    runs `swarmd` in manager mode (it listens at `0.0.0.0:4242`). The `swarmd` binary
    uses the Docker Engine on host directly, so Engine's socket is mounted inside
    container. The container maps port `4242` to the host port `4242`, so that `swarmd`
    is reachable by slaves directly by connecting to the host `4242` port.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在主机上，名为`swarmkit-master`的容器从图像`fsoppelsa/swarmkit`中运行`swarmd`以管理模式运行（它在`0.0.0.0:4242`处监听）。`swarmd`二进制文件直接使用主机上的Docker
    Engine，因此Engine的套接字被挂载到容器内。容器将端口`4242`映射到主机端口`4242`，以便从属节点可以通过连接到主机`4242`端口直接访问`swarmd`。
- en: 'In practice, it''s the equivalent of this Docker command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这相当于以下Docker命令：
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This command runs in detached mode (`-d`), passes via volumes (`-v`) the Docker
    machine Docker socket inside the container, exposes port `4242` from container
    to host (`-p`), and runs `swarmd` by putting the container itself in listening
    mode on any address, on port `4242`.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令以分离模式（`-d`）运行，通过卷（`-v`）将Docker机器Docker套接字传递到容器内部，将容器中的端口`4242`暴露到主机（`-p`），并通过将容器本身放在任何地址上的端口`4242`上运行`swarmd`，使其处于监听模式。
- en: 'Once the playbook has finished, you can source the `swarmkit-master` machine
    credentials and check whether our container is running correctly:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦playbook完成，您可以获取`swarmkit-master`机器的凭据并检查我们的容器是否正常运行：
- en: '![Provisioning a SwarmKit cluster with Ansible](images/image_03_006.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![使用Ansible配置SwarmKit集群](images/image_03_006.jpg)'
- en: 'Now it''s time to join some slaves. To start a slave, you can, guess what,
    just run:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是加入一些从属节点的时候了。要启动一个从属节点，您可以，猜猜看，只需运行：
- en: '[PRE4]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'But since we want to join at least several nodes to the SwarmKit cluster, we
    go with a little bit of shell scripting:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但由于我们希望至少加入几个节点到SwarmKit集群中，我们使用一点shell脚本：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This command runs five times the playbook, thus creating five worker nodes.
    The playbook, after creating a machine named `swarmkit-RANDOM` will start a `fsoppelsa/swarmkit`
    container doing the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令运行五次playbook，从而创建五个工作节点。playbook在创建名为`swarmkit-RANDOM`的机器后，将启动一个`fsoppelsa/swarmkit`容器，执行以下操作：
- en: '[PRE6]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, swarmd runs in join mode, and joins the cluster initiated on the Master,
    by connecting to port `4242/tcp`. This is the equivalent of the following docker
    command:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，swarmd以加入模式运行，并通过连接到端口`4242/tcp`加入在Master上启动的集群。这相当于以下docker命令：
- en: '[PRE7]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The ansible `loop` command will take some minutes to finish, depending on how
    many workers are starting. When the playbook has finished, we can control that
    the cluster was created correctly using `swarmctl`. If you haven''t sourced the
    `swarmkit-master` Machine credential yet, it''s time to:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ansible的`loop`命令将需要一些时间来完成，这取决于有多少工作节点正在启动。当playbook完成后，我们可以使用`swarmctl`来控制集群是否正确创建。如果您还没有提供`swarmkit-master`机器凭据，现在是时候了：
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we invoke the container running the swarmd master, using exec:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们使用exec来调用运行swarmd主节点的容器：
- en: '[PRE9]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Provisioning a SwarmKit cluster with Ansible](images/image_03_007.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![使用Ansible配置SwarmKit集群](images/image_03_007.jpg)'
- en: So, here we have listed the workers that have joined the master.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，这里列出了已加入主节点的工作节点。
- en: Creating a service on SwarmKit
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在SwarmKit上创建服务
- en: Using the usual `swarmctl` binary, we can now create a service (web), made of
    nginx containers.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用通常的`swarmctl`二进制文件，我们现在可以创建一个服务（web），由nginx容器制成。
- en: 'We begin by checking to make sure that there are no active services on this
    brand new cluster:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先检查一下，确保这个全新的集群上没有活动服务：
- en: '![Creating a service on SwarmKit](images/image_03_008.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![在SwarmKit上创建服务](images/image_03_008.jpg)'
- en: 'So we''re ready to start one, with this command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们准备好开始了，使用这个命令：
- en: '[PRE10]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Creating a service on SwarmKit](images/image_03_009.jpg)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![在SwarmKit上创建服务](images/image_03_009.jpg)'
- en: 'This command specifies to create a service named `web`, made of `nginx` container
    images, and replicate it with a factor of `5`, so as to create 5 nginx containers
    across the cluster. It will take some seconds to take effect, because on each
    node of the cluster, Swarm will pull and start the nginx image, but finally:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令指定创建一个名为`web`的服务，由`nginx`容器镜像制成，并且使用因子`5`进行复制，以在集群中创建5个nginx容器。这需要一些时间生效，因为在集群的每个节点上，Swarm将拉取并启动nginx镜像，但最终：
- en: '![Creating a service on SwarmKit](images/image_03_010.jpg)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![在SwarmKit上创建服务](images/image_03_010.jpg)'
- en: 'The **5/5** indicates that of 5 desired replicas, 5 are up. We can see in detail
    where those containers got spawned using `swarmctl task ls`:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**5/5**表示在5个期望的副本中，有5个正在运行。我们可以使用`swarmctl task ls`来详细查看这些容器生成的位置：'
- en: '![Creating a service on SwarmKit](images/image_03_011.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![在SwarmKit上创建服务](images/image_03_011.jpg)'
- en: But, wait, is a nginx service (web.5) running on the manager node? Yes. SwarmKit
    and Swarm Mode managers are allowed to run tasks, by default, and the scheduler
    can dispatch jobs onto them.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，等等，manager节点上是否正在运行nginx服务（web.5）？是的。默认情况下，SwarmKit和Swarm模式管理者被允许运行任务，并且调度程序可以将作业分派给它们。
- en: In a real production configuration, if you want to reserve managers to not run
    jobs, you need to apply a configuration with labels and constraints. This is a
    topic of [Chapter 5](ch05.html "Chapter 5. Administer a Swarm Cluster"), *Administer
    a Swarm Cluster*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在真实的生产配置中，如果您想要保留管理者不运行作业，您需要应用带有标签和约束的配置。这是[第5章](ch05.html "第5章。管理Swarm集群")*管理Swarm集群*的主题。
- en: Swarm mode
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm模式
- en: Docker Swarm mode (for Docker Engines of version 1.12 or newer) imports the
    SwarmKit libraries in order to make distributed container orchestration over multiple
    hosts possible and easy to operate.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm模式（适用于版本1.12或更新版本的Docker引擎）导入了SwarmKit库，以便实现在多个主机上进行分布式容器编排，并且操作简单易行。
- en: 'The main difference between SwarmKit and Swarm Mode is that Swarm Mode is integrated
    into Docker itself, starting from version 1.12\. This means that Swarm Mode commands
    such as `swarm`, `nodes`, `service`, and `task` are available *inside* the Docker
    client, and that through the docker command it''s possible to initiate and manage
    Swarms, as well as deploy services and tasks:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: SwarmKit和Swarm模式的主要区别在于，Swarm模式集成到了Docker本身，从版本1.12开始。这意味着Swarm模式命令，如`swarm`，`nodes`，`service`和`task`在Docker客户端*内部*可用，并且通过docker命令可以初始化和管理Swarm，以及部署服务和任务：
- en: '`docker swarm init`: This is to initialize a Swarm cluster'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm init`: 这是用来初始化Swarm集群的'
- en: '`docker node ls`: This is used to list the available nodes'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker node ls`: 用于列出可用节点'
- en: '`docker service tasks`: This is used to list the tasks associated to a specific
    service'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker service tasks`: 用于列出与特定服务相关的任务'
- en: Old versus new Swarm versus SwarmKit
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 旧的Swarm与新的Swarm与SwarmKit
- en: 'At the time of writing, (August 2016), we have three Docker orchestration systems:
    the old one (that is) Swarm v1, SwarmKit, and the new one (that is) integrated
    Swarm Mode.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时（2016年8月），我们有三个Docker编排系统：旧的Swarm v1，SwarmKit和集成的新Swarm模式。
- en: '![Old versus new Swarm versus SwarmKit](images/image_03_012.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![旧的Swarm与新的Swarm与SwarmKit](images/image_03_012.jpg)'
- en: The original Swarm v1, the one we showed in [Chapter 1](ch01.html "Chapter 1. Welcome
    to Docker Swarm"), *Welcome to Docker Swarm* and that's still used around, is
    not yet deprecated. It's a way of using (recycling?) older infrastructures. But
    starting from Docker 1.12, the new Swarm Mode is the recommended way to begin
    a new orchestration project, especially if it will need to scale to a big size.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.html "第1章。欢迎来到Docker Swarm")中展示的原始Swarm v1，*欢迎来到Docker Swarm*，仍在使用，尚未被弃用。这是一种使用（回收利用？）旧基础设施的方式。但是从Docker
    1.12开始，新的Swarm模式是开始新编排项目的推荐方式，特别是如果需要扩展到大规模。
- en: To make things simpler, let's summarize the differences between these projects
    with some tables.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化事情，让我们用一些表格总结这些项目之间的区别。
- en: 'First, the old Swarm v1 versus the new Swarm Mode:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，旧的Swarm v1与新的Swarm模式：
- en: '| **Swarm standalone** | **Swarm Mode** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **Swarm standalone** | **Swarm Mode** |'
- en: '| This is available since Docker 1.8 | This is available since Docker 1.12
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 这是自Docker 1.8起可用 | 这是自Docker 1.12起可用 |'
- en: '| This is available as a container | This is integrated into the Docker Engine
    |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 这可用作容器 | 这集成到Docker Engine中 |'
- en: '| This needs an external discovery service (such as Consul, Etcd, or Zookeeper)
    | This doesn''t need an external discovery service, Etcd integrated |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 这需要外部发现服务（如Consul、Etcd或Zookeeper） | 这不需要外部发现服务，Etcd集成 |'
- en: '| This is not secure by default | This is secure by default |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 这默认不安全 | 这默认安全 |'
- en: '| The replica and scaling features are not available | The replica and scaling
    features are available |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 复制和扩展功能不可用 | 复制和扩展功能可用 |'
- en: '| There are no service and task concepts for modeling microservices | There
    are out of the box services, tasks, load balancing, and service discovery |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 没有用于建模微服务的服务和任务概念 | 有现成的服务、任务、负载均衡和服务发现 |'
- en: '| There is no additional networking available | This has integrated VxLAN (mesh
    networking) |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: 没有额外的网络可用 | 这个集成了VxLAN（网状网络）|
- en: 'And now, to clarify ideas, let''s compare SwarmKit and Swarm mode:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了澄清想法，让我们比较一下SwarmKit和Swarm模式：
- en: '| **SwarmKit** | **Swarm mode** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **SwarmKit** | **Swarm mode** |'
- en: '| These are released as binaries (`swarmd` and `swarmctl`)--use swarmctl |
    These are integrated into the Docker Engine--use docker |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 这些发布为二进制文件（`swarmd`和`swarmctl`）-使用swarmctl | 这些集成到Docker Engine中-使用docker
    |'
- en: '| These are generic tasks | These are container tasks |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 这些是通用任务 | 这些是容器任务 |'
- en: '| These include services and tasks | These include services and tasks |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|这些包括服务和任务|这些包括服务和任务|'
- en: '| These include no service advanced features, such as load balancing and VxLAN
    networking | These include out of the box service advanced features, such as load
    balancing and VxLAN networking |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|这些不包括服务高级功能，如负载平衡和VxLAN网络|这些包括开箱即用的服务高级功能，如负载平衡和VxLAN网络|'
- en: Swarm Mode zoom in
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swarm模式放大
- en: As we already summarized in the preceding table in Swarm standalone versus Swarm
    mode comparison, the main new features available in Swarm Mode are the integration
    into the engine, no need for an external discovery service, and replica, scale,
    load balancing, and networking included.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在Swarm独立与Swarm模式比较的前表中已经总结的，Swarm模式中的主要新功能包括集成到引擎中，无需外部发现服务，以及包括副本、规模、负载平衡和网络。
- en: Integration into the engine
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集成到引擎中
- en: With docker 1.12+, some new commands are added to the docker client. We now
    take a survey on the ones that are relevant to the matter of this book.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 使用docker 1.12+，docker客户端添加了一些新命令。我们现在对与本书相关的命令进行调查。
- en: docker swarm command
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: docker swarm命令
- en: 'This is the current command to manage Swarms:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这是管理Swarm的当前命令：
- en: '![docker swarm command](images/image_03_013.jpg)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![docker swarm command](images/image_03_013.jpg)'
- en: 'It accepts the following options:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 它接受以下选项：
- en: '`init`: This initializes a Swarm. Behind the curtain, this command creates
    a manager for the current Docker host and generates a *secret* (its password that
    workers will pass to the API so as to be authorized to join the cluster).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init`：这将初始化一个Swarm。在幕后，此命令为当前Docker主机创建一个管理者，并生成一个*秘密*（工作节点将通过API传递给密码以获得加入集群的授权）。'
- en: '`join`: This is used by a worker to join a cluster, must specify the *secret*
    and a list of managers IP port values.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`join`：这是工作节点加入集群的命令，必须指定*秘密*和管理者IP端口值列表。'
- en: '`join-token`: This is used to manage the `join-tokens`. `join-tokens` are special
    token secrets used to make join managers or workers (managers and workers have
    different token values). This command is a convenient way to make Swarm print
    the necessary command to join a manager or a worker:'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`join-token`：这用于管理`join-tokens`。`join-tokens`是用于使管理者或工作节点加入的特殊令牌秘密（管理者和工作节点具有不同的令牌值）。此命令是使Swarm打印加入管理者或工作节点所需命令的便捷方式：'
- en: '[PRE11]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To add a worker to this swarm, run the following command:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要将工作节点添加到此Swarm，请运行以下命令：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To add a manager to this swarm, run the following command:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 要将管理者添加到此Swarm，请运行以下命令：
- en: '[PRE13]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`update`: This updates the cluster by changing some of its values, for example,
    you can use it to specify a new URL of the certificate endpoint'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`update`：这将通过更改一些值来更新集群，例如，您可以使用它来指定证书端点的新URL'
- en: '`leave`: This commands the current node to leave the cluster. If something
    is blocking the operation, there is a useful `--force` option.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leave`：此命令使当前节点离开集群。如果有什么阻碍了操作，有一个有用的`--force`选项。'
- en: docker node
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: docker节点
- en: This is the command to handle swarm nodes. You must launch it from a manager,
    so you need to be connected to a manager in order to use it.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是处理集群节点的命令。您必须从管理者启动它，因此您需要连接到管理者才能使用它。
- en: '![docker node](images/image_03_014.jpg)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![docker节点](images/image_03_014.jpg)'
- en: '`demote` and `promote`: These are commands used to manage the status of nodes.
    With that mechanism, you can promote a node to a manager, or demote it to a worker.
    In practice, Swarm will try to `demote`/`promote`. We will cover this concept
    just a bit later in this chapter.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`demote`和`promote`：这些是用于管理节点状态的命令。通过该机制，您可以将节点提升为管理者，或将其降级为工作节点。在实践中，Swarm将尝试`demote`/`promote`。我们将在本章稍后介绍这个概念。'
- en: '`inspect`: This is the equivalent of docker info, but for a Swarm node. It
    prints information regarding the node/s.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`inspect`：这相当于docker info，但用于Swarm节点。它打印有关节点的信息。'
- en: '`ls`: This lists the nodes connected to the cluster.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ls`：这列出了连接到集群的节点。'
- en: '`rm`: This attempts to remove a worker. If you want to remove a manager, you
    have before to demote it to worker.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rm`：这尝试移除一个worker。如果你想移除一个manager，在此之前你需要将其降级为worker。'
- en: '`ps`: This shows the list of tasks running on a specified node.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ps`：这显示了在指定节点上运行的任务列表。'
- en: '`update`: This allows you to change some configuration values for a node, namely
    tags.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`update`：这允许您更改节点的一些配置值，即标签。'
- en: docker service
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: docker service
- en: 'This is the command to manage the services running on a Swarm cluster:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这是管理运行在Swarm集群上的服务的命令：
- en: '![docker service](images/image_03_015.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![docker service](images/image_03_015.jpg)'
- en: 'Apart from the expected commands such as `create`, `inspect`, `ps`, `ls`, `rm`,
    and `update`, there is a new interesting one: `scale`.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 除了预期的命令，如`create`、`inspect`、`ps`、`ls`、`rm`和`update`，还有一个新的有趣的命令：`scale`。
- en: Docker Stack
  id: totrans-152
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Docker Stack
- en: Not directly necessary to Swarm operations, but introduced as experimental in
    Docker 1.12, there is the `stack` command. Stacks are now bundles of containers.
    For example, a nginx + php + mysql container setup can be stacked in a self-contained
    Docker Stack, called **Distributed Application Bundle** (**DAB**) and described
    by a JSON file.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 并不直接需要Swarm操作，但在Docker 1.12中作为实验引入了`stack`命令。Stacks现在是容器的捆绑。例如，一个nginx + php
    + mysql容器设置可以被堆叠在一个自包含的Docker Stack中，称为**分布式应用程序包**（**DAB**），并由一个JSON文件描述。
- en: The core command of docker stack will be deploy, thanks to which it will be
    possible to create and update DABs. We'll meet stacks later in [Chapter 6](ch06.html
    "Chapter 6. Deploy Real Applications on Swarm"), *Deploy Real Applications on
    Swarm*.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: docker stack的核心命令将是deploy，通过它将可以创建和更新DABs。我们稍后会在[第6章](ch06.html "第6章。在Swarm上部署真实应用程序")中遇到stacks，*在Swarm上部署真实应用程序*。
- en: Etcd's Raft is integrated already
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Etcd的Raft已经集成
- en: Docker Swarm Mode already integrates RAFT through CoreOS Etcd Raft library.
    There is no further need to integrate external discovery services such as Zookeeper
    or Consul anymore. Swarm directly takes care of essential services such as DNS
    and load balancing.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm Mode已经通过CoreOS Etcd Raft库集成了RAFT。不再需要集成外部发现服务，如Zookeeper或Consul。Swarm直接负责基本服务，如DNS和负载均衡。
- en: Installing a Swarm Mode cluster is just a matter of starting Docker hosts and
    running Docker commands, making it super easy to set up.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 安装Swarm Mode集群只是启动Docker主机并运行Docker命令的问题，使得设置变得非常容易。
- en: Load balancing and DNS
  id: totrans-158
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 负载均衡和DNS
- en: By design, the cluster managers assign to every service in the swarm a unique
    DNS name and load balances running containers, using an internal DNS to Docker.
    Queries and resolutions work automatically out of the box.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '按设计，集群管理器为Swarm中的每个服务分配一个唯一的DNS名称，并使用内部DNS对运行的容器进行负载均衡。查询和解析可以自动工作。 '
- en: For each service created with a `--name myservice`, every container in the swarm
    will be able to resolve the service IP address just as they were resolving (`dig
    myservice`) internal network names, using the Docker embedded DNS server. So,
    if you have a `nginx-service` (made of nginx containers, for example), you can
    just `ping nginx-service` to reach the frontend head.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用`--name myservice`创建的每个服务，Swarm中的每个容器都将能够解析服务IP地址，就像它们正在解析（`dig myservice`）内部网络名称一样，使用Docker内置的DNS服务器。因此，如果你有一个`nginx-service`（例如由nginx容器组成），你可以只需`ping
    nginx-service`来到达前端。
- en: Also, in Swarm mode, operators have the possibility to `publish` services ports
    to an external load balancer. Ports are then exposed outside to a port in a range
    from `30000` to `32767`. Internally, Swarm uses iptables and IPVS to execute packet
    filtering and forwarding, and load balancing respectively.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在Swarm模式下，操作员有可能将服务端口`发布`到外部负载均衡器。然后，端口在`30000`到`32767`的范围内暴露到外部。在内部，Swarm使用iptables和IPVS来执行数据包过滤和转发，以及负载均衡。
- en: Iptables is the default packet filter firewall used by Linux while IPVS is the
    seasoned IP Virtual Server defined in the Linux kernel, that can be used for load
    balancing traffic, and that's just what Docker Swarm uses.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: Iptables是Linux默认使用的数据包过滤防火墙，而IPVS是在Linux内核中定义的经验丰富的IP虚拟服务器，可用于负载均衡流量，这正是Docker
    Swarm所使用的。
- en: Ports are published either when a new service is created or updated, using the
    `--publish-add` option. With this option, an internal service is published, and
    gets load balanced.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 端口要么在创建新服务时发布，要么在更新时发布，使用`--publish-add`选项。使用此选项，内部服务被发布，并进行负载均衡。
- en: 'For example, if we have a cluster with three workers each running nginx (on
    a service named `nginx-service`), we can expose their target-port to the load
    balancer with:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们有一个包含三个工作节点的集群，每个节点都运行nginx（在名为`nginx-service`的服务上），我们可以将它们的目标端口暴露给负载均衡器：
- en: '[PRE14]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will create a mapping between the published port `30000` on any of the
    nodes cluster, and the `nginx` containers (port 80). If you connect any node to
    port `30000`, you will be greeted by the Nginx welcome page.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在集群的任何节点上创建一个映射，将发布端口`30000`与`nginx`容器（端口80）关联起来。如果您连接到端口`30000`的任何节点，您将看到Nginx的欢迎页面。
- en: '![Load balancing and DNS](images/image_03_016.jpg)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![负载均衡和DNS](images/image_03_016.jpg)'
- en: 'But how does this work? As you see in the preceding screenshot, there is an
    associated VirtualIP (`10.255.0.7/16`), or VIP, and it is collocated on the overlay
    network **2xbr2upsr3yl**, created by Swarm for ingress to the load balancer:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这是如何工作的呢？正如您在上面的屏幕截图中看到的，有一个关联的虚拟IP（`10.255.0.7/16`），或者VIP，它位于由Swarm创建的覆盖网络**2xbr2upsr3yl**上，用于负载均衡器的入口：
- en: '![Load balancing and DNS](images/image_03_017.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![负载均衡和DNS](images/image_03_017.jpg)'
- en: 'From any host, you are able to reach `nginx-service`, because the DNS name
    resolves to the VIP, here 10.255.0.7, acting as a frontend to the load balancer:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 从任何主机，您都可以访问`nginx-service`，因为DNS名称解析为VIP，这里是10.255.0.7，充当负载均衡器的前端：
- en: 'On each node of the swarm, Swarm implements load balancing in kernel, specifically
    inside the namespaces, by adding a MARK rule in the OUTPUT chain inside the network
    namespace dedicated to the network, as shown in the following screenshot:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm的每个节点上，Swarm在内核中实现负载均衡，具体来说是在命名空间内部，通过在专用于网络的网络命名空间中的OUTPUT链中添加一个MARK规则，如下屏幕截图所示：
- en: '![Load balancing and DNS](images/image_03_018.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![负载均衡和DNS](images/image_03_018.jpg)'
- en: We'll cover networking concepts in greater detail later, in [Chapter 5](ch05.html
    "Chapter 5. Administer a Swarm Cluster"), *Administer a Swarm Cluster* and [Chapter
    8](ch08.html "Chapter 8. Exploring Additional Features of Swarm"), *Exploring
    Additional features of Swarm*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后的[第5章](ch05.html "第5章。管理Swarm集群") *管理Swarm集群*和[第8章](ch08.html "第8章。探索Swarm的其他功能")
    *探索Swarm的其他功能*中更详细地介绍网络概念。
- en: Promotion and demotion
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升和降级
- en: With the `docker node` command, the cluster operator can promote nodes from
    workers to managers and, vice versa, demote them from managers to workers.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`docker node`命令，集群操作员可以将节点从工作节点提升为管理节点，反之亦然，将它们从管理节点降级为工作节点。
- en: Demoting a node from manager to worker is the only way to remove a manager (now
    worker) from the cluster.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将节点从管理节点降级为工作节点是从集群中删除管理节点（现在是工作节点）的唯一方法。
- en: We'll cover promotion and demotion operations in detail in [Chapter 5](ch05.html
    "Chapter 5. Administer a Swarm Cluster"), *Administer a Swarm Cluster*.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第5章](ch05.html "第5章。管理Swarm集群")中详细介绍晋升和降级操作，*管理Swarm集群*。
- en: Replicas and scale
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 副本和规模
- en: Deploying an app on a Swarm cluster means to define and configure services,
    start them and wait for Docker engines scattered across the cluster to launch
    containers. We'll deploy complete apps on Swarm in [Chapter 6](ch06.html "Chapter 6. Deploy
    Real Applications on Swarm"), *Deploy Real Applications on Swarm*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在Swarm集群上部署应用意味着定义和配置服务，启动它们，并等待分布在集群中的Docker引擎启动容器。我们将在[第6章](ch06.html "第6章。在Swarm上部署真实应用")中在Swarm上部署完整的应用程序，*在Swarm上部署真实应用程序*。
- en: Services and tasks
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务和任务
- en: The core of the Swarm workload is divided into services. A service is just an
    abstraction to group an arbitrary number of tasks (this number is called the *replica
    factor*, or just *replicas*). Tasks are running containers.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm工作负载的核心被划分为服务。服务只是一个将任意数量的任务（这个数量被称为*副本因子*或者*副本*）分组的抽象。任务是运行的容器。
- en: docker service scale
  id: totrans-182
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: docker service scale
- en: 'With the `docker service scale` command, you order Swarm to ensure that a certain
    number of replicas are running at the same time on the cluster. For example, you
    can start with 10 containers running some *task* distributed over the cluster,
    and then when you need to scale their size to 30 you just execute:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`docker service scale`命令，您可以命令Swarm确保集群中同时运行一定数量的副本。例如，您可以从运行在集群上的10个容器开始执行一些*任务*，然后当您需要将它们的大小扩展到30时，只需执行：
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Swarm is ordered to schedule 20 new containers, so it takes the appropriate
    decisions for load balancing, DNS, and networking coherence. If a container for
    *task* goes down, making the replica factor equal to 29, Swarm will reschedule
    another one on another cluster node (that will have a new ID) to maintain the
    factor equal to 30.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm被命令安排调度20个新容器，因此它会做出适当的决策来实现负载平衡、DNS和网络的一致性。如果一个*任务*的容器关闭，使副本因子等于29，Swarm将在另一个集群节点上重新安排另一个容器（它将具有新的ID）以保持因子等于30。
- en: A note on replicas and new nodes addition. People frequently ask about Swarm
    automatic capabilities. If you have five workers running 30 tasks, and add five
    new nodes, you should not expect Swarm to balance the 30 tasks across the new
    nodes automatically, moving them from the original to the new nodes. The behavior
    of the Swarm scheduler is conservative, until some event (for example, an operator
    intervention) triggers a new `scale` command. Only in that case, the scheduler
    will take into account the five new nodes and possibly start new replica tasks
    on the 5 new workers.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 关于副本和新节点添加的说明。人们经常询问Swarm的自动能力。如果您有五个运行30个任务的工作节点，并添加了五个新节点，您不应该期望Swarm自动地在新节点之间平衡30个任务，将它们从原始节点移动到新节点。Swarm调度程序的行为是保守的，直到某个事件（例如，操作员干预）触发了一个新的`scale`命令。只有在这种情况下，调度程序才会考虑这五个新节点，并可能在5个新工作节点上启动新的副本任务。
- en: We'll see how `scale` command works in practice in [Chapter 7](ch07.html "Chapter 7. Scaling
    Up Your Platform"), *Scaling Up Your Platform*.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[第7章](ch07.html "第7章。扩展您的平台")中详细介绍`scale`命令的实际工作，*扩展您的平台*。
- en: Summary
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we met the new actors in the Docker ecosystem: SwarmKit and
    Swarm Mode. We proceeded through a simple implementation of a SwarmKit cluster
    with Ansible on Amazon AWS. Then, we covered the essential concepts of Swarm Mode,
    introducing its interface and its internals, including DNS, load balancing, services,
    replicas, and the promotion/demotion mechanism. Now, it''s time to dive into a
    true Swarm Mode deployment, as we''ll see in [Chapter 4](ch04.html "Chapter 4. Creating
    a Production-Grade Swarm"), *Creating a Production-Grade Swarm*.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们遇到了Docker生态系统中的新角色：SwarmKit和Swarm Mode。我们通过在Amazon AWS上使用Ansible对SwarmKit集群进行了简单的实现。然后，我们介绍了Swarm
    Mode的基本概念，包括其界面和内部机制，包括DNS、负载平衡、服务、副本以及晋升/降级机制。现在，是时候深入了解真正的Swarm Mode部署了，就像我们将在[第4章](ch04.html
    "第4章。创建一个生产级别的Swarm") *创建一个生产级别的Swarm*中看到的那样。
