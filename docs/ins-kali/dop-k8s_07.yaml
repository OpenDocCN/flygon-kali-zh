- en: Continuous Delivery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付
- en: 'Topics we''ve discussed so far enable us to run our services in Kubernetes.
    With the monitoring system, we''ve gained more confidence in our service. The
    next thing we''d like to achieve to set our service on course is how to deliver
    our latest features as well as ameliorations to our service continuously in Kubernetes,
    and we''ll learn it with the following topics in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论的主题使我们能够在Kubernetes中运行我们的服务。通过监控系统，我们对我们的服务更有信心。我们接下来想要实现的下一件事是如何在Kubernetes中持续交付我们的最新功能和改进我们的服务，并且我们将在本章的以下主题中学习它：
- en: Updating Kubernetes resources
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新Kubernetes资源
- en: Setting up a delivery pipeline
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立交付流水线
- en: Techniques to improve the deployment process
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 改进部署过程的技术
- en: Updating resources
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新资源
- en: The property of Continuous Delivery is as what we described in [Chapter 1](part0022.html#KVCC0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Introduction to DevOps*, a set of operations including the **Continuous Integration**
    (**CI**) and ensuing deployment tasks. The CI flow comprises elements like version
    control systems, buildings, and different levels of automated tests. Tools to
    implement CI functions are usually at the application layer which can be independent
    to underlying infrastructure, but when it comes to achieving deployment, understanding
    and dealing with infrastructure is inevitable since the deployment tasks are tightly
    bound to the platform that our application is running on. In the environment that
    software runs on physical or virtual machines, we'd utilize configuration management
    tools, orchestrators, and scripts to deploy our software. However, if we're running
    our service on an application platform like Heroku, or even in the Serverless
    pattern, designing the deployment pipeline would be a totally different story.
    All in all, the goal of deployment tasks is about making sure our software works
    properly in the right places. In Kubernetes, it's about how to rightly update
    resources, in particular, pods.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 持续交付的属性就像我们在[第1章](part0022.html#KVCC0-6c8359cae3d4492eb9973d94ec3e4f1e)中描述的那样，是一组操作，包括**持续集成**（**CI**）和随后的部署任务。CI流程包括版本控制系统、构建和不同级别的自动化测试等元素。实现CI功能的工具通常位于应用程序层，可以独立于基础架构，但是在实现部署时，由于部署任务与我们的应用程序运行的平台紧密相关，理解和处理基础架构是不可避免的。在软件运行在物理或虚拟机上的环境中，我们会利用配置管理工具、编排器和脚本来部署我们的软件。然而，如果我们在像Heroku这样的应用平台上运行我们的服务，甚至是在无服务器模式下，设计部署流水线将是完全不同的故事。总之，部署任务的目标是确保我们的软件在正确的位置正常工作。在Kubernetes中，这涉及如何正确更新资源，特别是Pod。
- en: Triggering updates
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 触发更新
- en: 'In [Chapter 3](part0070.html#22O7C0-6c8359cae3d4492eb9973d94ec3e4f1e), *Getting
    Started with Kubernetes*, we''ve discussed the rolling update mechanism of pods
    of a Deployment. Let''s recap what''d happen after the update process is triggered:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](part0070.html#22O7C0-6c8359cae3d4492eb9973d94ec3e4f1e)中，*开始使用Kubernetes*，我们已经讨论了部署中Pod的滚动更新机制。让我们回顾一下在更新过程触发后会发生什么：
- en: The Deployment creates a new `ReplicaSet` with `0` pod according to the updated
    manifest.
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署根据更新后的清单创建一个新的`ReplicaSet`，其中包含`0`个Pod。
- en: The new `ReplicaSet` is scaled up gradually while the previous `ReplicaSet`
    keeps shrinking.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新的`ReplicaSet`逐渐扩展，同时先前的`ReplicaSet`不断缩小。
- en: The process ends after all the old pods are replaced.
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所有旧的Pod被替换后，该过程结束。
- en: 'Such a mechanism is done automatically by Kubernetes, and it exempts us from
    supervising the updating process. To trigger it, all we need to do is inform Kubernetes
    that the pod specification of a Deployment is updated, that is to say, modifying
    the manifest of one resource in Kubernetes. Suppose we have a Deployment `my-app`
    (see `ex-deployment.yml` under the example directory for this section), we can
    modify the manifest with the sub commands of `kubectl` as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes会自动完成这样的机制，使我们免于监督更新过程。要触发它，我们只需要通知Kubernetes更新Deployment的pod规范，也就是修改Kubernetes中一个资源的清单。假设我们有一个Deployment
    `my-app`（请参阅本节示例目录下的`ex-deployment.yml`），我们可以使用`kubectl`的子命令修改清单如下：
- en: '`kubectl patch`: Patches a manifest of an object partially according to the
    input JSON parameter. If we''d like to update the image of `my-app` from `alpine:3.5`
    to `alpine:3.6`, it''d be:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl patch`：根据输入的JSON参数部分地修补对象的清单。如果我们想将`my-app`的镜像从`alpine:3.5`更新到`alpine:3.6`，可以这样做：'
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`kubectl set`: Makes changes to certain properties of an object. This is a
    shortcut to change some properties directly, image of a Deployment is one of the
    properties it supports:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl set`：更改对象的某些属性。这是直接更改某些属性的快捷方式，其中支持的属性之一是Deployment的镜像：'
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`kubectl edit`: Opens an editor and dumps the current manifest so that we can
    edit it interactively. The modified one would take effect immediately after being
    saved.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl edit`：打开编辑器并转储当前的清单，以便我们可以进行交互式编辑。修改后的清单在保存后立即生效。'
- en: '`kubectl replace`: Replaces one manifest with another submitted template file.
    If a resource is not created yet or contains properties that can''t be changed,
    it yields errors. For instance, there are two resources in our example template
    `ex-deployment.yml`, namely the Deployment `my-app` and its Service `my-app-svc`.
    Let''s replace them with a new specification file:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl replace`：用另一个提交的模板文件替换一个清单。如果资源尚未创建或包含无法更改的属性，则会产生错误。例如，在我们的示例模板`ex-deployment.yml`中有两个资源，即Deployment
    `my-app`及其Service `my-app-svc`。让我们用一个新的规范文件替换它们：'
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After they are replaced, we'd see the error code would be `1` even though the
    result is expected, that is, updating the Deployment rather than the Service.
    Such behavior should be noticed especially when composing automation scripts for
    the CI/CD flow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 替换后，即使结果符合预期，我们会看到错误代码为`1`，也就是说，更新的是Deployment而不是Service。特别是在为CI/CD流程编写自动化脚本时，应该注意这种行为。
- en: '`kubectl apply`: Applies the manifest file anyway. In other words, if a resource
    exists in Kubernetes, then it''d be updated, otherwise it''d be created. When
    `kubectl apply` is used to create resources, it''s roughly equal to `kubectl create
    --save-config` in functionality. The applied specification file would be saved
    to the annotation field `kubectl.kubernetes.io/last-applied- configuration` accordingly,
    and we can manipulate it with sub commands `edit-last-applied`, `set-last-applied`,
    and `view-last-applied`. For example, we can view the template we''ve submitted
    previously, no matter what the actual content of `ex-deployment.yml` become with:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl apply`：无论如何都应用清单文件。换句话说，如果资源存在于Kubernetes中，则会被更新，否则会被创建。当使用`kubectl
    apply`创建资源时，其功能大致相当于`kubectl create --save-config`。应用的规范文件将相应地保存到注释字段`kubectl.kubernetes.io/last-applied-configuration`中，我们可以使用子命令`edit-last-applied`、`set-last-applied`和`view-last-applied`来操作它。例如，我们可以查看之前提交的模板，无论`ex-deployment.yml`的实际内容如何。'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The saved manifest information would exactly be the same as what we've sent,
    unlike the one we retrieve via `kubectl get -o yaml/json` which contains an object's
    live status, in addition to specifications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 保存的清单信息将与我们发送的完全相同，不同于通过`kubectl get -o yaml/json`检索的清单，后者包含对象的实时状态，以及规范。
- en: Although in this section we only focus on manipulating a Deployment, but the
    commands here also work for updating all other Kubernetes resources like Service,
    Role, and so on.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在本节中我们只关注操作部署，但这里的命令也适用于更新所有其他 Kubernetes 资源，如 Service、Role 等。
- en: Changes to `ConfigMap` and secret usually take seconds to propagate to pods.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `ConfigMap` 和 secret 的更改通常需要几秒钟才能传播到 pods。
- en: 'The recommended way to interact with an Kubernetes'' API server is by `kubectl`.
    If you''re under a confined environment, there are also REST APIs for manipulating
    resources of Kubernetes. For example, the `kubectl patch` command we used before
    would become as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Kubernetes 的 API 服务器进行交互的推荐方式是使用 `kubectl`。如果您处于受限制的环境中，还可以使用 REST API 来操作
    Kubernetes 的资源。例如，我们之前使用的 `kubectl patch` 命令将变为如下所示：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here the variable `$KUBEAPI` is the endpoint of the API server. See API references
    for more information: [https://kubernetes.io/docs/api-reference/v1.7/](https://kubernetes.io/docs/api-reference/v1.7/).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的变量 `$KUBEAPI` 是 API 服务器的端点。有关更多信息，请参阅 API 参考：[https://kubernetes.io/docs/api-reference/v1.7/](https://kubernetes.io/docs/api-reference/v1.7/)。
- en: Managing rollouts
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理部署
- en: 'Once the rollout process is triggered, Kubernetes would silently complete all
    tasks behind the backdrop. Let''s try some hands-on experiments. Again, the rolling
    update process won''t be triggered even if we''ve modified something with the
    commands mentioned earlier, unless the associated pod''s specification is changed.
    The example we prepared is a simple script that would respond to any request with
    its hostname and the Alpine version it runs on. We first create the Deployment,
    and check its response in another Terminal constantly:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦触发了滚动更新过程，Kubernetes 将在幕后默默完成所有任务。让我们进行一些实际的实验。同样，即使我们使用了之前提到的命令修改了一些内容，滚动更新过程也不会被触发，除非相关的
    pod 规范发生了变化。我们准备的示例是一个简单的脚本，它会响应任何请求并显示其主机名和其运行的 Alpine 版本。我们首先创建 Deployment，并在另一个终端中不断检查其响应：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now we change its image to another version and see what the responses are:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将其图像更改为另一个版本，看看响应是什么：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Messages from version 3.5 and 3.6 are interleaved until the updating process
    ends. To immediately determine the status of updating processes from Kubernetes
    rather than polling the service endpoint, there''s `kubectl rollout` for managing
    the rolling update process, including inspecting the progress of ongoing updates.
    Let''s see the acting rollout with sub command `status`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 来自版本 3.5 和 3.6 的消息在更新过程结束之前交错显示。为了立即确定来自 Kubernetes 的更新进程状态，而不是轮询服务端点，有 `kubectl
    rollout` 用于管理滚动更新过程，包括检查正在进行的更新的进度。让我们看看使用子命令 `status` 进行的滚动更新的操作：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'At this moment, the output at Terminal #2 should be all from version 3.6\.
    The sub command `history` allows us to review previous changes of the `deployment`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '此时，终端 #2 的输出应该全部来自版本 3.6。子命令 `history` 允许我们审查 `deployment` 的先前更改：'
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: However, the `CHANGE-CAUSE` field doesn't show any useful information that helps
    us to know the detail of the revision. To leverage it, add a flag `--record` after
    every command that leads to a change, such as what we've introduced earlier. Certainly,
    `kubectl create` also support the record flag.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`CHANGE-CAUSE` 字段没有显示任何有用的信息，帮助我们了解修订的详细信息。为了利用它，在导致更改的每个命令之后添加一个标志 `--record`，就像我们之前介绍的那样。当然，`kubectl
    create` 也支持记录标志。
- en: 'Let''s make some change to the Deployment, say, modifying the environment variable
    `DEMO` of pods of `my-app`. As it causes a change in the pod''s specification,
    a rollout would start right away. This sort of behavior allows us to trigger an
    update without building a new image. For simplicity''s sake, we use `patch` to
    modify the variable:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对部署进行一些更改，比如修改`my-app`的pod的环境变量`DEMO`。由于这会导致pod规范的更改，部署将立即开始。这种行为允许我们触发更新而无需构建新的镜像。为了简单起见，我们使用`patch`来修改变量：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `CHANGE-CAUSE` of `REVISION 3` notes the committed command clearly. Nonetheless,
    only the command would be recorded, which means any modification by `edit`/`apply`/`replace`
    wouldn't be marked down explicitly. If we'd like to get the manifest of former
    versions, we could retrieve the saved configuration as long as our changes are
    made with `apply`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`REVISION 3`的`CHANGE-CAUSE`清楚地记录了提交的命令。尽管如此，只有命令会被记录下来，这意味着任何通过`edit`/`apply`/`replace`进行的修改都不会被明确标记。如果我们想获取以前版本的清单，只要我们的更改是通过`apply`进行的，我们就可以检索保存的配置。'
- en: 'For all kinds of reasons, sometimes we want to roll back our application even
    if the rollout is successful to a certain extent. It can be achieved by the sub
    command `undo`:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 出于各种原因，有时我们希望回滚我们的应用，即使部署在一定程度上是成功的。可以通过子命令`undo`来实现：
- en: '[PRE10]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The whole process is basically identical to updating, that is, applying the
    previous manifest, and performing a rolling update. Also, we can utilize the flag
    `--to-revision=<REVISION#>` to rollback to a specific version, but only retained
    revisions are able to be rolled back. Kubernetes determines how many revisions
    it would keep according to the `revisionHistoryLimit` parameter in Deployment
    objects.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程基本上与更新是相同的，即应用先前的清单，然后执行滚动更新。此外，我们可以利用标志`--to-revision=<REVISION#>`回滚到特定版本，但只有保留的修订版本才能回滚。Kubernetes根据部署对象中的`revisionHistoryLimit`参数确定要保留多少修订版本。
- en: The progress of an update is controlled by `kubectl rollout pause` and `kubectl
    rollout resume`. As their names indicate, they should be used in pairs. The pause
    of a Deployment implicates not only stopping of an ongoing rollout, but also freezing
    any rolling updates even if the specification is modified unless it's resumed.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的进度由`kubectl rollout pause`和`kubectl rollout resume`控制。正如它们的名称所示，它们应该成对使用。部署的暂停不仅意味着停止正在进行的部署，还意味着冻结任何滚动更新，即使规范被修改，除非它被恢复。
- en: Updating DaemonSet and StatefulSet
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新DaemonSet和StatefulSet
- en: Kubernetes supports various ways to orchestrate pods for different kinds of
    workloads. In addition to Deployments, there are `DaemonSet` and `StatefulSet`
    for long-running, non-batch workloads. As pods they spawned have more constraint
    than Deployments, we should know caveats on handling their updates
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes支持各种方式来编排不同类型的工作负载的pod。除了部署外，还有`DaemonSet`和`StatefulSet`用于长时间运行的非批处理工作负载。由于它们生成的pod比部署有更多的约束，我们应该了解处理它们的更新时的注意事项
- en: DaemonSet
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DaemonSet
- en: '`DaemonSet` is a controller designed for system daemons as its name suggests.
    Consequently, a `DaemonSet` launches and maintains exactly one pod per node, this
    is to say, the total number of pods by a `DaemonSet` is adhered to a number of
    nodes in a cluster. Due to such limitations, updating a `DaemonSet` is not as
    straightforward as updating a Deployment. For instance, Deployment has a `maxSurge`
    parameter (`.spec.strategy.rollingUpdate.maxSurge`) that controls how many redundant
    pods over desired numbers can be created during updates. But we can''t employ
    the same strategy for the pod as a `DaemonSet` usually occupies host''s resources
    like ports. It could result in errors if we have two or more system pods simultaneously
    on a node. As such, the update is in the form that a new pod is created after
    the old pod is terminated on a host.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`DaemonSet`是一个专为系统守护程序设计的控制器，正如其名称所示。因此，`DaemonSet`在每个节点上启动和维护一个Pod，也就是说，`DaemonSet`的总Pod数量符合集群中节点的数量。由于这种限制，更新`DaemonSet`不像更新Deployment那样直接。例如，Deployment有一个`maxSurge`参数（`.spec.strategy.rollingUpdate.maxSurge`），用于控制更新期间可以创建多少超出所需数量的冗余Pod。但是我们不能对`DaemonSet`的Pod采用相同的策略，因为`DaemonSet`通常占用主机的资源，如端口。如果在一个节点上同时有两个或更多的系统Pod，可能会导致错误。因此，更新的形式是在主机上终止旧的Pod后创建一个新的Pod。'
- en: 'Kubernetes implements two update strategies for `DaemonSet`, namely `OnDelete`
    and `rollingUpdate`. An example demonstrates how to write a template of `DaemonSet`
    is at `7-1_updates/ex-daemonset.yml`. The update strategy is set at path `.spec.``updateStrategy``.type`,
    and its default is `OnDelete` in Kubernetes 1.7, and it becomes `rollingUpdate`
    since Kubernetes 1.8:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为`DaemonSet`实现了两种更新策略，即`OnDelete`和`rollingUpdate`。一个示例演示了如何编写`DaemonSet`的模板，位于`7-1_updates/ex-daemonset.yml`。更新策略设置在路径`.spec.updateStrategy.type`处，默认情况下在Kubernetes
    1.7中为`OnDelete`，在Kubernetes 1.8中变为`rollingUpdate`：
- en: '`OnDelete`: Pods are only updated after they are deleted manually.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：只有在手动删除Pod后才会更新。'
- en: '`rollingUpdate`: It actually works like `OnDelete` but the deletion of pods
    is performed by Kubernetes automatically. There is one optional parameter `.spec.updateStrategy.rollingUpdate.maxUnavailable`,
    which is akin to the one in Deployment. Its default value is `1`, which means
    Kubernetes replaces one pod at a time node by node.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rollingUpdate`：它实际上的工作方式类似于`OnDelete`，但是Kubernetes会自动执行Pod的删除。有一个可选参数`.spec.updateStrategy.rollingUpdate.maxUnavailable`，类似于Deployment中的参数。其默认值为`1`，这意味着Kubernetes会逐个节点替换一个Pod。'
- en: The trigger of the rolling update process is identical to a Deployment's. Moreover,
    we can also utilize `kubectl rollout` to manage rollouts of our `DaemonSet`. But
    `pause` and `resume` are not supported.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动更新过程的触发与Deployment的相同。此外，我们还可以利用`kubectl rollout`来管理`DaemonSet`的滚动更新。但是不支持`pause`和`resume`。
- en: Rolling updates for `DaemonSet` are only available at Kubernetes 1.6 and onward.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '`DaemonSet`的滚动更新仅适用于Kubernetes 1.6及以上版本。'
- en: StatefulSet
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StatefulSet
- en: 'The updating of `StatefulSet` and `DaemonSet` are pretty much the same -- they
    don''t create redundant pods during an update, and their update strategies also
    behave in a similar way. There is also a template file at `7-1_updates/ex-statefulset.yml`
    for practice. The option of update strategy is set at path `.spec.``updateStrategy``.type`:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatefulSet`和`DaemonSet`的更新方式基本相同——它们在更新期间不会创建冗余的Pod，它们的更新策略也表现出类似的行为。在`7-1_updates/ex-statefulset.yml`中还有一个模板文件供练习。更新策略的选项设置在路径`.spec.updateStrategy.type`处：'
- en: '`OnDelete`: Pods are only updated after they are manually deleted.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：只有在手动删除Pod后才会更新。'
- en: '`rollingUpdate`: Like every rolling update, Kubernetes deletes and creates
    pods in a controlled fashion. But Kubernetes knows the order matters in `StatefulSet`,
    so it would replace pods in reverse ordinal. Say we have three pods in a `StatefulSet`,
    and they are `my-ss-0`, `my-ss-1`, `my-ss-2` respectively. The update order is
    then starting from `my-ss-2` to `my-ss-0`. The deletion process does not respect
    the pod management policy, that is to say, even if we set the pod management policies
    to `Parallel`, the updating would still be performed one by one.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rollingUpdate`：像每次滚动更新一样，Kubernetes以受控的方式删除和创建Pod。但是Kubernetes知道在`StatefulSet`中顺序很重要，所以它会按照相反的顺序替换Pod。假设我们在`StatefulSet`中有三个Pod，它们分别是`my-ss-0`、`my-ss-1`、`my-ss-2`。然后更新顺序从`my-ss-2`开始到`my-ss-0`。删除过程不遵守Pod管理策略，也就是说，即使我们将Pod管理策略设置为`Parallel`，更新仍然会逐个执行。'
- en: The only parameter for type `rollingUpdate` is partition (`.spec.updateStrategy.rollingUpdate.partition`).
    If it's specified, any pod with its ordinal less than the partition number would
    keep its current version and wouldn't be updated. For instance, if we set it to
    1 in a `StatefulSet` with 3 pods, only pod-1 and pod-2 would be updated after
    a rollout. This parameter allows us to control the progress at certain degrees
    and it's particularly handy for scenarios such as waiting for data synchronization,
    testing the release with a canary, or maybe we just want to stage an update.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 类型`rollingUpdate`的唯一参数是分区（`.spec.updateStrategy.rollingUpdate.partition`）。如果指定了分区，任何序数小于分区号的Pod将保持其当前版本，不会被更新。例如，在具有3个Pod的`StatefulSet`中将其设置为1，只有pod-1和pod-2会在发布后进行更新。该参数允许我们在一定程度上控制进度，特别适用于等待数据同步、使用金丝雀进行测试发布，或者我们只是想分阶段进行更新。
- en: Pod management policies and rolling updates are two features implemented in
    Kubernetes 1.7 and later.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Pod管理策略和滚动更新是Kubernetes 1.7及更高版本中实现的两个功能。
- en: Building a delivery pipeline
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建交付流水线
- en: 'Implementing a continuous delivery pipeline for containerized applications
    is quite simple. Let''s remember what we have learnt about Docker and Kubernetes
    so far and organize them into the CD pipeline. Suppose we''ve done our code, Dockerfile,
    and corresponding Kubernetes templates. To deploy them to our cluster, we''d go
    through the following steps:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为容器化应用程序实施持续交付流水线非常简单。让我们回顾一下到目前为止我们对Docker和Kubernetes的学习，并将它们组织成CD流水线。假设我们已经完成了我们的代码、Dockerfile和相应的Kubernetes模板。要将它们部署到我们的集群，我们需要经历以下步骤：
- en: '`docker build`: Produces an executable immutable artifact.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker build`：生成一个可执行的不可变构件。'
- en: '`docker run`: Verifies if the build works with some simple test.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker run`：验证构建是否通过了一些简单的测试。'
- en: '`docker tag`: Tags the build with meaningful versions if it''s good.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker tag`：如果构建成功，为其打上有意义的版本标签。'
- en: '`docker push`: Moves the build to the artifacts repository for distribution.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker push`：将构建移动到构件存储库以进行分发。'
- en: '`kubectl apply`: Deploys the build to a desired environment.'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl apply`：将构建部署到所需的环境中。'
- en: '`kubectl rollout status`: tracks the progress of deployment tasks.'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl rollout status`：跟踪部署任务的进展。'
- en: That's all for a simple but viable delivery pipeline.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是一个简单但可行的交付流水线。
- en: Choosing tools
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择工具
- en: 'To make the pipeline ship builds continuously, we need at least three kinds
    of tools, namely version control systems, build servers, and a repository for
    storing container artifacts. In this section, we will set a reference CD pipeline
    based on the SaaS tools we''ve introduced in previous chapters. They are *GitHub*
    ([https://github.com](https://github.com)), *Travis CI* ([https://travis- ci.org](https://travis-ci.org)),
    and *Docker Hub* ([https://hub.docker.com](https://hub.docker.com)), all of them
    are free to open source projects. There are numerous alternatives for each tool
    we used here, like GitLab for VCS, or hosting a Jenkins for CI. The following
    diagram is our CD flow based on the three services earlier:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使流水线持续交付构建，我们至少需要三种工具，即版本控制系统、构建服务器和用于存储容器构件的存储库。在本节中，我们将基于前几章介绍的SaaS工具设置一个参考CD流水线。它们是*GitHub*
    ([https://github.com](https://github.com))、*Travis CI* ([https://travis-ci.org](https://travis-ci.org))和*Docker
    Hub* ([https://hub.docker.com](https://hub.docker.com))，它们都对开源项目免费。我们在这里使用的每个工具都有许多替代方案，比如GitLab用于VCS，或者托管Jenkins用于CI。以下图表是基于前面三个服务的CD流程：
- en: '>![](../images/00107.jpeg)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '>![](../images/00107.jpeg)'
- en: The workflow begins from committing codes into a repository on GitHub, and the
    commit would invoke a build job on Travis CI. Our Docker image is built at this
    stage. Meanwhile, we often run different levels of tests on the CI server to ensure
    that the quality of build is solid. Further, as running an application stack by
    Docker Compose or Kubernetes is easier than ever, we are capable of running tests
    involving many components in a build job. Afterwards, the verified image is tagged
    with identifiers and pushed to the public Docker Registry service, Docker Hub.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程始于将代码提交到GitHub上的存储库，提交将调用Travis CI上的构建作业。我们的Docker镜像是在这个阶段构建的。同时，我们经常在CI服务器上运行不同级别的测试，以确保构建的质量稳固。此外，由于使用Docker
    Compose或Kubernetes运行应用程序堆栈比以往任何时候都更容易，我们能够在构建作业中运行涉及许多组件的测试。随后，经过验证的镜像被打上标识并推送到公共Docker
    Registry服务Docker Hub。
- en: No blocks in our pipeline are dedicated to deployment tasks. Instead, we rely
    on Travis CI to deploy our builds. As a matter of fact, the deployment task is
    merely applying Kubernetes templates on certain builds after the image is pushed.
    Finally, the delivery is finished after the rolling update process by Kubernetes
    ends.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的流水线中没有专门用于部署任务的块。相反，我们依赖Travis CI来部署我们的构建。事实上，部署任务仅仅是在镜像推送后，在某些构建上应用Kubernetes模板。最后，在Kubernetes的滚动更新过程结束后，交付就完成了。
- en: Steps explained
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释的步骤
- en: 'Our example, `my-app` is a web service that echoes `OK` constantly, and the
    code as well as the files for deployment are committed in our repository over
    in GitHub here: ([https://github.com/DevOps-with-Kubernetes/my-app](https://github.com/DevOps-with-Kubernetes/my-app)).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例`my-app`是一个不断回显`OK`的Web服务，代码以及部署文件都提交在我们在GitHub上的存储库中：([https://github.com/DevOps-with-Kubernetes/my-app](https://github.com/DevOps-with-Kubernetes/my-app))。
- en: Before configuring our builds on Travis CI, let's create an image repository
    at Docker Hub first for later use. After signing in to Docker Hub, press the huge
    Create Repository at top-right, and then follow the steps on screen to create
    one. Image registry of `my-app` for pushing and pulling is at `devopswithkubernetes/my-app`
    ([https://hub.docker.com/r/devopswithkubernetes/my-app/](https://hub.docker.com/r/devopswithkubernetes/my-app/)).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置Travis CI上的构建之前，让我们首先在Docker Hub上创建一个镜像存储库以备后用。登录Docker Hub后，点击右上角的Create
    Repository，然后按照屏幕上的步骤创建一个。用于推送和拉取的`my-app`镜像注册表位于`devopswithkubernetes/my-app`
    ([https://hub.docker.com/r/devopswithkubernetes/my-app/](https://hub.docker.com/r/devopswithkubernetes/my-app/))。
- en: Connecting Travis CI with a GitHub repository is quite simple, all we need to
    do is authorize Travis CI to access our GitHub repositories, and enable Travis
    CI to build the repository at the profile page ([https://travis-ci.org/profile](https://travis-ci.org/profile)).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 将Travis CI与GitHub存储库连接起来非常简单，我们只需要授权Travis CI访问我们的GitHub存储库，并在个人资料页面启用Travis
    CI构建存储库即可([https://travis-ci.org/profile](https://travis-ci.org/profile))。
- en: 'The definition of a job in Travis CI is configured in a file `.travis.yml`
    placed under the same repository. It''s a YAML format template consisting of blocks
    of shell scripts that tell what Travis CI should do during a build. Explanations
    on blocks of our `.travis.yml` ([https://github.com/DevOps-with-Kubernetes/my-app/blob/master/.travis.yml](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/.travis.yml))
    are the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Travis CI中作业的定义是在同一存储库下放置的`.travis.yml`文件中配置的。它是一个YAML格式的模板，由一系列告诉Travis CI在构建期间应该做什么的shell脚本块组成。我们的`.travis.yml`文件块的解释如下：([https://github.com/DevOps-with-Kubernetes/my-app/blob/master/.travis.yml](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/.travis.yml))
- en: env
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: env
- en: 'This section defines environment variables that are visible throughout a build:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分定义了在整个构建过程中可见的环境变量：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here we set some variables that might be changed like the namespace and the
    docker registry path to where the built image is going. Besides, there''re also
    metadata about a build passed from Travis CI in the form of environment variables,
    and they are documented here: [https://docs.travis-ci.com/user/environment-variables/#Default-Environment-
    Variables](https://docs.travis-ci.com/user/environment-variables/#Default-Environment-Variables).
    For example, `TRAVIS_BUILD_NUMBER` represents the number of the current build,
    and we use it as an identifier to distinguish our images across builds.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们设置了一些可能会更改的变量，比如命名空间和构建图像的Docker注册表路径。此外，还有关于构建的元数据从Travis CI以环境变量的形式传递，这些都在这里记录着：[https://docs.travis-ci.com/user/environment-variables/#Default-Environment-
    Variables](https://docs.travis-ci.com/user/environment-variables/#Default-Environment-Variables)。例如，`TRAVIS_BUILD_NUMBER`代表当前构建的编号，我们将其用作标识符来区分不同构建中的图像。
- en: 'The other one source of environment variables is configured manually on Travis
    CI. Because the variables configured there would be hidden publicly, we stored
    some sensitive data such as credentials to Docker Hub and Kubernetes there:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个环境变量的来源是在Travis CI上手动配置的。因为在那里配置的变量会被公开隐藏，所以我们在那里存储了一些敏感数据，比如Docker Hub和Kubernetes的凭据：
- en: '![](../images/00108.jpeg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00108.jpeg)'
- en: Every CI tool has own best practices to deal with secrets. For instance, some
    CI tools also allow us to save variables in the CI server, but they would still
    be printed in the building logs, so we're unlikely to save secrets in the CI server
    in such cases.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 每个CI工具都有自己处理密钥的最佳实践。例如，一些CI工具也允许我们在CI服务器中保存变量，但它们仍然会在构建日志中打印出来，所以在这种情况下我们不太可能在CI服务器中保存密钥。
- en: script
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 脚本
- en: 'This section is where we run builds and tests:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个部分是我们运行构建和测试的地方：
- en: '[PRE12]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we're on Docker, the build is only one line of script. Our test is quite
    simple as well--launching a container with the built image and making some requests
    against it to determine its correctness and integrity. Definitely, we can do everything
    such as adding unit tests, doing the multi-stage build, or running an automated
    integration test to better the resultant artifacts in this stage.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们使用Docker，所以构建只需要一行脚本。我们的测试也很简单——使用构建的图像启动一个容器，并对其进行一些请求以确定其正确性和完整性。当然，在这个阶段我们可以做任何事情，比如添加单元测试、进行多阶段构建，或者运行自动化集成测试来改进最终的构件。
- en: after_success
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 成功后
- en: 'This block is executed only if the previous stage ends without any error. Once
    it comes here, we are good to publish our image:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 只有前一个阶段没有任何错误结束时，才会执行这个块。一旦到了这里，我们就可以发布我们的图像了：
- en: '[PRE13]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Our image tag trivially uses the build number on Travis CI, but using the hash
    of a commit, or version numbers to tag an image is common, too. However, using
    the default tag `latest` is strongly discouraged as it could result in version
    confusion such as running two different images but they have the same name. The
    last conditional block is publishing the image on certain branch tags, and it's
    not actually needed, for we just want to keep building and releasing on a separate
    track. Remember to authenticate to Docker Hub before pushing an image.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的镜像标签在Travis CI上简单地使用构建编号，但使用提交的哈希或版本号来标记镜像也很常见。然而，强烈不建议使用默认标签`latest`，因为这可能导致版本混淆，比如运行两个不同的镜像，但它们有相同的名称。最后的条件块是在特定分支标签上发布镜像，实际上并不需要，因为我们只是想保持在一个单独的轨道上构建和发布。在推送镜像之前，请记得对Docker
    Hub进行身份验证。
- en: 'Kubernetes decides whether the image should be pulled by the `imagePullPolicy`:
    [https://kubernetes.io/docs/concepts/containers/images/#updating-images](https://kubernetes.io/docs/concepts/containers/images/#updating-images).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes决定是否应该拉取镜像的`imagePullPolicy`：[https://kubernetes.io/docs/concepts/containers/images/#updating-images](https://kubernetes.io/docs/concepts/containers/images/#updating-images)。
- en: 'Because we set our project deploys to actual machines only on a release, a
    build may stop and be returned at that moment. Let''s see the log of this build:
    [https://travis- ci.org/DevOps-with-Kubernetes/my-app/builds/268053332](https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268053332).
    The log retains scripts that Travis CI executed and outputs from every line of
    the script:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将项目部署到实际机器上只在发布时，构建可能会在那一刻停止并返回。让我们看看这个构建的日志：[https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268053332](https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268053332)。日志保留了Travis
    CI执行的脚本和脚本每一行的输出：
- en: '![](../images/00109.jpeg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00109.jpeg)'
- en: 'As we can see, our build is successful, so the image is then published here:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的构建是成功的，所以镜像随后在这里发布：
- en: '[https://hub.docker.com/r/devopswithkubernetes/my-app/tags/](https://hub.docker.com/r/devopswithkubernetes/my-app/tags/).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://hub.docker.com/r/devopswithkubernetes/my-app/tags/](https://hub.docker.com/r/devopswithkubernetes/my-app/tags/)。'
- en: 'The build refers to tag `b1`, and we can run it outside the CI server now:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 构建引用标签`b1`，我们现在可以在CI服务器外运行它：
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: deploy
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Although we can achieve a fully automated pipeline from end to end, we'd often
    encounter situations to hold up deploying builds due to business reasons. As such,
    we tell Travis CI to run deployment scripts only when we release a new version.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以实现端到端的完全自动化流水线，但由于业务原因，我们经常会遇到需要暂停部署构建的情况。因此，我们告诉Travis CI只有在发布新版本时才运行部署脚本。
- en: 'To manipulate resources in our Kubernetes cluster from Travis CI, we''ll need
    to grant Travis CI sufficient permissions. Our example uses a service account
    `cd-agent` under RBAC mode to create and update our deployments on behalf of us.
    Later chapters will have more descriptions on RBAC. The templates for creating
    the account and permissions are at: [https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-
    2_service-account-for-ci-tool](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-2_service-account-for-ci-tool).
    The account is created under namespace `cd`, and it''s authorized to create and
    modify most kinds of resources across namespaces.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在Travis CI中从我们的Kubernetes集群中操作资源，我们需要授予Travis CI足够的权限。我们的示例使用了一个名为`cd-agent`的服务账户，在RBAC模式下代表我们创建和更新部署。后面的章节将对RBAC进行更多描述。创建账户和权限的模板在这里：[https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-2_service-account-for-ci-tool](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-2_service-account-for-ci-tool)。该账户是在`cd`命名空间下创建的，并被授权在各个命名空间中创建和修改大多数类型的资源。
- en: Here we use a service account that is able to read and modify most resources
    across namespaces, including secrets of the whole cluster. Due to security concerns,
    its always encouraged to restrict permissions of a service account to resources
    the account actually used, or it could be a potential vulnerability.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用一个能够读取和修改跨命名空间的大多数资源，包括整个集群的密钥的服务账户。由于安全问题，始终鼓励限制服务账户对实际使用的资源的权限，否则可能存在潜在的漏洞。
- en: 'Because Travis CI sits outside our cluster, we have to export credentials from
    Kubernetes so that we can configure our CI job to use them. Here we provide a
    simple script to help export those credentials. The script is at: [https://github.com/DevOps-with-
    Kubernetes/examples/blob/master/chapter7/get-sa-token.sh](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh).'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因为 Travis CI 位于我们的集群之外，我们必须从 Kubernetes 导出凭据，以便我们可以配置我们的 CI 任务来使用它们。在这里，我们提供了一个简单的脚本来帮助导出这些凭据。脚本位于：[https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh)。
- en: '[PRE15]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Corresponding variables of exported API endpoint, `ca.crt`, and `sa.token` are
    `CI_ENV_K8S_MASTER`, `CI_ENV_K8S_CA`, and `CI_ENV_K8S_SA_TOKEN` respectively.
    The client certificate (`ca.crt`) is encoded to base64 for portability, and it
    will be decoded at our deployment script.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 导出的 API 端点、`ca.crt` 和 `sa.token` 的对应变量分别是 `CI_ENV_K8S_MASTER`、`CI_ENV_K8S_CA`
    和 `CI_ENV_K8S_SA_TOKEN`。客户端证书（`ca.crt`）被编码为 base64 以实现可移植性，并且将在我们的部署脚本中解码。
- en: The deployment script ([https://github.com/DevOps-with-Kubernetes/my- app/blob/master/deployment/deploy.sh](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/deployment/deploy.sh))
    downloads `kubectl` first, and configures `kubectl` with environment variables
    accordingly. Afterwards, the image path of the current build is filled in the
    deployment template, and the templates are applied. Finally, after the rollout
    is finished, our deployment is done.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 部署脚本（[https://github.com/DevOps-with-Kubernetes/my-app/blob/master/deployment/deploy.sh](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/deployment/deploy.sh)）首先下载
    `kubectl`，并根据环境变量配置 `kubectl`。之后，当前构建的镜像路径被填入部署模板中，并且模板被应用。最后，在部署完成后，我们的部署就完成了。
- en: Let's see the entire flow in action.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看整个流程是如何运作的。
- en: 'As soon as we publish a release at GitHub:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们在 GitHub 上发布一个版本：
- en: '[https://github.com/DevOps-with-Kubernetes/my-app/releases/tag/rel.0.3](https://github.com/DevOps-with-Kubernetes/my-app/releases/tag/rel.0.3)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/DevOps-with-Kubernetes/my-app/releases/tag/rel.0.3](https://github.com/DevOps-with-Kubernetes/my-app/releases/tag/rel.0.3)'
- en: '![](../images/00110.jpeg)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00110.jpeg)'
- en: 'Travis CI starts to build our job right after that:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Travis CI 在那之后开始构建我们的任务：
- en: '![](../images/00111.jpeg)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00111.jpeg)'
- en: 'The built image is pushed onto Docker Hub after a while:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，构建的镜像被推送到 Docker Hub 上：
- en: '![](../images/00112.jpeg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00112.jpeg)'
- en: 'At this point, Travis CI should start to run deployment tasks, let''s see the
    building log to know the status of our deployment:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，Travis CI 应该开始运行部署任务，让我们查看构建日志以了解我们部署的状态：
- en: '[https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268107714](https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268107714)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268107714](https://travis-ci.org/DevOps-with-Kubernetes/my-app/builds/268107714)'
- en: '![](../images/00113.jpeg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00113.jpeg)'
- en: 'As we can see, our application has rolled out successfully, and it should start
    to welcome everyone with `OK`:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的应用已经成功部署，应该开始用 `OK` 欢迎每个人：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The pipeline we built and demonstrated in this section is a classical flow to
    deliver codes continuous in Kubernetes. Nonetheless, as the work style and cultures
    vary from team to team, designing a tailor-made continuously delivery pipeline
    for your team rewards efficiency boosts.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中构建和演示的流水线是在Kubernetes中持续交付代码的经典流程。然而，由于工作风格和文化因团队而异，为您的团队设计一个量身定制的持续交付流水线将带来效率提升的回报。
- en: Gaining deeper understanding of pods
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解pod
- en: Although the birth and the death are merely a wink during a pod's lifetime,
    they are the most fragile point of a service. Common situations in the real world
    such as routing requests to an unready box, or brutally cutting all in-flight
    connections to a terminating machine, are all what we want to avoid. As a result,
    even Kubernetes takes care of most things for us, and we should know how to configure
    it correctly to gain more confident in deploying.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在pod的生命周期中，出生和死亡仅仅是一瞬间，但它们是服务最脆弱的时刻。在现实世界中，常见的情况，如将请求路由到未准备就绪的盒子，或者残酷地切断所有正在进行的连接到终止的机器，都是我们要避免的。因此，即使Kubernetes为我们处理了大部分事情，我们也应该知道如何正确配置它，以便在部署时更加自信。
- en: Starting a pod
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动一个pod
- en: By default, Kubernetes transfers a pod's state to Running as soon as a pod launches.
    If the pod is behind a service, the endpoint controller registers an endpoint
    to Kubernetes immediately. Later on kube-proxy observes the change of endpoints
    and add rules to iptables accordingly. Requests from the outside world now go
    to pods. Kubernetes makes the pod registration lightning fast, so the changes
    are that the request goes to pods prior to an application's readiness, especially
    on bulky software. On the other hand, if a pod fails while running, we should
    have an automatic way to remove it instantly.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes在pod启动后立即将其状态转换为Running。如果pod在服务后面，端点控制器会立即向Kubernetes注册一个端点。稍后，kube-proxy观察端点的变化，并相应地向iptables添加规则。外部世界的请求现在会发送到pod。Kubernetes使得pod的注册速度非常快，因此有可能在应用程序准备就绪之前就已经发送请求到pod，尤其是在处理庞大软件时。另一方面，如果pod在运行时失败，我们应该有一种自动的方式立即将其移除。
- en: 'The `minReadySeconds` field of Deployment and other controllers doesn''t postpone
    a pod from becoming ready. Instead, it delays a pod from becoming available, which
    is meaningful during a rollout process: a rollout is successful only when all
    pods are available.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment和其他控制器的`minReadySeconds`字段不会推迟pod的就绪状态。相反，它会延迟pod的可用性，在部署过程中具有意义：只有当所有pod都可用时，部署才算成功。
- en: Liveness and readiness probes
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 活跃性和就绪性探针
- en: 'A probe is an indicator to a container''s health. It judges the health through
    periodically performing a diagnostic action against a container via kubelet:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 探针是对容器健康状况的指示器。它通过定期对容器执行诊断操作来判断健康状况，通过kubelet进行：
- en: '**Liveness** **probe**: Indicates whether a container is alive or not. If a
    container fails on this probe, kubelet kills it and may restart it based on the
    `restartPolicy` of a pod.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活跃性探针**：指示容器是否存活。如果容器在此探针上失败，kubelet会将其杀死，并根据pod的`restartPolicy`可能重新启动它。'
- en: '**Readiness probe**: Indicates whether a container is ready for incoming traffic.
    If a pod behind a service is not ready, its endpoint won''t be created until the
    pod is ready.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**就绪性探针**：指示容器是否准备好接收流量。如果服务后面的pod尚未准备就绪，其端点将在pod准备就绪之前不会被创建。'
- en: '`retartPolicy` tells how Kubernetes treats a pod on failures or terminations.
    It has three modes: `Always`, `OnFailure`, or `Never`. Default is set to `Always`.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '`retartPolicy`指示Kubernetes在失败或终止时如何处理pod。它有三种模式：`Always`，`OnFailure`或`Never`。默认设置为`Always`。'
- en: 'Three kinds of action handlers can be configured to perform against a container:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 可以配置三种类型的操作处理程序来针对容器执行：
- en: '`exec`: Executes a defined command inside the container. Considered to be successful
    if the exit code is `0`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exec`：在容器内执行定义的命令。如果退出代码为`0`，则被视为成功。'
- en: '`tcpSocket`: Tests a given port via TCP, successful if the port is opened.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tcpSocket`：通过TCP测试给定端口，如果端口打开则成功。'
- en: '`httpGet`: Performs an `HTTP GET` to the IP address of target container. Headers
    in the request to be sent is customizable. This check is considered to be healthy
    if the status code satisfies: `400 > CODE >= 200`.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`httpGet`：对目标容器的IP地址执行`HTTP GET`。要发送的请求中的标头是可定制的。如果状态码满足：`400 > CODE >= 200`，则此检查被视为健康。'
- en: 'Additionally, there are five parameters to define a probe''s behavior:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，有五个参数来定义探针的行为：
- en: '`initialDelaySeconds`: How long kubelet should be waiting for before the first
    probing.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initialDelaySeconds`：第一次探测之前kubelet应等待多长时间。'
- en: '`successThreshold`: A container is considered to be healthy when getting consecutive
    times of probing successes passed this threshold.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`successThreshold`：当连续多次探测成功通过此阈值时，容器被视为健康。'
- en: '`failureThreshold`: Same as preceding but defines the negative side.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failureThreshold`：与前面相同，但定义了负面。'
- en: '`timeoutSeconds`: The time limitation of a single probe action.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds`：单个探测操作的时间限制。'
- en: '`periodSeconds`: Intervals between probe actions.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`periodSeconds`：探测操作之间的间隔。'
- en: 'The following code snippet demonstrates the usage of a readiness probe, the
    full template is here: [https://github.com/DevOps-with- Kubernetes/examples/blob/master/chapter7/7-3_on_pods/probe.yml](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/7-3_on_pods/probe.yml)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段演示了就绪探针的用法，完整模板在这里：[https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/7-3_on_pods/probe.yml](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/7-3_on_pods/probe.yml)
- en: '[PRE17]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'How the probe behaves is illustrated in the following diagram:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 探针的行为如下图所示：
- en: '![](../images/00114.jpeg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00114.jpeg)'
- en: 'The upper timeline is a pod''s real readiness, and another line below is its
    readiness from Kubernetes'' view. The first probing executes 10 seconds after
    the pod is created, and the pod is regarded as ready after 2 probing successes.
    A few seconds later, the pod goes out of service due to an unknown reason, and
    it becomes unready after the next three failures. Try to deploy the preceding
    example and observe its output:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 上方时间线是pod的真实就绪情况，下方的另一条线是Kubernetes视图中的就绪情况。第一次探测在pod创建后10秒执行，经过2次探测成功后，pod被视为就绪。几秒钟后，由于未知原因，pod停止服务，并在接下来的三次失败后变得不可用。尝试部署上述示例并观察其输出：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'In our example file, there is another pod `tester` which is constantly making
    requests to our service, and the log entries `/from-tester` in our service is
    caused by the tester thereof. From tester''s activity logs, we can observe that
    the traffic from the `tester` is stopped after our service becomes unready:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例文件中，还有另一个名为`tester`的pod，它不断地向我们的服务发出请求，而我们服务中的日志条目`/from-tester`是由该测试人员引起的。从测试人员的活动日志中，我们可以观察到从`tester`发出的流量在我们的服务变得不可用后停止了：
- en: '[PRE19]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Since we didn't configure the liveness probe in our service, the unhealthy container
    wouldn't be restarted unless we kill it manually. Therefore, in general, we would
    use both probes together so as to make the healing process automated.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有在服务中配置活动探针，除非我们手动杀死它，否则不健康的容器不会重新启动。因此，通常情况下，我们会同时使用这两种探针，以使治疗过程自动化。
- en: Init containers
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化容器
- en: Even though `initialDelaySeconds` allows us to block a pod for some time prior
    to receiving traffic, it's still limited. Imagine that if our application is serving
    a file that fetches from somewhere upon initializing, the ready time might differ
    a lot depending on the file size. Hence, the Init containers come in handy here.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管`initialDelaySeconds`允许我们在接收流量之前阻塞Pod一段时间，但仍然有限。想象一下，如果我们的应用程序正在提供一个从其他地方获取的文件，那么就绪时间可能会根据文件大小而有很大的不同。因此，在这里初始化容器非常有用。
- en: Init containers are one or more containers that start prior to application containers
    and run one by one to completion in order. If any container fails, it's subject
    to the `restartPolicy` of a pod and starts over again, till all containers exited
    with code `0`.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化容器是一个或多个在应用容器之前启动并按顺序完成的容器。如果任何容器失败，它将受到Pod的`restartPolicy`的影响，并重新开始，直到所有容器以代码`0`退出。
- en: 'Defining Init containers is akin to regular containers:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 定义初始化容器类似于常规容器：
- en: '[PRE20]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'They only differ in:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 它们只在以下方面有所不同：
- en: Init containers don't have readiness probes as they'd run to completion
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化容器没有就绪探针，因为它们会运行到完成
- en: The port defined in init containers wouldn't be captured by the service in front
    of the pod
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 初始化容器中定义的端口不会被Pod前面的服务捕获
- en: The request/limit of resources are calculated with `max(sum(regular containers),
    max(init containers))`, which means if one of init containers sets a higher resource
    limit than other init containers as well as the sum of resource limit of all regular
    containers, Kubernetes schedules the pod according to the init container's resource
    limit
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源的请求/限制是通过`max(sum(regular containers), max(init containers))`计算的，这意味着如果一个初始化容器设置了比其他初始化容器以及所有常规容器的资源限制之和更高的资源限制，Kubernetes会根据初始化容器的资源限制来调度Pod
- en: The usefulness of init containers is more than blocking the application containers.
    For instance, we can utilize them to configure an image by sharing an `emptyDir`
    volume to Init containers and application containers, instead of building another
    image that only runs `awk`/`sed` on the base image, mounts and consume secrets
    in an Init container rather than in application containers.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化容器的用处不仅仅是阻塞应用容器。例如，我们可以利用它们通过在初始化容器和应用容器之间共享`emptyDir`卷来配置一个镜像，而不是构建另一个仅在基础镜像上运行`awk`/`sed`的镜像，挂载并在初始化容器中使用秘密而不是在应用容器中使用。
- en: Terminating a pod
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 终止一个Pod
- en: The sequence of shutdown events is similar to events while starting a pod. After
    receiving a deletion invocation, Kubernetes sends `SIGTERM` to the pod to be deleted,
    and the pod's state becomes Terminating. Meanwhile, Kubernetes removes the endpoint
    of that pod to stop further requests if the pod is backing a service. Occasionally,
    there are pods that aren't quitting at all. It could be the pods don't honor `SIGTERM`,
    or simply because their tasks aren't completed. Under such circumstances, Kubernetes
    would send a `SIGKILL` to forcibly kill those pods after the termination periods.
    The period length is set at `.spec.terminationGracePeriodSeconds` under pod specification.
    Nonetheless, even though Kubernetes has mechanisms to reclaim such pods anyway,
    we still should make sure our pods can be closed properly.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭事件的顺序类似于启动Pod时的事件。在接收到删除调用后，Kubernetes向要删除的Pod发送`SIGTERM`，Pod的状态变为Terminating。与此同时，如果Pod支持服务，Kubernetes会删除该Pod的端点以停止进一步的请求。偶尔会有一些Pod根本不会退出。这可能是因为Pod不遵守`SIGTERM`，或者仅仅是因为它们的任务尚未完成。在这种情况下，Kubernetes会在终止期间之后强制发送`SIGKILL`来强制杀死这些Pod。终止期限的长度在Pod规范的`.spec.terminationGracePeriodSeconds`下设置。尽管Kubernetes已经有机制来回收这些Pod，我们仍然应该确保我们的Pod能够正确关闭。
- en: Besides, like in starting a pod, here we also need to take care of a case that
    might affect our service, that is, the process which is serving requests in a
    pod closed prior to the corresponding iptables rules are entirely removed.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，就像启动一个pod一样，这里我们还需要注意一个可能影响我们服务的情况，即在pod中为请求提供服务的进程在相应的iptables规则完全删除之前关闭。
- en: Handling SIGTERM
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理SIGTERM
- en: Graceful termination is not a new idea, it's a common practice in programming,
    and especially important for business- critical missions.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅终止不是一个新的想法，在编程中是一个常见的做法，特别是对于业务关键任务而言尤为重要。
- en: 'The implementation principally includes three steps:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 实现主要包括三个步骤：
- en: Add a handler to capture termination signals.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个处理程序来捕获终止信号。
- en: Do everything required in the handler, such as returning resources, releasing
    distribution locks, or closing connections.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在处理程序中执行所有必需的操作，比如返回资源、释放分布式锁或关闭连接。
- en: 'Program shutdown. Our previous example demonstrates the idea: closing the controller
    thread on `SIGTERM` in the handler `graceful_exit_handler`. The code can be found
    here ([https://github.com/DevOps-with-Kubernetes/my-app/blob/master/app.py](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/app.py)).'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 程序关闭。我们之前的示例演示了这个想法：在`graceful_exit_handler`处理程序中关闭`SIGTERM`上的控制器线程。代码可以在这里找到([https://github.com/DevOps-with-Kubernetes/my-app/blob/master/app.py](https://github.com/DevOps-with-Kubernetes/my-app/blob/master/app.py))。
- en: 'As a matter of fact, common pitfalls that fail a graceful exit are not on the
    program side:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，导致优雅退出失败的常见陷阱并不在程序方面：
- en: SIGTERM is not forwarded to the container process
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SIGTERM不会转发到容器进程
- en: 'In [Chapter 2](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e), *DevOps
    with Container*, we''ve learned that there are two forms to invoke our program
    when writing a Dockerfile, namely the shell form and the exec form, and the shell
    to run the shell form commands is default to `/bin/sh` on Linux containers. Let''s
    see the following example ([https://github.com/DevOps-with- Kubernetes/examples/tree/master/chapter7/7-3_on_pods/graceful_docker](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-3_on_pods/graceful_docker)):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第2章](part0047.html#1CQAE0-6c8359cae3d4492eb9973d94ec3e4f1e) *使用容器进行DevOps*中，我们已经学习到在编写Dockerfile时调用我们的程序有两种形式，即shell形式和exec形式，而在Linux容器上运行shell形式命令的默认shell是`/bin/sh`。让我们看看以下示例([https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-3_on_pods/graceful_docker](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter7/7-3_on_pods/graceful_docker))：
- en: '[PRE21]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: We know that the signal sent to a container would be caught by the `PID 1` process
    inside the container, so let's build and run it.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道发送到容器的信号将被容器内的`PID 1`进程捕获，所以让我们构建并运行它。
- en: '[PRE22]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Our container is still there. Let''s see what happened inside the container:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的容器还在那里。让我们看看容器内发生了什么：
- en: '[PRE23]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The `PID 1` process is the shell itself, and it doesn't forward our signal to
    the sub process apparently. In this example, we're using Alpine as the base image
    which uses `ash` as the default shell. If we execute anything with `/bin/sh`,
    it's linked to `ash` actually. Similarly, the default shell in Debian family is
    `dash`, which doesn't forward signals as well. There is still a shell that forwards
    signals, such as `bash`. To leverage `bash`, we can either install an extra shell,
    or switch the base image to distributions that use `bash`. But both of them are
    rather cumbersome.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`PID 1`进程本身就是shell，并且显然不会将我们的信号转发给子进程。在这个例子中，我们使用Alpine作为基础镜像，它使用`ash`作为默认shell。如果我们用`/bin/sh`执行任何命令，实际上是链接到`ash`的。同样，Debian家族的默认shell是`dash`，它也不会转发信号。仍然有一个转发信号的shell，比如`bash`。为了利用`bash`，我们可以安装额外的shell，或者将基础镜像切换到使用`bash`的发行版。但这两种方法都相当繁琐。'
- en: 'Instead, there are still options to fix the signal problem without using `bash`.
    One is running our program with `exec` in the shell form:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，仍然有解决信号问题的选项，而不使用`bash`。其中一个是以shell形式在`exec`中运行我们的程序：
- en: '[PRE24]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Our process will replace the shell process and thus become the `PID 1` process.
    Another choice and also the recommended one is writing `Dockerfile` in EXEC form:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的进程将替换shell进程，从而成为`PID 1`进程。另一个选择，也是推荐的选择，是以EXEC形式编写`Dockerfile`：
- en: '[PRE25]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let''s try the example again with the one in EXEC form:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再试一次以EXEC形式的示例：
- en: '[PRE26]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: The EXEC form works like a charm. As we can see, the processes in the container
    is what we would anticipate, and our handler now receives `SIGTERM` correctly.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: EXEC形式运行得很好。正如我们所看到的，容器中的进程是我们预期的，我们的处理程序现在正确地接收到`SIGTERM`。
- en: SIGTERM doesn't invoke the termination handler
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: SIGTERM不会调用终止处理程序
- en: In some cases, the termination handler of a process is not triggered by `SIGTERM`.
    For instance, sending a `SIGTERM` to nginx actually causes a fast shutdown. To
    gracefully close a nginx controller, we have to send `SIGQUIT` with `nginx -s
    quit` instead.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，进程的终止处理程序不会被`SIGTERM`触发。例如，向nginx发送`SIGTERM`实际上会导致快速关闭。要优雅地关闭nginx控制器，我们必须使用`nginx
    -s quit`发送`SIGQUIT`。
- en: 'The full list of supported actions on the signal of nginx is listed here: [http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: nginx信号上支持的所有操作的完整列表在这里列出：[http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html)。
- en: Now another problem arises--how do we send signals other than `SIGTERM` to a
    container on deleting a pod? We can modify the behavior of our program to trap
    SIGTERM, but there's nothing we can do about a popular tool like nginx. For such
    a situation, the life cycle hook is capable of solving the problem.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在又出现了另一个问题——在删除pod时，我们如何向容器发送除`SIGTERM`之外的信号？我们可以修改程序的行为来捕获SIGTERM，但对于像nginx这样的流行工具，我们无能为力。对于这种情况，生命周期钩子能够解决问题。
- en: Container lifecycle hooks
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器生命周期钩子
- en: 'Lifecycle hooks are event-aware actions performs against a container. They
    work like a single Kubernetes probing action, but they''ll only be fired at least
    once per event during a container''s lifetime. Right now, there are two events
    supported:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 生命周期钩子是针对容器执行的事件感知操作。它们的工作方式类似于单个Kubernetes探测操作，但它们只会在容器的生命周期内的每个事件中至少触发一次。目前，支持两个事件：
- en: '`PostStart`: Executes right after a container is created. Since this hook and
    the entry point of a container are fired asynchronously, there is no guarantee
    that the hook would be executed before the container starts. As such, we''re unlikely
    to use it to initialize resources for a container.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PostStart`：在容器创建后立即执行。由于此钩子和容器的入口点是异步触发的，因此不能保证在容器启动之前执行该钩子。因此，我们不太可能使用它来初始化容器的资源。'
- en: '`PreStop`: executes right before sending `SIGTERM` to a container. One difference
    to `PostStart` hook is that the `PreStop` hook is a synchronous call, in other
    words, `SIGTERM` is only sent after a `PreStop` hook exited.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PreStop`：在向容器发送`SIGTERM`之前立即执行。与`PostStart`钩子的一个区别是，`PreStop`钩子是同步调用，换句话说，只有在`PreStop`钩子退出后才会发送`SIGTERM`。'
- en: 'So, our nginx shutdown problem is able to be trivially solved with a `PreStop`
    hook:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的nginx关闭问题可以通过`PreStop`钩子轻松解决：
- en: '[PRE27]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Additionally, an important property of hooks is they could affect the state
    of a pod in certain ways: a pod won''t be running unless its `PostStart` hook
    exited successfully; a pod is set to terminating immediately on deletion, but
    `SIGTERM` won''t be sent unless the `PreStop` hook exited successfully. Therefore,
    for the case we mentioned earlier, the container quits before its iptables rules
    are removed, we can resolve it by the `PreStop` hook. The following figure illustrates
    how to use the hook to eliminate the unwanted gap:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，钩子的一个重要属性是它们可以以某种方式影响pod的状态：除非其`PostStart`钩子成功退出，否则pod不会运行；在删除时，pod立即设置为终止，但除非`PreStop`钩子成功退出，否则不会发送`SIGTERM`。因此，对于我们之前提到的情况，容器在删除之前退出，我们可以通过`PreStop`钩子来解决。以下图示了如何使用钩子来消除不需要的间隙：
- en: '![](../images/00115.jpeg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00115.jpeg)'
- en: 'The implementation is just adding a hook that sleeps for few seconds:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 实现只是添加一个休眠几秒钟的钩子：
- en: '[PRE28]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Placing pods
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 放置pod
- en: Most of time we don't really care about which node our pods is running on as
    scheduling pods is a fundamental feature of Kubernetes. Nevertheless, Kubernetes
    is not aware of factors such as geographical location of a node, availability
    zones, or machine types when scheduling a pod. Moreover, at times we'd like to
    deploy pods that run testing builds in an isolated instance group. As such, to
    complete the scheduling, Kubernetes provides different levels of affinities that
    allows us to actively assign pods to certain nodes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，我们并不真的关心我们的pod运行在哪个节点上，因为调度pod是Kubernetes的一个基本特性。然而，当调度pod时，Kubernetes并不知道节点的地理位置、可用区域或机器类型等因素。此外，有时我们希望在一个隔离的实例组中部署运行测试构建的pod。因此，为了完成调度，Kubernetes提供了不同级别的亲和性，允许我们积极地将pod分配给特定的节点。
- en: The node selector of a pod is the simplest way to place pods manually. It's
    similar to pod selectors of service. A pod would only be put on nodes with matching
    labels. The field is set at `.spec.nodeSelector`. For example, the following snippet
    of a pod `spec` schedules the pod to nodes with label `purpose=sandbox,disk=ssd`.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: pod的节点选择器是手动放置pod的最简单方式。它类似于服务的pod选择器。pod只会放置在具有匹配标签的节点上。该字段设置在`.spec.nodeSelector`中。例如，以下pod
    `spec`的片段将pod调度到具有标签`purpose=sandbox,disk=ssd`的节点上。
- en: '[PRE29]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Checking labels on nodes is the same as how we check other resources in Kubernetes:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 检查节点上的标签与我们在Kubernetes中检查其他资源的方式相同：
- en: '[PRE30]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'As we can see, there are already labels on our node. Those labels are set by
    default, and the default labels are as follows:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的节点上已经有了标签。这些标签是默认设置的，默认标签如下：
- en: '`kubernetes.io/hostname`'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubernetes.io/hostname`'
- en: '`failure-domain.beta.kubernetes.io/zone`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failure-domain.beta.kubernetes.io/zone`'
- en: '`failure-domain.beta.kubernetes.io/region`'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failure-domain.beta.kubernetes.io/region`'
- en: '`beta.kubernetes.io/instance-type`'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta.kubernetes.io/instance-type`'
- en: '`beta.kubernetes.io/os`'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta.kubernetes.io/os`'
- en: '`beta.kubernetes.io/arch`'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`beta.kubernetes.io/arch`'
- en: 'If we''d like to label a node to make our example pods scheduled, we can either
    update the manifest of the node or use the shortcut command `kubectl label`:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要标记一个节点以使我们的示例pod被调度，我们可以更新节点的清单，或者使用快捷命令`kubectl label`：
- en: '[PRE31]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Aside from placing pods to a node, a node is able to reject pods as well, that
    is, *taints and tolerations*, and we will learn it at the next chapter.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将pod放置到节点上，节点也可以拒绝pod，即*污点和容忍*，我们将在下一章学习它。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we've discussed topics not only on building a continuous delivery
    pipeline, but also on techniques to strengthen our every deployment task. The
    rolling update of pods is a powerful tool that performs updates in a controlled
    fashion. To trigger a rolling update, what we need to do is update the pod's specification.
    Although the update is managed by Kubernetes, we can still control it with `kubectl
    rollout`.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们不仅讨论了构建持续交付流水线的话题，还讨论了加强每个部署任务的技术。pod的滚动更新是一个强大的工具，可以以受控的方式进行更新。要触发滚动更新，我们需要更新pod的规范。虽然更新由Kubernetes管理，但我们仍然可以使用`kubectl
    rollout`来控制它。
- en: Later on, we fabricated an extensible continuous delivery pipeline by `GitHub/DockerHub/Travis-CI`.
    Next, we moved our steps to learn more about the life of pods to prevent any possible
    failure, including using the readiness and liveness probe to protect a pod, initializing
    a pod with Init containers, handling `SIGTERM` properly by writing `Dockerfile`
    in the exec form, leveraging life cycle hooks to stall a pod's readiness as well
    as its termination for the iptables rules to be removed at the right timing, and
    assigning pods to specific nodes with node selectors.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们通过`GitHub/DockerHub/Travis-CI`创建了一个可扩展的持续交付流水线。接下来，我们将学习更多关于pod的生命周期，以防止任何可能的故障，包括使用就绪和存活探针来保护pod，使用Init容器初始化pod，通过以exec形式编写`Dockerfile`来正确处理`SIGTERM`，利用生命周期钩子来延迟pod的就绪以及终止，以便在正确的时间删除iptables规则，并使用节点选择器将pod分配给特定的节点。
- en: In the next chapter, we'll learn how to segment our cluster with logical boundaries
    to share resource more stable and secure in Kubernetes.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何在Kubernetes中使用逻辑边界来分割我们的集群，以更稳定和安全地共享资源。
