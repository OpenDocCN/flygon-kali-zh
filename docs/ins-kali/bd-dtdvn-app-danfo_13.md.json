["```js\n<script src=\"img/tf.min.js\"></script>\n```", "```js\n...\n<script>\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tf.ready().then(()=>{\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0console.log(\"Tensorflow.js loaded successfully!\");\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0})\n </script>\n...\n```", "```js\nnpm install @tensorflow/tfjs\n```", "```js\nyarn add @tensorflow/tfjs\n```", "```js\nimport * as tf from '@tensorflow/tfjs';\nconst x = tf.tensor2d([1, 2, 3, 4], [2, 2]);\nconst y = tf.tensor2d([1, 3, 5, 7], [2, 2]);\nconst sum = x.add(y)\n sum.print()\n```", "```js\nnpm install @tensorflow/tfjs-node\n```", "```js\nyarn add @tensorflow/tfjs-node\n```", "```js\nnpm install @tensorflow/tfjs-node-gpu\n```", "```js\nyarn add @tensorflow/tfjs-node-gpu\n```", "```js\nnpm install @tensorflow/tfjs\n```", "```js\nyarn add @tensorflow/tfjs\n```", "```js\nconst tf = require('@tensorflow/tfjs-node')\n// const tf = require('@tensorflow/tfjs-node-gpu') GPU version\n// const tf = require('@tensorflow/tfjs') Pure JS version\nconst xs = tf.randomNormal([100, 10])\nconst ys = tf.randomNormal([100, 1])\nconst sum = xs.add(ys)\nconst xsSum = xs.sum()\nconst xsMean = xs.mean()\n\nconsole.log(\"Sum of xs and ys\")\nsum.print()\nconsole.log(\"Sum of xs\")\nxsSum.print()\nconsole.log(\"Mean of xs\")\nxsMean.print()\n```", "```js\nconst tf = require('@tensorflow/tfjs-node')\n\nconst tvector = tf.tensor([1, 2, 3, 4]);\nconsole.log(tvector)\n//output\nTensor {\n\u00a0\u00a0kept: false,\n\u00a0\u00a0isDisposedInternal: false,\n\u00a0\u00a0shape: [ 4 ],\n\u00a0\u00a0dtype: 'float32',\n\u00a0\u00a0size: 4,\n\u00a0\u00a0strides: [],\n\u00a0\u00a0dataId: {},\n\u00a0\u00a0id: 0,\n\u00a0\u00a0rankType: '1'\n}\n```", "```js\nconsole.log('shape:', tvector.shape);\n//outputs: shape: [ 4 ]\n```", "```js\ntvector.print();\n//outputs\nTensor\n\u00a0\u00a0\u00a0\u00a0[1, 2, 3, 4]\n```", "```js\nconst tvectorArray = tvector.array()\nconst tvectorArraySync = tvector.arraySync()\nconsole.log(tvectorArray)\nconsole.log(tvectorArraySync)\n//outputs\nPromise { <pending> }\n[ 1, 2, 3, 4 ]\n```", "```js\nconst ts = tf.tensor([1, 2, 3, 4], [2, 2]);\nconsole.log('shape:', ts.shape);\nts.print();\n//outputs\nshape: [ 2, 2 ]\nTensor\n\u00a0\u00a0\u00a0\u00a0[[1, 2],\n\u00a0\u00a0\u00a0\u00a0\u00a0[3, 4]]\n```", "```js\nconst ts = tf.tensor([1, 2, 3, 4], [1, 4]);\nconsole.log('shape:', ts.shape);\nts.print();\n//outputs\nshape: [ 1, 4 ]\nTensor\n\u00a0\u00a0\u00a0\u00a0\u00a0[[1, 2, 3, 4],]\n```", "```js\nconst ts = tf.tensor([1, 2, 3, 4], [2, 5]);\n```", "```js\nconst tsInt = tf.tensor([1, 2, 3, 4], [1, 4], 'int32');\nconsole.log('dtype:', tsInt.dtype);\n//outputs\ndtype: int32\n```", "```js\nconst tf = require('@tensorflow/tfjs-node')\nconst a = tf.tensor1d([1, 2, 3, 4]);\nconst b = tf.tensor1d([10, 20, 30, 40]);\na.add(b).print();\n//outputs\nTensor\n\u00a0\u00a0\u00a0\u00a0[11, 22, 33, 44]\n```", "```js\nconst tf = require('@tensorflow/tfjs-node')\nconst a = tf.tensor1d([1, 2, 3, 4]);\nconst b = tf.tensor1d([10, 20, 30, 40]);\nconst sum = tf.add(a, b)\nsum.print()\n//outputs\nTensor\n\u00a0\u00a0\u00a0\u00a0[11, 22, 33, 44]\n```", "```js\nconst a = tf.tensor1d([1, 2, 3, 4]);\nconst b = tf.tensor1d([10, 20, 30, 40]);\n\nconst tfsum = tf.add(a, b)\nconst tfsub = tf.sub(b, a)\nconst tfdiv = tf.div(b, a)\nconst tfpow = tf.pow(b, a)\nconst tfmax = tf.maximum(a, b)\n\ntfsum.print()\ntfsub.print()\ntfdiv.print()\ntfpow.print()\ntfmax.print()\n//outputs\nTensor\n\u00a0\u00a0\u00a0\u00a0[11, 22, 33, 44]\nTensor\n\u00a0\u00a0\u00a0\u00a0[9, 18, 27, 36]\nTensor\n\u00a0\u00a0\u00a0\u00a0[10, 10, 10, 10]\nTensor\n\u00a0\u00a0\u00a0\u00a0[10, 400, 27000, 2560000]\nTensor\n\u00a0\u00a0\u00a0\u00a0[10, 20, 30, 40]\n```", "```js\nTensor\n\u00a0\u00a0\u00a0\u00a0[-9, -18, -27, -36]\n```", "```js\nconst a = tf.tensor1d([1, 2, 3, 4]);\nconst b = tf.tensor1d([10, 20, 30, 40, 50]);\nconst tfsum = tf.add(a, b)\n```", "```js\nconst tf = require('@tensorflow/tfjs-node')\n\nconst x = tf.tensor1d([-1, 2, -3, 4]);\nx.abs().print();\u00a0\u00a0// Computes the absolute values of the tensor\nx.cos().print(); // Computes the cosine of the tensor\nx.exp().print(); // Computes the exponential of the tensor\nx.log().print(); // Computes the natural logarithm\u00a0\u00a0of the tensor\nx.square().print(); // Computes the sqaure of the tensor\n```", "```js\nTensor\n\u00a0\u00a0\u00a0\u00a0[1, 2, 3, 4]\nTensor\n\u00a0\u00a0\u00a0\u00a0[0.5403023, -0.4161468, -0.9899925, -0.6536436]\nTensor\n\u00a0\u00a0\u00a0\u00a0[0.3678795, 7.3890562, 0.0497871, 54.5981522]\nTensor\n\u00a0\u00a0\u00a0\u00a0[NaN, 0.6931472, NaN, 1.3862944]\nTensor\n\u00a0\u00a0\u00a0\u00a0[1, 4, 9, 16]\n```", "```js\nconst x = tf.tensor1d([1, 2, 3]);\nx.mean().print();\u00a0\u00a0// or tf.mean(x)\u00a0\u00a0Returns the mean value of the tensor\nx.min().print();\u00a0\u00a0// or tf.min(x) Returns the smallest value in the tensor\nx.max().print();\u00a0\u00a0// or tf.max(x) Returns the largest value in the tensor\nx.argMax().print();\u00a0\u00a0// or tf.argMax(x) Returns the index of the largest value\nx.argMin().print();\u00a0\u00a0// or tf.argMin(x) Returns the index of the smallest value\n```", "```js\nTensor 2\nTensor 1\nTensor 3\nTensor 2\nTensor 0\n```", "```js\n    mkdir sales_predictor\n    cd sales_predictor\n    ```", "```js\n    npm init\n    ```", "```js\n    yarn add danfojs-node\n    or if using npm\n    npm install danfojs-node\n    ```", "```js\n    data_proc.js, and model.js) in the src folder. These files will contain code for processing data, creating a tfjs model, and model training, respectively.\n    ```", "```js\n|-data-proc.js\n|-dataset\n|\u00a0\u00a0\u00a0\u2514\u2500\u2500 Train.csv\n|-model.js\n|-train.js\n```", "```js\n    const dfd = require(\"danfojs-node\")\n    ```", "```js\n    async function processData(trainDataPath) {\n    \u00a0\u00a0\u00a0\u00a0//\u2026 process code goes here\n    }\n    ```", "```js\n    const salesDf = await dfd.read_csv(trainDataPath)\n    salesDf.head().print()\n    ```", "```js\n    processData(\"./dataset/train.csv\")\n    ```", "```js\n    node data_proc.js\n    ```", "```js\n    ...\u00a0\u00a0\u00a0\n     salesDf.fillna({\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0columns: [\"Item_Weight\", \"Outlet_Size\"],\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0values: [salesDf['Item_Weight'].mean(), \"Medium\"],\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0inplace: true\n    \u00a0\u00a0\u00a0\u00a0})\n    ...\n    ```", "```js\n    ...\n    \u00a0\u00a0\u00a0\u00a0\u00a0let encoder = new dfd.LabelEncoder()\n    \u00a0\u00a0\u00a0\u00a0\u00a0let catCols = salesDf.select_dtypes(includes = ['string']).column_names // get all categorical column names\n    \u00a0\u00a0\u00a0\u00a0\u00a0catCols.forEach(col => {\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0encoder.fit(salesDf[col])\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0enc_val = encoder.transform(salesDf[col])\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0salesDf.addColumn({ column: col, value: enc_val })\n    \u00a0\u00a0\u00a0\u00a0\u00a0})\n    \u00a0\u00a0\u00a0\u00a0\u00a0...\n    ```", "```js\n    ...\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0let Xtrain, ytrain;\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Xtrain = salesDf.iloc({ columns:\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0[`1:${salesDf.columns.length - 1}`] })\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ytrain = salesDf['Item_Outlet_Sales']\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0console.log(`Training Dataset Shape: ${Xtrain.shape}`)\n    ...\n    ```", "```js\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0... \n     let scaler = new dfd.MinMaxScaler()\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0scaler.fit(Xtrain)\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Xtrain = scaler.transform(Xtrain)\n    ...\n    ```", "```js\n    ...\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0return [Xtrain.tensor, ytrain.tensor]\n    ...\n    ```", "```js\nconst model = tf.sequential();\n// First layer must have an input shape defined.\nmodel.add(tf.layers.dense({units: 32, inputShape: [50]}));\nmodel.add(tf.layers.dense({units: 24})); \nmodel.add(tf.layers.dense({units: 1}));\n```", "```js\nconst model = tf.sequential({\n\u00a0\u00a0\u00a0layers: [tf.layers.dense({units: 32, inputShape: [50]}),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tf.layers.dense({units: 24}),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0tf.layers.dense({units: 1})]\n});\n```", "```js\nconst input = tf.input({ shape: [5] });\nconst denseLayer1 = tf.layers.dense({ units: 16, activation: 'relu' });\nconst denseLayer2 = tf.layers.dense({ units: 8, activation: 'relu' });\nconst denseLayer3 = tf.layers.dense({ units: 1 })\nconst output = denseLayer3.apply(denseLayer2.apply(denseLayer1.apply(input)))\nconst model = tf.model({ inputs: input, outputs: output });\n```", "```js\n...\nconst model = tf.sequential();\nmodel.add(tf.layers.dense({ inputShape: [11], units: 128, kernelInitializer: 'leCunNormal' }));\nmodel.add(tf.layers.dense({units: 64, activation: 'relu' }));\nmodel.add(tf.layers.dense({units: 32, activation: 'relu' }));\nmodel.add(tf.layers.dense({units: 1}))\n...\n```", "```js\n...\n\u00a0\u00a0\u00a0\u00a0model.compile({\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0optimizer: tf.train.adam(LEARNING_RATE),\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0loss: tf.losses.meanSquaredError,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0metrics: ['mse']\n\u00a0\u00a0\u00a0\u00a0});\n...\n```", "```js\n    \u2026\n    const data = await processData(\"./dataset/train.csv\")\n    const Xtrain = data[0]\n    const ytrain = data[1]\n    \u2026\n    ```", "```js\n    \u2026\n    const model = getModel()\n    \u2026\n    ```", "```js\n    \u2026\n    \u00a0\u00a0\u00a0\u00a0await model.fit(Xtrain, ytrain, {\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0batchSize: 24,\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0epochs: 20,\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0validationSplit: 0.2,\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0callbacks: {\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0onEpochEnd: async (epoch, logs) => {\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0const progressUpdate = `EPOCH (${epoch + 1}): Train MSE: ${Math.sqrt(logs.mse)}, Val MSE:\u00a0\u00a0${Math.sqrt(logs.val_mse)}\\n`\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0console.log(progressUpdate);\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0}\n    \u00a0\u00a0\u00a0\u00a0});\n    ...\n    ```", "```js\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0...\n    \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0await model.save(\"file://./sales_pred_model\")\n     ...\n    ```", "```js\n    const dfd = require(\"danfojs-node\")\n    const tf = dfd.tf\n    async function loadModel() {\n    \u00a0\u00a0\u00a0\u00a0const model = await tf.loadLayersModel('file://./sales_pred_model/model.json');\n    \u00a0\u00a0\u00a0\u00a0model.summary()\n    \u00a0\u00a0\u00a0\u00a0return model\n    }\n    loadModel()\n    ```", "```js\n    ...\n    async function predict() {\n    \u00a0\u00a0\u00a0\u00a0//You'll probably have to do some data pre-processing as we did before training\n    \u00a0\u00a0\u00a0\u00a0const data = [0.1, 0.21, 0.25, 0.058, 0.0, 0.0720, 0.111, 1, 0, 0.5, 0.33] //sample processed test data\n    \u00a0\u00a0\u00a0\u00a0const model = await loadModel()\n    \u00a0\u00a0\u00a0\u00a0const value = model.predict(tf.tensor(data, [1, 11])) //cast data to required shape\n    \u00a0\u00a0\u00a0\u00a0console.log(value.arraySync());\n\n    }\n    predict()\n    ```", "```js\n    [ [ 738.65380859375 ] ]\n    ...\n    ```"]