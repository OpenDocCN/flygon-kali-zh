["```java\n        String route;\n        System.out.println(Thread.currentThread().getName()+\": Reader start\");\n\n        while ((route = files.pollFirst()) != null) {\n            Path file = Paths.get(route);\n\n            TextFile textFile;\n            try {\n                textFile = new TextFile(file);\n                buffer.offer(textFile);\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(Thread.currentThread().getName()+\": Reader end: \"+buffer.size());\n        readersCounter.countDown();\n    }\n}\n```", "```java\npublic class TextFile {\n\n    private String fileName;\n    private List<String> content;\n\n    public TextFile(String fileName, List<String> content) {\n        this.fileName = fileName;\n        this.content = content;\n    }\n\n    public TextFile(Path path) throws IOException {\n        this(path.getFileName().toString(), Files.readAllLines(path));\n    }\n\n    public String getFileName() {\n        return fileName;\n    }\n\n    public List<String> getContent() {\n        return content;\n    }\n}\n```", "```java\npublic class Indexer implements Runnable {\n\n    private ConcurrentLinkedQueue<TextFile> buffer;\n    private ConcurrentLinkedDeque<Document> documents;\n    private CountDownLatch readersCounter;\n    private CountDownLatch indexersCounter;\n    private Vocabulary voc;\n```", "```java\n    @Override\n    public void run() {\n        System.out.println(Thread.currentThread().getName()+\": Indexer start\");\n        do {\n            TextFile textFile= buffer.poll();\n            if (textFile!=null) {\n                Document document= parseDoc(textFile);\n```", "```java\n                document.getVoc().values()\n                    .forEach(voc::addWord);\n                documents.offer(document);\n            }\n        } while ((readersCounter.getCount()>0) || (!buffer.isEmpty()));\n```", "```java\ncountDown() method of the CountDownLatch object to indicate that this task has finished its execution:\n```", "```java\n        indexersCounter.countDown();\n        System.out.println(Thread.currentThread().getName()+\": Indexer end\");\n    }\n```", "```java\n    private Document parseDoc(TextFile textFile) {\n        Document doc=new Document();\n\n        doc.setName(textFile.getFileName());\n        textFile.getContent().forEach(line -> parseLine(line,doc));\n\n        return doc;\n    }\n```", "```java\n    private static void parseLine(String inputLine, Document doc) {\n\n        // Clean string\n        String line=new String(inputLine);\n        line = Normalizer.normalize(line, Normalizer.Form.NFKD);\n        line = line.replaceAll(\"[^\\\\p{ASCII}]\", \"\");\n        line = line.toLowerCase();\n\n        // Tokenizer\n        StringTokenizer tokenizer = new StringTokenizer(line,\n                \" ,.;:-{}[]\u00bf?\u00a1!|\\\\=*+/()\\\"@\\t~#<>\", false);\n        while (tokenizer.hasMoreTokens()) {\n            doc.addWord(tokenizer.nextToken());\n        }\n    }\n```", "```java\nstatic final Pattern NON_ASCII = Pattern.compile(\"[^\\\\p{ASCII}]\");\n    line = NON_ASCII.matcher(line).replaceAll(\"\");\n    }\n```", "```java\npublic class Mapper implements Runnable {\n\n    private ConcurrentLinkedDeque<Document> documents;\n    private Vocabulary voc;\n```", "```java\n    public void run() {\n        Document doc;\n        int counter=0;\n        System.out.println(Thread.currentThread().getName()+\": Mapper start\");\n        while ((doc=documents.pollFirst())!=null) {\n            counter++;\n```", "```java\n            List<Attribute> attributes=new ArrayList<>();\n            doc.getVoc().forEach((key, item)-> {\n                Word word=voc.getWord(key);\n                item.setTfxidf(item.getTfxidf()/word.getDf());\n                Attribute attribute=new Attribute();\n                attribute.setIndex(word.getIndex());\n                attribute.setValue(item.getTfxidf());\n                attributes.add(attribute);\n            });\n```", "```java\n            Collections.sort(attributes);\n            doc.setExample(attributes);\n        }\n        System.out.println(Thread.currentThread().getName()+\": Mapper end: \"+counter);\n\n    }\n```", "```java\n    @Override\n    public void run() {\n        System.out.println(\"Documents to cluster: \"+documents.length);\n        ConcurrentKMeans.calculate(documents, 10, voc.getVocabulary().size(), 991, 10);\n    }\n```", "```java\npublic class ClusteringDocs {\n\n    private static int NUM_READERS = 2;\n    private static int NUM_WRITERS = 4;\n\n    public static void main(String[] args) throws InterruptedException {\n\n        ThreadPoolExecutor executor=(ThreadPoolExecutor) Executors.newCachedThreadPool();\n        ConcurrentLinkedDeque<String> files=readFiles(\"data\");\n        System.out.println(new Date()+\":\"+files.size()+\" files read.\");\n```", "```java\n        ConcurrentLinkedQueue<List<String>> buffer=new ConcurrentLinkedQueue<>();\n        CountDownLatch readersCounter=new CountDownLatch(2);\n        ConcurrentLinkedDeque<Document> documents=new ConcurrentLinkedDeque<>();\n        CountDownLatch indexersCounter=new CountDownLatch(4);\n        Vocabulary voc=new Vocabulary();\n```", "```java\n        System.out.println(new Date()+\":\"+\"Launching the tasks\");\n        for (int i=0; i<NUM_READERS; i++) {\n            DocumentReader reader=new DocumentReader(files,buffer,readersCounter);\n            executor.execute(reader);\n\n        }\n\n        for (int i=0; i<NUM_WRITERS; i++) {\n            Indexer indexer=new Indexer(documents, buffer, readersCounter, indexersCounter, voc);\n            executor.execute(indexer);\n        }\n```", "```java\n        System.out.println(new Date()+\":\"+\"Waiting for the readers\");\n        readersCounter.await();\n\n        System.out.println(new Date()+\":\"+\"Waiting for the indexers\");\n        indexersCounter.await();\n```", "```java\n        Document[] documentsArray=new Document[documents.size()];\n        documentsArray=documents.toArray(documentsArray);\n```", "```java\n        System.out.println(new Date()+\":\"+\"Launching the mappers\");\n        CompletableFuture<Void>[] completables = Stream.generate(() -> new Mapper(documents, voc))\n                .limit(4)\n                .map(CompletableFuture::runAsync)\n                .toArray(CompletableFuture[]::new);\n```", "```java\n        System.out.println(new Date()+\":\"+\"Launching the cluster calculation\");\n\n        CompletableFuture<Void> completableMappers= CompletableFuture.allOf(completables);\n        ClusterTask clusterTask=new ClusterTask(documentsArray, voc);\n        CompletableFuture<Void> completableClustering= completableMappers.thenRunAsync(clusterTask);\n```", "```java\n        System.out.println(new Date()+\":\"+\"Wating for the cluster calculation\");\n        try {\n            completableClustering.get();\n        } catch (InterruptedException | ExecutionException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(new Date()+\":\"+\"Execution finished\");\n        executor.shutdown();\n    }\n```"]