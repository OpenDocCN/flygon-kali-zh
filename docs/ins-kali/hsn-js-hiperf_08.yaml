- en: Data Formats - Looking at Different Data Types Other Than JSON
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据格式 - 查看除JSON之外的不同数据类型
- en: We have almost finished our discussion on server-side JavaScript. One topic
    that seems to fly under the radar, but does come up quite a bit when interfacing
    with other systems or even making things faster, is transmitting data in different
    formats. One of the most common, if not the most common, formats is JSON. JSON
    is quite easily one of the easiest data formats to interface with, especially
    in JavaScript.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎已经完成了关于服务器端JavaScript的讨论。一个话题似乎鲜为人知，但在与其他系统进行接口或使事情更快时经常出现的话题是以不同格式传输数据。其中最常见的，如果不是最常见的格式就是JSON。JSON是非常容易与之进行接口的数据格式之一，特别是在JavaScript中。
- en: 'In JavaScript, we do not have to worry about JSON objects that do not match
    a class. If we were utilizing a strongly typed language such as Java (or TypeScript
    for those that are using it), we would have to worry about the following things:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在JavaScript中，我们不必担心不匹配类的JSON对象。如果我们使用的是像Java（或者正在使用TypeScript的人）这样的强类型语言，我们将不得不担心以下事项：
- en: Creating a class that mimics the format of the JSON object.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个模仿JSON对象格式的类。
- en: Creating a map structure that keeps nesting based on how many nested objects
    there are.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个基于嵌套对象数量的嵌套映射结构。
- en: Creating on-the-fly classes based on the JSON that we get.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据我们收到的JSON创建即时类。
- en: None of these are necessarily hard, but it can add to speed and complexity when
    we are interfacing with systems that are written in these languages. With other
    data formats, we may get some major speed benefits; not only from possibly smaller
    data transfers, but also from the other languages being able to parse the objects
    more easily. There are even more benefits when we move to a schema-based data
    format, such as versioning, which can make backward compatibility easier.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都不一定难，但当我们与使用这些语言编写的系统进行接口时，它可能会增加速度和复杂性。使用其他数据格式时，我们可能会获得一些主要的速度优势；不仅可能会获得更小的数据传输量，而且其他语言也能更容易地解析对象。当我们转向基于模式的数据格式时，甚至会获得更多的好处，比如版本控制，这可以使向后兼容更容易。
- en: With all of this in mind, let's go ahead and take a look at JSON and see some
    of the benefits, but also the losses that we get with utilizing it. On top of
    this, we will take a look at a new custom format that we will create for our services
    to transfer data at a hopefully smaller size. After this, we will take a look
    at a schema-less data format such as JSON and, finally, take a look at a schema-based
    format.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到所有这些，让我们继续看一下JSON，并了解一些利弊，以及我们在使用它时得到的损失。除此之外，我们将看一下一个新的自定义格式，我们将为我们的服务创建一个更小的数据传输格式。之后，我们将看一下无模式数据格式，比如JSON，最后，我们将看一下基于模式的格式。
- en: This chapter might be lighter than almost all of the other chapters, but it
    is one that will prove useful when developing enterprise applications or interfacing
    with them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章可能比其他章节都要轻一些，但在开发企业应用程序或与其进行接口时，这是一个非常有用的章节。
- en: 'The topics covered in this chapter are as follows:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖的主题如下：
- en: Using JSON
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用JSON
- en: Encoding in JSON
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON编码
- en: Decoding in JSON
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON解码
- en: A look at data formats
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查看数据格式
- en: In TypeScript, we could just use the `any` type if we wanted to, but that would
    partially defeat the purpose of TypeScript. While we will not be looking at TypeScript
    in this book, it is good to know that it is out there, and it is easy to see how
    developers may run into it when developing backend applications.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在TypeScript中，如果我们愿意，我们可以只使用`any`类型，但这在某种程度上会削弱TypeScript的目的。虽然本书不会涉及TypeScript，但知道它存在，并且很容易看出开发人员在开发后端应用程序时可能会遇到它。
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following tools are needed to complete this chapter:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章需要以下工具：
- en: An editor or IDE, preferably VS Code
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个编辑器或IDE，最好是VS Code
- en: An operating system that supports Node.js
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持Node.js的操作系统
- en: The code found at [https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter08).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter08](https://github.com/PacktPublishing/Hands-On-High-Performance-Web-Development-with-JavaScript/tree/master/Chapter08)找到的代码。
- en: Using JSON
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用JSON
- en: As stated previously, JSON provides an easy-to-use and easy-to-operate interface
    for sending and receiving messages between services. For those that do not know,
    JSON stands for **JavaScript Object Notation**, which is one of the reasons that
    it interfaces with JavaScript so well. It mimics a lot of the behavior that JavaScript's
    objects do, except for some fundamental types (things such as functions). This
    also makes it quite easy to parse. We could use something such as the built-in `JSON.parse` function
    to turn stringified versions of JSON into objects, or `JSON.stringify` to turn
    one of our objects into its over-the-wire format.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，JSON提供了一个易于使用和操作的接口，用于在服务之间发送和接收消息。对于不了解的人来说，JSON代表**JavaScript对象表示法**，这也是它与JavaScript接口得很好的原因之一。它模仿了JavaScript对象的许多行为，除了一些基本类型（例如函数）。这也使得它非常容易解析。我们可以使用内置的`JSON.parse`函数将JSON的字符串化版本转换为对象，或者使用`JSON.stringify`将我们的对象转换为其在网络上传输的格式。
- en: 'So what are some of the disadvantages when utilizing JSON? We first have the
    problem that the format can get very verbose when sending data over the wire.
    Consider an array of objects that have the following format:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在使用JSON时有哪些缺点呢？首先，当通过网络发送数据时，格式可能会变得非常冗长。考虑一个具有以下格式的对象数组：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is probably a common sight for those that have worked with contact forms
    or customer information. Now, while we should involve paging of some kind for
    a website, we still might grab `100` or even `500` of these at a time. This could
    easily lead to a huge wire transfer cost. We can simulate this with the following
    code:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些曾经处理过联系表单或客户信息的人来说，这可能是一个常见的情景。现在，虽然我们应该为网站涉及某种分页，但我们仍然可能一次获取`100`甚至`500`个这样的数据。这可能很容易导致巨大的传输成本。我们可以使用以下代码来模拟这种情况：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By using this method, we get the byte length of the buffer that would come out
    of stringifying `100` entries for the data that we are sending. We will see that
    it comes out to around 22 KB worth of data. If we up this to `500`, we can deduce
    that it would be around 110 KB worth of data. While this may not seem like a lot
    of data, we could see this type of data being sent to a smartphone, where we want
    to limit the amount of data that we transfer in order that we do not drain the
    battery.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这种方法，我们可以得到对于我们发送的`100`条数据进行字符串化后的缓冲区的字节长度。我们将看到它大约为22 KB的数据。如果我们将这个数字增加到`500`，我们可以推断出它将大约为110
    KB的数据。虽然这可能看起来不像是很多数据，但我们可能会看到这种类型的数据被发送到智能手机上，我们希望限制我们传输的数据量，以免耗尽电池。
- en: We have not heavily discussed cellular phones and our applications, especially
    on the frontend, but it is something we need to increasingly be conscious of since
    we are becoming more and more of a remote business world. Many users, even if
    there is not a mobile version of the application, will still try to utilize it.
    One personal anecdote is utilizing email services that are meant for desktop applications
    because of some functionality that was not available in the mobile version of
    the application. We always need to be conscious of the amount of data we are transferring,
    but mobile has made that idea become a primary objective.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尚未深入讨论手机和我们的应用程序，尤其是在前端，但这是我们需要越来越意识到的事情，因为我们正在变得越来越像一个远程商业世界。许多用户，即使没有应用程序的移动版本，仍然会尝试使用它。一个个人的轶事是利用为桌面应用程序设计的电子邮件服务，因为移动版本的应用程序中缺少一些功能。我们始终需要意识到我们正在传输的数据量，但移动设备已经使这个想法成为主要目标。
- en: One way around this is to utilize some type of compression/decompression format.
    One fairly well-known format is `gzip`. This format is quite fast, has no loss
    in data quality (some compression formats have this, such as JPEG), and is ubiquitous
    with web pages.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一种方法是利用某种压缩/解压缩格式。一个相当知名的格式是`gzip`。这种格式非常快速，没有数据质量损失（一些压缩格式有这个问题，比如JPEG），并且在网页中非常普遍。
- en: 'Let''s go ahead and `gzip` this data by utilizing the `zlib` module in Node.js.
    The following code showcases an easy-to-use `gzip` method inside of `zlib`, and
    showcases the size difference between the original and the gzipped version:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续使用Node.js中的`zlib`模块来`gzip`这些数据。以下代码展示了`zlib`中一个易于使用的`gzip`方法，并展示了原始版本和gzip版本之间的大小差异：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We will now see that the gzipped version is only 301 bytes and, for the 500-length
    array, we see a gzipped version of around 645 bytes. That is quite a saving! However,
    there are a couple of points to remember here. First, we are using the exact same
    object for each item in the array. Compression algorithms are based on patterns,
    so seeing the exact same object over and over again is giving us a false sense
    of the original to the compressed form. This does not mean that this is not indicative
    of the size differences between uncompressed versus compressed data, but it is
    something to keep in mind when testing out various formats. Based on various sites,
    a compression ratio of 4-10 times the original is what we would see (this means
    if the original was 1 MB, we would see a compression size of anywhere from 250
    KB to 100 KB).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到经过gzip压缩的版本只有301字节，对于500长度的数组，我们看到大约645字节的gzip版本。这是相当节省的！然而，这里有几点需要记住。首先，我们在数组中的每个项目中使用完全相同的对象。压缩算法是基于模式的，因此一遍又一遍地看到完全相同的对象给了我们对原始形式到压缩形式的错误感觉。这并不意味着这不是未压缩与压缩数据之间大小差异的指示，但在测试各种格式时需要牢记这一点。根据各种网站，我们将看到原始数据的4-10倍的压缩比（这意味着如果原始数据为1
    MB，我们将看到压缩大小从250 KB到100 KB不等）。
- en: 'Instead of utilizing JSON, we can create a format ourselves that should represent
    the data in a much more compact way. First, we are going to only support three
    item types: a whole number, a floating number, and strings. Second, we will store
    all of the keys in the header of the message.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建一个自己的格式，以更紧凑的方式表示数据，而不是使用JSON。首先，我们将只支持三种项目类型：整数、浮点数和字符串。其次，我们将在消息头中存储所有的键。
- en: A schema can be best described as the definition of the data that is coming
    through. This means that we will know how to interpret the data that is coming
    through and not have to look for special encoding symbols to tell us when the
    end of the payload is (even though our format will use an end-of-body signal).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模式最好可以描述为传入数据的定义。这意味着我们将知道如何解释传入的数据，而不必寻找特殊的编码符号来告诉我们负载的结束（尽管我们的格式将使用一个结束信号）。
- en: 'Our schema is going to look something like the following:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模式将看起来像以下内容：
- en: We will use wrapper bytes for both the header and body of the message. The header
    will be denoted with the `0x10` byte and the body with the `0x11` byte.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将为消息的头部和主体使用包装字节。头部将用`0x10`字节表示，主体将用`0x11`字节表示。
- en: 'We will support the following types and their conversions will look similar
    to the following:'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将支持以下类型，它们的转换看起来类似于以下内容：
- en: 'Whole number: `0x01` followed by a 32-bit integer'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数：`0x01`后跟一个32位整数
- en: 'Floating-point number: `0x02` followed by a 32-bit integer'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浮点数：`0x02`后跟一个32位整数
- en: 'String: `0x03` followed by the length of the string followed by the data'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串：`0x03`后跟字符串的长度，后跟数据
- en: This should be good enough to get the concept of data formats and how they might
    work differently than just encoding and decoding JSON. In the next two sections,
    we will see how we might implement an encoder and decoder utilizing streams.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该足够让我们理解数据格式以及它们可能与仅对JSON进行编码和解码有所不同的工作方式。在接下来的两个部分中，我们将看到如何使用流来实现编码器和解码器。
- en: Implementing the encoder
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现编码器
- en: 'We are going to implement both the encoder and decoder utilizing transform
    streams. This will give us the most flexibility in terms of actually implementing
    the streams, and it already has a lot of the behavior that we need since we are
    technically transforming the data. First, we will need some generic helpers for
    both the encoding and decoding of our specific data types, and we will put all
    of these methods in a `helpers.js` helper file. The encoding functions will look
    like the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用转换流来实现编码器和解码器。这将为我们提供最大的灵活性，因为我们实际上正在实现流，并且它已经具有我们需要的许多行为，因为我们在技术上正在转换数据。首先，我们需要一些通用的辅助方法，用于编码和解码我们特定数据类型的方法，并将所有这些方法放在一个`helpers.js`辅助文件中。编码函数将如下所示：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Encoding the string takes in the string and outputs the buffer that will hold
    the information for the decoder to work on. First, we will change the string to
    the `Buffer` format. Next, we create a buffer to hold the length of the string.
    Then, we store the length of the buffer utilizing the `writeUInt32BE` method.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 编码字符串接受字符串并输出将保存解码器工作信息的缓冲区。首先，我们将字符串更改为`Buffer`格式。接下来，我们创建一个缓冲区来保存字符串的长度。然后，我们利用`writeUInt32BE`方法存储缓冲区的长度。
- en: For those that do not know byte/bit conversions, 8 bits of information (a bit
    is either a 1 or 0- the lowest form of data we can supply) makes up 1 byte. A
    32-bit integer, what we are trying to write, is then made up of 4 bytes (32/8).
    The U portion of that method means it is unsigned. Unsigned means we only want
    positive numbers (lengths can only be 0 or positive in our case). With this information,
    we can see why we allocated 4 bytes for this operation and why we are utilizing
    this specific method. For more information on both the write/read portions for
    buffers, go to [https://nodejs.org/api/buffer.html](https://nodejs.org/api/buffer.html)
    as it explains in depth the buffer operations we have access to. We will only
    explain the operations that we will be utilizing.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不了解字节/位转换的人来说，8位信息（位要么是1要么是0-我们可以提供的最低形式的数据）组成1个字节。我们要写入的32位整数由4个字节组成（32/8）。该方法的U部分表示它是无符号的。无符号表示我们只想要正数（在我们的情况下长度只能是0或正数）。有了这些信息，我们就可以看到为什么我们为这个操作分配了4个字节，以及为什么我们要使用这个特定的方法。有关缓冲区的写入/读取部分的更多信息，请访问[https://nodejs.org/api/buffer.html](https://nodejs.org/api/buffer.html)，因为它深入解释了我们可以访问的缓冲区操作。我们只会解释我们将要使用的操作。
- en: Once we have the string turned into the buffer format and the length of the
    string, we will write out a buffer that has `type` as the first byte, in our case
    the `0x03` byte; the length of the string, so we know how much of the incoming
    buffer is the string; and then finally, the string itself. This one should be
    the most complicated out of the two helper methods, but from a decoding perspective,
    it should make sense. When we are reading the buffer, we do not know how long
    a string is going to be. Because of this, we need some information in the prefix
    of this type to know how much to actually read. In our case, the `0x03` tells
    us that the type is a string and we know, based on our data type protocol that
    we established previously, that the next 4 bytes will be the length of the string.
    Finally, we can use this information to read so far ahead in the buffer to grab
    the string and decode it back to a string.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将字符串转换为缓冲区格式并获得字符串的长度，我们将写出一个缓冲区，其中`type`作为第一个字节，在我们的情况下是`0x03`字节；字符串的长度，这样我们就知道传入缓冲区的字符串有多长；最后，字符串本身。这个方法应该是两个辅助方法中最复杂的一个，但从解码的角度来看，它应该是有意义的。当我们读取缓冲区时，我们不知道字符串的长度。因此，我们需要在此类型的前缀中有一些信息，以知道实际读取多少。在我们的情况下，`0x03`告诉我们类型是字符串，根据我们之前建立的数据类型协议，我们知道接下来的4个字节将是字符串的长度。最后，我们可以使用这些信息来在缓冲区中向前读取，以获取字符串并将其解码回字符串。
- en: The `encodeNumber` method is much easier to understand. First, we check whether
    the rounding of the number equals itself. If it does, then we know that we are
    dealing with a whole number, otherwise, we treat it as a floating-point number.
    For those that are unaware, in most cases, knowing this information does not matter
    too much in JavaScript (though there are certain optimizations that the V8 engine
    utilizes when it knows that it is dealing with whole numbers), but if we want
    to use this data format with other languages, then the difference matters.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`encodeNumber`方法更容易理解。首先，我们检查数字的四舍五入是否等于自身。如果是，那么我们知道我们正在处理一个整数，否则，我们将其视为浮点数。对于不了解的人来说，在大多数情况下，在JavaScript中知道这些信息并不太重要（尽管V8引擎在知道它正在处理整数时会使用某些优化），但如果我们想要将这种数据格式与其他语言一起使用，那么差异就很重要了。'
- en: Next, we allocated 4 bytes since we are only going to write out 32-bit signed
    integers. Signed means they will support both positive and negative numbers (again,
    we won't go into the big difference between the two, but for those that are curious,
    we actually limit the maximum value we can store in here if we utilize signed
    integers since we have to utilize one of the bits to tell us whether the number
    is negative or not). We then write out the final buffer, which consists of our
    type and then the number in buffer format.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们分配了4个字节，因为我们只打算写出32位有符号整数。有符号意味着它们将支持正数和负数（再次，我们不会深入探讨两者之间的巨大差异，但对于那些好奇的人来说，如果我们使用有符号整数，我们实际上限制了我们可以在其中存储的最大值，因为我们必须利用其中一个位告诉我们这个数字是正数还是负数）。然后，我们写出最终的缓冲区，其中包括我们的类型，然后是缓冲区格式中的数字。
- en: 'Now, with the helper methods and the following constants in the `helper.js`
    file, proceed as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用`helper.js`文件中的辅助方法和以下常量进行如下操作：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can create our `encoder.js` file:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以创建我们的`encoder.js`文件：
- en: 'Import the necessary dependencies and also create the shell of our `SimpleSchemaWriter`
    class:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入必要的依赖项，并创建我们的`SimpleSchemaWriter`类的框架：
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the constructor and make sure that `objectMode` is always turned on:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建构造函数，并确保始终打开`objectMode`：
- en: '[PRE6]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Add a private `#encode` helper function that will do the underlying data check
    and conversion for us:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加一个私有的`#encode`辅助函数，它将为我们进行底层数据检查和转换：
- en: '[PRE7]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Write the main `_transform` function for our `Transform` stream. Details of
    this stream will be explained as follows:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写我们`Transform`流的主要`_transform`函数。该流的详细信息将在下文中解释：
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Overall, the `transform` function should look familiar to previous `_transform`
    methods we have implemented, with some exceptions:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，`transform`函数应该与我们之前实现的`_transform`方法很相似，但有一些例外：
- en: Our first portion of the encoding is wrapping our headers (the keys of the object).
    This means that we need to write out our delineator for headers, which is the
    `0x10` byte.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们编码的第一部分是包装我们的标头（对象的键）。这意味着我们需要写出我们的标头分隔符，即`0x10`字节。
- en: We will run through all of the keys of our object. From here, we will utilize
    the `private` method, `encode`. This method will check the data type of the key
    and return the encoding utilizing one of the helper methods that we discussed
    previously. If it does not get a type that it understands, it will return `null`.
    We will then give back an `Error` since our data protocol does not understand
    the type.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将遍历对象的所有键。然后，我们将利用`private`方法`encode`。这个方法将检查键的数据类型，并利用我们之前讨论过的辅助方法之一返回编码。如果它得到一个它不理解的类型，它将返回`null`。然后我们将返回一个`Error`，因为我们的数据协议不理解这种类型。
- en: Once we have run through all of the keys, we will write out the `0x10` byte
    again, stating that we are done with the headers, and write out the `0x11` byte
    to tell the decoder that we are starting with the body of our message. (We could
    have utilized the constants from the `helpers.js` file here and we probably should,
    but this should help with understanding the underlying protocol. The decoder will
    utilize these constants to showcase better programming practices.)
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们遍历完所有的键，我们将再次写出`0x10`字节，表示我们已经完成了标头，并写出`0x11`字节告诉解码器我们要开始消息的主体部分。（我们可以在这里使用`helpers.js`文件中的常量，而且我们可能应该这样做，但这应该有助于理解底层协议。解码器将利用这些常量来展示更好的编程实践。）
- en: We will now run through the values of the object and run them through the same
    encoding system that we did with the headers, and also return an `Error` if we
    do not understand the data type.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将遍历对象的值，并将它们通过与标头相同的编码系统运行，并在不理解数据类型时返回一个`Error`。
- en: Once we are finished with the body, we will push the `0x11` byte again to say
    that we are done with the body. This will be the signal to the decoder to stop
    converting this object and to send out the object it has been converting. We will
    then push all of this data to the `Readable` portion of our `Transform` stream
    and use the callback to say that we are ready to process more data.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们完成了主体部分，我们将再次推送`0x11`字节，表示我们已经完成了主体部分。这将是解码器停止转换此对象并发送出它一直在转换的信号。然后我们将所有这些数据推送到我们`Transform`流的`Readable`部分，并使用回调来表示我们已准备好处理更多数据。
- en: There are some problems with the overall structure of our encoding scheme (we
    shouldn't be using singular bytes for our wrappers since they can easily be misconstrued
    by our encoder and decoder) and we should support more data types, but this should
    give a nice understanding as to how an encoder can be built for more generally
    used data formats.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的编码方案的整体结构存在一些问题（我们不应该使用单个字节作为包装器，因为它们很容易被我们的编码器和解码器误解），我们应该支持更多的数据类型，但这应该对如何为更常用的数据格式构建编码器有一个很好的理解。
- en: Right now, we will not be able to test this, other than that it spits out the
    correct encoding, but once we have the decoder up and running, we will be able
    to test to see whether we get the same object on both sides. Let's now take a
    look at the decoder for this system.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们无法测试这一点，除了它能正确输出编码外，但一旦我们的解码器运行起来，我们就能测试是否两边得到相同的对象。现在让我们来看看这个系统的解码器。
- en: Implementing the decoder
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现解码器
- en: The decoder has quite a bit more state to it than the encoder and this is usually
    true of data formats. When dealing with raw bytes, trying to parse the information
    out of it is usually more difficult than writing the data out as that raw format.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器的状态比编码器要复杂得多，这通常是数据格式的特点。当处理原始字节时，尝试从中解析信息通常比以原始格式写出数据更困难。
- en: 'Let''s take a look at the helper methods that we will use to decode the data
    types we support:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们将用来解码支持的数据类型的辅助方法：
- en: '[PRE9]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `decodeString` method showcases how we could handle errors in the case of
    incorrectly formatted data, the `decodeNumber` method does not showcase this.
    For the `decodeString` method, we need to grab the length of the string from the
    buffer and we know this is the second byte of the buffer that would be passed
    in. Based on this, we know we can grab the string by starting at the fifth byte
    in the buffer (the first byte is the one that tells us that this is a string;
    the next four are the length of the string), and we grab everything until we get
    to the length of the string. We then run this buffer through the `toString` method.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`decodeString`方法展示了我们如何处理格式不正确的数据的错误，而`decodeNumber`方法则没有展示这一点。对于`decodeString`方法，我们需要从缓冲区中获取字符串的长度，我们知道这是传入的缓冲区的第二个字节。基于此，我们知道可以通过从缓冲区的第五个字节开始（第一个字节告诉我们这是一个字符串；接下来的四个字节是字符串的长度）获取字符串，并且获取直到达到字符串的长度。然后我们通过`toString`方法运行这个缓冲区。'
- en: '`decodeNumber` is quite simple since we only have to read the 4 bytes after
    the first byte telling us it is a number (again, we should do a check here, but
    we are keeping it simple). This showcases the two main helper methods that we
    need to decode the data types that we support. Next, we will take a look at the
    actual decoder. It will look something like the following.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`decodeNumber`非常简单，因为我们只需要读取告诉我们它是一个数字的第一个字节后面的4个字节（再次，我们应该在这里进行检查，但我们保持简单）。这展示了我们需要解码支持的数据类型的两个主要辅助方法。接下来，我们将看一下实际的解码器。它将看起来像下面这样。'
- en: 'As stated previously, the decoding process is a bit more involved. This is
    for a number of reasons, as follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，解码过程有点复杂。这是由于许多原因，如下所述：
- en: We are working directly on the bytes so we have to do quite a bit of processing.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们直接处理字节，所以我们需要做相当多的处理。
- en: We are dealing with a header and body section. If we created a non-schema-based
    system, we may be able to write a decoder without as much state as we have in
    this one.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在处理头部和主体部分。如果我们创建了一个非基于模式的系统，我们可能可以编写一个解码器，其状态不像这个解码器中那么多。
- en: Again, since we are dealing with the buffers directly, all of the data may not
    come in at once, so we need to handle this case. The encoder does not have to
    worry about this since we are operating the Writable stream in object mode.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同样，由于我们直接处理缓冲区，所有数据可能不会一次全部到达，因此我们需要处理这种情况。编码器不必担心这一点，因为我们正在以对象模式操作可写流。
- en: 'With this in mind, let''s run through the decoding stream:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这一点，让我们来看一下解码流程：
- en: 'We will set up our decode stream with all of the same types of setup that we
    have done with `Transform` streams in the past. We will set up a few private variables
    to track the state as we move through the decoder:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用与以前的`Transform`流相同类型的设置来设置我们的解码流。我们将设置一些私有变量来跟踪我们在解码器中的状态：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we are going to utilize an index throughout the decoding process. We
    are not able to simply read a byte at a time since the decoding process runs through
    the buffer at different speeds (when we read a number, we are reading 5 bytes;
    when we read a string, we read at least 6 bytes). Because of this, a `while` loop
    will be better:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将在解码过程中使用一个索引。我们不能简单地一次读取一个字节，因为解码过程以不同的速度运行（当我们读取一个数字时，我们要读取5个字节；当我们读取一个字符串时，至少要读取6个字节）。因此，使用`while`循环会更好：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, we do a check on the current byte to see whether it is a header or body
    delineation mark. This will let us know whether we are working on the object keys
    or on the object values. If we detect the `headers` flag, we will set the `#inHeaders` Boolean
    stating that we are in the headers. If we are in the body, we have more work to
    do:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们要检查当前字节，看它是头部还是主体的分隔标记。这将让我们知道我们是在处理对象键还是对象值。如果我们检测到`headers`标志，我们将设置`#inHeaders`布尔值，表示我们在头部。如果我们在主体中，我们还有更多工作要做：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Next, the paragraphs that follow will explain the process of getting the headers
    and the values of each JSON object.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，接下来的段落将解释获取每个JSON对象的头部和值的过程。
- en: First, we will change our body Boolean to the opposite of what it is currently
    at. Next, if we are going from inside the body to outside of the body, this means
    that we are done with this object. Because of this, we can push out the object
    that we are currently working on and reset all of our internal state variables
    (the temporary object, `#obj`; the temporary set of `#keys` that we get from the
    header; and the `#currKey` to know which key we are working on when we are in
    the body). Once we have this, we can run the callback (we are returning here so
    we don't run through more of our main body). If we do not do this, we will keep
    going through the loop and we will be in a bad state.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将把我们的主体布尔值更改为当前状态的相反值。接下来，如果我们从主体内部到主体外部，这意味着我们已经完成了这个对象。因此，我们可以推出我们当前正在处理的对象，并重置所有内部状态变量（临时对象`#obj`，我们从头部获取的临时`#keys`集合，以及`#currKey`，用于在主体中工作时知道我们正在处理哪个键）。一旦我们完成这些操作，我们就可以运行回调（我们在这里返回，所以我们不会运行更多的主体）。如果我们不这样做，我们将继续循环，并处于一个糟糕的状态。
- en: Otherwise, we have gone through the headers of our payload and have reached
    the values for each object. We will set our private `#keys` variable to the keys
    of the object (since, at this point, the headers should have grabbed all of the
    keys from the headers). We can now start to see the decoding process.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，我们已经浏览了有效负载的头部，并已经到达了每个对象的值。我们将把我们的私有`#keys`变量设置为对象的键（因为在这一点上，头部应该已经从头部获取了所有的键）。我们现在可以开始看到解码过程。
- en: If we are in the headers, we will run our private `#decode` method and not utilize
    the third argument since the default is to run the method as if we are in headers.
    Otherwise, we will run it like we are in the body and pass a third argument to
    state that we are in the body. Also, if we are in the body, we will increment
    our `#currKey` variable.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们在头部，我们将运行我们的私有`#decode`方法，并且不使用第三个参数，因为默认情况下是以头部运行该方法。否则，我们将像在主体中一样运行它，并传递第三个参数以说明我们在主体中。此外，如果我们在主体中，我们将增加我们的`#currKey`变量。
- en: Finally, we can take a look at the heart of the decoding process, the `#decode`
    method. We grab the item based on the first byte in the buffer, which will tell
    us which decoding helper method we should run. Then, if we are running this method
    in header mode, we will set a new key for our temporary object, and we will set
    its value to null since that will be filled in once we get to the body. If we
    are in body mode, we will set the value of the key corresponding to the `#currKey`
    index in our `#keys` array that we are looping through once we are in the body.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以看一下解码过程的核心，`#decode`方法。我们根据缓冲区中的第一个字节获取项目，这将告诉我们应该运行哪个解码辅助方法。然后，如果我们在头部模式下运行此方法，我们将为我们的临时对象设置一个新键，并将其值设置为null，因为一旦我们到达主体，它将被填充。如果我们在主体模式下，我们将设置与我们正在循环的`#keys`数组中的`#currKey`索引对应的键的值，一旦我们进入主体，我们就会开始循环。
- en: 'With that code explanation, the basic process that is happening can be summed
    up in a few basic steps:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个代码解释，正在发生的基本过程可以总结为几个基本步骤：
- en: We need to go through the headers and set the object's keys to these values.
    We are temporarily setting the values for each of these keys to null since they
    will be filled in later.
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要浏览头部并将对象的键设置为这些值。我们暂时将这些键的值设置为null，因为它们将在以后填充。
- en: Once we move out of the header section and we go to the body section, we can
    grab all of the keys from the temporary object, and the decode run we do at that
    time should correspond to the key at the current key's index in the array.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们离开头部部分并进入主体部分，我们可以从临时对象中获取所有键，并且我们在那时进行的解码运行应该对应于数组中当前键索引处的键。
- en: Once we are out of the body, we reset all of the temporary variables for the
    state and send out the corresponding object since we are finished with the decoding
    process.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦我们离开主体部分，我们将重置所有临时变量的状态，并发送相应的对象，因为我们已经完成了解码过程。
- en: 'This may seem confusing, but all we are doing is lining up the header at some
    index with the body element at that same index. It would be similar to the following
    code if we wanted to put an array of keys and values together:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来令人困惑，但我们所做的就是将头部与相同索引处的主体元素对齐。如果我们想要将键和值的数组放在一起，这将类似于以下代码：
- en: '[PRE13]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This code is almost exactly the same as what we were doing with the preceding
    buffer, except we have to work with the raw bytes instead of higher-level items
    such as strings, arrays, and objects.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码几乎与之前的缓冲区完全相同，只是我们必须使用原始字节而不是更高级的项目，如字符串、数组和对象。
- en: 'With both the decoder and the encoder finished, we can now run an object through
    our encoder and decoder to see whether we get the same value out. Let''s run the
    following test harness code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 解码器和编码器都完成后，我们现在可以通过我们的编码器和解码器运行一个对象，看看我们是否得到相同的值。让我们运行以下测试代码：
- en: '[PRE14]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We''ll use the following test object:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用以下测试对象：
- en: '[PRE15]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We will see that we will spit the same object out as we pipe the data through
    the encoder into the decoder. Now, it''s great that we created our own encoding
    and decoding scheme, but how does it hold up to the transfer size compared to
    JSON (since we are trying to do better than just stringifying and parsing)? With
    this payload, we are actually increasing the size! If we think about it, this
    makes sense. We have to add in all of our special encoding items (all of the information
    other than the data such as the `0x10` and `0x11` bytes), but we now start to
    add more numerical items to our list that are quite large. We will see that we
    start to beat the basic `JSON.stringify` and `JSON.parse`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到，当我们将数据通过编码器传输到解码器时，我们将得到相同的对象。现在，我们已经创建了自己的编码和解码方案，但它与JSON相比在传输大小上如何？使用这个负载，我们实际上增加了大小！如果我们考虑一下，这是有道理的。我们必须添加所有特殊的编码项（除了数据之外的所有信息，如`0x10`和`0x11`字节），但现在我们开始向我们的列表中添加更多的大型数字项。我们将看到，我们开始击败基本的`JSON.stringify`和`JSON.parse`。
- en: '[PRE16]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This is happening because stringified numbers are turned into just that, string
    versions of the numbers, so when we get numbers that are larger than 5 bytes,
    we are starting to save on bytes (1 byte for the data type and 4 bytes for the
    32-bit number encoding). With strings, we will never see savings since we are
    always adding an extra 5 bytes of information (1 byte for the data type and 4
    bytes for the length of the string).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为字符串化的数字被转换成了字符串版本的数字，所以当我们得到大于5个字节的数字时，我们开始节省字节（1个字节用于数据类型，4个字节用于32位数字编码）。对于字符串，我们永远不会节省，因为我们总是添加额外的5个字节的信息（1个字节用于数据类型，4个字节用于字符串的长度）。
- en: In most encoding and decoding schemes, this is the case. The way they handle
    data has trade-offs depending on the type of data that is being passed. In our
    case, if we are sending large, highly numerical data over the wire, our scheme
    will probably work better, but if we are sending strings across, we are not going
    to benefit at all from this encoding and decoding scheme. Keep this thought in
    mind as we take a look at some data formats that are used quite heavily out in
    the wild.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数编码和解码方案中，情况都是如此。它们处理数据的方式取决于传递的数据类型。在我们的情况下，如果我们通过网络发送大量的高度数值化的数据，我们的方案可能效果更好，但如果我们传输字符串，我们将无法从这种编码和解码方案中获益。在我们看一些在野外广泛使用的数据格式时，请记住这一点。
- en: Remember, this encoding and decoding scheme is not meant to be used in actual
    environments as it is riddled with issues. However, it does showcase the underlying
    theme of building out data formats. While most of us will never have to build
    data formats, it is nice to understand what goes on when building them out, and
    where data formats may have to specialize their encoding and decoding schemes
    based on the type of data that they are primarily working with.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这种编码和解码方案并不是用于实际环境的，因为它充满了问题。然而，它展示了构建数据格式的基本主题。虽然大多数人永远不需要构建数据格式，但了解构建数据格式时发生的情况以及数据格式可能需要根据其主要处理的数据类型专门化其编码和解码方案是很好的。
- en: A look at data formats
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据格式的一瞥
- en: Now that we have looked at our own data format, let's go ahead and take a look
    at some fairly popular data formats that are currently out there. This is not
    an exhaustive look at these, but more an introduction to data formats and what
    we may find out in the wild.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过了我们自己的数据格式，让我们继续看看一些目前流行的数据格式。这不是对这些数据格式的详尽了解，而是对数据格式和我们可能在野外发现的内容的介绍。
- en: The first data format that we will look at is a schema-less format. As stated
    previously, schema-based formats either send ahead of time the schema for data,
    or they will send the schema with the data itself. This allows, usually, a more
    compact form of the data to come in, while also making sure both endpoints agree
    on the way the data will be received. The other form is schema-less, where we
    send the data in a new form, but all of the information to decode it is done through
    the specification.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要查看的第一种数据格式是无模式格式。如前所述，基于模式的格式要么提前发送数据的模式，要么将模式与数据本身一起发送。这通常允许数据以更紧凑的形式传入，同时确保双方同意数据接收方式。另一种形式是无模式，我们通过规范发送数据的新形式，但解码所有信息都是通过规范完成的。
- en: JSON is one of these formats. When we send JSON, we have to encode it and then
    decode it once we are on the other side. Another schema-less data format is XML.
    Both of these should be quite familiar to web developers as we utilize JSON extensively
    and we use a form of XML when putting together our frontends (HTML).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: JSON就是其中一种格式。当我们发送JSON时，我们必须对其进行编码，然后在另一端对其进行解码。另一种无模式数据格式是XML。这两种格式对于Web开发人员来说应该非常熟悉，因为我们广泛使用JSON，并且在组装前端（HTML）时使用一种XML形式。
- en: 'Another popular format is `MessagePack` ([https://msgpack.org/index.html](https://msgpack.org/index.html)).
    `MessagePack` is a format that is known for producing smaller payloads than JSON.
    What is also nice about `MessagePack` is the number of languages that have the
    library written natively for them. We will take a look at the Node.js version,
    but just note that this could be used on both the frontend (in the browser) and
    on the server. So let''s begin:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种流行的格式是`MessagePack`（[https://msgpack.org/index.html](https://msgpack.org/index.html)）。`MessagePack`是一种以比JSON更小的有效载荷而闻名的格式。`MessagePack`的另一个优点是有许多语言为其编写了原生库。我们将看一下Node.js版本，但请注意，这可以在前端（浏览器）和服务器上都可以使用。所以让我们开始吧：
- en: 'We will `npm install` the `what-the-pack` extension by utilizing the following
    command:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用以下命令通过`npm install`安装`what-the-pack`扩展。
- en: '[PRE17]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Once we have done this, we can start to utilize this library. With the following
    code, we can see how easy it is to utilize this data format over the wire:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，我们可以开始使用这个库。通过以下代码，我们可以看到在网络上传输这种数据格式是多么容易。
- en: '[PRE18]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: What we see here is a slightly modified version of the example that is on the
    page for `what-the-pack` ([https://www.npmjs.com/package/what-the-pack](https://www.npmjs.com/package/what-the-pack)).
    We import the package and then we initialize the library. One way this library
    is different is that we need to initialize a buffer for the encoding and decoding
    process. This is what the `2**22` is doing in the `initialize` method. We are
    initializing a buffer that is 2 to the power of 22 bytes large. This way, it can
    easily slice the buffer and copy it without having expensive array-based operations.
    Another thing keen observers will note is that the library is not based on streaming.
    They have most likely done this to be compatible between the browser and Node.js.
    Other than these small issues, the overall library works just like we think it
    would.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里看到的是对`what-the-pack`页面上示例的略微修改版本（[https://www.npmjs.com/package/what-the-pack](https://www.npmjs.com/package/what-the-pack)）。我们导入了该包，然后初始化了该库。该库的一个不同之处在于，我们需要为编码和解码过程初始化一个缓冲区。这就是`initialize`方法中的`2**22`所做的。我们正在初始化一个大小为2的22次方字节的缓冲区。这样，它可以轻松地切割缓冲区并复制它，而不需要昂贵的基于数组的操作。敏锐的观察者还会注意到的另一件事是，该库不是基于流的。他们很可能这样做是为了在浏览器和Node.js之间保持兼容。除了这些小问题，整个库的工作方式与我们想象的一样。
- en: The first console log shows us that the encoded buffer is 5 bytes less than
    the JSON version. While this does showcase that the library gives us a more compact
    form, it should be noted that there are cases where `MessagePack` may not be smaller
    than the corresponding JSON. It also may run slower than the built-in `JSON.stringify`
    and `JSON.parse` methods. Remember, everything is a trade-off.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个控制台日志向我们展示了编码后的缓冲区比JSON版本少了5个字节。虽然这确实表明该库给我们提供了更紧凑的形式，但应该注意到，有些情况下`MessagePack`可能不比相应的JSON更小。它也可能比内置的`JSON.stringify`和`JSON.parse`方法运行得更慢。记住，一切都是一种权衡。
- en: There are plenty of schema-less data formats out there and each of them has
    their own tricks to try to make the encoding/decoding time faster and to make
    the over-the-wire data smaller. However, when we are dealing with enterprise systems,
    we will most likely see a schema-based data format being used.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多无模式数据格式，每种格式都有自己的技巧，试图使编码/解码时间更快，使过程中的数据更小。然而，当我们处理企业系统时，我们很可能会看到使用基于模式的数据格式。
- en: 'There are a couple of ways to define a schema but, in our case, we will use
    the proto file format:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种定义模式的方法，但在我们的情况下，我们将使用proto文件格式。
- en: 'Let''s go ahead and create a **proto** file to simulate the `test.json` file
    that we had. The schema could look something like the following:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们继续创建一个**proto**文件，以模拟我们之前的`test.json`文件。模式可能看起来像以下内容：
- en: '[PRE19]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: What we are declaring here is that this message called `TestData` is going to
    live in a package called `exampleProtobuf`. The package is mainly there to group
    like items (this is heavily utilized in languages such as Java and C#). The syntax
    tells our encoder and decoder that the protocol we are going to use is `proto3`.
    There were other versions of the protocol and this one is the most up-to-date
    stable version.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里声明的是，这条名为`TestData`的消息将存储在名为`exampleProtobuf`的包中。该包主要用于将类似的项目分组（这在诸如Java和C#等语言中被广泛利用）。语法告诉我们的编码器和解码器，我们将使用的协议是`proto3`。协议还有其他版本，而这个版本是最新的稳定版本。
- en: We then declare a new message called `TestData` that has three entries. One
    will be called `item1` and will be of type `string`, one will be a whole number
    called `item2`, and the final one will be a floating-point number called `item3`.
    We are also giving them IDs as this makes it easier for things such as indexing
    and for self-reference types (also because it is mandatory for `protobuf` to work).
    We will not go into exactly what this does, but note that it can help with the
    encoding and decoding process.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们声明一个名为`TestData`的新消息，其中包含三个条目。一个将被称为`item1`，类型为`string`，一个将是称为`item2`的整数，最后一个将是称为`item3`的浮点数。我们还为它们分配了ID，因为这样可以更容易进行索引和自引用类型（也因为这对于`protobuf`来说是强制性的）。我们不会详细介绍这样做的具体作用，但请注意它可以帮助编码和解码过程。
- en: 'Next, we can write some code that can use this to create a `TestData` object
    in our code that can specifically handle these messages. This would look like
    the following:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们可以编写一些代码，可以使用它在我们的代码中创建一个`TestData`对象，可以专门处理这些消息。这将看起来像下面这样：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Notice that this is similar to most of the code we have seen except for some
    verification and creation processes. First, the library needs to read in the proto
    file that we have and make sure it is actually correct. Next, we create the object
    based on the namespace and name we gave it. Now, we verify our payload and create
    a message from this. We then run it through the encoder specific to this data
    type. Finally, we decode the message and test to make sure that we got the same
    data that we put in.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这与我们之前看到的大多数代码类似，除了一些验证和创建过程。首先，库需要读取我们拥有的原型文件，并确保它确实是正确的。接下来，我们根据我们给它的命名空间和名称创建对象。现在，我们验证我们的有效负载并从中创建消息。然后，我们通过特定于此数据类型的编码器运行它。最后，我们解码消息并测试以确保我们得到了与输入相同的数据。
- en: Two things should be noticeable from this example. First, the data size is quite
    small! This is one advantage that schema-based/protobuf has over schema-less data
    formats. Since we know ahead of time what the types should be, we do not need
    to encode that information into the message itself. Second, we will see that the
    floating-point number did not come back out as 3.3\. This is due to precision
    errors and it is something that we should be on the lookout for.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个例子中应该注意到两件事。首先，数据大小非常小！这是基于模式/protobuf的优势之一，超过了无模式数据格式。由于我们提前知道类型应该是什么，我们不需要将该信息编码到消息本身中。其次，我们将看到浮点数并没有返回为3.3。这是由于精度错误，这是我们应该警惕的事情。
- en: 'Now, if we do not want to read in proto files like this, we could build the
    message in the code like the following:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果我们不想像这样读取原型文件，我们可以在代码中构建消息，就像下面这样：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This should resemble the message that we created in the proto file, but we will
    go over each line to show that it is the same `protobuf` object. We are first
    creating a new type called `TestType` in this case (instead of `TestData`). Next,
    we add three fields, each with their own label, an index number, and the type
    of data that is stored in it. If we run this through the same type of verification,
    create, encode, decode process, we will get the same results as before.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该类似于我们在原型文件中创建的消息，但我们将逐行查看以显示它与`protobuf`对象相同。在这种情况下，我们首先创建一个名为`TestType`的新类型（而不是`TestData`）。接下来，我们添加三个字段，每个字段都有自己的标签、索引号和存储在其中的数据类型。如果我们通过相同类型的验证、创建、编码、解码过程运行它，我们将得到与之前相同的结果。
- en: While this has not been a comprehensive overview of different data formats,
    it should help to recognize when we might use schema-less (when we don't know
    what the data may look like) and when to use schemas (when communicating between
    unknown systems or we need a decrease in payload size).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这并不是对不同数据格式的全面概述，但它应该有助于识别何时使用无模式（当我们不知道数据可能是什么样子时）以及何时使用模式（当在未知系统之间通信或我们需要减少有效负载大小时）。
- en: Summary
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: While most of our starting applications will be done utilizing JSON to pass
    data between different servers, or even different parts of our applications, it
    should be noticeable where we may not want to use it. By utilizing other data
    formats, we can make sure that we get as much speed out of our application as
    possible.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们大多数起始应用程序将使用JSON在不同服务器之间传递数据，甚至在我们应用程序的不同部分之间传递数据，但应该注意到我们可能不想使用它的地方。通过利用其他数据格式，我们可以确保尽可能地提高应用程序的速度。
- en: We have seen what building our own data format could entail and then we took
    a look at other popular formats that are currently out there. This should be the
    last piece of information that we need to build highly performant server applications
    in Node.js. While we will use some libraries for data formats, we should also
    note that we have really only used the vanilla libraries that come with Node.js.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到了构建自己的数据格式可能涉及的内容，然后我们看了一下当前流行的其他格式。这应该是我们构建高性能Node.js服务器应用程序所需的最后一部分信息。虽然我们将使用一些数据格式的库，但我们也应该注意到，我们实际上只使用了Node.js自带的原始库。
- en: We will next take a look at a practical example of a static server that caches
    information. From here, we will utilize all of the previous concepts to create
    a highly available and speedy static server.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一个实际的静态服务器示例，该服务器缓存信息。从这里开始，我们将利用之前的所有概念来创建一个高可用和高速的静态服务器。
