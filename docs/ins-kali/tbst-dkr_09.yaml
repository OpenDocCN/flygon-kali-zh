- en: Chapter 9. Hooking Volume Baggage
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。挂载卷行李
- en: 'This chapter introduces data volumes and storage driver concepts, which are
    widely used in Docker to manage persistent or shared data. We''ll be also taking
    a deep dive into various storage drivers supported by Docker, and the basic commands
    associated with them for management. The three main use cases for Docker data
    volumes are as follows:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了数据卷和存储驱动程序的概念，在Docker中被广泛用于管理持久或共享数据。我们还将深入研究Docker支持的各种存储驱动程序，以及与其相关的基本命令进行管理。Docker数据卷的三个主要用例如下：
- en: To keep data persistent after a container is deleted
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在容器被删除后保持数据持久
- en: To share data between the host and the Docker container
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在主机和Docker容器之间共享数据
- en: To share data across Docker containers
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于在Docker容器之间共享数据
- en: In order to understand a Docker volume, we need to understand how the Docker
    filesystem works. Docker images are stored as a series of read-only layers. When
    the container is started, the read-only image adds a read-write layer on top.
    If the current file needs to be modified, it is copied from the read-only layer
    to the read-write layer, where changes are applied. The version of the file in
    the read-write layer hides the underlying file but doesn't destroy it. Thus, when
    a Docker container is deleted, relaunching the image will start a fresh container
    with a fresh read-write layer and all the changes are lost. The combination of
    read-write layers on top of the read-only layer is termed the **Union File System**
    (**UFS**). In order to persist the data and be able to share it with the host
    and other containers, Docker has come up with the concept of volumes. Basically,
    volumes are directories that exist outside the UFS and behave as normal directories
    or files on the host filesystem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解Docker卷，我们需要了解Docker文件系统的工作原理。Docker镜像存储为一系列只读层。当容器启动时，只读镜像在顶部添加一个读写层。如果需要修改当前文件，则将其从只读层复制到读写层，然后应用更改。读写层中的文件版本隐藏了底层文件，但并未销毁它。因此，当删除Docker容器时，重新启动镜像将启动一个带有全新读写层的全新容器，并且所有更改都将丢失。位于只读层之上的读写层的组合称为**联合文件系统**（**UFS**）。为了持久保存数据并能够与主机和其他容器共享，Docker提出了卷的概念。基本上，卷是存在于UFS之外的目录，并在主机文件系统上表现为普通目录或文件。
- en: 'Some important features of Docker volumes are as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: Docker卷的一些重要特性如下：
- en: Volumes can be initialized when the container is created
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在创建容器时可以初始化卷
- en: Data volumes can be reused and shared among other data containers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据卷可以被重用并在其他数据容器之间共享
- en: Data volumes persist the data even if a container is deleted
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据卷即使容器被删除也可以保留数据
- en: Changes to the data volume are made directly, bypassing the UFS
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据卷的更改是直接进行的，绕过了UFS
- en: 'In this chapter, we will cover the following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下内容：
- en: Data-only containers
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅数据容器
- en: Hosting a mapped volume backed up by shared storage
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托管由共享存储支持的映射卷
- en: Docker storage driver performance
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker存储驱动程序性能
- en: Avoiding troubleshooting by understanding Docker volumes
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过理解Docker卷来避免故障排除
- en: In this section, we'll be looking at four ways to deal with data and Docker
    containers, which will help us to understand and achieve the preceding use cases
    mentioned with Docker volumes.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨处理数据和Docker容器的四种方法，这将帮助我们理解并实现前面提到的Docker卷的用例。
- en: Default case storing data inside the Docker container
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认情况下将数据存储在Docker容器内部
- en: 'In this case, data is only visible inside the Docker containers and is not
    from the host system. The data is lost if the container is shut down or the Docker
    host dies. This case mostly works with services that are packaged in Docker containers
    and are not dependent on persistent data when they return:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，数据只能在Docker容器内部可见，而不是来自主机系统。如果容器关闭或Docker主机死机，数据将丢失。这种情况主要适用于打包在Docker容器中的服务，并且在它们返回时不依赖于持久数据：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'As seen in the preceding example, the `hello.txt` file only exists inside the
    container and will not be persisted once the container dies:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的例子所示，`hello.txt`文件只存在于容器内部，一旦容器关闭，它将不会被保存。
- en: '![Default case storing data inside the Docker container](graphics/image_09_001.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![默认情况下将数据存储在Docker容器内部](graphics/image_09_001.jpg)'
- en: Data stored inside Docker Container
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 存储在Docker容器内部的数据
- en: Data-only container
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据专用容器
- en: 'Data can be stored outside the Docker UFS in a data-only container. The data
    will be visible inside the data-only container mount namespace. As the data is
    persisted outside the container, it remains even after the container is deleted.
    If any other container wants to connect to this data-only container, simply use
    the `--volumes-from` option to grab the container and apply it to the current
    container. Let''s try out data volume container:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 数据可以存储在Docker UFS之外的数据专用容器中。数据将在数据专用容器的挂载命名空间内可见。由于数据持久保存在容器之外，即使容器被删除，数据仍然存在。如果任何其他容器想要连接到这个数据专用容器，只需使用`--volumes-from`选项来获取容器并将其应用到当前容器。让我们尝试使用数据卷容器：
- en: '![Data-only container](graphics/image_09_002.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![数据专用容器](graphics/image_09_002.jpg)'
- en: Using a data-only container
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 使用数据专用容器
- en: Creating a data-only container
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建数据专用容器
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In the preceding command, we created an Ubuntu container and attached `/tmp`.
    It is a data-only container based on the Ubuntu image, and exists in the `/tmp`
    directory. If the new Ubuntu container needs to write some data to the `/tmp`
    directory of our data-only container, this can be achieved with help of `--volumes-from`
    option. Now, anything we write to the `/tmp` directory of the new container will
    be saved in the `/tmp` volume of the Ubuntu data container:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的命令中，我们创建了一个Ubuntu容器并附加了`/tmp`。它是基于Ubuntu镜像的数据专用容器，并存在于`/tmp`目录中。如果新的Ubuntu容器需要向我们的数据专用容器的`/tmp`目录写入一些数据，可以通过`--volumes-from`选项实现。现在，我们在新容器的`/tmp`目录中写入的任何内容都将保存在Ubuntu数据容器的`/tmp`卷中：
- en: '[PRE2]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Use a data-volume container in container-1:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器-1中使用数据卷容器：
- en: '[PRE3]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Use a data-volume container in container-2 to get the data shared by container-1:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器-2中使用数据卷容器来获取容器-1共享的数据：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As we can see, container-2 gets the data written by container-1 in the `/tmp`
    space. These examples demonstrate the basic usage of data-only containers.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，容器-2获得了容器-1在`/tmp`空间中写入的数据。这些示例演示了数据专用容器的基本用法。
- en: Sharing data between the host and the Docker container
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在主机和Docker容器之间共享数据
- en: This is a common use case where it is necessary to share files between the host
    and the Docker container. In this scenario, we don't need to create a data-only
    container; we can simply run a container of any Docker image and simply override
    one of its directories with content from the host system directory.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个常见的用例，需要在主机和Docker容器之间共享文件。在这种情况下，我们不需要创建一个数据专用容器；我们可以简单地运行任何Docker镜像的容器，并简单地用主机系统目录的内容覆盖其中一个目录。
- en: 'Let''s consider an example where we want to access the logs of Docker NGINX from
    the host system. Currently, they are not available outside the host, but this
    can be achieved simply by mapping the `/var/log/nginx` from inside the container
    to a directory on the host system. In this scenario, we will run a copy of the
    NGINX image with a shared volume from the host system, as shown here:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个例子，我们想要从主机系统访问Docker NGINX的日志。目前，它们在主机外部不可用，但可以通过简单地将容器内的`/var/log/nginx`映射到主机系统上的一个目录来实现。在这种情况下，我们将使用来自主机系统的共享卷运行NGINX镜像的副本，如下所示：
- en: '![Sharing data between the host and the Docker container](graphics/image_09_003.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![在主机和Docker容器之间共享数据](graphics/image_09_003.jpg)'
- en: Sharing data between the host and Docker container
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在主机和Docker容器之间共享数据
- en: 'Create a `serverlogs` directory in the host system:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在主机系统中创建一个`serverlogs`目录：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Run the NGINX container and map `/home/serverlogs` to the `/var/log/nginx`
    directory inside the Docker container:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 运行NGINX容器，并将`/home/serverlogs`映射到Docker容器内的`/var/log/nginx`目录：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Access `http://localhost:5000` from the host system, post this, logs will be
    generated, and they can be accessed on the host system in `/home/serverlogs` directory,
    which is mapped to `/var/log/nginx` inside the Docker container, as shown here:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从主机系统访问`http://localhost:5000`，之后将生成日志，并且可以在主机系统中的`/home/serverlogs`目录中访问这些日志，该目录映射到Docker容器内的`/var/log/nginx`，如下所示：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Host mapped volume backed up by shared storage
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 由共享存储支持的主机映射卷
- en: Docker volume plugins allow us to mount a shared storage backend. The main advantage
    of this is that the user will never suffer data loss in the case of host failure,
    as it is backed by shared storage. In the preceding approaches, if we migrate
    the container, the volumes doesn't get migrated. It can be achieved with the help
    of external Docker volume plugins such **Flocker** and **Convy**, which make the
    volume portable and help to migrate the containers across hosts with volumes easily,
    as well as protecting the data, as it is not dependent on the host file system.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Docker卷插件允许我们挂载共享存储后端。这样做的主要优势是用户在主机故障的情况下不会遭受数据丢失，因为它由共享存储支持。在先前的方法中，如果我们迁移容器，卷不会被迁移。可以借助外部Docker卷插件实现这一点，例如**Flocker**和**Convy**，它们使卷可移植，并有助于轻松迁移带有卷的容器，同时保护数据，因为它不依赖于主机文件系统。
- en: Flocker
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Flocker
- en: Flocker is widely used to run containerized stateful services and applications
    that require persistent storage. Docker provides a very basic view of volume management,
    but Flocker enhances it by providing durability, failover, and high availability
    of the volumes. Flocker can be deployed manually with Docker Swarm and compose,
    or can be set up easily on AWS with the help of the CloudFormation template if
    the backed up storage has to be used in production set ups.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker被广泛用于运行容器化的有状态服务和需要持久存储的应用程序。Docker提供了卷管理的基本视图，但Flocker通过提供卷的耐久性、故障转移和高可用性来增强它。Flocker可以手动部署到Docker
    Swarm和compose中，或者可以借助CloudFormation模板在AWS上轻松设置，如果备份存储必须在生产设置中使用。
- en: 'Flocker can be deployed easily on AWS with the help of the following steps:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker可以通过以下步骤轻松部署到AWS上：
- en: Log in to your AWS account and create a key pair in Amazon EC2.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到您的AWS帐户并在Amazon EC2中创建一个密钥对。
- en: Select **CloudFormation** from the home page of AWS.
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从AWS的主页中选择**CloudFormation**。
- en: 'The Flocker cloud formation stack can be launched with the help of the template
    in the AWS S3 storage using the following link: `https://s3.amazonaws.com/installer.downloads.clusterhq.com/flocker-cluster.cloudformation.json`'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Flocker云形成堆栈可以使用AWS S3存储中的模板启动，链接如下：`https://s3.amazonaws.com/installer.downloads.clusterhq.com/flocker-cluster.cloudformation.json`
- en: Select create stack; then select the second option and specify the Amazon S3
    template URL:![Flocker](graphics/image_09_004.jpg)
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择创建堆栈；然后选择第二个选项并指定Amazon S3模板URL：![Flocker](graphics/image_09_004.jpg)
- en: On the next screen, specify the **Stack name**, **AmazonAccessKeyID**, and **AmazonSecretAccessKey**
    for the account:![Flocker](graphics/image_09_005.jpg)
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一个屏幕上，指定**堆栈名称**，**AmazonAccessKeyID**和**AmazonSecretAccessKey**：![Flocker](graphics/image_09_005.jpg)
- en: Provide the key-value pairs to tag this Flocker stack, and provide the **IAM
    Role** for this stack if required:![Flocker](graphics/image_09_006.jpg)
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供键值对以标记此Flocker堆栈，并在必要时提供此堆栈的**IAM角色**：![Flocker](graphics/image_09_006.jpg)
- en: Review the details and launch the Flocker cloud formation stack:![Flocker](graphics/image_09_007.jpg)
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查详细信息并启动Flocker云形成堆栈：![Flocker](graphics/image_09_007.jpg)
- en: Once, the stack deployment is completed from the outputs tab, get the IP address
    of the client node and control node. SSH into the client node using the key-value
    pair generated during the start of the Flocker stack deployment.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦从输出选项卡完成堆栈部署，获取客户端节点和控制节点的IP地址。使用在Flocker堆栈部署开始时生成的键值对SSH进入客户端节点。
- en: 'Set the following parameters:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 设置以下参数：
- en: '[PRE8]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: If the Flocker `status` and `ls` commands ran successfully, this means the Docker
    Swarm and Flocker have been successfully set up on the AWS.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Flocker的`status`和`ls`命令成功运行，这意味着Docker Swarm和Flocker已成功在AWS上设置。
- en: 'The Flocker volume can be easily set up and allows you to create a container
    that will persist beyond the lifecycle of the container or container host:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Flocker卷可以轻松设置，并允许您创建一个将超出容器或容器主机生命周期的容器：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: An external storage block will be created and mounted, to our host and the container
    directory will be bounded to it. If the container is deleted or the host crashes,
    the data remains secured. The alternate container can be brought up in the second
    host using the same command, and we will be able to access our shared storage.
    The preceding tutorial was to set up Flocker on the AWS for a production use case,
    but we can also test Flocker locally with the help of Docker Swarm setup. Let
    us consider a use case where you have two Docker Swarm nodes and a Flocker client
    node.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 将创建并挂载外部存储块到我们的主机上，并将容器目录绑定到它。如果容器被删除或主机崩溃，数据仍然受到保护。可以使用相同的命令在第二个主机上启动备用容器，并且我们将能够访问我们的共享存储。前面的教程是为了在AWS上为生产用例设置Flocker，但我们也可以通过Docker
    Swarm设置在本地测试Flocker。让我们考虑一个使用情况，您有两个Docker Swarm节点和一个Flocker客户端节点。
- en: In the Flocker client node
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Flocker客户端节点
- en: 'Create a `docker-compose.yml` file and define the containers `redis` and `clusterhq/flask`.
    Provide the respective configuration Docker image, names, ports, and data volumes:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`docker-compose.yml`文件，并定义容器`redis`和`clusterhq/flask`。提供相应的配置Docker镜像、名称、端口和数据卷：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Create a file named `flocker-deploy.yml`, where we will define both containers
    that will be deployed on the same nodes-`node-1`; leave `node-2` blank as of now
    of the Swarm cluster:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为`flocker-deploy.yml`的文件，在其中我们将定义将部署在相同节点`node-1`上的两个容器；暂时将`node-2`留空作为Swarm集群的一部分：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Deploy the containers using the preceding `.yml` files; we simply need to run
    the following command to do so:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前述的`.yml`文件部署容器；我们只需要运行以下命令即可：
- en: '[PRE12]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The cluster configuration has been updated. It may take a short while for the
    changes to take effect, in particular if Docker images need to be pulled.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 集群配置已更新。可能需要一段时间才能生效，特别是如果需要拉取Docker镜像。
- en: 'Both containers can be observed running in `node-1`. Once the setup has been
    done, we can access the application on `http://node-1`. It will show the visit
    count of this webpage:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 两个容器都可以在`node-1`上运行。一旦设置完成，我们可以在`http://node-1`上访问应用程序。它将显示此网页的访问计数：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Recreate the deployment file in order to move the container to `node-2`:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 重新创建部署文件以将容器移动到`node-2`：
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we''ll be migrating the container from `node-1` to `node-2`, and we''ll
    see that Flocker will auto handle the volume management. It will plug the existing
    volume to the Redis container when it comes up in `node-2`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将把容器从`node-1`迁移到`node-2`，我们将看到Flocker将自动处理卷管理。当Redis容器在`node-2`上启动时，它将连接到现有的卷：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The cluster configuration has been updated. It may take a short while for the
    changes to take effect, in particular if Docker images need to be pulled.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 集群配置已更新。这可能需要一段时间才能生效，特别是如果需要拉取Docker镜像。
- en: 'We can SSH into `node-2` and list the running Redis container. Try to access
    the application on `http://node2`; we''ll be able to see that the count is still
    persisted as it were in `node-1` and gets incremented by `1` as the application
    is accessed from `node-2`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以SSH进入`node-2`并列出正在运行的Redis容器。尝试访问`http://node2`上的应用程序；我们将能够看到计数仍然保持在`node-1`中，并且当从`node-2`访问应用程序时，计数会增加`1`：
- en: '[PRE16]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This example demonstrates how easily we can migrate the container with its data
    volume in a Flocker cluster from one node to another.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子演示了我们如何在Flocker集群中轻松地将容器及其数据卷从一个节点迁移到另一个节点。
- en: Convoy Docker volume plugin
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Convoy Docker卷插件
- en: 'Convoy is the other Docker volume plugin that is widely used to provide storage
    backend. It is written in Go and the main advantage is that it can be deployed
    in standalone mode. Convoy will run as a Docker volume extension, and will behave
    like an intermediate container. The initial implementation of Convoy utilizes
    Linux devices and provides the following four Docker storage function for volumes:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Convoy是另一个广泛使用的Docker卷插件，用于提供存储后端。它是用Go语言编写的，其主要优势是可以以独立模式部署。Convoy将作为Docker卷扩展运行，并且会像一个中间容器一样运行。Convoy的初始实现利用Linux设备，并为卷提供以下四个Docker存储功能：
- en: Thin provisioned volumes
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 薄配置卷
- en: Restore volumes across hosts
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在主机之间恢复卷
- en: Take snapshots of volumes
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对卷进行快照
- en: Back up the volumes to external object stores such as **Amazon EBS**, **Virtual
    File System** (**VFS**), and **Network File System** (**NFS**):![Convoy Docker
    volume plugin](graphics/image_09_008.jpg)
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将卷备份到外部对象存储，如**Amazon EBS**，**虚拟文件系统**（**VFS**）和**网络文件系统**（**NFS**）：![Convoy
    Docker卷插件](graphics/image_09_008.jpg)
- en: Using Convoy volume plugin
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Convoy卷插件
- en: 'In the following example, we''ll be running a local Convoy device mapper driver
    and showcasing the use of the Convoy volume plugin in between two containers for
    sharing the data:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的例子中，我们将运行一个本地的Convoy设备映射驱动程序，并展示在两个容器之间使用Convoy卷插件共享数据的用法：
- en: Verify the Docker version is above 1.8.
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证Docker版本是否高于1.8。
- en: 'Install the Convoy plugin by locally downloading the plugin tar file and extracting
    it:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过本地下载插件tar文件并解压缩来安装Convoy插件：
- en: '[PRE17]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We can go ahead and use the file backed loop device which acts as a pseudo
    device and makes file accessible as a block device in order to demo the Convoy
    device mapper driver:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以继续使用文件支持的环回设备，它充当伪设备，并使文件可在块设备中访问，以演示Convoy设备映射驱动程序：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once the data and metadata device is setup start Convoy plugin daemon:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦数据和元数据设备设置好，启动Convoy插件守护程序：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'In the preceding Terminal, the Convoy daemon will start running; open the next
    Terminal instance and create a `busybox` Docker container, which uses the Convoy
    volume `test_volume` mounted at `/sample` directory inside the container:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在前面的终端中，Convoy守护程序将开始运行；打开下一个终端实例并创建一个使用Convoy卷`test_volume`挂载到容器内`/sample`目录的`busybox`
    Docker容器：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Create a sample file in the mounted directory:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在挂载的目录中创建一个示例文件：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Start a different container by using the volume driver as Convoy and mount
    the same Convoy volume:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Convoy作为卷驱动程序启动不同的容器，并挂载相同的Convoy卷：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As we do `ls`, we''ll be able to see the file created in the previous container:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们执行`ls`时，我们将能够看到在先前容器中创建的文件：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Thus, the preceding example shows how Convoy can allow the sharing of volumes
    between containers residing in the same, or a different, host.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前面的例子显示了Convoy如何允许在同一主机或不同主机上的容器之间共享卷。
- en: 'Basically, the volume driver should be used for persistent data such as WordPress
    MySQL DB:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，卷驱动程序应该用于持久数据，例如WordPress MySQL DB：
- en: '[PRE24]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: In the preceding example, we have started the MySQL DB using the Convoy volume
    driver in order to provide persistence in case the host fails. We then linked
    the MySQL database in the WordPress Docker container.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们使用Convoy卷驱动程序启动了MySQL DB，以便在主机故障时提供持久性。然后我们将MySQL数据库链接到WordPress Docker容器中。
- en: Docker storage driver performance
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker存储驱动程序性能
- en: In this section, we'll be looking into the performance aspect and comparison
    of file systems supported by Docker. Pluggable storage driver architecture and
    the flexibility to plug in a volume is the best approach for containerized environments
    and production use cases. Docker supports the aufs, btrfs, devicemapper, vfs,
    zfs, and overlayfs filesystems.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将研究Docker支持的文件系统的性能方面和比较。可插拔的存储驱动程序架构和灵活性插入卷是容器化环境和生产用例的最佳方法。Docker支持aufs、btrfs、devicemapper、vfs、zfs和overlayfs文件系统。
- en: UFS basics
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: UFS基础知识
- en: As discussed previously, Docker uses UFS in order to have a read-only, layered
    approach.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，Docker使用UFS以实现只读的分层方法。
- en: Docker uses UFS to combine several such layers into a single image. This section
    will take a deep dive into the basics of UFS and storage drivers supported by
    Docker.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用UFS将多个这样的层合并为单个镜像。本节将深入探讨UFS的基础知识以及Docker支持的存储驱动程序。
- en: UFS recursively merges several directories into a single virtual view. The fundamental
    desire of UFS is to have a read-only file system and some writable overlay on
    it. This gives the illusion that the file system has read-write access, even though
    it is read-only. UFS uses copy-on-write to support this feature. Also, UFS operates
    on directories instead of drives.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: UFS递归地将多个目录合并为单个虚拟视图。UFS的基本愿望是拥有一个只读文件系统和一些可写的覆盖层。这会产生一个假象，即文件系统具有读写访问权限，即使它是只读的。UFS使用写时复制来支持此功能。此外，UFS操作的是目录而不是驱动器。
- en: 'The underlying filesystem does not matter. UFS can combine directories from
    different underlying file systems. Combining different underlying filesystems
    is possible because UFS intercepts the operations bound to those file systems.
    The following diagram shows that the UFS lies between the user applications and
    filesystems. Examples of UFS are Union FS, Another Union FS (AUFS), and so on:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 底层文件系统并不重要。UFS可以合并来自不同底层文件系统的目录。由于UFS拦截了与这些文件系统绑定的操作，因此可以合并不同的底层文件系统。下图显示了UFS位于用户应用程序和文件系统之间。UFS的示例包括Union
    FS、Another Union FS（AUFS）等：
- en: '![UFS basics](graphics/B04534_09_9.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![UFS基础知识](graphics/B04534_09_9.jpg)'
- en: UFS and underlying file systems for branches
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: UFS和分支的底层文件系统
- en: UFS - terminology
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UFS - 术语
- en: Branches in UFS are filesystems that are merged. Branches can have different
    access permissions, such as read-only, read-write, and so on. UFSs are stackable
    filesystems. The branches can also be assigned preferences, which determine the
    order in which operations will be performed on the filesystems. If a directory
    with the same file name exists in multiple branches, the contents of the directory
    appear to be merged in the UFS, but the operations on the files in those directories
    are redirected to respective filesystems.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: UFS中的分支是合并的文件系统。分支可以具有不同的访问权限，例如只读、读写等。UFS是可堆叠的文件系统。分支还可以被分配偏好，确定对文件系统执行操作的顺序。如果在多个分支中存在具有相同文件名的目录，则UFS中的目录内容似乎被合并，但对这些目录中的文件的操作会被重定向到各自的文件系统。
- en: UFS allows us to create a writable layer over a read-only file system and create
    new files/directories. It also allows the updating of existing files. The existing
    files are updated by copying the file to the writable layer and then making the
    changes. A file in a read-only file system is kept as it is, but the virtual view
    created by UFS will show an updated file. This phenomenon of copying a file to
    a writable layer to update it is called copy-up.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: UFS允许我们在只读文件系统上创建可写层，并创建新文件/目录。它还允许更新现有文件。通过将文件复制到可写层，然后进行更改来更新现有文件。只读文件系统中的文件保持不变，但UFS创建的虚拟视图将显示更新后的文件。将文件复制到可写层以更新它的现象称为复制上升。
- en: With copy-up in place, removing files becomes complex. When trying to delete
    a file, we have to delete all the copies from bottom to top. This can result in
    errors on read-only layers, which cannot remove the file. In such situations,
    the file is removed from writable layers, but still exists in the read-only layers
    below.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 使用复制上升后，删除文件变得复杂。在尝试删除文件时，我们必须从底部到顶部删除所有副本。这可能导致只读层上的错误，无法删除文件。在这种情况下，文件会从可写层中删除，但仍然存在于下面的只读层中。
- en: UFS - issues
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: UFS - 问题
- en: The most obvious problem with UFS is support for underlying filesystems. Since
    UFS wraps the necessary branches and their filesystems, the filesystem support
    has to be added in the UFS source code. The underlying filesystems do not change,
    but UFS has to add support for each one of them.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: UFS最明显的问题是对底层文件系统的支持。由于UFS包装了必要的分支及其文件系统，因此必须在UFS源代码中添加文件系统支持。底层文件系统不会改变，但UFS必须为每个文件系统添加支持。
- en: The whiteouts created after removing files also cause a lot of problems. First
    and foremost is that they pollute the filesystem namespace. This can be reduced
    by adding whiteouts in a single sub-directory, but that needs special handling.
    Also, because of whiteouts, `rmdir` performance degrades. Even if a directory
    seems empty, it might contain a lot of whiteouts, because of which `rmdir` cannot
    remove the directory.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 删除文件后创建的白出也会造成很多问题。首先，它们会污染文件系统命名空间。可以通过在单个子目录中添加白出来减少这种情况，但这需要特殊处理。此外，由于白出，`rmdir`的性能会下降。即使一个目录看起来是空的，它可能包含很多白出，因此`rmdir`无法删除该目录。
- en: 'Copy-up is an excellent feature in UFS, but it also has drawbacks. It reduces
    the performance for the first update, as it has to copy the complete file and
    directory hierarchy to a writable layer. Also, the time of directory copies needs
    to be decided. There are two choices: copy the whole directory hierarchy while
    updating, or do it when the directory is opened. Both techniques have their trade-offs.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在UFS中，复制上升是一个很好的功能，但它也有缺点。它会降低第一次更新的性能，因为它必须将完整的文件和目录层次结构复制到可写层。此外，需要决定目录复制的时间。有两种选择：在更新时复制整个目录层次结构，或者在打开目录时进行复制。这两种技术都有各自的权衡。
- en: AuFS
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AuFS
- en: AuFS is another UFS. AuFS is forked from the UFS file system. This caught the
    eye of developers, and is now way ahead of UFS. In fact, UFS is now following
    some of the design decisions taken while developing AuFS. Like any UFS, AuFS makes
    existing filesystem and overlays a unified view on it.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: AuFS是另一种UFS。AuFS是从UFS文件系统分叉出来的。这引起了开发者的注意，并且现在远远领先于UFS。事实上，UFS现在在遵循开发AuFS时所做的一些设计决策。像任何UFS一样，AuFS使现有的文件系统和叠加在其上形成一个统一的视图。
- en: AuFS supports all the UFS features mentioned in the previous sections. You need
    to install the `aufs-tools` package on Ubuntu to use AuFS commands. More information
    about AuFS and its commands can be found on the AuFS man page.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: AuFS支持前几节中提到的所有UFS功能。您需要在Ubuntu上安装`aufs-tools`软件包才能使用AuFS命令。有关AuFS及其命令的更多信息，请参阅AuFS手册页。
- en: Device Mapper
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 设备映射器
- en: '**Device Mapper** is a Linux kernel component; it provides a mechanism for
    mapping physical block devices onto virtual block devices. These mapped devices
    can be used as logical volumes. Device Mapper provides a generic way to create
    such mappings.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**设备映射器**是Linux内核组件；它提供了将物理块设备映射到虚拟块设备的机制。这些映射设备可以用作逻辑卷。设备映射器提供了创建这种映射的通用方法。'
- en: 'Device Mapper maintains a table, which defines device mappings. The table specifies
    how to map each range of logical sectors of the device. The table contains lines
    for the following parameters:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 设备映射器维护一个表，该表定义了设备映射。该表指定了如何映射设备的每个逻辑扇区范围。该表包含以下参数的行：
- en: '`start`'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`起始`'
- en: '`length`'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`长度`'
- en: '`mapping`'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`映射`'
- en: '`mapping_parameters`'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`映射参数`'
- en: The `start` value for the first line is always zero. For other lines, start
    plus the length of the previous line should be equal to the `start` value of the
    current line. Device Mapper sizes are always specified in 512 byte sectors. There
    are different types of mapping targets, such as linear, striped, mirror, snapshot,
    snapshot-origin, and so on.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行的`起始`值始终为零。对于其他行，起始加上前一行的长度应等于当前行的`起始`值。设备映射器的大小始终以512字节扇区指定。有不同类型的映射目标，例如线性、条带、镜像、快照、快照原点等。
- en: How device-mapper is used by Docker
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker如何使用设备映射器
- en: Docker uses the thin provisioning and snapshots features of Device Mapper. These
    features allow many virtual devices to be stored on the same data volume. Two
    separate devices are used for data and metadata. The data device is utilized for
    the pool itself and the metadata device contains information about volumes, snapshots,
    blocks in the storage pool, and mapping between the blocks of each snapshot. So,
    Docker creates a single large block device on which a thin pool is created. It
    then creates a base block device. Every image and container is formed from the
    snapshot of this base device.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用设备映射器的薄配置和快照功能。这些功能允许许多虚拟设备存储在同一数据卷上。数据和元数据使用两个单独的设备。数据设备用于池本身，元数据设备包含有关卷、快照、存储池中的块以及每个快照的块之间的映射的信息。因此，Docker创建了一个单个的大块设备，然后在其上创建了一个薄池。然后创建一个基本块设备。每个镜像和容器都是从此基本设备的快照中形成的。
- en: BTRFS
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: BTRFS
- en: '**BTRFS** is a Linux filesystem that has the potential to replace the current
    default Linux filesystem, EXT3/EXT4\. BTRFS (also known as **butter FS**) is basically
    a copy-on-write filesystem. **Copy-on-Write** (**CoW**) means it never updates
    the data. Instead, it creates a new copy of that part of the data which is stored
    somewhere else on the disk, keeping the old part as it is. Anyone with decent
    filesystem knowledge will understand that CoW requires more space because it stores
    the old copies of data as well. Also, it has the problem of fragmentation. So,
    how can a CoW filesystem be used as a default Linux filesystem? Wouldn''t that
    reduce the performance? No need to mention the storage space problem. Let''s dive
    into BTRFS to understand why it has become so popular.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**BTRFS**是一个Linux文件系统，有潜力取代当前默认的Linux文件系统EXT3/EXT4。BTRFS（也称为**butter FS**）基本上是一个写时复制文件系统。**写时复制**（**CoW**）意味着它永远不会更新数据。相反，它会创建数据的新副本，该副本存储在磁盘的其他位置，保留旧部分不变。任何具有良好文件系统知识的人都会理解，写时复制需要更多的空间，因为它也存储了旧数据的副本。此外，它还存在碎片化的问题。那么，写时复制文件系统如何成为默认的Linux文件系统呢？这不会降低性能吗？更不用说存储空间的问题了。让我们深入了解BTRFS，了解为什么它变得如此受欢迎。'
- en: The primary design goal of BTRFS was to develop a generic filesystem that can
    perform well with any use case and workload. Most filesystems perform well for
    a specific filesystem benchmark, and performance is not that great for other scenarios.
    Apart from this, BTRFS also supports snapshots, cloning, and RAID (Level 0, 1,
    5, 6, 10). This is more than anyone has previously bargained for from a filesystem.
    One can understand the design complexity, because Linux filesystems are deployed
    on all kinds of devices, from computers and smart phones to small embedded devices.
    The BTRFS layout is represented with B-trees, more like a forest of B-trees. These
    are copy-on-write-friendly B-trees. As CoW filesystems require a little more disk
    space, in general, BTRFS has a very sophisticated mechanism for space reclamation.
    It has a garbage collector, which makes use of reference counting to reclaim unused
    disk space. For data integrity, BTRFS uses check sums.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: BTRFS的主要设计目标是开发一种通用文件系统，可以在任何用例和工作负载下表现良好。大多数文件系统对于特定的文件系统基准测试表现良好，但在其他情况下性能并不那么好。除此之外，BTRFS还支持快照、克隆和RAID（0级、1级、5级、6级、10级）。这比以往任何人从文件系统中得到的都要多。人们可以理解设计的复杂性，因为Linux文件系统部署在各种设备上，从计算机和智能手机到小型嵌入式设备。BTRFS布局用B树表示，更像是一片B树的森林。这些是适合写时复制的B树。由于写时复制文件系统通常需要更多的磁盘空间，总的来说，BTRFS具有非常复杂的空间回收机制。它有一个垃圾收集器，利用引用计数来回收未使用的磁盘空间。为了数据完整性，BTRFS使用校验和。
- en: 'The storage driver can be selected by passing the `--storage-driver` option
    to the `dockerd` command line, or setting the `DOCKER_OPTS` option in the `/etc/default/docker`
    file:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 存储驱动程序可以通过将`--storage-driver`选项传递给`dockerd`命令行，或在`/etc/default/docker`文件中设置`DOCKER_OPTS`选项来选择：
- en: '[PRE25]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We have considered the preceding three widely used filesystems with Docker
    in order to do performance analysis for the following Docker commands using micro
    benchmark tools; `fio` is the tool used to analyze the details of the filesystem,
    such as random write:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经考虑了前面三种广泛使用的文件系统与Docker，以便使用微基准测试工具对以下Docker命令进行性能分析；`fio`是用于分析文件系统详细信息的工具，比如随机写入：
- en: '`commit`: This is used to create a Docker image out of a running container:![BTRFS](graphics/image_09_010.jpg)'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`commit`：这用于从运行的容器创建Docker镜像：![BTRFS](graphics/image_09_010.jpg)'
- en: Chart depicting the time required to commit a large-size container containing
    a single large file
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图表描述了提交包含单个大文件的大型容器所需的时间
- en: '`build`: This is used to build an image from using a Dockerfile which contains
    a set of steps to be followed to create an image from scratch containing a single
    large file:![BTRFS](graphics/image_09_011.jpg)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`build`：用于使用包含一系列步骤的Dockerfile构建镜像的命令，以便从头开始创建包含单个大文件的镜像：![BTRFS](graphics/image_09_011.jpg)'
- en: Chart depicting the time required to build the container on different file systems
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图表描述了在不同文件系统上构建容器所需的时间
- en: '`rm`: This is used to remove a stopped container:![BTRFS](graphics/image_09_012.jpg)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rm`：用于删除已停止的容器的命令：![BTRFS](graphics/image_09_012.jpg)'
- en: Chart depicting the time required to remove the container holding many thousands
    of files using the rm command
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图表描述了使用rm命令删除包含成千上万文件的容器所需的时间。
- en: '`rmi`: This is used to remove an image:![BTRFS](graphics/image_09_013.jpg)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rmi`：用于删除镜像的命令：![BTRFS](graphics/image_09_013.jpg)'
- en: Chart depicting the time required to remove a large size container containing
    a single large file using the rmi command
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图表描述了使用rmi命令删除包含单个大文件的大型容器所需的时间
- en: From the preceding tests, we can clearly see that AuFS and BTRFS perform extremely
    well for Docker commands, but BTRFS containers performing many small writes leads
    to poor use of the BTRFS chunk. This can ultimately lead to out-of-space conditions
    on the Docker host and stop working. Using the BTRFS storage driver closely monitors
    the free space on the BTRFS filesystem. Also, due to the BTRFS journaling technique,
    the sequential writes are affected and can halve performance.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的测试中，我们可以清楚地看到，AuFS和BTRFS在Docker命令方面表现非常出色，但是BTRFS容器执行许多小写操作会导致BTRFS块的使用不佳。这最终可能导致Docker主机的空间不足并停止工作。使用BTRFS存储驱动程序可以密切监视BTRFS文件系统上的可用空间。此外，由于BTRFS日志技术，顺序写入受到影响，可能会减半性能。
- en: Device Mapper performs badly, as each time the container updates existing data,
    the storage driver performs a CoW operation. The copy is from the image snapshot
    to the container's snapshot and can have a noticeable impact on container performance.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 设备映射器的性能不佳，因为每次容器更新现有数据时，存储驱动程序执行一次CoW操作。复制是从镜像快照到容器的快照，可能会对容器性能产生明显影响。
- en: AuFS looks like a good choice for PaaS and other similar use-cases where container
    density plays an important role. AuFS efficiently shares images between running,
    enabling a fast container start time and minimal use of disk space. It also uses
    system page cache very efficiently. OverlayFS is a modern filesystem similar to
    AuFS, but with a simpler design and potentially faster. But currently, OverlayFS
    is not mature enough to be used in a production environment. It may be a successor
    to AuFS in the near future. No single driver is well suited for every use case.
    Users should either select the storage driver as per the use case and considering
    the stability required for the application, or go ahead with the default driver
    installed by the distribution's Docker package. If the host system is RHEL or
    a variation, Device Mapper is the default storage driver. For Ubuntu, AuFS is
    the default driver.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: AuFS看起来是PaaS和其他类似用例的不错选择，其中容器密度起着重要作用。AuFS在运行时有效地共享镜像，实现快速容器启动时间和最小磁盘空间使用。它还非常有效地使用系统页面缓存。OverlayFS是一种类似于AuFS的现代文件系统，但设计更简单，可能更快。但目前，OverlayFS还不够成熟，无法在生产环境中使用。它可能会在不久的将来成为AuFS的继任者。没有单一的驱动程序适用于每种用例。用户应根据用例选择存储驱动程序，并考虑应用程序所需的稳定性，或者使用发行版Docker软件包安装的默认驱动程序。如果主机系统是RHEL或其变体，则Device
    Mapper是默认的存储驱动程序。对于Ubuntu，AuFS是默认驱动程序。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we took a deep dive into data volumes and storage driver concepts
    related to Docker. We discussed troubleshooting the data volumes with the help
    of the four approaches, as well as their pros and cons. The first case of storing
    data inside the Docker container is the most basic case, but doesn't provide the
    flexibility to manage and handle data in a production environment. The second
    and third cases are about storing the data using data-only containers or directly
    on the host. These cases help to provide reliability, but still depend on the
    availability of host. The fourth case, which is about using a third-party volume
    plugin such as Flocker or Convoy, solves all of the preceding issues by storing
    the data in a separate block, and provides the reliability with data, even if
    the container is transferred from one host to another or if the container dies.
    In the final section we discussed Docker storage drivers and the plugin architecture
    provided by Docker to use required filesystems such as AuFS, BTRFS, Device Mapper,
    vfs, zfs and OverlayFS. We looked in depth at AuFS, BTRFS, and Device Mapper,
    which are widely used filesystems. From the various tests we conducted using the
    basic Docker commands, AuFS and BTRFS provide a better performance than Device
    Mapper. Users should select a Docker storage driver as per their application use
    case and Docker daemon host system.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入探讨了与Docker相关的数据卷和存储驱动器概念。我们讨论了使用四种方法来排除数据卷故障，以及它们的优缺点。将数据存储在Docker容器内的第一种情况是最基本的情况，但在生产环境中无法灵活管理和处理数据。第二种和第三种情况是关于使用仅数据容器或直接在主机上存储数据。这些情况有助于提供可靠性，但仍然依赖于主机的可用性。第四种情况是关于使用第三方卷插件，如Flocker或Convoy，通过将数据存储在单独的块中解决了所有先前的问题，并在容器从一个主机转移到另一个主机或容器死亡时提供了数据的可靠性。在最后一节中，我们讨论了Docker存储驱动程序和Docker提供的插件架构，以使用所需的文件系统，如AuFS、BTRFS、Device
    Mapper、vfs、zfs和OverlayFS。我们深入研究了AuFS、BTRFS和Device Mapper，这些是广泛使用的文件系统。通过使用基本的Docker命令进行的各种测试表明，AuFS和BTRFS比Device
    Mapper提供更好的性能。用户应根据其应用用例和Docker守护程序主机系统选择Docker存储驱动程序。
- en: In the next chapter, we'll discuss Docker deployment in a public cloud, AWS
    and Azure, and troubleshooting issues.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论Docker在公共云AWS和Azure中的部署以及故障排除。
