- en: '*Chapter 10*: Real-Time Monitoring and Resource Management of a Kubernetes
    Cluster'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第10章*：Kubernetes集群的实时监控和资源管理'
- en: The availability of services is one of the critical components of the **Confidentiality,
    Integrity and Availability** (**CIA**) triad. There have been many instances of
    malicious attackers using different techniques to disrupt the availability of
    services for users. Some of these attacks on critical infrastructure such as the
    electricity grid and banks have resulted in significant losses to the economy.
    One of the most significant attacks was an attack on Amazon AWS Route 53 infrastructure
    that resulted in the disruption of core IT services all over the world. To avoid
    such issues, infrastructure engineers monitor resource usage and application health
    in real time to ensure the availability of services offered by an organization.
    Real-time monitoring is often plugged into an alert system that notifies the stakeholders
    when symptoms of service disruption are observed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 服务的可用性是**机密性、完整性和可用性**（**CIA**）三要素中的关键组成部分之一。曾经有许多恶意攻击者使用不同的技术来破坏用户服务的可用性。一些对关键基础设施的攻击，如电力网络和银行，导致了经济上的重大损失。其中最显著的攻击之一是对亚马逊AWS
    Route 53基础设施的攻击，导致全球核心IT服务中断。为了避免这样的问题，基础设施工程师实时监控资源使用和应用程序健康状况，以确保组织提供的服务的可用性。实时监控通常与警报系统相结合，当观察到服务中断的症状时通知利益相关者。
- en: In this chapter, we will look at how you can ensure that services in the Kubernetes
    cluster are always up and running. We will begin by discussing monitoring and
    resource management in monolith environments. Next, we will discuss resource requests
    and resource limits, two concepts at the heart of resource management in Kubernetes.
    We will then look at tools such as `LimitRanger`, which Kubernetes provides for
    resource management, before shifting our focus to resource monitoring. We will
    look at built-in monitors, such as Kubernetes Dashboard and Metrics Server. Finally,
    we will look at open source tools, such as Prometheus and Grafana, that can be
    used to monitor the state of a Kubernetes cluster.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何确保Kubernetes集群中的服务始终正常运行。我们将首先讨论单体环境中的监控和资源管理。接下来，我们将讨论资源请求和资源限制，这是Kubernetes资源管理的核心概念。然后，我们将看看Kubernetes提供的诸如`LimitRanger`之类的工具，用于资源管理，然后将重点转移到资源监控。我们将研究内置监视器，如Kubernetes仪表板和Metrics
    Server。最后，我们将研究一些开源工具，如Prometheus和Grafana，用于监视Kubernetes集群的状态。
- en: 'In this chapter, we will discuss the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论以下内容：
- en: Real-time monitoring and management in monolith environments
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在单体环境中进行实时监控和管理
- en: Managing resources in Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes中管理资源
- en: Monitoring resources in Kubernetes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes中监控资源
- en: Real-time monitoring and management in monolith environments
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在单体环境中进行实时监控和管理
- en: Resource management and monitoring are important in monolith environments as
    well. In monolith environments, infrastructure engineers often pipe the output
    of Linux tools such as `top`, `ntop`, and `htop` to data visualization tools in
    order to monitor the state of VMs. In managed environments, built-in tools such
    as Amazon CloudWatch and Azure Resource Manager help to monitor resource usage.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 资源管理和监控在单体环境中同样很重要。在单体环境中，基础设施工程师经常将Linux工具（如`top`、`ntop`和`htop`）的输出导入数据可视化工具，以监视虚拟机的状态。在托管环境中，内置工具如Amazon
    CloudWatch和Azure资源管理器有助于监视资源使用情况。
- en: 'In addition to resource monitoring, infrastructure engineers proactively allocate
    minimum resource requirements and usage limits for processes and other entities.
    This ensures that sufficient resources are available to services. Furthermore,
    resource management ensures that misbehaving or malicious processes do not hog
    resources and prevent other processes from working. For monolith deployments,
    resources such as CPU, memory, and spawned processes are capped for different
    processes. On Linux, process limits can be capped using `prlimit`:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 除了资源监控之外，基础设施工程师还会主动为进程和其他实体分配最低资源需求和使用限制。这确保了服务有足够的资源可用。此外，资源管理还确保不良行为或恶意进程不会占用资源并阻止其他进程工作。对于单体部署，诸如CPU、内存和生成的进程等资源会被限制在不同的进程中。在Linux上，可以使用`prlimit`来限制进程的限制：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This command sets the limit of child processes that a parent process can spawn
    to `2`. With this limit set, if a process with a PID of `18065` tries to spawn
    more than `2` child processes, it will be denied.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令设置了父进程可以生成的子进程的限制为`2`。设置了这个限制后，如果一个PID为`18065`的进程尝试生成超过`2`个子进程，它将被拒绝。
- en: Similar to monolith environments, a Kubernetes cluster runs multiple pods, deployments,
    and services. If an attacker is able to spawn up Kubernetes objects such as pods
    or deployments, the attacker can cause a denial-of-service attack by depleting
    resources available in the Kubernetes cluster. Without adequate resource monitoring
    and resource management in place, unavailability of the services running in the
    cluster can cause an economic impact to the organization.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 与单体环境类似，Kubernetes集群运行多个pod、部署和服务。如果攻击者能够生成Kubernetes对象，比如pod或部署，攻击者可以通过耗尽Kubernetes集群中可用的资源来发动拒绝服务攻击。如果没有足够的资源监控和资源管理，集群中运行的服务不可用可能会对组织造成经济影响。
- en: Managing resources in Kubernetes
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes中管理资源
- en: Kubernetes provides the ability to proactively allocate and limit resources
    available to Kubernetes objects. In this section, we will discuss resource requests
    and limits, which form the basis for resource management in Kubernetes. Next,
    we explore namespace resource quotas and limit ranges. Using these two feature,
    clusters, administrators can cap the compute and storage limits available to different
    Kubernetes objects.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了主动分配和限制Kubernetes对象可用资源的能力。在本节中，我们将讨论资源请求和限制，这构成了Kubernetes中资源管理的基础。接下来，我们将探讨命名空间资源配额和限制范围。使用这两个功能，集群管理员可以限制不同Kubernetes对象可用的计算和存储资源。
- en: Resource requests and limits
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源请求和限制
- en: '`kube-scheduler`, as we discussed in [*Chapter 1*](B15566_01_Final_ASB_ePub.xhtml#_idTextAnchor020),
    *Kubernetes Architecture*, is the default scheduler and runs on the master node.
    `kube-scheduler` finds the most optimal node for the unscheduled pods to run on.
    It does that by filtering the nodes based on the storage and compute resources
    requested for the pod. If the scheduler is not able to find a node for the pod,
    the pod will remain in a pending state. Additionally, if all the resources of
    the node are being utilized by the pods, `kubelet` on the node will clean up dead
    pods – unused images. If the cleanup does not reduce the stress, `kubelet` will
    start evicting those pods that consume more resources.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在[*第1章*](B15566_01_Final_ASB_ePub.xhtml#_idTextAnchor020)中讨论的那样，*Kubernetes架构*中，默认的调度程序是`kube-scheduler`，它运行在主节点上。`kube-scheduler`会找到最适合的节点来运行未调度的pod。它通过根据pod请求的存储和计算资源来过滤节点来实现这一点。如果调度程序无法为pod找到节点，pod将保持在挂起状态。此外，如果节点的所有资源都被pod利用，节点上的`kubelet`将清理死掉的pod
    - 未使用的镜像。如果清理不能减轻压力，`kubelet`将开始驱逐那些消耗更多资源的pod。
- en: Resource requests specify what a Kubernetes object is guaranteed to get. Different
    Kubernetes variations or cloud providers have different defaults for resource
    requests. Custom resource requests for Kubernetes objects can be specified in
    the workload's specifications. Resource requests can be specified for CPU, memory,
    and HugePages. Let's look at an example of resource requests.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 资源请求指定了 Kubernetes 对象保证获得的资源。不同的 Kubernetes 变体或云提供商对资源请求有不同的默认值。可以在工作负载的规范中指定
    Kubernetes 对象的自定义资源请求。资源请求可以针对 CPU、内存和 HugePages 进行指定。让我们看一个资源请求的例子。
- en: 'Let''s create a pod without a resource request in the `yaml` specification,
    as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个没有在 `yaml` 规范中指定资源请求的 Pod，如下所示：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The pod will use the default resource request for deployment:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 将使用部署的默认资源请求：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'For the preceding example, the default resource request is for 0.1 CPU cores
    for the pod. Let''s now add a resource request to the `.yaml` specification and
    see what happens:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前面的例子，Pod 的默认资源请求是 0.1 CPU 核心。现在让我们向 `.yaml` 规范中添加一个资源请求并看看会发生什么：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This specification creates a pod with a resource request of 0.5 CPU cores,
    300 MB, and `hugepages-2Mi` of 100 MB. You can check the resource request for
    a pod using the following command:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这个规范创建了一个具有 0.5 CPU 核心、300 MB 和 `hugepages-2Mi` 的 100 MB 的资源请求的 Pod。您可以使用以下命令检查
    Pod 的资源请求：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As you can see from the output, the pod uses a custom resource request of 0.5
    CPU cores, 300 MB of `memory`, and 100 MB of 2 MB `hugepages`, instead of the
    default 1 MB.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，Pod 使用了 0.5 CPU 核心、300 MB `内存` 和 100 MB 2 MB `hugepages` 的自定义资源请求，而不是默认的
    1 MB。
- en: 'Limits, on the other hand, are hard limits on the resources that the pod can
    use. Limits specify the maximum resources that a pod should be allowed to use.
    Pods are restricted if more resources are required than are specified in the limit.
    Similar to resource requests, you can specify limits for CPU, memory, and HugePages.
    Let''s look at an example of limits:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，限制是 Pod 可以使用的资源的硬限制。限制指定了 Pod 应该被允许使用的最大资源。如果需要的资源超过了限制中指定的资源，Pod 将受到限制。与资源请求类似，您可以为
    CPU、内存和 HugePages 指定限制。让我们看一个限制的例子：
- en: '[PRE5]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This pod initiates a stress process that tries to allocate memory of `150M`
    at startup. If no limits are specified in the `.yaml` specification, the pod runs
    without any issues:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 Pod 启动一个尝试在启动时分配 `150M` 内存的压力进程。如果 `.yaml` 规范中没有指定限制，Pod 将可以正常运行：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Limits are added to the container section of the `yaml` specification for the
    pod:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 限制被添加到 Pod 的 `yaml` 规范的容器部分：
- en: '[PRE7]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The stress process fails to run and the pod runs into `CrashLoopBackOff`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 压力进程无法运行，Pod 进入 `CrashLoopBackOff` 状态：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can see that the pod was terminated with an `OOMKilled` error when you
    described the pod:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当您描述 Pod 时，可以看到 Pod 被终止并出现 `OOMKilled` 错误：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Resource requests and limits are converted, mapped to `docker` arguments – `—cpu-shares`
    and `—memory` flags – and passed to the container runtime.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 资源请求和限制被转换、映射到 `docker` 参数——`—cpu-shares` 和 `—memory` 标志——并传递给容器运行时。
- en: We looked at examples of how resource requests and limits work for pods, but
    the same examples apply to DaemonSet, Deployments, and StatefulSets. Next, we
    look at how namespace resource quotas can help set an upper limit for the resources
    that can be used by namespaces.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看了资源请求和限制如何为 Pod 工作的例子，但是相同的例子也适用于 DaemonSet、Deployments 和 StatefulSets。接下来，我们将看一下命名空间资源配额如何帮助设置命名空间可以使用的资源的上限。
- en: Namespace resource quotas
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命名空间资源配额
- en: 'Resource quotas for namespaces help define the resource requests and limits
    available to all objects within the namespace. Using resource quotas, you can
    limit the following:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间的资源配额有助于定义命名空间内所有对象可用的资源请求和限制。使用资源配额，您可以限制以下内容：
- en: '`request.cpu`: The maximum resource request for CPU for all objects in the
    namespace.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`request.cpu`：命名空间中所有对象的CPU的最大资源请求。'
- en: '`request.memory`: The maximum resource request for memory for all objects in
    the namespace.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`request.memory`：命名空间中所有对象的内存的最大资源请求。'
- en: '`limit.cpu`: The maximum resource limit for CPU for all objects in the namespace.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit.cpu`：命名空间中所有对象的CPU的最大资源限制。'
- en: '`limit.memory`: The maximum resource limit for memory for all objects in the
    namespace.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limit.memory`：命名空间中所有对象的内存的最大资源限制。'
- en: '`requests.storage`: The sum of storage requests in a namespace cannot exceed
    this value.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests.storage`：命名空间中存储请求的总和不能超过这个值。'
- en: '`count`: Resource quotas can also be used to limit the count of different Kubernetes
    objects in a cluster, including pods, services, PersistentVolumeClaims, and ConfigMaps.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`count`：资源配额也可以用来限制集群中不同Kubernetes对象的数量，包括pod、服务、PersistentVolumeClaims和ConfigMaps。'
- en: 'By default, cloud providers or different variations have standard limits applied
    to the namespace. On **Google Kubernetes Engine** (**GKE**), the `cpu` request
    is set to 0.1 CPU cores:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，云提供商或不同的变体对命名空间应用了标准限制。在**Google Kubernetes Engine**（**GKE**）上，`cpu`请求被设置为0.1
    CPU核心：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Let''s see an example of what happens when resource quotas are applied to a
    namespace:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个例子，当资源配额应用到一个命名空间时会发生什么：
- en: 'Create a namespace demo:'
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个命名空间演示：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Define a resource quota. In this example, the quota limits the resource request
    CPU to `1` CPU:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个资源配额。在这个例子中，配额将CPU的资源请求限制为`1` CPU：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Apply the quota to the namespace by using the following command:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过以下命令将配额应用到命名空间：
- en: '[PRE13]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can check whether the resource quota is applied successfully to the namespace
    by executing the following command:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以通过执行以下命令来检查资源配额是否成功应用到命名空间：
- en: '[PRE14]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, if we try to create two pods that use `1` CPU, the second request will
    fail with the following error:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果我们尝试创建使用`1` CPU的两个pod，第二个请求将失败，并显示以下错误：
- en: '[PRE15]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Resource quotas ensure quality of service for namespaced Kubernetes objects.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 资源配额确保了命名空间中Kubernetes对象的服务质量。
- en: LimitRanger
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LimitRanger
- en: We discussed the `LimitRanger` admission controller in [*Chapter 7*](B15566_07_Final_ASB_ePub.xhtml#_idTextAnchor186),
    *Authentication, Authorization, and Admission Control*. Cluster administrators
    can leverage limit ranges to ensure that misbehaving pods, containers, or `PersistentVolumeClaims`
    don't consume all available resources.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第7章*](B15566_07_Final_ASB_ePub.xhtml#_idTextAnchor186)中讨论了`LimitRanger`准入控制器，*身份验证、授权和准入控制*。集群管理员可以利用限制范围来确保行为不端的pod、容器或`PersistentVolumeClaims`不会消耗所有可用资源。
- en: 'To use limit ranges, enable the `LimitRanger` admission controller:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用限制范围，启用`LimitRanger`准入控制器：
- en: '[PRE16]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Using LimitRanger, we can enforce `default`, `min`, and `max` limits on storage
    and compute resources. Cluster administrators create a limit range for objects
    such as pods, containers, and PersistentVolumeClaims. For any request for object
    creation or update, the LimitRanger admission controller verifies that the request
    does not violate any limit ranges. If the request violates any limit ranges, a
    403 Forbidden response is sent.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LimitRanger，我们可以对存储和计算资源强制执行`default`、`min`和`max`限制。集群管理员为诸如pod、容器和PersistentVolumeClaims等对象创建一个限制范围。对于任何对象创建或更新的请求，LimitRanger准入控制器会验证请求是否违反了任何限制范围。如果请求违反了任何限制范围，将发送403
    Forbidden响应。
- en: 'Let''s look at an example of a simple limit range:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个简单限制范围的例子：
- en: 'Create a namespace in which a limit range will be applied:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个将应用限制范围的命名空间：
- en: '[PRE17]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Define a `LimitRange` for the namespace:'
  id: totrans-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为命名空间定义一个`LimitRange`：
- en: '[PRE18]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Verify that the `limitrange` was applied:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证`limitrange`是否被应用：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Create a pod that violates the limit range:'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个违反限制范围的pod：
- en: '[PRE20]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This request will be denied:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这个请求将被拒绝：
- en: '[PRE21]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: If a LimitRanger specifies a CPU or memory, all pods and containers should have
    the CPU or memory request or limits. LimitRanger works when the request to create
    or update the object is received by the API Server but not at runtime. If a pod
    has a violating limit before the limit is applied, it will keep running. Ideally,
    limits should be applied to the namespace when it is created.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果LimitRanger指定了CPU或内存，所有的pod和容器都应该有CPU或内存的请求或限制。LimitRanger在API服务器接收到创建或更新对象的请求时起作用，但在运行时不起作用。如果一个pod在限制被应用之前就违反了限制，它将继续运行。理想情况下，限制应该在命名空间创建时应用。
- en: Now that we have looked at a couple of features that can be used for proactive
    resource management, we switch gears and look at tools that can help us monitor
    the cluster and notify us before matters deteriorate.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看了一些可以用于积极资源管理的功能，我们转而看一些可以帮助我们监控集群并在事态恶化之前通知我们的工具。
- en: Monitoring resources in Kubernetes
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控Kubernetes资源
- en: As we discussed earlier, resource monitoring is an essential step for ensuring
    the availability of your services in your cluster. Resource monitoring uncovers
    early signs or symptoms of service unavailability in your clusters. Resource monitoring
    is often complemented with alert management to ensure that stakeholders are notified
    as soon as any problems, or symptoms associated with any problems, in the cluster
    are observed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，资源监控是确保集群中服务可用性的重要步骤。资源监控可以发现集群中服务不可用的早期迹象或症状。资源监控通常与警报管理相结合，以确保利益相关者在观察到集群中出现任何问题或与任何问题相关的症状时尽快收到通知。
- en: In this section, we first look at some built-in monitors provided by Kubernetes,
    including Kubernetes Dashboard and Metrics Server. We look at how we can set it
    up and discuss how to use these tools efficiently. Next, we look at some open
    source tools that can plug into your Kubernetes cluster and provide far more in-depth
    insight than the built-in tools.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们首先看一些由Kubernetes提供的内置监视器，包括Kubernetes Dashboard和Metrics Server。我们将看看如何设置它，并讨论如何有效地使用这些工具。接下来，我们将看一些可以插入到您的Kubernetes集群中并提供比内置工具更深入的洞察力的开源工具。
- en: Built-in monitors
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内置监视器
- en: Let's look at some tools provided by Kubernetes that are used for monitoring
    Kubernetes resources and objects – Metrics Server and Kubernetes Dashboard.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些由Kubernetes提供的用于监控Kubernetes资源和对象的工具 - Metrics Server和Kubernetes Dashboard。
- en: Kubernetes Dashboard
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes Dashboard
- en: Kubernetes Dashboard provides a web UI for cluster administrators to create,
    manage, and monitor cluster objects and resources. Cluster administrators can
    also create pods, services, and DaemonSets using the dashboard. The dashboard
    shows the state of the cluster and any errors in the cluster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Dashboard为集群管理员提供了一个Web UI，用于创建、管理和监控集群对象和资源。集群管理员还可以使用仪表板创建pod、服务和DaemonSets。仪表板显示了集群的状态和集群中的任何错误。
- en: Kubernetes Dashboard provides all the functionality a cluster administrator
    requires in order to manage resources and objects within the cluster. Given the
    functionality of the dashboard, access to the dashboard should be limited to cluster
    administrators. The dashboard has a login functionality starting v1.7.0\. In 2018,
    a privilege escalation vulnerability (CVE-2018-18264) was identified in the dashboard
    that allowed unauthenticated users to log in to the dashboard. There were no known
    in-the-wild exploits for this issue, but this simple vulnerability could have
    wreaked havoc on many Kubernetes distributions.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 仪表板提供了集群管理员在集群中管理资源和对象所需的所有功能。鉴于仪表板的功能，应该将对仪表板的访问限制在集群管理员范围内。从 v1.7.0
    版本开始，仪表板具有登录功能。2018年，仪表板中发现了一个特权升级漏洞（CVE-2018-18264），允许未经身份验证的用户登录到仪表板。对于这个问题，尚无已知的野外利用，但这个简单的漏洞可能会对许多
    Kubernetes 发行版造成严重破坏。
- en: 'Current login functionality allows logging in using a service account and `kubeconfig`.
    It is recommended that service account tokens should be used to access Kubernetes
    Dashboard:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的登录功能允许使用服务账户和 `kubeconfig` 登录。建议使用服务账户令牌来访问 Kubernetes 仪表板：
- en: '![Figure 10.1 – Kubernetes Dashboard'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.1 – Kubernetes 仪表板'
- en: '](image/B15566_10_001.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_001.jpg)'
- en: Figure 10.1 – Kubernetes Dashboard
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 – Kubernetes 仪表板
- en: 'To allow a service account to use the Kubernetes dashboard, you need to add
    the `cluster-admin` role to the service account. Let''s look at an example of
    how a service account can be used to access the Kubernetes dashboard:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了允许服务账户使用 Kubernetes 仪表板，您需要将 `cluster-admin` 角色添加到服务账户中。让我们看一个示例，说明如何使用服务账户来访问
    Kubernetes 仪表板：
- en: 'Create a service account in the default namespace:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在默认命名空间中创建一个服务账户：
- en: '[PRE22]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Associate the `cluster-admin` role with the service account:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 `cluster-admin` 角色与服务账户关联：
- en: '[PRE23]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Fetch the token for the service account:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取服务账户的令牌：
- en: '[PRE24]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Use the following command to fetch the token for the service account:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令获取服务账户的令牌：
- en: '[PRE25]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Use the service account token to log in to the dashboard:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用服务账户令牌登录到仪表板：
- en: '![Figure 10.2 – Kubernetes dashboard login'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.2 – Kubernetes 仪表板登录'
- en: '](image/B15566_10_002.jpg)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_002.jpg)'
- en: Figure 10.2 – Kubernetes dashboard login
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 – Kubernetes 仪表板登录
- en: 'Using Kubernetes Dashboard, administrators have insight into resource availability,
    resource allocation, Kubernetes objects, and event logs:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 仪表板，管理员可以了解资源可用性、资源分配、Kubernetes 对象和事件日志：
- en: '![Figure 10.3 – Kubernetes Dashboard – resource allocation'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.3 – Kubernetes 仪表板 – 资源分配'
- en: '](image/B15566_10_003.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_003.jpg)'
- en: Figure 10.3 – Kubernetes Dashboard – resource allocation
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 – Kubernetes 仪表板 – 资源分配
- en: 'The preceding screenshot shows resource allocation on a node for resource requests
    and limits. The following screenshot highlights the events for a node on the Kubernetes
    dashboard:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 上述截图显示了节点上资源请求和限制的资源分配情况。以下截图突出显示了 Kubernetes 仪表板上节点的事件：
- en: '![Figure 10.4 – Kubernetes Dashboard – event logs'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.4 – Kubernetes 仪表板 – 事件日志'
- en: '](image/B15566_10_004.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_004.jpg)'
- en: Figure 10.4 – Kubernetes Dashboard – event logs
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 – Kubernetes 仪表板 – 事件日志
- en: 'Kubernetes Dashboard runs as a container on the master node. You can see this
    by enumerating the Docker containers on the master node:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 仪表板作为一个容器在主节点上运行。您可以通过枚举主节点上的 Docker 容器来查看这一点：
- en: '[PRE26]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The dashboard process runs with a set of arguments on the master node:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表板进程在主节点上以一组参数运行：
- en: '[PRE27]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Ensure that the dashboard container is running with the following arguments:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 确保仪表板容器使用以下参数运行：
- en: '**Disable insecure port**: `--insecure-port` enables Kubernetes Dashboard to
    receive requests over HTTP. Ensure that it is disabled in production environments.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用不安全端口**：`--insecure-port`允许 Kubernetes 仪表板接收 HTTP 请求。确保在生产环境中禁用它。'
- en: '**Disable insecure address**: `--insecure-bind-address` should be disabled
    to avoid a situation where Kubernetes Dashboard is accessible via HTTP.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用不安全的地址**：应禁用`--insecure-bind-address`，以避免 Kubernetes 仪表板可以通过 HTTP 访问的情况。'
- en: '**Bind address to localhost**: `--bind-address` should be set to `127.0.0.1`
    to prevent hosts from being connected over the internet.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将地址绑定到本地主机**：`--bind-address`应设置为`127.0.0.1`，以防止主机通过互联网连接。'
- en: '**Enable TLS**: Use `tls-cert-file` and `tls-key-file` to access the dashboard
    over secure channels.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启用 TLS**：使用`tls-cert-file`和`tls-key-file`来通过安全通道访问仪表板。'
- en: '**Ensure token authentication mode is enabled**: Authentication mode can be
    specified using the `--authentication-mode` flag. By default, it is set to `token`.
    Ensure that basic authentication is not used with the dashboard.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**确保启用令牌身份验证模式**：可以使用`--authentication-mode`标志指定身份验证模式。默认情况下，它设置为`token`。确保仪表板不使用基本身份验证。'
- en: '**Disable insecure login**: Insecure login is used when the dashboard is available
    via HTTP. This should be disabled by default.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用不安全登录**：当仪表板可以通过 HTTP 访问时，会使用不安全登录。这应该默认禁用。'
- en: '**Disable skip login**: Skip login allows unauthenticated users to access the
    Kubernetes dashboard. `--enable-skip-login` enables skip login; this should not
    be present in production environments.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用跳过登录**：跳过登录允许未经身份验证的用户访问 Kubernetes 仪表板。`--enable-skip-login`启用跳过登录；这在生产环境中不应存在。'
- en: '**Disable settings authorizer**: `--disable-settings-authorizer` allows unauthenticated
    users to access the settings page. This should be disabled in production environments.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**禁用设置授权器**：`--disable-settings-authorizer`允许未经身份验证的用户访问设置页面。在生产环境中应禁用此功能。'
- en: Metrics Server
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Metrics Server
- en: Metrics Server aggregates cluster usage data using the Summary API exposed by
    each `kubelet` on each node. It is registered with `kube-apiserver` using `kube-aggregator`.
    Metrics Server exposes the collected metrics through the Metrics API, which are
    used by the horizontal pod autoscalar and the vertical pod autoscalar. `kubectl
    top`, which is used to debug clusters, also uses the Metrics API. Metrics Server
    is specifically designed for autoscaling.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Metrics Server 使用每个节点上的`kubelet`公开的摘要 API 聚合集群使用数据。它使用`kube-aggregator`在`kube-apiserver`上注册。Metrics
    Server通过 Metrics API 公开收集的指标，这些指标被水平 Pod 自动缩放器和垂直 Pod 自动缩放器使用。用于调试集群的`kubectl
    top`也使用 Metrics API。Metrics Server 特别设计用于自动缩放。
- en: 'Metrics Server is enabled by default on some Kubernetes distributions. You
    can enable it on `minikube` by using the following command:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些 Kubernetes 发行版上，默认情况下启用了 Metrics Server。您可以使用以下命令在`minikube`上启用它：
- en: '[PRE28]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'You can check whether Metrics Server is enabled by using the following command:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令检查 Metrics Server 是否已启用：
- en: '[PRE29]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Once Metrics Server is enabled, it takes some time to query the Summary API
    and co-relate the data. You can see the current metrics by using `kubectl top
    node`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 Metrics Server 后，需要一些时间来查询摘要 API 并关联数据。您可以使用`kubectl top node`来查看当前的指标：
- en: '[PRE30]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Similar to other services and components, Metrics Server also has configuration
    parameters. In production clusters, make sure that Metrics Server does not use
    the `--kubelet-insecure-tls` flag, which allows Metrics Server to skip verification
    of certificates by the CA.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他服务和组件类似，Metrics Server 也有配置参数。在生产集群中，请确保 Metrics Server 不使用`--kubelet-insecure-tls`标志，该标志允许
    Metrics Server 跳过 CA 对证书的验证。
- en: Third-party monitoring tools
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三方监控工具
- en: Third-party monitoring tools integrate in Kubernetes to provide many more features
    and insights into the health of Kubernetes resources. In this section, we will
    discuss Prometheus and Grafana, which are the most popular monitoring tools in
    the open source community.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 第三方监控工具集成到Kubernetes中，提供了更多功能和对Kubernetes资源健康的洞察。在本节中，我们将讨论Prometheus和Grafana，它们是开源社区中最流行的监控工具。
- en: Prometheus and Grafana
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus和Grafana
- en: Prometheus is an open source instrumentation and data collection framework developed
    by SoundCloud and adopted by CNCF. Prometheus can be used to see time series data
    for different data points. Prometheus uses a pull system. It sends an HTTP request
    called a scrape, which fetches data from the system components, including API
    Server, `node-exporter`, and `kubelet`. The response to the scrape and the metrics
    are stored in a custom database on the Prometheus server.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus是由SoundCloud开发并被CNCF采用的开源仪表和数据收集框架。Prometheus可以用来查看不同数据点的时间序列数据。Prometheus使用拉取系统。它发送一个称为抓取的HTTP请求，从系统组件（包括API服务器、`node-exporter`和`kubelet`）获取数据。抓取的响应和指标存储在Prometheus服务器上的自定义数据库中。
- en: 'Let''s see how Prometheus can be set up to monitor a namespace in Kubernetes:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何设置Prometheus来监视Kubernetes中的一个命名空间：
- en: 'Create a namespace:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个命名空间：
- en: '[PRE31]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Define a cluster role to read Kubernetes objects such as pods, nodes, and services
    and add the role binding to a service account. In this example, we are using the
    default service account:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个集群角色来读取Kubernetes对象，如pods、nodes和services，并将角色绑定到一个服务账户。在这个例子中，我们使用默认的服务账户：
- en: '[PRE32]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Now, we create a role binding to associate the role with the default service
    account:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们创建一个角色绑定，将角色与默认服务账户关联起来：
- en: '[PRE33]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Prometheus uses ConfigMap to specify the scrape rule. The following rule-scrapes
    the `kube-apiserver`. Multiple scraps can be defined to fetch metrics:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus使用ConfigMap来指定抓取规则。以下规则抓取`kube-apiserver`。可以定义多个抓取来获取指标：
- en: '[PRE34]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Create a deployment for Prometheus:'
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Prometheus创建一个部署：
- en: '[PRE35]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Once deployment is successful, port forwarding or Kubernetes services can be
    used to access the dashboard:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署成功后，可以使用端口转发或Kubernetes服务来访问仪表板：
- en: '[PRE36]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'This enables port forwarding for the Prometheus pod. Now, you can access it
    using the cluster IP on port `8080`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这样可以为Prometheus pod启用端口转发。现在，您可以使用端口`8080`上的集群IP来访问它：
- en: '![Figure 10.5 – Prometheus Dashboard'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.5 – Prometheus仪表板'
- en: '](image/B15566_10_005.jpg)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_005.jpg)'
- en: Figure 10.5 – Prometheus Dashboard
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.5 – Prometheus仪表板
- en: Queries can be entered as expressions and the results viewed as **Graph** or
    **Console** messages. Using Prometheus queries, cluster administrators can view
    the status of clusters, nodes, and services that are being monitored by Prometheus.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 查询可以输入为表达式，并查看结果为**图形**或**控制台**消息。使用Prometheus查询，集群管理员可以查看由Prometheus监视的集群、节点和服务的状态。
- en: 'Let''s look at some examples of Prometheus queries that will be helpful for
    cluster administrators:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些对集群管理员有帮助的Prometheus查询的例子：
- en: 'Kubernetes CPU usage:'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes CPU使用率：
- en: '[PRE37]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Kubernetes CPU usage by namespace:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes命名空间的CPU使用率：
- en: '[PRE38]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'CPU requests by pod:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按pod的CPU请求：
- en: '[PRE39]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let''s look at CPU usage by namespace for the demo cluster:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下演示集群的命名空间的CPU使用率：
- en: '![Figure 10.6 – CPU usage by namespace'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.6 – 命名空间的CPU使用率'
- en: '](image/B15566_10_006.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_006.jpg)'
- en: Figure 10.6 – CPU usage by namespace
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.6 – 命名空间的CPU使用率
- en: 'Prometheus also allows cluster administrators to set alerts using ConfigMaps:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus还允许集群管理员使用ConfigMaps设置警报：
- en: '[PRE40]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'This alert triggers an alert with a label severity of `high` when container
    memory usage is greater than `1000` MB for `1` minute:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器内存使用大于`1000` MB并持续`1`分钟时，此警报将触发一个带有`high`严重性标签的警报：
- en: '![Figure 10.7 – Prometheus Alerts'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.7 – Prometheus警报'
- en: '](image/B15566_10_007_New.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_007_New.jpg)'
- en: Figure 10.7 – Prometheus Alerts
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.7 – Prometheus警报
- en: Using `Alertmanager` with Prometheus helps deduplicate, group, and route alerts
    from applications such as Prometheus and route it to integrated clients, including
    email, OpsGenie, and PagerDuty.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`Alertmanager`与Prometheus有助于对来自诸如Prometheus的应用程序的警报进行去重、分组和路由，并将其路由到集成客户端，包括电子邮件、OpsGenie和PagerDuty。
- en: Prometheus integrates well with other third-party tools that enhance data visualization
    and alert management. Grafana is one such tool. Grafana allows visualization,
    querying, and alerting on data retrieved from Prometheus.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus与其他增强数据可视化和警报管理的第三方工具很好地集成。Grafana就是这样的工具。Grafana允许对从Prometheus检索的数据进行可视化、查询和警报。
- en: 'Let''s now look at how we set up Grafana with Prometheus:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用Prometheus设置Grafana：
- en: 'Grafana needs a data source for ingestion; in this case, it is Prometheus.
    The data source can be added using the UI or can be specified using a ConfigMap:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grafana需要一个数据源进行摄入；在本例中，它是Prometheus。数据源可以使用UI添加，也可以使用ConfigMap指定：
- en: '[PRE41]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create a deployment for Grafana:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为Grafana创建一个部署：
- en: '[PRE42]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Port forwarding or Kubernetes services can then be used to access the dashboard:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后可以使用端口转发或Kubernetes服务来访问仪表板：
- en: '[PRE43]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The dashboard, by default, has `admin` as a username and password. Once logged
    in, you can either set up a new dashboard or import one from Grafana. To import
    one, you can click **+ > Import**, where you will be presented with the following
    screen. Enter `315` in the first textbox to import dashboard 315 from Grafana:![Figure
    10.8 – Importing a dashboard in Grafana
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，仪表板的用户名和密码为`admin`。登录后，您可以设置一个新的仪表板，或者从Grafana导入一个仪表板。要导入一个仪表板，您可以点击**+
    > 导入**，然后会出现以下屏幕。在第一个文本框中输入`315`，以从Grafana导入仪表板315：![图10.8 – 在Grafana中导入仪表板
- en: '](image/B15566_10_009.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_009.jpg)'
- en: Figure 10.8 – Importing a dashboard in Grafana
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.8 – 在Grafana中导入仪表板
- en: This dashboard was created by Instrumentisto Team. On import, all fields on
    the next screen will be filled up automatically:![Figure 10.9 – Grafana Dashboard
    – 315
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个仪表板是由Instrumentisto团队创建的。导入时，下一个屏幕上的所有字段将自动填充：![图10.9 – Grafana仪表板 – 315
- en: '](image/B15566_10_010.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_010.jpg)'
- en: Figure 10.9 – Grafana Dashboard – 315
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.9 – Grafana仪表板 – 315
- en: A new dashboard can also be created with custom Prometheus queries:![Figure
    10.10 – Custom dashboard
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 也可以使用自定义的Prometheus查询创建一个新的仪表板：![图10.10 – 自定义仪表板
- en: '](image/B15566_10_011.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_011.jpg)'
- en: Figure 10.10 – Custom dashboard
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.10 – 自定义仪表板
- en: 'Similar to Prometheus, you can set up alerts on each dashboard:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与Prometheus类似，您可以在每个仪表板上设置警报：
- en: '![Figure 10.11 – New alerts in Grafana'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.11 – Grafana中的新警报'
- en: '](image/B15566_10_012.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B15566_10_012.jpg)'
- en: Figure 10.11 – New alerts in Grafana
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – Grafana中的新警报
- en: There are other tools that integrate with Prometheus that make it such a valuable
    tool for DevOps and cluster administrators.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他与Prometheus集成的工具，使其成为DevOps和集群管理员的宝贵工具。
- en: Summary
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we discussed availability as an important part of the CIA triad.
    We discussed the importance of resource management and real-time resource monitoring
    from a security standpoint. We then introduced resource requests and limits, core
    concepts for resource management in Kubernetes. Next, we discussed resource management
    and how cluster administrators can proactively ensure that Kubernetes objects
    can be prevented from misbehaving.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了可用性作为CIA三要素的重要组成部分。我们从安全的角度讨论了资源管理和实时资源监控的重要性。然后，我们介绍了资源请求和限制，这是Kubernetes资源管理的核心概念。接下来，我们讨论了资源管理以及集群管理员如何积极确保Kubernetes对象不会表现不端。
- en: We dived deep into the details of namespace resource quotas and limit ranges
    and looked at examples on how to set it up. We then shifted gears to resource
    monitoring. We looked at some built-in monitors that are available as part of
    Kubernetes, including Dashboard and Metrics Server. Finally, we looked at a number
    of third-party tools – Prometheus and Grafana – that are much more powerful and
    preferred by most cluster administrators and DevOps engineers.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们深入研究了命名空间资源配额和限制范围的细节，并看了如何设置它的示例。然后我们转向资源监控。我们看了一些作为Kubernetes一部分提供的内置监视器，包括Dashboard和Metrics
    Server。最后，我们看了一些第三方工具 - Prometheus和Grafana - 这些工具更强大，大多数集群管理员和DevOps工程师更喜欢使用。
- en: Using resource management, cluster administrators can ensure that services in
    a Kubernetes cluster have sufficient resources available for operation and that
    malicious or misbehaving entities don't hog all the resources. Resource monitoring,
    on the other hand, helps to identify issues and the symptoms in real time. With
    alert management used in conjunction with resource monitoring, stakeholders are
    notified of symptoms, such as reduced disk space or high memory consumption, as
    soon as they occur, ensuring that downtime is minimal.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 通过资源管理，集群管理员可以确保Kubernetes集群中的服务有足够的资源可用于运行，并且恶意或行为不端的实体不会独占所有资源。另一方面，资源监控有助于实时识别问题和症状。与资源监控一起使用的警报管理可以在发生问题时通知利益相关者，例如磁盘空间不足或内存消耗过高，从而确保停机时间最小化。
- en: In the next chapter, we will discuss Defense in Depth in detail. We will look
    at how cluster administrators and DevOps engineers can supplement secure configuration,
    resource management, and resource monitoring with a layered approach to security.
    Defense in Depth will introduce more toolkits to ensure that attacks are easily
    detected and mitigated in production environments.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将详细讨论深度防御。我们将看看集群管理员和DevOps工程师如何通过分层安全配置、资源管理和资源监控来增强安全性。深度防御将引入更多的工具包，以确保在生产环境中可以轻松检测和减轻攻击。
- en: Questions
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What is the difference between a resource request and limits?
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 资源请求和限制之间有什么区别？
- en: Define a resource quota that limits the memory limit to 500 mi.
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个将内存限制限制为500 mi的资源配额。
- en: How does limit-range differ from resource-quotas?
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制范围与资源配额有何不同？
- en: What is the recommended authentication method for Kubernetes Dashboard?
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes Dashboard的推荐认证方法是什么？
- en: Which is the most widely recommended resource monitoring tool?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个是最广泛推荐的资源监控工具？
- en: Further references
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更多参考资料
- en: 'You can refer to the following links for more information on topics covered
    in this chapter:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下链接，了解本章涵盖的主题的更多信息：
- en: 'Denial-of-service attacks on electrical systems: [https://www.cnbc.com/2019/05/02/ddos-attack-caused-interruptions-in-power-system-operations-doe.html](https://www.cnbc.com/2019/05/02/ddos-attack-caused-interruptions-in-power-system-operations-doe.html)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 电力系统的拒绝服务攻击：[https://www.cnbc.com/2019/05/02/ddos-attack-caused-interruptions-in-power-system-operations-doe.html](https://www.cnbc.com/2019/05/02/ddos-attack-caused-interruptions-in-power-system-operations-doe.html)
- en: 'Amazon Route53 DDoS: [https://www.cpomagazine.com/cyber-security/ddos-attack-on-amazon-web-services-raises-cloud-safety-concerns/](https://www.cpomagazine.com/cyber-security/ddos-attack-on-amazon-web-services-raises-cloud-safety-concerns/)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚马逊Route53 DDoS：[https://www.cpomagazine.com/cyber-security/ddos-attack-on-amazon-web-services-raises-cloud-safety-concerns/](https://www.cpomagazine.com/cyber-security/ddos-attack-on-amazon-web-services-raises-cloud-safety-concerns/)
- en: 'Limit Ranger design documentation: [https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/admission_control_limit_range.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/admission_control_limit_range.md)'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Limit Ranger设计文档: [https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/admission_control_limit_range.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/admission_control_limit_range.md)'
- en: 'Kubernetes Dashboard: [https://github.com/kubernetes/dashboard/blob/master/docs/README.md](https://github.com/kubernetes/dashboard/blob/master/docs/README.md)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kubernetes Dashboard: [https://github.com/kubernetes/dashboard/blob/master/docs/README.md](https://github.com/kubernetes/dashboard/blob/master/docs/README.md)'
- en: 'Privilege escalation using Kubernetes Dashboard: [https://sysdig.com/blog/privilege-escalation-kubernetes-dashboard/](https://sysdig.com/blog/privilege-escalation-kubernetes-dashboard/)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用Kubernetes Dashboard进行特权升级: [https://sysdig.com/blog/privilege-escalation-kubernetes-dashboard/](https://sysdig.com/blog/privilege-escalation-kubernetes-dashboard/)'
- en: 'Metrics Server: [https://github.com/kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Metrics Server: [https://github.com/kubernetes-sigs/metrics-server](https://github.com/kubernetes-sigs/metrics-server)'
- en: 'Aggregated API servers: [https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '聚合API服务器: [https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/api-machinery/aggregated-api-servers.md)'
- en: 'Prometheus queries: [https://prometheus.io/docs/prometheus/latest/querying/examples/](https://prometheus.io/docs/prometheus/latest/querying/examples/)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prometheus查询: [https://prometheus.io/docs/prometheus/latest/querying/examples/](https://prometheus.io/docs/prometheus/latest/querying/examples/)'
- en: 'Grafana documentation: [https://grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grafana文档: [https://grafana.com/docs/grafana/latest/](https://grafana.com/docs/grafana/latest/)'
