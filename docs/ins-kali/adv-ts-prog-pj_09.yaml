- en: Image Recognition with Vue.js and TensorFlow.js
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Vue.js和TensorFlow.js进行图像识别
- en: One of the hottest topics in computing at the moment is machine learning. In
    this chapter, we are going to step into the world of machine learning and look
    at using the popular `TensorFlow.js` package to perform image classification,
    as well as to detect poses. As a break from Angular and React, we will move on
    to Vue.js to provide our client implementation.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当前计算机领域最热门的话题之一是机器学习。在本章中，我们将进入机器学习的世界，使用流行的`TensorFlow.js`包进行图像分类，以及姿势检测。作为对Angular和React的改变，我们将转向Vue.js来提供我们的客户端实现。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: What machine learning is and how it relates to AI
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习是什么，以及它与人工智能的关系
- en: How to install Vue
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何安装Vue
- en: Creating an application with Vue
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Vue创建应用程序
- en: Showing a home page with the Vue template
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Vue模板显示主页
- en: Using routing in Vue
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Vue中使用路由
- en: What **Convolutional Neural Networks** (**CNNs**) are
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷积神经网络**（**CNNs**）是什么'
- en: How models are trained in TensorFlow
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow中模型的训练方式
- en: Building an image classification class using pre-trained TensorFlow models
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用预训练的TensorFlow模型构建图像分类类
- en: The image types that TensorFlow supports for image classification and pose detection
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TensorFlow支持的图像类型，用于图像分类和姿势检测
- en: Using pose detection to show body joints
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用姿势检测显示身体关节
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The finished project can be downloaded from [https://github.com/PacktPublishing/Advanced-TypeScript-3-Programming-Projects/tree/master/chapter09](https://github.com/PacktPublishing/Advanced-TypeScript-3-Programming-Projects/tree/master/chapter09).
    This project uses TensorFlow, so the following additional components will be used
    in this chapter:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 完成的项目可以从[https://github.com/PacktPublishing/Advanced-TypeScript-3-Programming-Projects/tree/master/chapter09](https://github.com/PacktPublishing/Advanced-TypeScript-3-Programming-Projects/tree/master/chapter09)下载。本项目使用TensorFlow，因此本章将使用以下额外组件：
- en: '`@tensorflow-models/mobilenet`'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@tensorflow-models/mobilenet`'
- en: '`@tensorflow-models/posenet`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@tensorflow-models/posenet`'
- en: '`@tensorflow/tfjs`'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`@tensorflow/tfjs`'
- en: 'We will also use Bootstrap with Vue, so we will need to install the following
    Bootstrap components:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将在Vue中使用Bootstrap，因此我们需要安装以下Bootstrap组件：
- en: '`bootstrap`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap`'
- en: '`bootstrap-vue`'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap-vue`'
- en: After downloading the project, you will have to install the package requirements
    using the `npm install` command.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下载项目后，您将需要使用`npm install`命令安装包要求。
- en: What is machine learning and how does TensorFlow fit in?
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习，TensorFlow如何适用？
- en: It's very hard nowadays to get away from the idea of artificially intelligent
    machines. People have become accustomed to having access to tools such as Siri,
    Alexa, and Cortana, which create the appearance that the technology understands
    us and is able to interact with us. These voice-activated systems use natural
    language processing to recognize sentences such as, *What's the weather like in
    Kos today?*
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在很难摆脱人工智能机器的概念。人们已经习惯于使用Siri、Alexa和Cortana等工具，这些工具给人一种科技能理解我们并与我们互动的假象。这些语音激活系统使用自然语言处理来识别句子，比如“今天Kos的天气如何？”
- en: The magic behind these systems is machine learning. To pick one of these systems,
    we will quickly look at what Alexa does behind the scenes before we look at how
    machine learning relates to AI.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些系统背后的魔力就是机器学习。为了选择其中一个系统，我们将快速查看Alexa在展示之前的工作，然后再看机器学习与人工智能的关系。
- en: When we ask Alexa a question, *she* recognizes *her* name so that she knows
    that she should start listening to what comes after to start processing. This
    is the software equivalent of tapping someone on their shoulder to get their attention.
    Alexa then records the following sentence until a point is reached where Alexa
    can transmit the recording via the internet to the Alexa voice service. This incredibly
    sophisticated service parses the recording as best it can (sometimes, heavy accents
    can confuse the service). The service then acts on the parsed recording and sends
    the results back to your Alexa device.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们问Alexa一个问题时，*她*会认出*她*的名字，这样她就知道应该开始倾听后面的内容以开始处理。这相当于在某人的肩膀上轻拍以引起他们的注意。然后Alexa会记录以下句子，直到达到一个点，Alexa可以通过互联网将录音传输到Alexa语音服务。这项极其复杂的服务尽其所能地解析录音（有时，重口音可能会让服务混淆）。然后服务根据解析的录音进行操作，并将结果发送回您的Alexa设备。
- en: As well as answering questions about the weather, there is an exhausting number
    of Alexa skills that users can use, and Amazon encourages developers to create
    skills that go beyond what they have time to come up with. This means that it's
    as easy to order a pizza as it is to check the latest racing results.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 除了回答关于天气的问题，Alexa还有大量的技能供用户使用，亚马逊鼓励开发者创建超出他们有时间想出的技能。这意味着轻松订购披萨和查看最新的赛车结果一样容易。
- en: This preamble leads us to the point where we start to touch on what machine
    learning has to do with Alexa. The software behind Alexa uses machine learning
    to continually update itself, so every time it makes a mistake, this is fed back
    in so that the system is *smarter* the next time around and doesn't make that
    mistake in the future.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这个序言引导我们开始接触机器学习与Alexa有什么关系。Alexa背后的软件使用机器学习不断更新自己，所以每次出错时，都会反馈回去，这样系统在下一次变得*更聪明*，并且不会在未来犯同样的错误。
- en: As you can imagine, interpreting speech is a hugely complicated task. It's something
    that we, as humans, learn from an early age, and the analogy with machine learning
    is quite breathtaking because we also learn speech through repetition and reinforcement.
    So, when a baby randomly says *dada*, the baby has learned to make the sounds,
    but does not know the correct context for the sound yet. Reinforcement, usually
    provided by the parents pointing to themselves, is used to link the sound to a
    person. Similar reinforcement takes place when we use picture books; when we teach
    a baby the word *cow*, we point to a picture of a cow. That way, the baby learns
    to associate the word with the picture.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以想象的那样，解释语音是一项非常复杂的任务。这是我们作为人类从小就学会的东西，与机器学习的类比令人叹为观止，因为我们也是通过重复和强化来学习语音的。因此，当一个婴儿随机说出“爸爸”时，婴儿已经学会发出这些声音，但还不知道这个声音的正确语境。通常由父母指向自己来提供的强化用于将声音与人物联系起来。当我们使用图片书时，类似的强化也会发生；当我们教婴儿“牛”的时候，我们会指向一张牛的图片。这样，婴儿就学会将这个词与图片联系起来。
- en: Since speech interpretation is so complicated, it takes a huge amount of processing
    power, and it also requires a huge pre-trained dataset. Imagine how frustrating
    it would be if we had to teach Alexa everything. This is partly why machine learning
    systems are only really coming into their own now. We now have enough infrastructure
    in place to offload the computations to reliable, powerful, and dedicated machines.
    Additionally, we now have internet that is, by and large, powerful and fast enough
    to cope with the vast amounts of data that is being transmitted to these machine
    learning systems. We certainly wouldn't have been able to do half of what we can
    do now if we were still running on 56K modems.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 由于语音解释非常复杂，它需要大量的处理能力，也需要一个庞大的预先训练的数据集。想象一下，如果我们不得不教Alexa一切会有多么令人沮丧。这在一定程度上解释了为什么机器学习系统现在才真正开始发挥作用。我们现在有足够的基础设施，可以将计算卸载到可靠、强大和专用的机器上。此外，我们现在有足够强大和快速的互联网来处理传输到这些机器学习系统的大量数据。如果我们仍然使用56K调制解调器，我们肯定无法做到现在能做到的一半。
- en: What is machine learning?
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是机器学习？
- en: We know that computers are good at yes and no answers, or 1s and 0s, if you
    like. This means that a computer fundamentally cannot reply with an *-ish* answer,
    so it cannot say yes-ish to a question. Bear with me for a moment, as this will
    become clear shortly.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道计算机擅长是或否答案，或者说1和0。这意味着计算机基本上无法回答“-ish”，因此它无法对问题回答“有点是”。请稍等片刻，这很快就会变得清楚。
- en: At its most basic level, we can say that machine learning boils down to teaching
    computers to learn in the same way that we do. They learn to interpret data from
    all sorts of sources and use this learning to classify that data. The machine
    will learn from successes and failures, which will, in turn, make it more accurate
    and capable of making even more complex inferences.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在其最基本的层面上，我们可以说，机器学习归结为教计算机以我们相同的方式学习。它们学会解释来自各种来源的数据，并利用这种学习对数据进行分类。机器将从成功和失败中学习，从而使其更准确和能够进行更复杂的推断。
- en: Getting back to the idea of computers working with yes or no answers, when we
    come up with an answer that amounts to *well, it depends*, we are largely coming
    up with multiple answers based on the same input—the equivalent of multiple routes
    through to yes or no answers. Machine learning systems are becoming much better
    at learning, so the algorithms behind them are able to draw on more and more data,
    along with more and more reinforcement to make deeper connections.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 回到计算机处理是或否答案的想法，当我们得出一个答案，相当于“嗯，这取决于”的时候，我们基本上是基于相同的输入得出多个答案——相当于通过多种途径得出是或否的答案。机器学习系统在学习方面变得越来越好，因此它们背后的算法能够利用越来越多的数据，以及越来越多的强化来建立更深层次的联系。
- en: Behind the scenes, machine learning applies an incredible array of algorithms
    and statistical models so that systems can perform set tasks without having to
    be given detailed instructions on how to accomplish those tasks. This level of
    inference is light years away from the way we have traditionally built applications,
    and this draws on the fact that, given the right mathematical models, computers
    are very, very good at spotting patterns. Along with that, they are doing a huge
    number of related tasks simultaneously, meaning that the mathematical models underpinning
    the learning can take the results of their calculations back in as feeds to themselves
    in order to build a better understanding of the world.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，机器学习应用了一系列令人难以置信的算法和统计模型，以便系统可以执行一些任务，而无需详细说明如何完成这些任务。这种推断水平远远超出了我们传统构建应用程序的方式，这是因为，鉴于正确的数学模型，计算机非常擅长发现模式。除此之外，它们同时执行大量相关任务，这意味着支持学习的数学模型可以将其计算结果作为反馈输入，以便更好地理解世界。
- en: At this point, we must mention that AI and machine learning are not the same.
    Machine learning is an application of AI based on the ability to automatically
    learn without being programmed to deal with a particular task. The success of
    machine learning is based on having a sufficient amount of data for the system
    to learn for itself. There are a number of algorithm types that can be applied.
    Some are known as unsupervised learning algorithms, while others are known as
    supervised learning algorithms.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们必须提到AI和机器学习并不相同。机器学习是基于自动学习的AI应用，而无需为处理特定任务而进行编程。机器学习的成功基于系统学习所需的足够数量的数据。可以应用一些算法类型。有些被称为无监督学习算法，而其他一些被称为监督学习算法。
- en: Unsupervised algorithms take in data that has not been classified or labeled
    previously. The algorithms are run on such datasets to look for underlying or
    hidden patterns, which can be used to create inferences.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督算法接收以前未分类或标记的数据。这些算法在这些数据集上运行，以寻找潜在或隐藏的模式，这些模式可以用来创建推断。
- en: A supervised learning algorithm takes its previous learning and applies it to
    new data using labeled examples. These labeled examples help it learn the correct
    answers. Behind the scenes, there is a training dataset that learning algorithms
    use to refine their knowledge and learn from. The greater the level of training
    data, the more likely the algorithm is to be able to produce correct answers.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习算法利用其先前的学习，并使用标记的示例将其应用于新数据。这些标记的示例帮助它学习正确的答案。在幕后，有一个训练数据集，学习算法用它来完善他们的知识并学习。训练数据的级别越高，算法产生正确答案的可能性就越大。
- en: There are other types of algorithms, including reinforcement learning algorithms
    and semi-supervised learning algorithms, but these are outside the scope of this
    book.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他类型的算法，包括强化学习算法和半监督学习算法，但这些超出了本书的范围。
- en: What is TensorFlow and how does it relate to machine learning?
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是TensorFlow，它与机器学习有什么关系？
- en: We have talked about what machine learning is and that it could seem very daunting
    if were to try and implement it ourselves. Fortunately, there are libraries that
    help us create our own machine learning implementations. Originally created by
    the Google Brain team, TensorFlow is one such library designed to support large-scale
    machine learning and numerical computation. Initially, TensorFlow was written
    as a hybrid Python/C++ library, where Python provided the frontend API for building
    learning applications and the C++ side executed them. TensorFlow brings a number
    of machine learning and neural networking (sometimes called **deep learning**)
    algorithms together.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了机器学习是什么，如果我们试图自己实现它，可能会显得非常令人生畏。幸运的是，有一些库可以帮助我们创建自己的机器学习实现。最初由Google
    Brain团队创建，TensorFlow是这样一个旨在支持大规模机器学习和数值计算的库。最初，TensorFlow是作为混合Python/C++库编写的，其中Python提供了用于构建学习应用程序的前端API，而C++端执行它们。TensorFlow汇集了许多机器学习和神经网络（有时称为**深度学习**）算法。
- en: Given the success of the original Python implementation, we now have an implementation
    of TensorFlow (properly called `TensorFlow.js`) written in TypeScript that we
    can use in our applications. This is the version we are going to use in this chapter.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于原始Python实现的成功，我们现在有了一个用TypeScript编写的TensorFlow实现（称为`TensorFlow.js`），我们可以在我们的应用程序中使用。这是我们将在本章中使用的版本。
- en: Project overview
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目概述
- en: The project we are going to write in this chapter is the one that excited me
    the most when I was writing the proposal for this book. I have a long-term love
    affair with all things AI; the topic fascinates me. With the rise of frameworks
    such as `TensorFlow.js` (I'll be shortening this to just TensorFlow), the ability
    to perform sophisticated machine learning has never been more readily available
    outside of academia. As I said, this chapter really got me excited, so we aren't
    going to use just one machine learning operation—we are going to use image classification
    to determine what is in a picture and we will use pose detection to draw the key
    points, such as the major joints and major facial landmarks of a person.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中编写的项目是我在为这本书写提案时最激动人心的项目。我对所有AI相关的事物都有长期的热爱；这个主题让我着迷。随着`TensorFlow.js`等框架的兴起（我将简称为TensorFlow），在学术界之外进行复杂的机器学习的能力从未如此容易获得。正如我所说，这一章真的让我兴奋，所以我们不仅仅使用一个机器学习操作——我们将使用图像分类来确定图片中的内容，并使用姿势检测来绘制关键点，如人体的主要关节和主要面部标志。
- en: 'Working alongside the GitHub code, this topic should take about an hour to
    complete and, when you have finished it, it should look like this:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 与GitHub代码一起工作，这个主题应该需要大约一个小时才能完成，完成后应该是这样的：
- en: '![](assets/55d8a477-ed6c-4ab5-bcd7-752183ee41b7.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/55d8a477-ed6c-4ab5-bcd7-752183ee41b7.png)'
- en: Now that we know what project we are going to build, we are ready to start the
    implementation. In the next section, we are going to start off by installing Vue.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们要构建的项目是什么，我们准备开始实施。在下一节中，我们将开始安装Vue。
- en: Getting started with TensorFlow in Vue
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Vue中开始使用TensorFlow
- en: 'If you do not already have Vue installed, the first step is to install the
    Vue **Command-Line Interface** (**CLI**). This is installed using `npm` with the
    following command:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尚未安装Vue，则第一步是安装Vue **命令行界面**（**CLI**）。使用以下命令使用`npm`安装：
- en: '[PRE0]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Creating our Vue-based application
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建基于Vue的应用程序
- en: Our TensorFlow application is going to run entirely in the client browser. This
    means that we need to write an application to host the TensorFlow functionality.
    We are going to use Vue to provide our client, so the following steps are needed
    to automatically build our Vue application.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的TensorFlow应用程序将完全在客户端浏览器中运行。这意味着我们需要编写一个应用程序来托管TensorFlow功能。我们将使用Vue来提供我们的客户端，因此需要以下步骤来自动构建我们的Vue应用程序。
- en: 'Creating our client is as simple as running the `vue create` command, as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 创建我们的客户端就像运行`vue create`命令一样简单，如下所示：
- en: '[PRE1]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This starts off the process of creating the application. There are a number
    of decision points that need to happen when going through the client creation
    process, starting off with choosing whether to accept the defaults or to manually
    select the features we want to add. Since we want to add TypeScript support, we
    need to choose the Manually select features preset. The following screenshot shows
    the steps that we will go through to select the features for our Vue application:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这开始了创建应用程序的过程。在进行客户端创建过程时，需要进行一些决策点，首先是选择是否接受默认设置或手动选择要添加的功能。由于我们想要添加TypeScript支持，我们需要选择手动选择功能预设。以下截图显示了我们将要进行的步骤，以选择我们Vue应用程序的功能：
- en: '![](assets/56bc69f3-88ed-4234-a191-fd175d22128c.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/56bc69f3-88ed-4234-a191-fd175d22128c.png)'
- en: 'There are a number of features that we could add to our project, but we are
    only interested in a few of them, so deselect Babel and choose to add TypeScript,
    Router, VueX, and Linter / Formatter from the list. Selection/deselection is accomplished
    by using the spacebar:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的项目可以添加许多功能，但我们只对其中一些感兴趣，所以取消选择Babel，选择添加TypeScript、Router、VueX和Linter / Formatter。通过使用空格键来进行选择/取消选择：
- en: '![](assets/f775f672-aba1-4246-bd40-b253649f4616.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f775f672-aba1-4246-bd40-b253649f4616.png)'
- en: When we press *Enter*, a number of other options will be presented. Pressing
    *Enter* will set the default value for the first three options. When we get to
    the option for selecting the **linter** (short for **Lexical INTERpreter**), choose
    TSLint from the list, and then keep pressing *Enter* for the other options. A
    linter is a tool that automatically parses your code, looking for potential issues.
    It does this by looking at our code to see if it breaches a set of predefined
    rules, which could indicate that there are bugs or code-styling issues.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们按下*Enter*时，将呈现出许多其他选项。按下*Enter*将为前三个选项设置默认值。当我们到达选择**linter**（缩写为**Lexical
    INTERpreter**）的选项时，请从列表中选择TSLint，然后继续按*Enter*处理其他选项。linter是一个自动解析代码的工具，寻找潜在问题。它通过查看我们的代码来检查是否违反了一组预定义的规则，这可能表明存在错误或代码样式问题。
- en: 'When we have gone all the way through this process, our client will be created;
    this will take some time to complete as there is a lot of code being downloaded
    and installed:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们完成了整个过程，我们的客户端将被创建；这将需要一些时间来完成，因为有大量的代码需要下载和安装。
- en: '![](assets/b4cb17e8-85fa-472a-afd6-a6971ed16521.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b4cb17e8-85fa-472a-afd6-a6971ed16521.png)'
- en: 'Now that our application has been created, we can run it by running `npm run
    serve` in the root of the client folder. Unlike Angular and React, the browser
    won''t display the page by default, so we will need to open the page for ourselves
    using `http://localhost:8080`. When we do so, the page will look like this:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的应用程序已经创建，我们可以在客户端文件夹的根目录中运行`npm run serve`来运行它。与Angular和React不同，浏览器不会默认显示页面，所以我们需要自己打开页面，使用`http://localhost:8080`。这样做时，页面将如下所示：
- en: '![](assets/82e894fd-191f-4704-a6b0-d7c39d47429c.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/82e894fd-191f-4704-a6b0-d7c39d47429c.png)'
- en: We are going to make our life easier when we write the image classifier since
    we are going to reuse some of the existing infrastructure that the Vue CLI created
    for us by modifying the home page to show our image classifier in action.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们编写图像分类器时，我们将使生活更加轻松，因为我们将通过修改主页来展示我们的图像分类器的运行情况，从而重用Vue CLI为我们创建的一些现有基础设施。
- en: Showing a home page with the Vue template
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示带有Vue模板的主页
- en: In a similar way to React giving us the special `.jsx`/`.tsx` extensions to
    allow us to put our code and web page together, Vue provides us with single-file
    components that are created as `.vue` files. These files allow us to mix our code
    and web templates together to build up our page. Let's open up our `Home.vue`
    page and analyze it before we go on to create our first TensorFlow component.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与React以`.jsx`/`.tsx`扩展名为我们提供将代码和网页放在一起的特殊扩展名类似，Vue为我们提供了单文件组件，创建为`.vue`文件。这些文件允许我们将代码和网页模板混合在一起构建我们的页面。在继续创建我们的第一个TensorFlow组件之前，让我们打开我们的`Home.vue`页面并对其进行分析。
- en: We can see that our `.vue` component is broken up into two separate parts. There's
    a template section that defines the layout of the HTML that will be displayed
    on the screen, and there's a separate script section where we include our code.
    Since we are using TypeScript, the language for our `script` section is `ts`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的`.vue`组件分为两个部分。有一个模板部分定义了将显示在屏幕上的HTML的布局，还有一个单独的脚本部分，我们在其中包含我们的代码。由于我们使用TypeScript，我们的`script`部分的语言是`ts`。
- en: 'The script section starts off by defining the `import` section in much the
    same way that we would see in a standard `.ts` file. Where we see `@` in the import,
    this tells us that the import path is relative to the `src` directory, so the
    `HelloWorld.vue` component is located in the `src/components` folder:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本部分首先通过定义`import`部分开始，这与标准的`.ts`文件中看到的方式非常相似。在导入中看到`@`时，这告诉我们导入路径是相对于`src`目录的，因此`HelloWorld.vue`组件位于`src/components`文件夹中：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The next thing we need to do is create a class that extends from the `Vue`
    class. What we are doing with this is using `@Component` to create a component
    registration called `Home` that can be used elsewhere:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们需要做的是创建一个从`Vue`类继承的类。我们使用`@Component`创建一个名为`Home`的组件注册，可以在其他地方使用：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'There is something else that we need to do. Our template is going to reference
    an external `HelloWorld` component. We must decorate our class with the components
    that the template is going to use, like this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一件事情我们需要做。我们的模板将引用一个外部的`HelloWorld`组件。我们必须用模板将要使用的组件装饰我们的类，就像这样：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The template is very straightforward. It consists of a single `div` class that
    we are going to render the `HelloWorld` component into:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 模板非常简单。它由一个单一的`div`类组成，我们将在其中渲染`HelloWorld`组件：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: From the previous code template, we can see that, unlike React, Vue does not
    give us an explicit `render` function to deal with rendering HTML and state. Instead,
    the build-up of rendering is a lot closer to the Angular model, in which a template
    is parsed into content that can be served up.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码模板中，我们可以看到，与React不同，Vue没有为我们提供一个明确的`render`函数来处理HTML和状态的渲染。相反，渲染的构建更接近于Angular模型，其中模板被解析为可以提供的内容。
- en: The reason that we mentioned Angular here is because Vue.js started off being
    developed by Evan You, who was working on the AngularJS project at Google; he
    wanted to create a more performant library. While AngularJS was a great framework,
    it did require a complete buy-in to the Angular ecosystem in order to work with it
    (the Angular team is working to rectify this). So, while Vue leverages Angular
    features such as templates, it has a very light touch in that you can just add
    a script tag to your existing code and start slowly migrating your existing code
    base over to Angular.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到Angular的原因是因为Vue.js最初是由Evan You开发的，他当时正在谷歌的AngularJS项目上工作；他想要创建一个性能更好的库。虽然AngularJS是一个很棒的框架，但它需要完全接受Angular生态系统才能使用（Angular团队正在努力解决这个问题）。因此，虽然Vue利用了Angular的特性，比如模板，但它的影响力很小，你只需在现有代码中添加一个脚本标签，然后慢慢将现有代码迁移到Angular。
- en: Vue borrows concepts from React such as the use of the Virtual DOM (as we discussed
    when we introduced React). Vue also uses a virtual DOM but implements it in a
    slightly different fashion, primarily with Vue only re-rendering out components
    that have a change, where React, by default, would also re-render child components.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Vue从React中借鉴了一些概念，比如使用虚拟DOM（我们在介绍React时讨论过）。Vue也使用虚拟DOM，但以稍微不同的方式实现，主要是Vue只重新渲染有变化的组件，而React默认情况下也会重新渲染子组件。
- en: 'What we want to do now is modify the `HelloWorld` component so that we can
    work with TensorFlow. But, before we do that, we need to write a couple of supporting
    classes that will do the heavy lifting with TensorFlow. These aren''t big classes
    in terms of code, but they are extremely important. Our `ImageClassifier` class
    starts off with a standard class definition, as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们要修改`HelloWorld`组件，以便与TensorFlow一起使用。但在这之前，我们需要编写一些支持类来处理TensorFlow的重要工作。这些类在代码量上并不大，但非常重要。我们的`ImageClassifier`类以标准的类定义开始，如下所示：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The next step is optional, but it has a major impact on the stability of our
    application if it is running on a Windows client. Underneath the cover, TensorFlow
    uses WebGLTextures, but there is a problem with creating WebGLTextures on Windows
    platforms. To get around this issue, our constructor needs to be modified to look
    like this:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是可选的，但如果应用程序在Windows客户端上运行，它对应用程序的稳定性有重大影响。在底层，TensorFlow使用WebGLTextures，但在Windows平台上创建WebGLTextures存在问题。为了解决这个问题，我们的构造函数需要修改如下：
- en: '[PRE7]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Since we can run the image classification any number of times, we are going
    to add a private variable that represents the standard `MobileNet` TensorFlow:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们可以运行图像分类任意次数，我们将添加一个表示标准`MobileNet` TensorFlow的私有变量：
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Introducing MobileNet
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MobileNet介绍
- en: At this point, we need to take a small detour into the world of CNNs. `MobileNet`
    is a CNN model, so having a little understanding of what a CNN is helps us to
    understand how it relates to the problem we are solving here. Don't worry, we
    aren't going to dig into the mathematics behind CNNs, but knowing a little bit
    about what they do will help us appreciate what they bring to the table for us.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们需要稍微了解一下CNN的世界。`MobileNet`是一个CNN模型，因此稍微了解CNN是如何帮助我们理解它与我们解决的问题有关。不用担心，我们不会深入研究CNN背后的数学，但了解一点它们的工作原理将有助于我们欣赏它们为我们带来了什么。
- en: CNN classifiers work by taking in an input image (potentially from a video stream),
    processing the image, and classifying it under predefined categories. In order
    to understand how they work, we need to take a step back and think about the problem
    from a computer's point of view. Suppose we have a picture of a horse. To a computer,
    that picture is just a series of pixels, so if we were to show a picture of a
    slightly different horse, the computer cannot say that they match just by comparing
    pixels.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: CNN分类器通过接收输入图像（可能来自视频流），处理图像，并将其分类到预定义的类别中。为了理解它们的工作原理，我们需要退后一步，从计算机的角度思考问题。假设我们有一张马的照片。对于计算机来说，那张照片只是一系列像素，所以如果我们展示一张稍微不同的马的照片，计算机无法仅通过比较像素来判断它们是否匹配。
- en: A CNN breaks the images down into pieces (say, into 3x3 grids of pixels) and
    compares those pieces. Simplistically speaking, what it is looking for is the
    number of matches that it can make with these pieces. The greater the number of
    matches, the greater the confidence that we have a match. This is a very simplified
    description of what a CNN does, which involves a number of steps and filters,
    but it should serve to provide an understanding of why we would want to use a
    CNN such as `MobileNet` in TensorFlow.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: CNN将图像分解成片段（比如3x3像素的网格），并比较这些片段。简单地说，它寻找的是这些片段能够匹配的数量。匹配的数量越多，我们就越有信心有一个匹配。这是对CNN的一个非常简化的描述，它涉及多个步骤和滤波器，但它应该有助于理解为什么我们想要在TensorFlow中使用`MobileNet`这样的CNN。
- en: '`MobileNet` is a specialist CNN that, among other things, provides us with
    image classification that has been trained against images in the ImageNet database
    ([http://www.image-net.org/](http://www.image-net.org/)). When we load the model,
    we are loading a pre-trained model that has been created for us. The reason we
    are using a pre-trained network is that it has been trained on a large dataset
    on the server. We would not want to run image classification training in the browser
    because it would require too much load being carried over from the server to the
    browser in order to perform the training. So, no matter how powerful your client
    PC is, copying over the training datasets will be too much.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`MobileNet`是一个专门的CNN，除其他功能外，它为我们提供了针对ImageNet数据库中的图像进行训练的图像分类（[http://www.image-net.org/](http://www.image-net.org/)）。当我们加载模型时，我们加载的是一个为我们创建的预训练模型。我们使用预训练网络的原因是它已经在服务器上的大型数据集上进行了训练。我们不希望在浏览器中运行图像分类训练，因为这将需要从服务器到浏览器传输太多负载以执行训练。因此，无论您的客户端PC有多强大，复制训练数据集都会太多。'
- en: We have mentioned `MobileNetV1` and `MobileNetV2` without going into what they
    are and what datasets they were trained on. Basically, the `MobileNet` models
    were developed by Google and trained on the ImageNet dataset, a dataset containing
    1.4 million images broken down into 1,000 classes of images. The reason these
    are called `MobileNet` models is because they were trained with mobile devices
    in mind, so they are designed to run on low power and/or low storage devices.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到了`MobileNetV1`和`MobileNetV2`，但没有详细介绍它们是什么以及它们是在什么数据集上训练的。基本上，`MobileNet`模型是由谷歌开发的，并在ImageNet数据集上进行了训练，该数据集包含了140万张图像，分为1000类图像。之所以称这些模型为`MobileNet`模型，是因为它们是针对移动设备进行训练的，因此它们被设计为在低功耗和/或低存储设备上运行。
- en: With a pre-trained model, we can use it as it is or we could customize it to
    use it for transfer learning.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用预训练模型，我们可以直接使用它，或者我们可以自定义它以用于迁移学习。
- en: The Classify method
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类方法
- en: 'Now that we understand a little bit about CNNs, we are ready to put this knowledge
    into practice. We are going to create an asynchronous classification method. TensorFlow
    can work with a number of formats when it needs to detect images, so we are going
    to generalize our method to only accept the appropriate types:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对CNN有了一点了解，我们准备将这些知识付诸实践。我们将创建一个异步分类方法。当TensorFlow需要检测图像时，它可以使用多种格式，因此我们将概括我们的方法，只接受适当的类型：
- en: '[PRE9]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Only one of these types is specific to TensorFlow—the `Tensor3D` type. All the
    other types are standard DOM types, so this can be easily consumed in a web page
    without having to jump through numerous hoops to convert the image into a suitable
    format.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这些类型中只有一个是特定于TensorFlow的——`Tensor3D`类型。所有其他类型都是标准的DOM类型，因此可以在网页中轻松消耗，而无需跳过许多环节将图像转换为适当的格式。
- en: 'We haven''t introduced our `TensorInformation` interface yet. When we receive
    classifications back from `MobileNet`, we receive a classification name and a
    confidence level for the classification. This comes back as `Promise<Array<[string,
    number]>>` from the classification operation, so we convert this into something
    more meaningful for our consuming code:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有介绍我们的`TensorInformation`接口。当我们从`MobileNet`接收分类时，我们会收到一个分类名称和一个分类的置信水平。这作为`Promise<Array<[string,
    number]>>`从分类操作返回，因此我们将其转换为对我们的消费代码更有意义的东西：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We now know that we are going to be returning an array of classifications and
    a probability (the confidence level). Getting back to our `Classify` method, we
    need to load `MobileNet` if it has not previously been loaded. This operation
    can take a while, which is why we cache it so that we don''t have to reload it
    the next time we call this method:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们将返回一个分类数组和一个概率（置信水平）。回到我们的`Classify`方法，如果以前没有加载`MobileNet`，我们需要加载它。这个操作可能需要一段时间，这就是为什么我们对它进行缓存，这样我们下次调用这个方法时就不必重新加载它了：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We have accepted the defaults for the `load` operation. There are a number
    of options that we could have supplied if we needed to:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经接受了`load`操作的默认设置。如果需要，我们可以提供一些选项：
- en: '`version`: This sets the `MobileNet` version number, and defaults to 1\. Right
    now, there are two values that can be set: `1` means that we use `MobileNetV1`,
    and `2` means that we use `MobileNetV2`. Practically, for us, the difference between
    versions relates to the accuracy and performance of the model.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`version`：这设置了`MobileNet`的版本号，默认为1。现在，可以设置两个值：`1`表示我们使用`MobileNetV1`，`2`表示我们使用`MobileNetV2`。对我们来说，版本之间的区别实际上与模型的准确性和性能有关。'
- en: '`alpha`: This can be set to `0.25`, `0.5`, `0.75`, or `1`. Surprisingly, this
    has nothing to do with the `alpha` channel on an image. Instead, it refers to
    the width of the network that will be used, effectively trading accuracy for performance.
    The higher the number, the greater the accuracy. Conversely, the higher the number,
    the slower the performance. The default for the `alpha` is `1`.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`alpha`：这可以设置为`0.25`、`0.5`、`0.75`或`1`。令人惊讶的是，这与图像上的`alpha`通道无关。相反，它指的是将要使用的网络宽度，有效地以性能换取准确性。数字越高，准确性越高。相反，数字越高，性能越慢。`alpha`的默认值为`1`。'
- en: '`modelUrl`: If we wanted to work with a custom model, we could supply this
    here.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modelUrl`：如果我们想要使用自定义模型，我们可以在这里提供。'
- en: 'If the model loads successfully, then we can now perform the image classification.
    This is a straightforward call to the `classify` method, taking in the `image`
    that has been passed into our method. Following the completion of this operation,
    we return the array of classification results:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型成功加载，那么我们现在可以执行图像分类。这是对`classify`方法的直接调用，传入我们方法中传递的`image`。完成此操作后，我们返回分类结果的数组：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The `model.classify` method returns three classifications by default, but if
    we wanted to, we could pass a parameter to return a different number of classifications.
    If we wanted to retrieve the top five results, we would change the `model.classify`
    line, as follows:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`model.classify`方法默认返回三个分类，但如果需要，我们可以传递参数返回不同数量的分类。如果我们想要检索前五个结果，我们将更改`model.classify`行如下：'
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Finally, in the unlikely event that the model failed to load, we return `null`.
    With this in place, our completed `Classify` method looks like this:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果模型加载失败，我们将返回`null`。有了这个设置，我们完成的`Classify`方法如下所示：
- en: '[PRE14]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: TensorFlow really can be that simple. Obviously, behind the scenes, a great
    deal of complexity has been hidden, but that is the beauty of well-designed libraries.
    They should shield us from the complexities while leaving us with room to get
    into the more complex operations and customization if we need to.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow确实可以如此简单。显然，在幕后，隐藏了大量的复杂性，但这就是设计良好的库的美妙之处。它们应该保护我们免受复杂性的影响，同时为我们留出空间，以便在需要时进行更复杂的操作和定制。
- en: So, that's our image classification component written. How do we use it in our
    Vue application, though? In the next section, we are going to see how we modify
    the `HelloWorld` component to use this class.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们的图像分类组件就写好了。但是我们如何在Vue应用程序中使用它呢？在下一节中，我们将看到如何修改`HelloWorld`组件以使用这个类。
- en: Modifying the HelloWorld component to support image classification
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 修改HelloWorld组件以支持图像分类
- en: When we created our Vue application, the CLI helpfully created a `HelloWorld.vue`
    file for us containing the `HelloWorld` component. We are going to take advantage
    of the fact that we already have this component, and we are going to use it to
    classify a pre-loaded image. If we wanted to, we could use it to load images using
    a file upload component and drive the classifications when this changes.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建Vue应用程序时，CLI会为我们创建一个`HelloWorld.vue`文件，其中包含`HelloWorld`组件。我们将利用我们已经有这个组件的事实，并将其用于对预加载图像进行分类。如果我们愿意，我们可以使用它来使用文件上传组件加载图像，并在更改时驱动分类。
- en: 'Now, let''s take a look at what our `HelloWorld` TypeScript code looks like.
    Obviously, we are going to start with a class definition. Just like we saw earlier,
    we have marked this with the `@Component` decorator to say that this is a component:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们的`HelloWorld` TypeScript代码是什么样子的。显然，我们将从类定义开始。就像我们之前看到的那样，我们已经用`@Component`装饰器标记了这个组件：
- en: '[PRE15]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We have two member variables that we want to declare in our class. We know
    that we want to use the `ImageClassifier` class that we have just written, so
    we will bring that one in. We also want to create an array of the `TensorInformation`
    results from the classification operation. The reason that we are going to store
    them as a class-level value is that we are going to have to bind to this when
    the operation finishes:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有两个成员变量要在我们的类中声明。我们知道我们想要使用刚刚编写的`ImageClassifier`类，所以我们会引入它。我们还想创建一个`TensorInformation`结果数组，原因是我们将不得不在操作完成时绑定到它：
- en: '[PRE16]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Before we finish writing our class, we need to see what our template will look
    like. We start off with the `template` definition:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们完成编写我们的类之前，我们需要看一下我们的模板会是什么样子。我们从`template`定义开始：
- en: '[PRE17]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'As we can see, we are using Bootstrap, so we are going to use a `div` container
    to lay out our content. The first thing we are going to add to our container is
    an image. I have chosen to use an image of a group of Border Collie dogs here,
    largely because I am a fan of dogs. In order for us to read this image inside
    TensorFlow, we need to set `crossorigin` to `anonymous`. Pay particular attention
    to `ref="dogId"` in this part because we are going to need it again shortly:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们正在使用Bootstrap，所以我们将使用一个`div`容器来布置我们的内容。我们要添加到容器中的第一件事是一个图像。我选择在这里使用一组边境牧羊犬的图像，主要是因为我是狗的粉丝。为了我们能够在TensorFlow中读取这个图像，我们需要将`crossorigin`设置为`anonymous`。在这一部分中特别注意`ref="dogId"`，因为我们很快会再次需要它：
- en: '[PRE18]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Following the image, we are going to add further Bootstrap support with the `row`
    and `col` classes:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像之后，我们将进一步添加Bootstrap支持，使用`row`和`col`类：
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Inside this row, we are going to create a Bootstrap list. We saw that Vue has
    its own Bootstrap support, so we are going to use its version for list support,
    `b-list-group`:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一行内，我们将创建一个Bootstrap列表。我们看到Vue有自己的Bootstrap支持，所以我们将使用它的版本来支持列表，即`b-list-group`：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we finally get to the meat of the template. The reason that we exposed
    the array of tensors in our class was so that we could iterate over each result
    in the array when it is populated. In the following code, we create a dynamic
    number of `b-list-group-item` by using `v-for` to automatically iterate over each
    tensor item. This creates the `b-list-group-item` entry, but we still need to
    display the individual `className` and `probability` items. With Vue, we bind
    text items such as this using `{{ <<item>> }}`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们终于到了模板的实质部分。我们在类中公开张量数组的原因是为了在数组被填充时能够迭代每个结果。在下面的代码中，我们使用`v-for`动态创建了`b-list-group-item`的数量，以自动迭代每个张量项。这创建了`b-list-group-item`条目，但我们仍然需要显示单独的`className`和`probability`项。使用Vue，我们使用`{{
    <<item>> }}`来绑定文本项，比如这样：
- en: '[PRE21]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The reason we have added `v-bind:key` alongside `v-for` is because Vue provides
    something it calls an **in-place patch** by default. This means that Vue uses
    this key as a hint to uniquely track the item so that it can keep the values up
    to date on changes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以在`v-for`旁边添加了`v-bind:key`，是因为Vue默认提供了所谓的**原地修补**。这意味着Vue使用这个键作为提示，以唯一地跟踪该项，以便在更改时保持值的最新状态。
- en: 'That''s it; our template is complete. As we can see, the following is a simple
    template, but there''s a lot going on with it. We have a Bootstrap container showing
    an image and, following that, letting Vue dynamically bind in the `tensor` details:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样；我们的模板完成了。正如我们所看到的，以下是一个简单的模板，但其中有很多内容。我们有一个Bootstrap容器显示一个图像，然后让Vue动态绑定`tensor`的细节：
- en: '[PRE22]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Getting back to our TypeScript code, we are going to write the method that
    takes the image and then uses it to call our `ImageClassifier.Classify` method:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的TypeScript代码，我们将编写一个方法，该方法获取图像，然后使用它调用我们的`ImageClassifier.Classify`方法：
- en: '[PRE23]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Since we are loading an image onto our client, we have to wait for the page
    to render with the image so that we can retrieve it. We are going to call our
    `Classify` method from the constructor so, as it runs while the page is being
    created, we need to use a little trick to wait for the image to load. Specifically,
    we are going to use a Vue function called `nextTick`. It is important to understand
    that updates to the DOM happen asynchronously. When a value changes, the change
    isn''t rendered immediately. Instead, Vue requests a DOM update, which is then
    triggered by a timer. So, by using `nextTick`, we wait for the next DOM update
    tick and perform the relevant operation:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在将图像加载到客户端上，我们必须等待页面呈现图像，以便我们可以检索它。我们将从构造函数中调用我们的`Classify`方法，因此在页面创建时运行，我们需要使用一个小技巧来等待图像加载。具体来说，我们将使用一个名为`nextTick`的Vue函数。重要的是要理解DOM的更新是异步发生的。当值发生变化时，更改不会立即呈现。相反，Vue请求DOM更新，然后由计时器触发。因此，通过使用`nextTick`，我们等待下一个DOM更新时刻并执行相关操作：
- en: '[PRE24]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The reason why we mark the `async` function inside the `then` block is that
    we are going to perform an await inside this section, which means that we have
    to scope this as `async` as well.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`then`块内标记`async`函数的原因是，我们将在此部分执行等待，这意味着我们也必须将其作为`async`范围。
- en: 'In the template, we defined our image with a `ref` statement because we want
    to access this from inside our class. To do that, we query the map of `ref` statements that
    Vue maintains for us here, and since we have set our own reference up with `dogId`,
    we can now access the image. This trick saves us from having to use `getElementById`
    to retrieve our HTML element:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在模板中，我们使用`ref`语句定义了我们的图像，因为我们希望从类内部访问它。为此，我们在这里查询Vue为我们维护的`ref`语句映射，由于我们已经设置了自己的引用为`dogId`，我们现在可以访问图像。这个技巧使我们不必使用`getElementById`来检索我们的HTML元素。
- en: '[PRE25]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: When we built our Vue application, the CLI automatically set up TSLint rules
    for us. One of these rules related to accessing elements via string literals.
    We disable the rule temporarily by using `tslint:disable:no-string-literal`. To
    re-enable the rule, we use `tslint:enable:no-string-literal`. There is an alternative
    way to disable this rule for a single line, which is to use `/* tslint:disable-next-line:no-string-literal
    */`. The approach you take doesn't really matter; what matters is the end result.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建Vue应用程序时，CLI会自动为我们设置TSLint规则。其中一个规则涉及通过字符串字面量访问元素。我们可以使用`tslint:disable:no-string-literal`临时禁用该规则。要重新启用该规则，我们使用`tslint:enable:no-string-literal`。还有一种禁用此规则的替代方法是在单行上使用`/*
    tslint:disable-next-line:no-string-literal */`。您采取的方法并不重要；重要的是最终结果。
- en: 'Once we have a reference to the dog image, we can now cast the image to `HTMLImageElement`
    and use this in the call to our `Classify` method in the `ImageClassifier` class:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了对狗图片的引用，我们现在可以将图像转换为`HTMLImageElement`，并在`ImageClassifier`类中的`Classify`方法调用中使用它：
- en: '[PRE26]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: When the call to `Classify` comes back, as long as the model has loaded and
    successfully found classifications, it will populate our onscreen list through
    the power of binding.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 当`Classify`调用返回时，只要模型已加载并成功找到分类，它将通过绑定的力量填充我们的屏幕列表。
- en: 'Throughout our examples, I have tried to keep our code base as clean and as
    simple as possible. The code has been separated into separate classes just so
    we can create small and powerful pieces of functionality. To see why I like to
    do this, this is what our `HelloWorld` code looks like:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我尽量保持我们的代码库尽可能干净和简单。代码已分离为单独的类，以便我们可以创建小而强大的功能块。要了解为什么我喜欢这样做，这是我们的`HelloWorld`代码的样子：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: In total, including `tslint` formatters and white space, this code is only 20
    lines long. Our `ImageClassifier` class is only 22 lines long, and that's an `ImageClassifier`
    class that could be used elsewhere without modification. By keeping classes simple,
    we decrease the number of ways that they could go wrong and we increase our chances
    of being able to reuse them. More importantly, we stick to the rather unfriendly
    named **Keep It Simple, Stupid** (**KISS**) principle, which states that systems
    work best if they are inherently as simple as they can possibly be.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 总共，包括`tslint`格式化程序和空格，这段代码只有20行。我们的`ImageClassifier`类只有22行，这是一个可以在其他地方使用而无需修改的`ImageClassifier`类。通过保持类简单，我们减少了它们可能出错的方式，并增加了重用它们的机会。更重要的是，我们遵循了名为**保持简单，愚蠢**（**KISS**）原则，该原则指出系统在本质上尽可能简单时效果最好。
- en: Now that we have seen image classification in action, we can think about adding
    pose detection to our application. Before we do so, we need to look at a couple
    of other Vue areas that are going to be important to us.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到图像分类的实际操作，我们可以考虑将姿势检测添加到我们的应用程序中。在这样做之前，我们需要看一下其他一些对我们重要的Vue领域。
- en: The Vue application entry point
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Vue应用程序入口点
- en: Something that we haven't touched on yet is what the entry point to our Vue
    application is. We have seen the `Home.vue` page, but that is just a component
    that gets rendered somewhere else. We need to take a step back and see how our
    Vue application actually handles loading itself and showing the relevant components.
    While we are doing this, we will also touch on routing in Vue so that we can see
    how that all hangs together.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有涉及的是Vue应用程序的入口点是什么。我们已经看到了`Home.vue`页面，但那只是一个在其他地方呈现的组件。我们需要退一步，看看我们的Vue应用程序实际上是如何处理加载自身并显示相关组件的。在这个过程中，我们还将涉及Vue中的路由，以便我们可以看到所有这些是如何联系在一起的。
- en: 'Our starting point is found inside the `public` folder. In there, we have an
    `index.html` file, which we can think of as being the master template for our
    application. It''s a fairly standard HTML file—we might want to give it a more
    suitable `title` (here, we''re going with `Advanced TypeScript - Machine Learning`):'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的起点位于`public`文件夹内。在那里，我们有一个`index.html`文件，我们可以将其视为应用程序的主模板。这是一个相当标准的HTML文件-我们可能希望给它一个更合适的`title`（在这里，我们选择`Advanced
    TypeScript - Machine Learning`）：
- en: '[PRE28]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The important element here is the `div` with its `id` property set to `app`.
    This is the element into which we are going to render our components. The way
    we do this is controlled from the `main.ts` file. Let''s start by adding Bootstrap
    support, both by adding the Bootstrap CSS files and by registering the `BootstrapVue`
    plugin using `Vue.use`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的重要元素是`div`，其`id`属性设置为`app`。这是我们将要呈现组件的元素。我们控制这个的方式是从`main.ts`文件中进行的。让我们首先通过添加Bootstrap支持来添加Bootstrap支持，既通过添加Bootstrap
    CSS文件，又通过使用`Vue.use`注册`BootstrapVue`插件：
- en: '[PRE29]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Even though we have Bootstrap support in place, we don''t have anything that
    hooks our components into `app div`. The reason why we add this support is to
    create a new Vue application. This accepts a router, a Vue store that is used
    to contain things such as Vue state and mutations, and a `render` function, which
    is called when the component is being rendered. The `App` component that''s passed
    into our `render` method is the top-level `App` component that we will use to
    render all the other components into. When the Vue application finishes being
    created, it is mounted into the `app` div from `index.html`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们已经有了Bootstrap支持，但我们没有任何东西将我们的组件连接到`app div`。我们添加此支持的原因是创建一个新的Vue应用程序。这接受一个路由器，一个用于包含Vue状态和突变等内容的Vue存储库，以及一个`render`函数，在呈现组件时调用。传递给我们的`render`方法的`App`组件是我们将用于呈现所有其他组件的顶级`App`组件。当Vue应用程序创建完成时，它被挂载到`index.html`中的`app`
    div中：
- en: '[PRE30]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Our `App.vue` template consists of two separate areas. Before we add those
    areas, let''s define the `template` element and containing `div` tag:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`App.vue`模板由两个独立的区域组成。在添加这些区域之前，让我们定义`template`元素和包含的`div`标签：
- en: '[PRE31]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Inside this `div` tag, we are going to add our first logical section—our good
    old friend, the navigation bar. Since these come in from the Vue Bootstrap implementation,
    they are all prefixed with `b-`, but they should need no dissection now, as they
    should be very familiar by this point:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个`div`标签中，我们将添加我们的第一个逻辑部分——我们的老朋友，导航栏。由于这些来自Vue Bootstrap实现，它们都以`b-`为前缀，但现在不需要解剖它们，因为到这一点它们应该非常熟悉：
- en: '[PRE32]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'When the user navigates to a page, we need to display the appropriate component.
    Under the cover, the component that is displayed is controlled by the Vue router,
    but we need somewhere to display it. This is accomplished by using the following
    tag below our navigation bar:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 用户导航到页面时，我们需要显示适当的组件。在幕后，显示的组件由Vue路由器控制，但我们需要一个地方来显示它。这是通过在我们的导航栏下方使用以下标签来实现的：
- en: '[PRE33]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'This is what our `App` template looks like when it has been completed. As we
    can see, if we want to route to other pages, we will need to add separate `b-nav-item`
    entries to this list. If we wanted to, we could dynamically create this navigation
    list using `v-for` in a similar way to what we saw when we were building up the
    classifications with the image classifier view:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的`App`模板完成后的样子。正如我们所看到的，如果我们想要路由到其他页面，我们需要将单独的`b-nav-item`条目添加到此列表中。如果我们愿意，我们可以使用`v-for`以类似的方式动态创建这个导航列表，就像我们在构建图像分类器视图时看到的那样：
- en: '[PRE34]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'When we first started looking at routing, all those chapters ago, you possibly
    thought that routing was a highly complicated thing to add to our applications.
    By now, you should be a lot more comfortable with routing and it isn''t going
    to be much of a surprise that it is straightforward and simple to add routing
    support in Vue. We start off by registering the `Router` plugin inside Vue using
    the following command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始研究路由时，可能会认为将路由添加到我们的应用程序是一件非常复杂的事情。到现在为止，你应该对路由更加熟悉了，而且不会感到惊讶，因为在Vue中添加路由支持是直接而简单的。我们首先通过以下命令在Vue中注册`Router`插件：
- en: '[PRE35]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'With this in place, we are now ready to build routing support. We export an
    instance of `Router` that can be used in our `new Vue` call:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个，我们现在准备构建路由支持。我们导出一个`Router`的实例，可以在我们的`new Vue`调用中使用：
- en: '[PRE36]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'We are now at the point where we need to add our routing options. The first
    option we are going to set up is the routing mode. We are going to use the HTML5
    `history` API to manage our links:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要添加我们的路由选项。我们要设置的第一个选项是路由模式。我们将使用HTML5 `history` API来管理我们的链接：
- en: '[PRE37]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We could use URL hashing for routing. This works in all the browsers that Vue
    supports and is a good choice if the HTML5 `history` API is unavailable. Alternatively,
    there is an abstract routing mode that works across all JavaScript environments,
    including Node. If the browser API is not present, no matter what we set the mode
    to, the router will automatically be forced to use this.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用URL哈希进行路由。这在Vue支持的所有浏览器中都可以工作，并且如果HTML5 `history` API不可用，则是一个不错的选择。或者，还有一种抽象的路由模式，可以在包括Node在内的所有JavaScript环境中工作。如果浏览器API不存在，无论我们将模式设置为什么，路由器都将自动强制使用这个模式。
- en: The reason we want to use the `history` API is that it allows us to modify the
    URL without triggering full-page refreshes. Since we know that we only want to
    replace components, rather than replacing the whole `index.html` page, we end
    up leveraging this API to only reload the component parts of the page, without
    doing a full-page reload.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要使用`history` API的原因是它允许我们修改URL而不触发整个页面的刷新。由于我们知道我们只想替换组件，而不是替换整个`index.html`页面，我们最终利用这个API只重新加载页面的组件部分，而不进行整个页面的重新加载。
- en: 'We also want to set the base URL of our application. If we wanted to override
    this location to serve everything from the `deploy` folder, for instance, then
    we would set this to `/deploy/`:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想设置应用程序的基本URL。如果我们想要覆盖此位置以从`deploy`文件夹中提供所有内容，那么我们将其设置为`/deploy/`：
- en: '[PRE38]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'While it is all well and good setting up the routing mode and the base URL,
    we are missing out on the important part here—setting the routes themselves. At
    a minimum, each route contains a path and a component. The path relates to the
    path in the URL, and the component identifies what component will be displayed
    as a result of that path. Our routes look like this:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然设置路由模式和基本URL都很好，但我们错过了重要的部分——设置路由本身。每个路由至少包含一个路径和一个组件。路径与URL中的路径相关联，组件标识将作为该路径结果显示的组件。我们的路由看起来像这样：
- en: '[PRE39]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We have a special path match in our route. If the user types in a URL that doesn't
    exist, then we use `*` to capture that and redirect it to a particular component.
    We must put this as the last entry because otherwise, it would take precedence
    over the exact matches. The eagle-eyed reader will notice that, strictly speaking,
    we don't need the first path because our routing would still show the `Home` component
    due to our `*` fallback.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的路由中有一个特殊的路径匹配。如果用户输入一个不存在的URL，那么我们使用`*`来捕获它，并将其重定向到特定的组件。我们必须将其放在最后一个条目，否则它将优先于精确匹配。敏锐的读者会注意到，严格来说，我们不需要第一个路径，因为我们的路由仍然会显示`Home`组件，因为我们的`*`回退。
- en: One thing we added to our route was a reference to a component that doesn't
    exist yet. We're going to address that now by adding the `Pose` component.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在路由中添加了一个指向尚不存在的组件的引用。现在我们将通过添加`Pose`组件来解决这个问题。
- en: Adding pose detection capabilities
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 添加姿势检测功能
- en: 'Before we start addressing pose detection, we are going to add a component
    that will play host to the relevant functionality. As this is our first component
    *from scratch*, we''ll also cover it from scratch. Inside our `views` folder,
    create a file called `Pose.vue`. This file is going to contain three logical elements,
    so we will start off by adding those and setting up our template to use Bootstrap:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始处理姿势检测之前，我们将添加一个组件，该组件将承载相关功能。由于这是我们第一个*从头开始*的组件，我们也将从头开始介绍它。在我们的`views`文件夹中，创建一个名为`Pose.vue`的文件。这个文件将包含三个逻辑元素，所以我们将首先添加这些元素，并设置我们的模板以使用Bootstrap：
- en: '[PRE40]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The only one of these that we haven't looked at so far is the `style` section.
    Scoped styles allow us to apply styling that just applies to the current component.
    We will apply local styling shortly, but first, we need to set up the image that
    we are going to display.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们还没有看过的是`style`部分。作用域样式允许我们应用仅适用于当前组件的样式。我们很快将应用本地样式，但首先，我们需要设置要显示的图像。
- en: 'For our example code, I have selected a picture that is 1,200 pixels wide and
    675 pixels high. This information is important because, when we do our pose detection,
    we are going to draw these points on the image, which means that we need to do
    a little bit of styling arrangement to put a canvas in place on which we can draw
    the points that match the locations on the image. We start off with two containers
    to hold our image:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例代码，我选择了一张宽1200像素，高675像素的图片。这些信息很重要，因为当我们进行姿势检测时，我们将在图像上绘制这些点，这意味着我们需要进行一些样式安排，以便在图像上放置一个画布，我们可以在上面绘制与图像上的位置匹配的点。我们首先使用两个容器来容纳我们的图像：
- en: '[PRE41]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We are now going to add some CSS inside our style-scoped section to hardwire
    the dimensions in place. We start by setting the outside wrapper to have the dimensions
    I have just described. We then position our inside wrapper relative to our outer
    one, and set the width and height to 100% so that they fill the bounds exactly:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在要在我们的样式作用域部分添加一些CSS来固定尺寸。我们首先设置外部包装器的尺寸，然后相对于外部包装器定位我们的内部包装器，并将宽度和高度设置为100%，以便它们完全填充边界：
- en: '[PRE42]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Going back to `insideWrapper`, we need to add our image inside this. The image
    I chose for our example was a neutral pose, showing the key body points. The format
    of our image tag should look familiar, having done this already with the image
    classification code:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 回到`insideWrapper`，我们需要在其中添加我们的图像。我选择的示例图像是一个中性姿势，显示了关键身体点。我们的图像标签的格式应该看起来很熟悉，因为我们已经用图像分类代码做过这个：
- en: '[PRE43]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'In the same `insideWrapper` `div` tag, just below our image, we need to add
    a canvas. We will use the canvas when we want to draw the key body points. The
    key thing with this is that the width and height of the canvas match the container
    dimensions exactly:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在相同的`insideWrapper` `div`标签中，就在我们的图像下面，我们需要添加一个画布。当我们想要绘制关键身体点时，我们将使用这个画布。关键是画布的宽度和高度与容器的尺寸完全匹配：
- en: '[PRE44]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'At this point, our `template` looks like this:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们的`template`看起来像这样：
- en: '[PRE45]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We have added classes to the image and canvas, but we haven''t added their
    definitions. We could use one class to cover both, but I''m happy enough for us
    to have separate ones in place to set the width and height to 100%, and to position
    them absolutely inside the container:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为图像和画布添加了类，但我们还没有添加它们的定义。我们可以使用一个类来覆盖两者，但我对我们分别设置宽度和高度为100%的类感到满意，并将它们绝对定位在容器内部：
- en: '[PRE46]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Our completed, the styling section will look like this:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成后，样式部分将如下所示：
- en: '[PRE47]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We have a couple of helper classes that we need to write at this point—one to
    do the pose detection, and the other to draw the points on the image.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们需要编写一些辅助类——一个用于进行姿势检测，另一个用于在图像上绘制点。
- en: Drawing the key points on the canvas
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在画布上绘制关键点
- en: Whenever we detect a pose, we receive a number of key points back with it. Each
    key point is made up of a position (the *x* and *y* coordinates), the score (or
    confidence), and the actual part that the key point represents. We want to loop
    over the points and draw them on the canvas.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我们检测到一个姿势，我们都会得到一些关键点。每个关键点由位置（*x*和*y*坐标）、分数（或置信度）和关键点表示的实际部分组成。我们希望循环遍历这些点并在画布上绘制它们。
- en: 'As always, let''s start off with our class definition:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，让我们从我们的课程定义开始：
- en: '[PRE48]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We only need to get the canvas element once as it''s not going to change. This
    indicates that we could pass this as our canvas and, because we are interested
    in the two-dimensional element of the canvas, we can extract the drawing context
    directly from the canvas. With this context, we clear off any previously drawn
    elements on the canvas and set a `fillStyle` color to `#ff0300`, which we will
    use to color in our pose points:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要获取一次画布元素，因为它不会改变。这表明我们可以将这个作为我们的画布，因为我们对画布的二维元素感兴趣，我们可以直接从画布中提取绘图上下文。有了这个上下文，我们清除画布上以前绘制的任何元素，并将`fillStyle`颜色设置为`#ff0300`，我们将用它来填充我们的姿势点：
- en: '[PRE49]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'In order to draw our key points, we write a method that loops over each `Keypoint` instance
    and calls `fillRect` to draw the point. The rectangle is offset from the *x* and
    *y* coordinates by 2.5 pixels so that drawing a 5-pixel rectangle actually draws
    a rectangle that is roughly centered on the point:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了绘制我们的关键点，我们编写一个方法，循环遍历每个`Keypoint`实例，并调用`fillRect`来绘制点。矩形从*x*和*y*坐标偏移2.5像素，以便绘制一个5像素的矩形实际上是在点的大致中心绘制一个矩形：
- en: '[PRE50]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Once finished, our `DrawPose` class looks like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，我们的`DrawPose`类如下所示：
- en: '[PRE51]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Using pose detection on the image
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在图像上使用姿势检测
- en: 'Earlier, we created an `ImageClassifier` class to perform our image classification.
    In keeping with the spirit of this class, we are now going to write a `PoseClassifier`
    class to manage the physical pose detection:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们创建了一个`ImageClassifier`类来执行图像分类。为了保持这个类的精神，我们现在要编写一个`PoseClassifier`类来管理物理姿势检测：
- en: '[PRE52]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'We are going to set up two private members for our class. The model is a `PoseNet`
    model, which will be populated when we call the relevant load method. `DrawPose`
    is the class we just defined:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将为我们的类设置两个私有成员。模型是一个`PoseNet`模型，在调用相关的加载方法时将被填充。`DrawPose`是我们刚刚定义的类：
- en: '[PRE53]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Before we go any further into our pose detection code, we should start to get
    an understanding of what pose detection is, some of the things it is good for,
    and what some of the constraints are.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进一步进行姿势检测代码之前，我们应该开始了解姿势检测是什么，它适用于什么，以及一些约束是什么。
- en: A brief aside about pose detection
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于姿势检测的简要说明
- en: We are using the term **pose detection** here, but this is also known as **pose
    estimation**. If you have not come across pose estimation, this simply refers
    to a computer vision operation where human figures are detected, either from an
    image or from a video. Once the figure(s) have been detected, the model is able
    to determine roughly where the key joints and body segments (such as the left
    ear) are.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里使用术语**姿势检测**，但这也被称为**姿势估计**。如果你还没有接触过姿势估计，这简单地指的是计算机视觉操作，其中检测到人物形象，无论是从图像还是视频中。一旦人物被检测到，模型就能大致确定关键关节和身体部位（如左耳）的位置。
- en: The growth of pose detection has been rapid, and it has some obvious usages.
    For instance, we could use pose detection to perform motion capture for animation;
    studios are increasingly turning to motion capture to capture live-action performances
    and convert them into 3D images. Another usage lives in the field of sports; in
    fact, sports have many potential usages of motion capture. Suppose you are a pitcher
    in a major league baseball team. Pose detection could be used to determine whether
    your stance was correct at the point of releasing the ball; perhaps you were leaning
    over too far, or your elbow positioning was incorrect. With pose detection, it
    becomes easier for coaches to work with players to correct potential problems.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势检测的增长速度很快，它有一些明显的用途。例如，我们可以使用姿势检测来进行动作捕捉以制作动画；工作室越来越多地转向动作捕捉，以捕捉现场表演并将其转换为3D图像。另一个用途在体育领域；事实上，体育运动有许多潜在的动作捕捉用途。假设你是一支大联盟棒球队的投手。姿势检测可以用来确定在释放球时你的站姿是否正确；也许你倾斜得太远，或者你的肘部位置不正确。有了姿势检测，教练们更容易与球员合作纠正潜在问题。
- en: At this point, it's worth noting that pose detection is not the same as person
    recognition. I know it seems obvious, but there are people who have been confused
    by this technology into thinking that this somehow identified who a person is.
    That's a completely different form of machine learning.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，值得注意的是，姿势检测并不等同于人物识别。我知道这似乎很明显，但有些人被这项技术所困惑，以为这种技术可以识别一个人是谁。那是完全不同的机器学习形式。
- en: How does PoseNet work?
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PoseNet是如何工作的？
- en: Even with camera-based input, the process of performing pose detection does
    not change. We start with an input image (a single still of a video is good enough
    for this). The image is passed through a CNN to do the first part and identify
    where the people are in the scene. The next step takes the output from the CNN,
    passes it through a pose decoding algorithm (we'll come back to this in a moment),
    and uses this to decode poses.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用基于摄像头的输入，执行姿势检测的过程也不会改变。我们从输入图像开始（视频的一个静止画面就足够了）。图像通过CNN进行第一部分处理，识别场景中人物的位置。下一步是将CNN的输出传递给姿势解码算法（我们稍后会回到这一点），并使用它来解码姿势。
- en: The reason we said *pose decoding algorithm* was to gloss over the fact that
    we actually have two decoding algorithms. We can detect single poses, or if there
    are multiple people, we can detect multiple poses.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之所以说*姿势解码算法*是为了掩盖我们实际上有两个解码算法的事实。我们可以检测单个姿势，或者如果有多个人，我们可以检测多个姿势。
- en: 'We have opted to go with the single pose algorithm because it is the simpler
    and faster algorithm. If there are multiple people in the picture, there is potential
    for the algorithm to merge key points from different people together; therefore,
    things such as occlusion could mean that the algorithm detects person 2''s right
    shoulder as person 1''s left elbow. In the following image, we can see how the
    elbow of the girl on the right obscures the left elbow of the person in the middle:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们选择了单姿势算法，因为它是更简单和更快的算法。如果图片中有多个人，算法有可能将不同人的关键点合并在一起；因此，遮挡等因素可能导致算法将人2的右肩检测为人1的左肘。在下面的图片中，我们可以看到右侧女孩的肘部遮挡了中间人的左肘：
- en: '![](assets/2d6da8aa-084f-4de7-aa17-509e2f214ad3.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/2d6da8aa-084f-4de7-aa17-509e2f214ad3.png)'
- en: Occlusion is when one part of an image hides another part.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 遮挡是指图像的一部分遮挡了另一部分。
- en: 'The key points that are detected by `PoseNet` are as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '`PoseNet`检测到的关键点如下：'
- en: Nose
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鼻子
- en: Left eye
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左眼
- en: Right eye
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右眼
- en: Left ear
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左耳
- en: Right ear
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右耳
- en: Left shoulder
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左肩
- en: Right shoulder
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右肩
- en: Left elbow
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左肘
- en: Right elbow
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右肘
- en: Left wrist
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左腕
- en: Right wrist
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右腕
- en: Left hip
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左臀
- en: Right hip
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右臀
- en: Left knee
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左膝
- en: Right knee
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右膝
- en: Left ankle
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 左踝
- en: Right ankle
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 右踝
- en: 'We can see where these are placed in our application. When it has finished
    detecting the points, we get an overlay of images, such as this:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到它们在我们的应用程序中的位置。当它完成检测点时，我们会得到一组图像叠加，如下所示：
- en: '![](assets/8bbfe2de-3b60-43e1-98b1-2075ccf2e1ba.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/8bbfe2de-3b60-43e1-98b1-2075ccf2e1ba.png)'
- en: Back to our pose detection code
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回到我们的姿势检测代码
- en: 'Getting back to our `PoseClassifier` class, our constructor deals with exactly
    the same WebGLTexture issue that we discussed for our `ImageClassifier` implementation:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的`PoseClassifier`类，我们的构造函数处理了与我们的`ImageClassifier`实现讨论过的完全相同的WebGLTexture问题：
- en: '[PRE54]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'We are now going to write an asynchronous `Pose` method that returns either
    an array of `Keypoint` items, or `null` if the `PoseNet` model fails to load or
    find any poses. As well as accepting an image, this method will also accept the
    canvas that provides the context that we are going to draw our points on:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在要编写一个异步的`Pose`方法，它会返回一个`Keypoint`项的数组，或者如果`PoseNet`模型加载失败或找不到任何姿势，则返回`null`。除了接受图像，这个方法还将接受提供上下文的画布，我们将在上面绘制我们的点：
- en: '[PRE55]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'In the same way that `ImageClassifier` retrieved the `MobileNet` model as a
    cached operation, we are going to retrieve the `PoseNet` model and cache it. We
    will take this opportunity to instantiate the `DrawPose` instance as well. The
    point behind performing logic such as this is to ensure that this is something
    that we only do once, no matter how many times we call this method. Once the model
    is not null, the code prevents us from attempting to load `PoseNet` again:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`ImageClassifier`检索`MobileNet`模型一样，我们将检索`PoseNet`模型并对其进行缓存。我们将利用这个机会来实例化`DrawPose`实例。执行这样的逻辑是为了确保这是我们只做一次的事情，无论我们调用这个方法多少次。一旦模型不为空，代码就会阻止我们尝试再次加载`PoseNet`：
- en: '[PRE56]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'When we load the model, we can supply the following option:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们加载模型时，我们可以提供以下选项：
- en: '**Multiplier**: This is the float multiplier for the number of channels (the
    depth) for all convolution operations. Choose from 1.01, 1.0, 0.75, or 0.50\.
    There is a trade-off of speed and accuracy here, with the larger values being
    more accurate.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Multiplier**：这是所有卷积操作的通道数（深度）的浮点乘数。可以选择1.01、1.0、0.75或0.50。这里有速度和准确性的权衡，较大的值更准确。'
- en: 'Finally, if the model loads successfully, we are going to call `estimateSinglePose`
    with our image to retrieve the `Pose` prediction, which also contains the `keypoints`
    that we will draw:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果模型成功加载，我们将使用我们的图像调用`estimateSinglePose`来检索`Pose`预测，其中还包含我们将绘制的`keypoints`：
- en: '[PRE57]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Again, putting this all together to show how we don''t have to write huge amounts
    of code to accomplish all this work, and how separating the code out into small,
    self-contained logical chunks, makes our code so much simpler to understand, as
    well as easier to write. This is the full `PoseClassifier` class:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 再次将所有这些放在一起，以展示我们不必写大量代码来完成所有这些工作，以及将代码分离成小的、自包含的逻辑块，使我们的代码更容易理解，也更容易编写。这是完整的`PoseClassifier`类：
- en: '[PRE58]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Completing our pose detection component
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完成我们的姿势检测组件
- en: 'Getting back to our `Pose.vue` component, we now have to fill in the `script`
    section. We are going to need the following `import` statements and class definition
    for our component (remember that I promised we would build this class up from
    scratch). Again, we can see the use of `@Component` to give us a component registration.
    We see this time and time again with Vue components:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 回到我们的`Pose.vue`组件，现在我们需要填写`script`部分。我们需要以下`import`语句和组件的类定义（记住我承诺过我们会从头开始构建这个类）。同样，我们可以看到使用`@Component`来给我们一个组件注册。我们在Vue组件中一次又一次地看到这一点：
- en: '[PRE59]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'We have reached the point where we can write our `Classify` method, which will
    retrieve the image and canvas when they have been created and pass this through
    to the `PoseClassifier` class. We need a couple of private fields to hold the
    `PoseClassifier` instance and the returned `Keypoint` array:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经到了可以编写我们的`Classify`方法的地步，当图像和画布被创建时，它将检索图像和画布，并将其传递给`PoseClassifier`类。我们需要一些私有字段来保存`PoseClassifier`实例和返回的`Keypoint`数组：
- en: '[PRE60]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Inside our `Classify` code, we are going to employ the same life cycle trick
    of waiting for `nextTick` before we retrieve the image referenced as `poseId`,
    and the canvas referenced as `posecanvas`:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`Classify`代码中，我们将使用相同的生命周期技巧，在检索名为`poseId`的图像引用和名为`posecanvas`的画布之前等待`nextTick`：
- en: '[PRE61]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Once we have the image reference, we cast them to the appropriate `HTMLImageElement`
    and `HTMLCanvasElement` types, before we call the `Pose` method and populate our
    `keypoints` member with the resulting values:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了图像引用，我们将它们转换为适当的`HTMLImageElement`和`HTMLCanvasElement`类型，然后调用`Pose`方法，并用结果值填充我们的`keypoints`成员：
- en: '[PRE62]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'At this point, we can run the application. It''s very satisfying seeing the
    `keypoints` results being overlaid onto the image, but we can go further. With
    just a little bit of extra effort, we can display the `keypoints` results in a
    Bootstrap table. Go back to our template and add the following `div` statements
    to add a Bootstrap row and column below the image:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以运行应用程序。看到`keypoints`结果叠加在图像上非常令人满意，但我们可以做得更多。只需稍加努力，我们就可以在Bootstrap表格中显示`keypoints`结果。返回到我们的模板，并添加以下`div`语句以在图像下方添加Bootstrap行和列：
- en: '[PRE63]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Since we have already exposed the `keypoints` results, we can simply create
    a Vue Bootstrap table using `b-table`. We set the binding to the items using `:items`,
    setting it to the `keypoints` results that we defined in our class. This means
    that, whenever the `keypoints` entry gets new values, the table will be updated
    to display these values:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经暴露了`keypoints`结果，我们可以简单地使用`b-table`创建一个Vue Bootstrap表格。我们使用`:items`将绑定设置为我们在类中定义的`keypoints`结果。这意味着每当`keypoints`条目获得新值时，表格将更新以显示这些值。
- en: '[PRE64]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Refreshing our application adds the table below the image, with the table looking
    like this:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 刷新我们的应用程序会在图像下方添加表格，表格如下所示：
- en: '![](assets/0e3e8bd3-753d-4108-bd61-fa17d61ffe87.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/0e3e8bd3-753d-4108-bd61-fa17d61ffe87.png)'
- en: While this is a reasonable start, it would be good if we could take a bit more
    control of the table. Right now, the fields are picked up and automatically formatted
    by `b-table`. With a small change, we can separate the `Position` instance out
    into two separate entries and make the `Score` and `Part` fields sortable.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这是一个合理的开始，但如果我们能更多地控制表格就更好了。目前，`b-table`自动捕捉并格式化字段。通过小小的改变，我们可以将`Position`实例分离为两个单独的条目，并使`Score`和`Part`字段可排序。
- en: 'In our `Pose` class, we will create a `fields` entry. The `fields` entry maps
    the score entry to use the `Confidence` label and sets it to be `sortable`. The
    `part` field maps to a `label` value of `Part` and is also set to be `sortable`.
    We break `position` into two separate mapped entries labeled `X` and `Y`, respectively:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的`Pose`类中，我们将创建一个`fields`条目。`fields`条目将分数条目映射到`Confidence`标签，并将其设置为`sortable`。`part`字段映射到`Part`的`label`值，并且也设置为`sortable`。我们将`position`分为两个单独的映射条目，分别标记为`X`和`Y`：
- en: '[PRE65]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The last thing we need to do is hook the `fields` entry into `b-table`. We
    do this using the `:fields` property, like this:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的最后一件事是将`fields`输入连接到`b-table`。我们可以使用`:fields`属性来实现这一点，就像这样：
- en: '[PRE66]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Refreshing our application shows us the effect of such little changes. This
    is a much more attractive screen, and the fact that the user can sort the `Confidence`
    (originally called `score`) and `Part` fields with such little effort shows just
    how powerful Vue really is:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 刷新我们的应用程序会显示这些微小更改的效果。这是一个更具吸引力的屏幕，用户可以轻松地对`Confidence`（原名`score`）和`Part`字段进行排序，这显示了Vue的强大之处：
- en: '![](assets/afc205c4-af29-4c59-b390-b0afb12d4398.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/afc205c4-af29-4c59-b390-b0afb12d4398.png)'
- en: That's it—we have reached the end of introducing TensorFlow and Vue. We have
    steered clear of the mathematical aspects behind CNNs because although they can
    appear intimidating at first glance, they aren't really as bad as all of that,
    but there are a lot of parts to a typical CNN. There is also a lot more that we
    can do with Vue; for such a small library, it is incredibly powerful, and this
    combination of small size and power is one of the reasons that it is becoming
    ever more popular.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样——我们已经介绍了TensorFlow和Vue。我们避开了CNN背后的数学方面，因为尽管乍一看可能令人生畏，但实际上并没有那么糟糕，但典型的CNN有很多部分。Vue还有很多功能可以使用；对于一个如此小的库来说，它非常强大，这种小巧和强大的组合是它变得越来越受欢迎的原因之一。
- en: Summary
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have taken our first steps into writing machine learning
    applications using the popular `TensorFlow.js` library. As well as learning about
    what machine learning is, we have also seen how it fits into the AI space. While
    we wrote our classes to hook up to `MobileNet` and pose detection libraries, we
    also covered what CNNs are.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们迈出了使用流行的`TensorFlow.js`库编写机器学习应用程序的第一步。除了了解机器学习是什么，我们还看到了它如何适用于人工智能领域。虽然我们编写了类来连接到`MobileNet`和姿势检测库，但我们也介绍了CNN是什么。
- en: As well as looking at `TensorFlow.js`, we have started a journey into using
    Vue.js, the up-and-coming client side library that is rapidly gaining popularity
    alongside Angular and React. We saw how to use `.vue` files and how to hook our
    TypeScript alongside the web templates, including using Vue's binding syntax.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 除了研究`TensorFlow.js`，我们还开始了使用Vue.js的旅程，这是一个正在迅速赢得人气的客户端库，与Angular和React并驾齐驱。我们看到了如何使用`.vue`文件，以及如何将TypeScript与Web模板结合使用，包括使用Vue的绑定语法。
- en: In the next chapter, we are going to take a radical step sideways and see how
    we can incorporate TypeScript alongside ASP.NET Core to build a music library
    combining C# with TypeScript.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将迈出一大步，看看如何将TypeScript与ASP.NET Core结合起来，构建一个将C#与TypeScript结合的音乐库。
- en: Questions
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: What languages was TensorFlow originally released in?
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow最初是用哪些语言发布的？
- en: What is supervised machine learning?
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是监督式机器学习？
- en: What is `MobileNet`?
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是`MobileNet`？
- en: How many classifications are returned to us by default?
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 默认情况下，我们会返回多少个分类？
- en: What command do we use to create our Vue application?
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们用什么命令来创建Vue应用程序？
- en: How do we denote a component in Vue?
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何在Vue中表示一个组件？
- en: Further reading
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Packt has an extensive number of TensorFlow books and videos, should you want
    to improve your knowledge of TensorFlow. These books aren''t just limited to `TensorFlow.js`,
    so there is an incredible depth of topics that go back to the original implementation
    of TensorFlow. Here are some of the ones I recommend:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: Packt有大量关于TensorFlow的书籍和视频，如果您想提高对TensorFlow的了解。这些书籍不仅限于`TensorFlow.js`，因此涵盖了与TensorFlow最初实现相关的各种主题。以下是我推荐的一些书籍：
- en: '*TensorFlow Reinforcement Learning Quick Start Guide* ([https://www.packtpub.com/in/big-data-and-business-intelligence/tensorflow-reinforcement-learning-quick-start-guide](https://www.packtpub.com/in/big-data-and-business-intelligence/tensorflow-reinforcement-learning-quick-start-guide)):
    Get up and running with training and deploying intelligent and self-learning agents
    using Python by Kaushik Balakrishnan: ISBN 978-1789533583.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《TensorFlow强化学习快速入门指南》（https://www.packtpub.com/in/big-data-and-business-intelligence/tensorflow-reinforcement-learning-quick-start-guide）：使用Python培训和部署智能和自学习代理，作者是Kaushik
    Balakrishnan：ISBN 978-1789533583。
- en: '*TensorFlow Machine Learning Projects* ([https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-projects](https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-projects)):
    Build 13 real-world projects with advanced numerical computations using the Python
    ecosystem by Ankit Jain and Amita Kapoor: ISBN 978-1789132212.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《TensorFlow机器学习项目》（https://www.packtpub.com/big-data-and-business-intelligence/tensorflow-machine-learning-projects）：使用Python生态系统进行高级数值计算，构建13个真实世界项目，作者是Ankit
    Jain和Amita Kapoor：ISBN 978-1789132212。
- en: '*Hands-On Computer Vision with TensorFlow 2* ([https://www.packtpub.com/in/application-development/hands-computer-vision-tensorflow-2](https://www.packtpub.com/in/application-development/hands-computer-vision-tensorflow-2)):
    Leverage deep learning to create powerful image processing apps with TensorFlow
    2.0 and Keras by Benjamin Planche and Eliot Andres: ISBN 978-1788830645.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《使用TensorFlow 2进行计算机视觉实践》（https://www.packtpub.com/in/application-development/hands-computer-vision-tensorflow-2）：利用深度学习和Keras创建强大的图像处理应用，作者是Benjamin
    Planche和Eliot Andres：ISBN 978-1788830645。
- en: 'As well as TensorFlow, we have also looked at using Vue, so the following will
    also be helpful for furthering your knowledge:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 除了TensorFlow，我们还研究了使用Vue，因此以下内容也将有助于进一步提高您的知识：
- en: '*Vue CLI 3 Quick Start Guide* ([https://www.packtpub.com/in/web-development/vue-cli-3-quick-start-guide](https://www.packtpub.com/in/web-development/vue-cli-3-quick-start-guide))
    by Ajdin Imsirovic: ISBN 978-1789950342'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 《Vue CLI 3快速入门指南》（https://www.packtpub.com/in/web-development/vue-cli-3-quick-start-guide）作者是Ajdin
    Imsirovic：ISBN 978-1789950342。
