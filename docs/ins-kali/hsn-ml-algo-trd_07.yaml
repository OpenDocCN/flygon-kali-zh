- en: Linear Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性模型
- en: The family of linear models represents one of the most useful hypothesis classes.
    Many learning algorithms that are widely applied in algorithmic trading rely on
    linear predictors because they can be efficiently trained in many cases, they
    are relatively robust to noisy financial data, and they have strong links to the
    theory of finance. Linear predictors are also intuitive, easy to interpret, and
    often fit the data reasonably well or at least provide a good baseline.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 线性模型家族代表了最有用的假设类之一。许多广泛应用于算法交易的学习算法依赖于线性预测器，因为它们在许多情况下可以被有效地训练，相对而言，它们对嘈杂的金融数据相对稳健，并且它们与金融理论有着紧密的联系。线性预测器也直观，易于解释，并且通常能够很好地拟合数据，或者至少提供一个良好的基线。
- en: 'Linear regression has been known for over 200 years when Legendre and Gauss
    applied it to astronomy and began to analyze its statistical properties. Numerous
    extensions have since adapted the linear regression model and the baseline **ordinary
    least squares** (**OLS**) method to learn its parameters:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 线性回归已经被人们所熟知超过200年，当Legendre和Gauss将其应用于天文学并开始分析其统计特性。此后，许多扩展已经调整了线性回归模型和基线**普通最小二乘法**（**OLS**）方法来学习其参数：
- en: '**Generalized linear models** (**GLM**) expand the scope of applications by
    allowing for response variables that imply an error distribution other than the
    normal distribution. GLM include the probit or logistic models for **categorical
    response variables** that appear in classification problems.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**广义线性模型**（**GLM**）通过允许响应变量的应用扩展到除正态分布以外的误差分布。GLM包括用于分类问题中出现的**分类响应变量**的概率或逻辑模型。'
- en: More **robust estimation methods** enable statistical inference where the data
    violates baseline assumptions due to, for example, correlation over time or across
    observations. This is often the case with panel data that contains repeated observations
    on the same units such as historical returns on a universe of assets.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多**鲁棒估计方法**使统计推断能够适应数据违反基线假设的情况，例如，随时间或观察之间的相关性。这在包含对同一单位的重复观察的面板数据中经常发生，例如，资产组合的历史回报。
- en: '**Shrinkage methods** aim to improve the predictive performance of linear models.
    They use a complexity penalty that biases the coefficients learned by the model
    with the goal of reducing the model''s variance and improving out-of-sample predictive
    performance.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**收缩方法**旨在改善线性模型的预测性能。它们使用复杂性惩罚来偏置模型学习的系数，以减少模型的方差并提高样本外的预测性能。'
- en: In practice, linear models are applied to regression and classification problems
    with the goals of inference and prediction. Numerous asset pricing models that
    have been developed by academic and industry researchers leverage linear regression.
    Applications include the identification of significant factors that drive asset
    returns, for example, as a basis for risk management, as well as the prediction
    of returns over various time horizons. Classification problems, on the other hand,
    include directional price forecasts.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，线性模型被应用于推断和预测的回归和分类问题。许多学术和行业研究人员开发的资产定价模型利用了线性回归。应用包括识别推动资产回报的重要因素，例如作为风险管理的基础，以及在不同时间范围内预测回报。另一方面，分类问题包括方向性价格预测。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: How linear regression works and which assumptions it makes
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归的工作原理及其假设
- en: How to train and diagnose linear regression models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何训练和诊断线性回归模型
- en: How to use linear regression to predict future returns
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用线性回归来预测未来回报
- en: How use regularization to improve the predictive performance
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用正则化来提高预测性能
- en: How logistic regression works
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归的工作原理
- en: How to convert a regression into a classification problem
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将回归转化为分类问题
- en: For code examples, additional resources, and references, see the directory for
    this chapter in the online GitHub repository.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有关代码示例，附加资源和参考资料，请参阅在线GitHub存储库中本章的目录。
- en: Linear regression for inference and prediction
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 推断和预测的线性回归
- en: As the name suggests, linear regression models assume that the output is the
    result of a linear combination of the inputs. The model also assumes a random
    error that allows for each observation to deviate from the expected linear relationship.
    The reasons that the model does not perfectly describe the relationship between
    inputs and output in a deterministic way include, for example, missing variables,
    measurement, or data collection issues.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，线性回归模型假设输出是输入的线性组合的结果。该模型还假设了一个随机误差，允许每个观察结果偏离预期的线性关系。模型不能以确定性方式完美地描述输入和输出之间的关系的原因包括，例如，缺少变量，测量或数据收集问题。
- en: If we want to draw statistical conclusions about the true (but not observed)
    linear relationship in the population based on the regression parameters estimated
    from the sample, we need to add assumptions about the statistical nature of these
    errors. The baseline regression model makes the strong assumption that the distribution
    of the errors is identical across errors and that errors are independent of each
    other, that is, knowing one error does not help to forecast the next error. The
    assumption of **independent and identically distributed** (**iid**) errors implies
    that their covariance matrix is the identity matrix multiplied by a constant representing
    the error variance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要根据样本估计的回归参数对人口中真实（但未观察到）的线性关系进行统计结论，我们需要对这些误差的统计性质添加假设。基线回归模型做出了一个强烈的假设，即错误的分布在错误之间是相同的，并且错误是彼此独立的，也就是说，知道一个错误并不能帮助预测下一个错误。**独立同分布**（**iid**）误差的假设意味着它们的协方差矩阵是乘以代表误差方差的常数的单位矩阵。
- en: These assumptions guarantee that the OLS method delivers estimates that are
    not only unbiased but also efficient, that is, they have the lowest sampling error
    learning algorithms. However, these assumptions are rarely met in practice. In
    finance, we often encounter panel data with repeated observations on a given cross-section.
    The attempt to estimate the systematic exposure of a universe of assets to a set
    of risk factors over time typically surfaces correlation in the time or cross-sectional
    dimension, or both. Hence, alternative learning algorithms have emerged that assume
    more error covariance matrices that differ from multiples of the identity matrix.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设保证OLS方法提供的估计不仅是无偏的，而且是高效的，即它们具有最低的抽样误差学习算法。然而，这些假设在实践中很少得到满足。在金融领域，我们经常遇到具有给定横截面上重复观察的面板数据。试图估计一组资产对一组风险因素的系统暴露通常会在时间或横截面维度或两者中出现相关性。因此，出现了更多假设错误的错误协方差矩阵的替代学习算法。
- en: On the other hand, methods that learn biased parameters for a linear model may
    yield estimates with a lower variance and, hence, improve the predictive performance.
    **Shrinkage methods** reduce the model complexity by applying regularization that
    adds a penalty term to the linear objective function. The penalty is positively
    related to the absolute size of the coefficients so that these are shrunk relative
    to the baseline case. Larger coefficients imply a more complex model that reacts
    more strongly to variations in the inputs. Properly calibrated, the penalty can
    limit the growth of the model's coefficients beyond what an optimal bias-variance
    trade-off would suggest.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，学习线性模型的偏差参数的方法可能会产生方差较低的估计，从而提高预测性能。**收缩方法**通过对线性目标函数添加惩罚项来减少模型复杂性。惩罚与系数的绝对大小正相关，因此相对于基线情况，这些系数会收缩。较大的系数意味着更复杂的模型，对输入的变化反应更强烈。经过适当校准，惩罚可以限制模型系数的增长，超出最佳偏差-方差权衡所建议的范围。
- en: We will introduce the baseline cross-section and panel techniques for linear
    models and important enhancements that produce accurate estimates when key assumptions
    are violated. We will then illustrate these methods by estimating factor models
    that are ubiquitous in the development of algorithmic trading strategies. Lastly,
    we will focus on regularization methods.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍线性模型的基线横截面和面板技术以及在关键假设被违反时产生准确估计的重要增强。然后，我们将通过估计在算法交易策略的发展中普遍存在的因子模型来说明这些方法。最后，我们将专注于正则化方法。
- en: The multiple linear regression model
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多元线性回归模型
- en: We will introduce the model's specification and objective function, methods
    to learn its parameters, statistical assumptions that allow for inference and
    diagnostics of these assumptions, as well as extensions to adapt the model to
    situations where these assumptions fail.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将介绍模型的规范和目标函数，学习其参数的方法，允许推断和诊断这些假设的统计假设，以及扩展以适应这些假设失败的情况下的模型。
- en: How to formulate the model
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何制定模型
- en: The multiple regression model defines a linear functional relationship between
    one continuous outcome variable and *p* input variables that can be of any type
    but may require preprocessing. Multivariate regression, in contrast, refers to
    the regression of multiple outputs on multiple input variables.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 多元回归模型定义了一个连续结果变量和*p*个输入变量之间的线性功能关系，这些输入变量可以是任何类型，但可能需要预处理。相比之下，多元回归是指多个输出变量对多个输入变量的回归。
- en: 'In the population, the linear regression model has the following form for a
    single instance of the output *y*, an input vector ![](img/ca17efd5-4e85-4e63-a2b2-59e7e7afc866.png), and
    the error *ε*:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在人口中，线性回归模型对于输出*y*的单个实例，输入向量![](img/ca17efd5-4e85-4e63-a2b2-59e7e7afc866.png)，和误差*ε*具有以下形式：
- en: '![](img/c3c0ce60-a6be-4b9d-96c4-e0f29963c384.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c3c0ce60-a6be-4b9d-96c4-e0f29963c384.png)'
- en: 'The interpretation of the coefficients is straightforward: the value of a coefficient ![](img/f2a0ef61-33a5-44a1-9f1a-fb132389afa3.png) is the
    partial, average effect of the variable *x[i ]*on the output, holding all other
    variables constant.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的解释很简单：系数![](img/f2a0ef61-33a5-44a1-9f1a-fb132389afa3.png)的值是变量*x[i]*对输出的部分平均影响，保持所有其他变量不变。
- en: 'The model can also be written more compactly in matrix form. In this case,
    *y* is a vector of *N* output observations, *X*is the design matrix with *N* rows
    of observations on the *p* variables plus a column of 1s for the intercept, and ![](img/681890d8-fe44-4a8b-8bc4-33b2159a51c5.png) is
    the vector containing the *P = p+1* coefficients ![](img/96e3b5c2-497d-449d-9c8e-bf3c4a038d2a.png):'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型也可以以矩阵形式更简洁地表示。在这种情况下，*y*是*N*个输出观察的向量，*X*是设计矩阵，具有*p*个变量的*N*行观察加上一个用于截距的1列，![](img/681890d8-fe44-4a8b-8bc4-33b2159a51c5.png)是包含*P=p+1*系数的向量![](img/96e3b5c2-497d-449d-9c8e-bf3c4a038d2a.png)：
- en: '![](img/18eef579-bc58-4079-a75f-b75ccb553879.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](img/18eef579-bc58-4079-a75f-b75ccb553879.png)'
- en: The model is linear in its *p +1* parameters but can model non-linear relationships
    by choosing or transforming variables accordingly, for example by including a
    polynomial basis expansion or logarithmic terms. It can also use categorical variables
    with dummy encoding, and interactions between variables by creating new inputs
    of the form *x[i] . x[j]*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型在其*p+1*个参数中是线性的，但可以通过选择或相应地转换变量来建模非线性关系，例如通过包括多项式基扩展或对数项。它还可以使用具有虚拟编码的分类变量，并通过创建形式为*x[i].x[j]*的新输入来处理变量之间的交互。
- en: To complete the formulation of the model from a statistical point of view so
    that we can test a hypothesis about the parameters, we need to make specific assumptions
    about the error term. We'll do this after first introducing the alternative methods
    to learn the parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从统计角度完成模型的制定，以便我们可以测试关于参数的假设，我们需要对误差项做出具体的假设。在介绍学习参数的替代方法之后，我们将这样做。
- en: How to train the model
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何训练模型
- en: 'There are several methods to learn the model parameters ![](img/cabc1f80-1d1b-4793-8a1f-80370fd84fea.png) from
    the data: **ordinary least squares** (**OLS**), **maximum likelihood estimation**
    (**MLE**), and **stochastic gradient descent** (**SGD**).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 学习模型参数![](img/cabc1f80-1d1b-4793-8a1f-80370fd84fea.png) 的几种方法：**普通最小二乘法**（**OLS**），**最大似然估计**（**MLE**），和**随机梯度下降**（**SGD**）。
- en: Least squares
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最小二乘法
- en: The least squares method is the original method to learn the parameters of the
    hyperplane that best approximates the output from the input data. As the name
    suggests, the best approximation minimizes the sum of the squared distances between
    the output value and the hyperplane represented by the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最小二乘法是学习最佳逼近输出的超平面参数的原始方法。顾名思义，最佳逼近最小化了输出值与模型表示的超平面之间的平方距离的总和。
- en: 'The difference between the model''s prediction and the actual outcome for a
    given data point is the residual (whereas the deviation of the true model from
    the true output in the population is called **error**). Hence, in formal terms,
    the least squares estimation method chooses the coefficient vector ![](img/b3139f6c-4371-4a74-9335-bbe76eeeba46.png) to
    minimize the **residual** **sum of squares** (**RSS**):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 给定数据点的模型预测与实际结果的差异是残差（而真实模型与真实输出在总体中的偏差称为**误差**）。因此，在正式术语中，最小二乘估计方法选择系数向量![](img/b3139f6c-4371-4a74-9335-bbe76eeeba46.png) 以最小化**残差平方和**（**RSS**）：
- en: '![](img/8123f8ed-b798-41e9-be38-a8c004d4d0ef.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8123f8ed-b798-41e9-be38-a8c004d4d0ef.png)'
- en: 'Hence, the least-squares coefficients ![](img/087b73ba-7e6b-4d5b-b7c6-fd90f2cf6d8d.png) are
    computed as:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，最小二乘系数![](img/087b73ba-7e6b-4d5b-b7c6-fd90f2cf6d8d.png) 计算如下：
- en: '![](img/8480afe1-ae4b-4e12-91db-e20143a84b40.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/8480afe1-ae4b-4e12-91db-e20143a84b40.png)'
- en: 'The optimal parameter vector that minimizes RSS results from setting the derivatives
    of the preceding expression with respect to ![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) to zero.
    This produces a unique solution, assuming X has full column rank, that is, the
    input variables are not linearly dependent, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 最小化RSS的最优参数向量来自于将前述表达式对![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) 的导数设置为零。这产生了一个唯一的解，假设X具有完整的列秩，即输入变量不是线性相关的，如下所示：
- en: '![](img/53ae7775-f160-40be-b1ec-4a80c1fba44e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/53ae7775-f160-40be-b1ec-4a80c1fba44e.png)'
- en: 'When *y* and *X* have been de-meaned by subtracting their respective means, ![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) represents
    the ratio of the covariance between the inputs and the outputs ![](img/af4e8def-395c-49b0-a82e-25b2593dd732.png) and the
    output variance ![](img/181b1459-5eef-4d5b-b978-c00e00be4c71.png). There is also
    a geometric interpretation: the coefficients that minimize RSS ensure that the
    vector of residuals ![](img/7ff3850e-4378-4c76-b59a-72eb4c5aa04d.png) is orthogonal
    to the subspace of ![](img/540ecc41-c8d6-462b-8676-971ecc683b25.png)spanned by
    the columns of *X*, and the estimates ![](img/80dcda91-dc61-4571-8345-9f646a4e9b5a.png) are orthogonal
    projections into that subspace.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当*y*和*X*已通过减去各自的均值而被去均值时，![](img/90907b87-43c2-4724-ac11-b62f61852e2a.png) 代表了输入和输出之间的协方差的比率![](img/af4e8def-395c-49b0-a82e-25b2593dd732.png) 和输出方差![](img/181b1459-5eef-4d5b-b978-c00e00be4c71.png)。也有一个几何解释：最小化RSS的系数确保残差向量![](img/7ff3850e-4378-4c76-b59a-72eb4c5aa04d.png) 是![](img/540ecc41-c8d6-462b-8676-971ecc683b25.png)的列向量所张成的子空间的正交向量，并且估计值![](img/80dcda91-dc61-4571-8345-9f646a4e9b5a.png) 是该子空间的正交投影。
- en: Maximum likelihood estimation
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: MLE is an important general method to estimate the parameters of a statistical
    model. It relies on the likelihood function that computes how likely it is to
    observe the sample of output values for a given set of both input data as a function
    of the model parameters. The likelihood differs from probabilities in that it
    is not normalized to range from 0 to 1.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: MLE是估计统计模型参数的重要通用方法。它依赖于似然函数，计算出在给定输入数据和模型参数的情况下观察到输出值样本的可能性。似然性与概率不同，它不会归一化到0到1的范围内。
- en: 'We can set up the likelihood function for the linear regression example by
    assuming a distribution for the error term, such as the standard normal distribution:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过假设误差项的分布（如标准正态分布）来建立线性回归示例的似然函数：
- en: '![](img/60eff427-da2c-43a5-8d3e-7f13c71a89a9.png).'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![](img/60eff427-da2c-43a5-8d3e-7f13c71a89a9.png).'
- en: 'This allows us to compute the conditional probability of observing a given
    output ![](img/ca374814-159c-47ee-beda-967393c46f27.png) given the corresponding
    input vector *x[i]* and the parameters, ![](img/3fb23a9c-71d9-4391-9ace-33350e36821b.png):'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够计算观察到给定输出![](img/ca374814-159c-47ee-beda-967393c46f27.png) 在给定输入向量*x[i]*和参数![](img/3fb23a9c-71d9-4391-9ace-33350e36821b.png) 的条件概率：
- en: '![](img/219455c0-b5e2-43a9-9310-4472d95f6164.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](img/219455c0-b5e2-43a9-9310-4472d95f6164.png)'
- en: 'Assuming the output values are conditionally independent given the inputs,
    the likelihood of the sample is proportional to the product of the conditional
    probabilities of the individual output data points. Since it is easier to work
    with sums than with products, we apply the logarithm to obtain the log-likelihood
    function:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 假设输出值在给定输入的条件下是独立的，样本的似然性与各个输出数据点的条件概率的乘积成正比。由于求和比乘积更容易处理，我们应用对数得到对数似然函数：
- en: '![](img/197fca5b-2456-41f0-a988-fc5b646fa4a2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](img/197fca5b-2456-41f0-a988-fc5b646fa4a2.png)'
- en: 'The goal of MLE is to maximize the probability of the output sample that has
    in fact been observed by choosing model parameters, taking the observed inputs
    as given. Hence, the MLE parameter estimate results from maximizing the (log)
    likelihood function:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: MLE的目标是通过选择模型参数来最大化实际观察到的输出样本的概率，以观察到的输入为给定。因此，MLE参数估计的结果来自于最大化（对数）似然函数：
- en: '![](img/c2814000-7a34-48a2-b790-2dd022c3944d.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c2814000-7a34-48a2-b790-2dd022c3944d.png)'
- en: Due to the assumption of normal distribution, maximizing the log-likelihood
    function produces the same parameter solution as least squares because the only
    expression that depends on the parameters is squared residual in the exponent.
    For other distributional assumptions and models, MLE will produce different results,
    and in many cases, least squares is not applicable, as we will see later for logistic
    regression.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于正态分布的假设，最大化对数似然函数产生与最小二乘相同的参数解，因为唯一依赖于参数的表达式是指数中的平方残差。对于其他分布假设和模型，MLE将产生不同的结果，在许多情况下，最小二乘不适用，正如我们将在后面看到的逻辑回归。
- en: Gradient descent
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 梯度下降
- en: Gradient descent is a general-purpose optimization algorithm that will find
    stationary points of smooth functions. The solution will be a global optimum if
    the objective function is convex. Variations of gradient descent are widely used
    in the training of complex neural networks, but also to compute solutions for
    MLE problems.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是一种通用的优化算法，可以找到平滑函数的稳定点。如果目标函数是凸的，解将是全局最优的。梯度下降的变体广泛用于复杂神经网络的训练，也用于计算MLE问题的解决方案。
- en: The algorithm uses the gradient of the objective function that contains its
    partial derivatives with respect to the parameters. These derivatives indicate
    how much the objective changes for infinitesimal steps in the direction of the
    corresponding parameters. It turns out that the maximal change of the function
    value results from a step in the direction of the gradient itself.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 该算法使用包含相对于参数的偏导数的目标函数的梯度。这些导数指示了在相应参数的方向上无穷小步骤时目标的变化量。结果表明，函数值的最大变化来自于梯度本身的方向的步骤。
- en: Hence, when minimizing a function that describes, for example, the cost of a
    prediction error, the algorithm computes the gradient for the current parameter
    values using the training data and modifies each parameter according to the negative
    value of its corresponding gradient component. As a result, the objective function
    will assume a lower value and move the parameters move closer to the solution. The
    optimization stops when the gradient becomes small, and the parameter values change
    very little.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当最小化描述例如预测误差成本的函数时，该算法使用训练数据计算当前参数值的梯度，并根据其相应梯度分量的负值修改每个参数。结果，目标函数将假定一个较低的值，并将参数移动到解决方案附近。当梯度变得很小时，参数值几乎不变时，优化停止。
- en: The size of these steps is the learning rate, which is a critical parameter
    that may require tuning; many implementations include the option for this learning
    rate to increase with the number of iterations gradually. Depending on the size
    of the data, the algorithm may iterate many times over the entire dataset. Each
    such iteration is called an **epoch.** The number of epochs and the tolerance
    used to stop further iterations are hyperparameters you can tune.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤的大小是学习率，这是一个可能需要调整的关键参数；许多实现包括逐渐增加学习率的选项。根据数据的大小，算法可能会在整个数据集上进行多次迭代。每次迭代称为一个**时代**。您可以调整的超参数包括时代的数量和用于停止进一步迭代的容差。
- en: Stochastic gradient descent randomly selects a data point and computes the gradient
    for this data point as opposed to an average over a larger sample to achieve a
    speedup. There are also batch versions that use a certain number of data points
    for each step.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降随机选择一个数据点，并计算该数据点的梯度，而不是对更大样本的平均值进行加速。还有使用一定数量的数据点进行每一步的批处理版本。
- en: The Gauss—Markov theorem
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高斯-马尔可夫定理
- en: To assess the statistical of the model and conduct inference, we need to make
    assumptions about the residuals, that is, the properties of the unexplained part
    of the input. The **Gauss—Markov theorem** (**GMT**) defines the assumptions required
    for OLS to produce unbiased estimates of the model parameters ![](img/33eb8f33-f98e-4c29-82c8-76db82a7b46a.png), and
    when these estimates have the lowest standard error among all linear models for
    cross-sectional data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估模型的统计性并进行推断，我们需要对残差进行假设，即输入未解释部分的属性。**高斯-马尔可夫定理**（**GMT**）定义了OLS产生模型参数无偏估计所需的假设![](img/33eb8f33-f98e-4c29-82c8-76db82a7b46a.png)，并且当这些估计在横截面数据的所有线性模型中具有最低的标准误差时。
- en: 'The baseline multiple regression model makes the following GMT assumptions:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 基线多元回归模型做出以下GMT假设：
- en: In the population, **linearity** holds, ![](img/8feae49c-7c0f-492c-8581-fa3fb1b0d30a.png) where ![](img/ebb48f07-023f-4a4f-b46d-a0cf606d8ceb.png) are
    unknown but constant and ![](img/c6cfab11-33d7-4c05-81c8-fded5bb113da.png) is
    a random error
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在总体中，**线性性**成立，![](img/8feae49c-7c0f-492c-8581-fa3fb1b0d30a.png)，其中![](img/ebb48f07-023f-4a4f-b46d-a0cf606d8ceb.png)是未知但恒定的，![](img/c6cfab11-33d7-4c05-81c8-fded5bb113da.png)是随机误差
- en: The data for the input variables ![](img/ac422091-f903-413e-ab66-b8f884a4b0d8.png) are
    a **random sample** from the population
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入变量![](img/ac422091-f903-413e-ab66-b8f884a4b0d8.png)的数据是来自总体的**随机样本**
- en: No perfect **collinearity**—there are no exact linear relationships among the
    input variables
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有完美的**共线性**——输入变量之间没有精确的线性关系
- en: The **error has a conditional mean of zero** given any of the inputs: ![](img/fc56cd9c-b8ea-483b-b6c6-b6a01481a1df.png)
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误在任何输入条件下的条件均值为零：![](img/fc56cd9c-b8ea-483b-b6c6-b6a01481a1df.png)
- en: '**Homoskedasticity**, the error term ![](img/f0ded6ea-538b-40a8-9d3a-cb9f5483e17d.png) has
    constant variance given the inputs: ![](img/e5f9d3b1-a11c-4072-9cd9-d443cc1ce234.png)'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同方差性**，误差项![](img/f0ded6ea-538b-40a8-9d3a-cb9f5483e17d.png)在给定输入时具有恒定方差：![](img/e5f9d3b1-a11c-4072-9cd9-d443cc1ce234.png)'
- en: 'The fourth assumption implies that no missing variable exists that is correlated
    with any of the input variables. Under the first four assumptions, the OLS method
    delivers **unbiased** estimates: including an irrelevant variable does not bias
    the intercept and slope estimates, but omitting a relevant variable will bias
    the OLS estimates. OLS is then also **consistent**: as the sample size increases,
    the estimates converge to the true value as the standard errors become arbitrary.
    The converse is unfortunately also true: if the conditional expectation of the
    error is not zero because the model misses a relevant variable or the functional
    form is wrong (that is, quadratic or log terms are missing), then all parameter
    estimates are biased. If the error is correlated with any of the input variables
    then OLS is also not consistent, that is, adding more data will not remove the
    bias.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个假设意味着不存在与任何输入变量相关的缺失变量。在前四个假设下，OLS方法提供**无偏**估计：包括一个无关的变量不会使截距和斜率估计产生偏差，但省略一个相关的变量将使OLS估计产生偏差。OLS也是**一致**的：随着样本量的增加，估计值收敛到真实值，标准误差变得任意。不幸的是，反之亦然：如果误差的条件期望不为零，因为模型缺少相关变量或者函数形式错误（即缺少二次或对数项），那么所有参数估计都是有偏的。如果误差与任何输入变量相关，则OLS也不是一致的，也就是说，增加更多数据将无法消除偏差。
- en: If we add the fifth assumptions, then OLS also produces the best linear, unbiased
    estimates (BLUE), where best means that the estimates have the lowest standard
    error among all linear estimators. Hence, if the five assumptions hold and statistical inference
    is the goal, then the OLS estimates is the way to go. If the goal, however, is
    to predict, then we will see that other estimators exist that trade off some bias
    for a lower variance to achieve superior predictive performance in many settings.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们加入第五个假设，那么OLS也会产生最佳线性无偏估计（BLUE），其中最佳意味着估计在所有线性估计器中具有最低的标准误差。因此，如果五个假设成立，并且统计推断是目标，那么OLS估计是正确的选择。然而，如果目标是预测，那么我们将看到其他估计器存在，它们在许多情况下通过一些偏差来换取更低的方差，以实现更优越的预测性能。
- en: Now that we have introduced the basic OLS assumptions, we can take a look at
    inference in small and large samples.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了基本的OLS假设，我们可以看看在小样本和大样本中的推断。
- en: How to conduct statistical inference
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行统计推断
- en: Inference in the linear regression context aims to draw conclusions about the
    true relationship in the population from the sample data. This includes tests
    of hypothesis about the significance of the overall relationship or the values
    of particular coefficients, as well as estimates of confidence intervals.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在线性回归背景下的推断旨在从样本数据中得出关于总体真实关系的结论。这包括关于整体关系的显著性或特定系数值的假设检验，以及置信区间的估计。
- en: The key ingredient for statistical inference is a test statistic with a known
    distribution. We can use it to assume that the null hypothesis is true and compute
    the probability of observing the value for this statistic in the sample, familiar
    as the p-value. If the p-value drops below a significance threshold (typically
    five percent) then we reject the hypothesis because it makes the actual sample
    value very unlikely. At the same time, we accept that the p-value reflects the
    probability that we are wrong in rejecting what is, in fact, a correct hypothesis.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 统计推断的关键要素是具有已知分布的检验统计量。我们可以使用它来假设零假设成立，并计算在样本中观察到该统计量值的概率，即所谓的p值。如果p值低于显著性阈值（通常为五个百分点），那么我们拒绝假设，因为它使得实际样本值非常不可能。与此同时，我们接受p值反映了我们在拒绝实际上是正确的假设时可能出错的概率。
- en: In addition to the five GMT assumptions, the classical linear model assumes **normality**—the population
    error is normally distributed and independent of the input variables. This assumption
    implies that the output variable is normally distributed, conditional on the input
    variables. This strong assumption permits the derivation of the exact distribution
    of the coefficients, which in turn implies exact distributions of the test statistics
    required for similarly exact hypotheses tests in small samples. This assumption
    often fails—asset returns, for instance, are not normally distributed—but, fortunately,
    the methods used under normality are also approximately valid.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了五个GMT假设外，经典线性模型还假设**正态性**——总体误差服从正态分布，并且独立于输入变量。这一假设意味着在输入变量条件下，输出变量服从正态分布。这一强假设允许推导系数的精确分布，从而意味着在小样本中需要的检验统计量的精确分布。这一假设经常不成立——例如，资产回报并不服从正态分布——但幸运的是，在正态性下使用的方法也大致有效。
- en: 'We have the following distributional characteristics and test statistics, approximately
    under GMT assumptions 1–5, and exactly when normality holds:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在GMT假设1-5下，以及正态性成立时，我们已经有以下分布特征和检验统计量：
- en: The parameter estimates follow a multivariate normal distribution: ![](img/41d4d2b8-7cf6-4a50-aa7a-b9ada8e5b6eb.png) .
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 参数估计遵循多元正态分布：![](img/41d4d2b8-7cf6-4a50-aa7a-b9ada8e5b6eb.png)。
- en: Under GMT 1–5, the parameter estimates are already unbiased and we can get an unbiased
    estimate of ![](img/c255ed13-6923-4756-ba34-fc71c5b92cb3.png), the constant error
    variance, using ![](img/b5d5614e-5b53-416d-83d9-d168b96e8207.png).
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在GMT 1-5下，参数估计已经是无偏的，我们可以使用![](img/b5d5614e-5b53-416d-83d9-d168b96e8207.png)来得到![](img/c255ed13-6923-4756-ba34-fc71c5b92cb3.png)的无偏估计，即常数误差方差。
- en: The t statistic for a hypothesis tests about an individual coefficient ![](img/fbfdf074-0b0d-4404-9e4b-80a87114d05a.png)is ![](img/60566dde-3959-4693-a060-9cac717f012b.png) and
    follows a t distribution with *N-p-1* degrees of freedom where ![](img/3bda39a2-09ae-4e22-9920-c0dfe0fa9414.png) is
    the j's element of the diagonal of ![](img/7a6b5101-d2be-4553-b96f-43949ce9508b.png).
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于单个系数的假设检验的t统计量为![](img/fbfdf074-0b0d-4404-9e4b-80a87114d05a.png)，并且遵循具有*N-p-1*自由度的t分布，其中![](img/3bda39a2-09ae-4e22-9920-c0dfe0fa9414.png)是![](img/7a6b5101-d2be-4553-b96f-43949ce9508b.png)对角线的第j个元素。
- en: The *t* distribution converges to the normal distribution and since the 97.5
    quantile of the normal distribution is 1.96, a useful rule of thumb for a 95%
    confidence interval around a parameter estimate is ![](img/bb155050-7a1f-40b1-b171-eb5ca79d1622.png).
    An interval that includes zero implies that we can't reject the null hypothesis
    that the true parameter is zero and, hence, irrelevant for the model.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*t*分布收敛于正态分布，由于正态分布的97.5分位数为1.96，因此围绕参数估计的95%置信区间的一个有用的经验法则是![](img/bb155050-7a1f-40b1-b171-eb5ca79d1622.png)。包含零的区间意味着我们无法拒绝真实参数为零的零假设，因此对模型无关。'
- en: The *F* statistic allows for tests of restrictions on several parameters, including
    whether the entire regression is significant. It measures the change (reduction)
    in the RSS that results from additional variables.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F*统计量允许对多个参数的限制进行测试，包括整个回归是否显著。它衡量了由于额外变量而导致的RSS的变化（减少）。'
- en: Finally, the **Lagrange Multiplier** (**LM**) test is an alternative to the
    *F* test to restrict multiple restrictions.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，**Lagrange Multiplier**（**LM**）测试是*F*测试的替代方法，用于限制多个限制。
- en: How to diagnose and remedy problems
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何诊断和解决问题
- en: Diagnostics validate the model assumptions and prevent wrong conclusions when
    interpreting the result and conducting statistical inference. They include measures
    of goodness of fit and various tests of the assumptions about the error term,
    including how closely the residuals match a normal distribution. Furthermore,
    diagnostics test whether the residual variance is indeed constant or exhibits
    heteroskedasticity, and if the errors are conditionally uncorrelated or exhibit
    serial correlation, that is, if knowing one error helps to predict consecutive
    errors.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断验证模型假设，并在解释结果和进行统计推断时防止错误结论。它们包括拟合度的度量和关于误差项的各种假设的测试，包括残差与正态分布的匹配程度。此外，诊断还测试残差方差是否确实恒定或者是否存在异方差性，以及错误是否有条件相关或者存在串行相关，即知道一个错误是否有助于预测连续的错误。
- en: In addition to the tests outlined as follows, it is always important to visually
    inspect the residuals to detect whether there are systematic patterns because
    these indicate that the model is missing one or more factors that drive the outcome.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 除了以下列出的测试之外，始终重要的是直观地检查残差，以检测是否存在系统模式，因为这些表明模型缺少一个或多个驱动结果的因素。
- en: Goodness of fit
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拟合度
- en: Goodness-of-fit measures assess how well a model explains the variation in the
    outcome. They help to assess the quality of model specification, for instance,
    to select among different model designs. They differ in how they evaluate the
    fit. The measures discussed here provide in-sample information; we will use out-of-sample
    testing and cross-validation when we focus on predictive models in the next section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合度量评估模型解释结果变化的能力。它们有助于评估模型规范的质量，例如选择不同的模型设计。它们在评估拟合度方面有所不同。这里讨论的度量提供了样本内信息；在下一节中，当我们专注于预测模型时，我们将使用样本外测试和交叉验证。
- en: 'Prominent goodness-of-fit measures include the (adjusted) R² that should be
    maximized and is based on the least-squares estimate:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 突出的拟合度量包括（调整后的）R²，应该最大化，并且基于最小二乘估计。
- en: R² measures the share of the variation in the outcome data explained by the
    model and is computed as ![](img/6a2363f4-83b4-42ce-85f0-3103f56a7a5a.png), where
    TSS is the sum of squared deviations of the outcome from its mean. It also corresponds
    to the squared correlation coefficient between the actual outcome values and those
    estimated (fitted) by the model. The goals is to maximize R² but it never decreases
    as the model adds more variables and, hence, encourages overfitting.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: R²衡量了模型解释结果数据变化的比例，并计算为![](img/6a2363f4-83b4-42ce-85f0-3103f56a7a5a.png)，其中TSS是结果与其均值的平方偏差之和。它还对应于实际结果值与模型估计（拟合）之间的平方相关系数。目标是最大化R²，但随着模型增加更多变量，它永远不会减少，因此鼓励过拟合。
- en: The adjusted R² penalizes R² for adding more variables; each additional variable
    needs to reduce RSS significantly to produce better goodness of fit.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调整后的R²对增加更多变量的R²进行惩罚；每个额外变量需要显著减少RSS才能产生更好的拟合度。
- en: 'Alternatively, the Akaike (AIC) and the **Bayesian Information Criterion**
    (**BIC**) are to be minimized and are based on the maximum-likelihood estimate:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，Akaike（AIC）和**贝叶斯信息准则**（**BIC**）需要最小化，并且基于最大似然估计：
- en: '![](img/58a56311-c140-4adf-bcd0-adb48108167a.png), where ![](img/030f5c24-ec0a-47c9-9a82-265617c34044.png) is
    the value of the maximized likelihood function, k is the number of parameters'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/58a56311-c140-4adf-bcd0-adb48108167a.png)，其中![](img/030f5c24-ec0a-47c9-9a82-265617c34044.png)是最大化似然函数的值，k是参数的数量'
- en: '![](img/232898ca-2946-4ac5-8d69-1b9f4e32bfdb.png) where *N* is the sample size'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '![](img/232898ca-2946-4ac5-8d69-1b9f4e32bfdb.png) 其中*N*是样本大小'
- en: Both metrics penalize for complexity, with BIC imposing a higher penalty so
    that it might underfit whereas AIC might overfit in relative terms. Conceptually, AIC
    aims at finding the model that best describes an unknown data-generating process,
    whereas BIC tries to find the best model among the set of candidates. In practice,
    both criteria can be used jointly to guide model selection when the goal is in-sample
    fit; otherwise, cross-validation and selection based on estimates of generalization
    error are preferable.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个度量都对复杂性进行惩罚，BIC对此进行更高的惩罚，因此可能会欠拟合，而AIC在相对术语中可能会过拟合。在概念上，AIC旨在找到最好描述未知数据生成过程的模型，而BIC试图在候选模型集中找到最佳模型。在实践中，当目标是样本内拟合时，可以同时使用这两个标准来指导模型选择；否则，交叉验证和基于泛化误差估计的选择更可取。
- en: Heteroskedasticity
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异方差性
- en: GMT assumption 5 requires the residual covariance to take the shape ![](img/881489a2-b2d6-4688-a184-051c15fca6b3.png),
    that is, a diagonal matrix with entries equal to the constant variance of the
    error term. Heteroskedasticity occurs when the residual variance is not constant
    but differs across observations. If the residual variance is positively correlated
    with an input variable, that is, when errors are larger for input values that
    are far from their mean, then OLS standard error estimates will be too low, and,
    consequently, the t-statistic will be inflated leading to false discoveries of
    relationships where none actually exist.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: GMT假设5要求残差协方差采用形状![](img/881489a2-b2d6-4688-a184-051c15fca6b3.png)，即对角矩阵，其条目等于误差项的恒定方差。异方差性发生在残差方差不恒定，而是在观察中不同的情况。如果残差方差与输入变量呈正相关，即当误差较大时，OLS标准误差估计将过低，因此t统计量将被夸大，导致发现不存在的关系。
- en: Diagnostics starts with a visual inspection of the residuals. Systematic patterns
    in the (supposedly random) residuals suggest statistical tests of the null hypothesis
    that errors are homoscedastic against various alternatives. These tests include
    the Breusch—Pagan and White tests.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 诊断从对残差的视觉检查开始。在（假定随机的）残差中出现系统性模式，表明错误是同方差的零假设的统计检验，有多种替代方案。这些测试包括Breusch—Pagan和White测试。
- en: 'There are several ways to correct OLS estimates for heteroskedasticity:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种方法可以纠正OLS估计的异方差：
- en: Robust standard errors (sometimes called white standard errors) take heteroskedasticity
    into account when computing the error variance using a so-called **sandwich**
    **estimator**.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 鲁棒标准误差（有时称为白色标准误差）在计算误差方差时考虑了异方差性，使用所谓的**夹心**估计量。
- en: Clustered standard errors assume that there are distinct groups in your data
    that are homoskedastic but the error variance differs between groups. These groups
    could be different asset classes or equities from different industries.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聚类标准误假设数据中存在不同的组，这些组是同方差的，但误差方差在组之间不同。这些组可能是不同的资产类别或来自不同行业的股票。
- en: 'Several alternatives to OLS estimate the error covariance matrix using different
    assumptions when ![](img/1fa8ab87-92ba-4bad-b08f-75d550e4d599.png). The following
    are available in `statsmodels`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种替代OLS的方法使用不同的假设来估计误差协方差矩阵，当![](img/1fa8ab87-92ba-4bad-b08f-75d550e4d599.png)。在`statsmodels`中提供以下选项：
- en: '**Weighted least squares** (**WLS**): For heteroskedastic errors where the
    covariance matrix has only diagonal entries as for OLS, but now the entries are
    allowed to vary'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加权最小二乘法（WLS）：用于异方差误差，其中协方差矩阵只有对角条目，与OLS相同，但现在允许条目变化
- en: Feasible **generalized least squares** (**GLSAR**), for autocorrelated errors
    that follow an autoregressive AR (p) process (see the chapter on linear time series
    models)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可行的广义最小二乘法（GLSAR），用于遵循自回归AR（p）过程的自相关误差（请参阅线性时间序列模型章节）
- en: '**Generalized least squares** (**GLS**) for arbitrary covariance matrix structure;
    yields efficient and unbiased estimates in the presence of heteroskedasticity
    or serial correlation'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 广义最小二乘法（GLS）适用于任意协方差矩阵结构；在异方差性或序列相关性存在时产生高效和无偏估计
- en: Serial correlation
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列相关
- en: Serial correlation means that consecutive residuals produced by linear regression
    are correlated, which violates the fourth GMT assumption. Positive serial correlation
    implies that the standard errors are underestimated and the t-statistics will
    be inflated, leading to false discoveries if ignored. However, there are procedures
    to correct for serial correlation when calculating standard errors.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 序列相关意味着线性回归产生的连续残差是相关的，这违反了第四个GMT假设。正序列相关意味着标准误差被低估，t统计量被夸大，如果忽略，会导致虚假发现。然而，在计算标准误差时有纠正序列相关的程序。
- en: The Durbin—Watson statistic diagnoses serial correlation. It tests the hypothesis
    that the OLS residuals are not autocorrelated against the alternative that they
    follow an autoregressive process (that we will explore in the next chapter). The
    test statistic ranges from 0 to 4, and values near 2 indicate non-autocorrelation,
    lower values suggest positive, and higher values indicate negative autocorrelation.
    The exact threshold values depend on the number of parameters and observations
    and need to be looked up in tables.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Durbin—Watson统计量诊断序列相关性。它检验了OLS残差不自相关的零假设，而是遵循自回归过程的替代方案（我们将在下一章中探讨）。检验统计量范围从0到4，接近2的值表示非自相关，较低的值表示正相关，较高的值表示负相关。确切的阈值取决于参数和观测值的数量，需要在表中查找。
- en: Multicollinearity
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多重共线性
- en: 'Multicollinearity occurs when two or more independent variables are highly
    correlated. This poses several challenges:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当两个或更多的自变量高度相关时，就会出现多重共线性。这带来了几个挑战：
- en: It is difficult to determine which factors influence the dependent variable
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很难确定哪些因素影响了因变量
- en: The individual p values can be misleading—a p-value can be high even if the
    variable is important
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 个别p值可能会误导-即使变量很重要，p值也可能很高
- en: The confidence intervals for the regression coefficients will be excessive,
    possibly even including zero, making it impossible to determine the effect of
    an independent variable on the outcome
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回归系数的置信区间可能过大，甚至可能包括零，使得无法确定自变量对结果的影响
- en: There is no formal or theory-based solution that corrects for multicollinearity.
    Instead, try to remove one or more of the correlated input variables, or increase
    the sample size.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正式的或基于理论的解决方案可以纠正多重共线性。相反，尝试去除一个或多个相关的输入变量，或增加样本量。
- en: How to run linear regression in practice
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在实践中运行线性回归
- en: 'The accompanying notebook `linear_regression_intro.ipynb` illustrates a simple
    and then a multiple linear regression, the latter using both OLS and gradient
    descent. For the multiple regression, we generate two random input variables *x[1 ]*and
    *x[2]* that range from -50 to +50, and an outcome variable calculated as a linear
    combination of the inputs plus random Gaussian noise to meet the normality assumption
    GMT 6:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 附带的笔记本`linear_regression_intro.ipynb`演示了简单的线性回归和多元线性回归，后者使用了OLS和梯度下降。对于多元回归，我们生成了两个随机输入变量*x[1]*和*x[2]*，范围从-50到+50，并且一个结果变量计算为输入的线性组合加上随机高斯噪声，以满足正态性假设GMT
    6：
- en: '![](img/e51fe442-ed74-43fd-82fe-bc610bc10f8e.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e51fe442-ed74-43fd-82fe-bc610bc10f8e.png)'
- en: OLS with statsmodels
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OLS with statsmodels
- en: 'We use `statsmodels` to estimate a multiple regression model that accurately
    reflects the data generating process as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`statsmodels`来估计一个准确反映数据生成过程的多元回归模型如下：
- en: '[PRE0]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This yields the following **OLS Regression Results** summary:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了以下**OLS回归结果**摘要：
- en: '![](img/bb6ff5b6-0bd0-4778-9951-91d5cc77e648.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bb6ff5b6-0bd0-4778-9951-91d5cc77e648.png)'
- en: Summary ofOLS Regression Results
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: OLS回归结果摘要
- en: 'The upper part of the summary displays the dataset characteristics, namely
    the estimation method, the number of observations and parameters, and indicates
    that standard error estimates do not account for heteroskedasticity. The middle
    panel shows the coefficient values that closely reflect the artificial data generating
    process. We can confirm that the estimates displayed in the middle of the summary
    result can be obtained using the OLS formula derived previously:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要的上部显示了数据集的特征，即估计方法、观测值和参数的数量，并指出标准误差估计不考虑异方差性。中间面板显示了系数值，这些系数值与人工数据生成过程密切相关。我们可以确认摘要结果中间显示的估计可以使用先前推导的OLS公式获得：
- en: '[PRE1]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following diagram illustrates the hyperplane fitted by the model to the
    randomly generated data points:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了模型对随机生成的数据点拟合的超平面：
- en: '![](img/e3ec55b4-5d60-473b-ae25-2d5a9be6af8d.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e3ec55b4-5d60-473b-ae25-2d5a9be6af8d.png)'
- en: Hyperplane
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 超平面
- en: The upper right part of the panel displays the goodness-of-fit measures just
    discussed, alongside the F-test that rejects the hypothesis that all coefficients
    are zero and irrelevant. Similarly, the t-statistics indicate that intercept and
    both slope coefficients are, unsurprisingly, highly significant.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 面板的右上部显示了刚才讨论的拟合优度指标，以及拒绝所有系数为零和不相关的F检验。同样，t统计量表明截距和斜率系数都是非常显著的，这并不奇怪。
- en: The bottom part of the summary contains the residual diagnostics. The left panel
    displays skew and kurtosis that are used to test the normality hypothesis. Both
    the Omnibus and the Jarque—Bera test fails to reject the null hypothesis that
    the residuals are normally distributed. The Durbin—Watson statistic tests for
    serial correlation in the residuals and has a value near 2 which, given 2 parameters
    and 625 observations, fails to reject the hypothesis of no serial correlation.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 总结的底部包含了残差诊断。左侧面板显示了用于测试正态性假设的偏度和峰度。Omnibus和Jarque—Bera测试都未能拒绝残差正态分布的零假设。Durbin—Watson统计量测试残差的串行相关性，并且在2附近具有一个值，考虑到2个参数和625个观测值，未能拒绝无串行相关性的假设。
- en: 'Lastly, the condition number provides evidence about multicollinearity: it is
    the ratio of the square roots of the largest and the smallest eigenvalue of the design
    matrix that contains the input data. A value above 30 suggests that the regression
    may have significant multicollinearity.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，条件数提供了关于多重共线性的证据：它是包含输入数据的设计矩阵的最大和最小特征值的平方根的比值。值超过30表明回归可能存在显著的多重共线性。
- en: '`statsmodels` includes additional diagnostic tests that are linked in the notebook.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`statsmodels`包括与笔记本中链接的其他诊断测试。'
- en: Stochastic gradient descent with sklearn
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn的随机梯度下降
- en: 'The `sklearn` library includes an `SGDRegressor` model in its `linear_models`
    module. To learn the parameters for the same model using this method, we need
    to first standardize the data because the gradient is sensitive to the scale.
    We use `StandardScaler()` for this purpose that computes the mean and the standard
    deviation for each input variable during the fit step, and then subtracts the
    mean and divides by the standard deviation during the transform step that we can
    conveniently conduct in a single `fit_transform()` command:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '`sklearn`库在其`linear_models`模块中包括了一个`SGDRegressor`模型。要使用这种方法学习相同模型的参数，我们需要首先标准化数据，因为梯度对尺度敏感。我们使用`StandardScaler()`来计算每个输入变量的均值和标准差，在拟合步骤中减去均值并除以标准差，在转换步骤中进行方便的`fit_transform()`命令：'
- en: '[PRE2]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then we instantiate the `SGDRegressor` using the default values except for
    a `random_state` setting to facilitate replication:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用默认值实例化`SGDRegressor`，除了设置`random_state`以便复制：
- en: '[PRE3]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now we can fit the `sgd` model, create the in-sample predictions for both the
    OLS and the `sgd` models, and compute the root mean squared error for each:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以拟合`sgd`模型，为OLS和`sgd`模型创建样本内预测，并计算每个模型的均方根误差：
- en: '[PRE4]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, both models yield the same result. We will now take on a more ambitious
    project using linear regression to estimate a multi-factor asset pricing model.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，两个模型产生了相同的结果。现在我们将承担一个更有雄心的项目，使用线性回归来估计多因素资产定价模型。
- en: How to build a linear factor model
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何构建线性因子模型
- en: Algorithmic trading strategies use **linear factor models** to quantify the
    relationship between the return of an asset and the sources of risk that represent
    the main drivers of these returns. Each factor risk carries a premium, and the
    total asset return can be expected to correspond to a weighted average of these
    risk premia.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 算法交易策略使用**线性因子模型**来量化资产回报与代表这些回报主要驱动因素的风险来源之间的关系。每个因子风险都带有一个风险溢价，总资产回报可以预期对应于这些风险溢价的加权平均值。
- en: 'There are several practical applications of factor models across the portfolio
    management process from construction and asset selection to risk management and
    performance evaluation. The importance of factor models continues to grow as common
    risk factors are now tradeable:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因子模型在投资组合管理过程中有几个实际应用，从构建和资产选择到风险管理和绩效评估。随着常见风险因素现在可以交易，因子模型的重要性不断增加：
- en: A summary of the returns of many assets by a much smaller number of factors
    reduces the amount of data required to estimate the covariance matrix when optimizing
    a portfolio
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过少数因素对许多资产的回报进行总结，可以减少在优化投资组合时估计协方差矩阵所需的数据量
- en: An estimate of the exposure of an asset or a portfolio to these factors allows
    for the management of the resultant risk, for instance by entering suitable hedges
    when risk factors are themselves traded
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对资产或投资组合对这些因素的暴露的估计允许管理由此产生的风险，例如在风险因素本身交易时进入适当的对冲
- en: A factor model also permits the assessment of the incremental signal content
    of new alpha factors
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还允许评估新的阿尔法因子的增量信号内容
- en: A factor model can also help assess whether a manager's performance relative
    to a benchmark is indeed due to skill in selecting assets and timing the market,
    or if instead, the performance can be explained by portfolio tilts towards known
    return drivers that can today be replicated as low-cost, passively managed funds
    without incurring active management fees
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因子模型还可以帮助评估经理相对于基准的绩效是否确实是由于选择资产和市场定时的技能，还是绩效可以解释为投资组合倾向于已知回报驱动因素，这些因素今天可以以低成本、被动管理的基金进行复制而不产生主动管理费用
- en: The following examples apply to equities, but risk factors have been identified
    for all asset classes (see references in the GitHub repository).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例适用于股票，但已经为所有资产类别确定了风险因素（请参阅GitHub存储库中的参考资料）。
- en: From the CAPM to the Fama—French five-factor model
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从CAPM到法玛-法国五因素模型
- en: 'Risk factors have been a key ingredient to quantitative models since the **Capital
    Asset Pricing Model **(**CAPM**) explained the expected returns of all *N* assets ![](img/31afacbc-b4b4-4f0f-97ac-fff357bc652a.png)
    using their respective exposure ![](img/a332fea0-7be6-4858-a873-73742a227f66.png)
    to a single factor, the expected excess return of the overall market over the
    risk-free rate ![](img/4f4b2d16-602f-4672-941b-3be7cc28d1a4.png). The model takes
    the following linear form:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 风险因素自**资本资产定价模型**（**CAPM**）解释了所有*N*资产的预期回报！[](img/31afacbc-b4b4-4f0f-97ac-fff357bc652a.png)使用它们各自的暴露度！[](img/a332fea0-7be6-4858-a873-73742a227f66.png)到一个因素，即整体市场的预期超额回报超过无风险利率！[](img/4f4b2d16-602f-4672-941b-3be7cc28d1a4.png)。该模型采用以下线性形式：
- en: '![](img/3a6152b2-582b-4452-a8d2-c70388fd9827.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3a6152b2-582b-4452-a8d2-c70388fd9827.png)'
- en: This differs from classic fundamental analysis a la Dodd and Graham where returns
    depend on firm characteristics. The rationale is that, in the aggregate, investors
    cannot eliminate this so-called systematic risk through diversification. Hence, in
    equilibrium, they require compensation for holding an asset commensurate with
    its systematic risk. The model implies that, given efficient markets where prices
    immediately reflect all public information, there should be no superior risk-adjusted
    returns, that is, the value of ![](img/f9d4110b-3746-4824-9340-1ec387bb81f6.png)
    should be zero.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这与道德和格雷厄姆的经典基本面分析不同，后者的回报取决于公司特征。理由是，总体上，投资者无法通过分散化消除所谓的系统风险。因此，在均衡状态下，他们要求持有资产的补偿与其系统风险相称。该模型暗示，鉴于价格立即反映所有公共信息的有效市场，不应该有优越的风险调整回报，也就是说，![](img/f9d4110b-3746-4824-9340-1ec387bb81f6.png)的价值应该为零。
- en: 'Empirical tests of the model use linear regression and have consistently failed,
    prompting a debate whether the efficient markets or the single factor aspect of
    the joint hypothesis is to blame. It turns out that both premises are probably
    wrong:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型的实证测试使用线性回归，并一直失败，引发了一场辩论，即是有效市场还是联合假设的单一因素方面有问题。结果表明，这两个前提可能都是错误的：
- en: 'Joseph Stiglitz earned the 2001 Nobel Prize in economics in part for showing
    that markets are generally not perfectly efficient: if markets are efficient,
    there is no value in collecting data because this information is already reflected
    in prices. However, if there is no incentive to gather information, it is hard
    to see how it should be already reflected in prices.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约瑟夫·斯蒂格利茨因部分展示市场通常不是完全有效而获得了2001年诺贝尔经济学奖：如果市场是有效的，那么收集数据就没有价值，因为这些信息已经反映在价格中。然而，如果没有收集信息的动机，很难看出它应该已经反映在价格中。
- en: On the other hand, theoretical and empirical improvements on the CAPM suggest
    that additional factors help explain some of the anomalies that consisted in superior
    risk-adjusted returns that do not depend on overall market exposure, such as higher
    returns for smaller firms.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，对CAPM的理论和实证改进表明，额外的因素有助于解释一些异常，这些异常包括不依赖于整体市场暴露的优越风险调整回报，例如较小公司的更高回报。
- en: Stephen Ross proposed the **Arbitrage Pricing Theory** (**APT**) in 1976 as
    an alternative that allows for several risk factors while eschewing market efficiency.
    In contrast to the CAPM, it assumes that opportunities for superior returns due
    to mispricing may exist but will quickly be arbitraged away. The theory does not
    specify the factors, but research by the author suggests that the most important
    are changes in inflation and industrial production, as well as changes in risk
    premia or the term structure of interest rates.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 斯蒂芬·罗斯于1976年提出了**套利定价理论**（**APT**）作为一种替代方案，允许多个风险因素，同时避免市场效率。与CAPM相反，它假设由于定价错误而存在优越回报的机会，但这些机会将很快被套利掉。该理论并未指定因素，但作者的研究表明，最重要的因素是通货膨胀和工业生产的变化，以及风险溢价或利率期限结构的变化。
- en: Kenneth French and Eugene Fama (who won the 2013 Nobel Prize) identified additional
    risk factors that depend on firm characteristics and are widely used today. In
    1993, the Fama—French three-factor model added the relative size and value of
    firms to the single CAPM source of risk. In 2015, the five-factor model further
    expanded the set to include firm profitability and level of investment that had
    been shown to be significant in the intervening years. In addition, many factor
    models include a price momentum factor.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 肯尼斯·弗伦奇和尤金·法玛（获得2013年诺贝尔奖）确定了依赖于公司特征的额外风险因素，这些因素今天被广泛使用。1993年，法玛-弗伦奇三因子模型在单一CAPM风险来源的基础上增加了公司相对规模和价值。2015年，五因子模型进一步扩展了该集合，包括公司盈利能力和投资水平，这些因素在中间年份已被证明是显著的。此外，许多因子模型还包括价格动量因子。
- en: 'The Fama—French risk factors are computed as the return difference on diversified
    portfolios with high or low values according to metrics that reflect a given risk
    factor. These returns are obtained by sorting stocks according to these metrics
    and then going long stocks above a certain percentile while shorting stocks below
    a certain percentile. The metrics associated with the risk factors are defined
    as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛-弗伦奇风险因素是根据多样化投资组合的回报差异计算的，这些投资组合具有根据反映特定风险因素的指标的高或低价值。通过根据这些指标对股票进行排序，然后做多高于某个百分位数的股票，同时做空低于某个百分位数的股票来获得这些回报。与风险因素相关的指标定义如下：
- en: '**Size**: **Market Equity** (**ME**)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**规模**：**市场权益**（**ME**）'
- en: '**Value**: **Book Value of Equity** (**BE**) divided by ME'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值**：**股权账面价值**（**BE**）除以ME'
- en: '**Operating Profitability (OP)**: Revenue minus cost of goods sold/assets'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**营运盈利能力（OP）**：营收减去销售成本/资产'
- en: '**Investment**: Investment/assets'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资**：投资/资产'
- en: There are also unsupervised learning techniques for a data-driven discovery
    of risk factors using factors and principal component analysis that we will explore
    in [Chapter 12](c187906e-9fde-4f85-b709-df88dd0f7e88.xhtml), *Unsupervised Learning.*
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些无监督学习技术，可以使用因子和主成分分析进行数据驱动的风险因素发现，我们将在[第12章](c187906e-9fde-4f85-b709-df88dd0f7e88.xhtml)
    *无监督学习*中探讨。
- en: Obtaining the risk factors
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取风险因素
- en: Fama and French make updated risk factor and research portfolio data available
    through their website, and you can use the `pandas_datareader` library to obtain
    the data. For this application, refer to the `fama_macbeth.ipynb` notebook for
    additional detail.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和弗伦奇通过他们的网站提供更新的风险因素和研究投资组合数据，并且您可以使用`pandas_datareader`库来获取这些数据。对于这个应用程序，请参考`fama_macbeth.ipynb`笔记本以获取更多细节。
- en: 'In particular, we will be using the five Fama—French factors that result from
    sorting stocks first into three size groups and then into two for each of the
    remaining three firm-specific factors. Hence, the factors involve three sets of
    value-weighted portfolios formed as 3 x 2 sorts on size and book-to-market, size
    and operating profitability, and size and investment. The risk factor values computed
    as the average returns of the **portfolios** (**PF**) as outlined in the following
    table:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，我们将使用从股票首先分为三个规模组，然后对剩下的三个公司特定因素的每个分为两个的法玛-弗伦奇五因子。因此，这些因子涉及三组价值加权投资组合，分别形成了规模和账面市值比、规模和营运盈利能力、规模和投资的3
    x 2排序。风险因素的值计算为如下表中所述的**投资组合**（**PF**）的平均回报：
- en: '| **Concept** | **Label** | **Name** | **Risk factor calculation** |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| **概念** | **标签** | **名称** | **风险因素计算** |'
- en: '| Size | SMB | Small minus big | Nine small stock PF minus nine large stock
    PF |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 规模 | SMB | 小减大 | 九个小股票PF减去九个大股票PF |'
- en: '| Value | HML | High minus low |  Two value PF minus two growth (with low BE/ME
    value) PF |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 价值 | HML | 高减低 | 两个价值PF减去两个成长（低BE/ME价值）PF |'
- en: '| Profitability | RMW | Robust minus weak | Two robust OP PF minus two weak
    OP PF |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 盈利能力 | RMW | 强劲减弱 | 两个强劲OP PF减去两个弱OP PF |'
- en: '| Investment | CMA | Conservative minus aggressive | Two conservative investment
    portfolios minus two aggressive investment portfolios |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| 投资 | CMA | 保守减激进 | 两个保守投资组合减去两个激进投资组合 |'
- en: '| Market | Rm-Rf | Excess return on the market | Value-weight return of all
    firms incorporated in and listed on  major US exchanges with good data minus the
    one-month Treasury bill rate |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 市场 | Rm-Rf | 市场超额回报 | 所有在美国主要交易所上市并具有良好数据的公司的市值加权回报减去一个月期国库券利率 |'
- en: 'We will use returns at a monthly frequency that we obtain for the period 2010
    – 2017 as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用2010年至2017年期间获得的月度频率的回报，如下所示：
- en: '[PRE5]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Fama and French also make available numerous portfolios that we can illustrate
    the estimation of the factor exposures, as well as the value of the risk premia
    available in the market for a given time period. We will use a panel of the 17
    industry portfolios at a monthly frequency. We will subtract the risk-free rate
    from the returns because the factor model works with excess returns:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 法玛和弗伦奇还提供了许多投资组合，我们可以用来说明因子暴露的估计，以及市场上某一特定时间段内风险溢价的价值。我们将使用月度频率的17个行业投资组合的面板。我们将从回报中减去无风险利率，因为因子模型使用的是超额回报：
- en: '[PRE6]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We will now build a linear factor model based on this panel data using a method
    that addresses the failure of some basic linear regression assumptions.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将基于这些面板数据构建一个线性因子模型，使用一种能够解决一些基本线性回归假设失败的方法。
- en: Fama—Macbeth regression
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 法玛-麦克贝斯回归
- en: Given data on risk factors and portfolio returns, it is useful to estimate the
    portfolio's exposure, that is, how much the risk factors drive portfolio returns,
    as well as how much the exposure to a given factor is worth, that is, the what
    market's risk factor premium is. The risk premium then permits to estimate the
    return for any portfolio provided the factor exposure is known or can be assumed.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于风险因素和投资组合回报的数据，估计投资组合的暴露是有用的，即风险因素对投资组合回报的影响有多大，以及对于给定因素的暴露价值有多大，即市场风险因素溢价是多少。然后，风险溢价允许估计任何投资组合的回报，只要因子暴露是已知的或可以假定的。
- en: More formally, we will have *i=1, ..., N* asset or portfolio returns over *t=1,
    ..., T* periods and each asset's excess period return will be denoted ![](img/65e5c37d-8bfd-47b8-85a9-07e538fd00f8.png). The
    goals is to test whether the *j=1, ..., M* factors ![](img/ca9ceac1-0c7c-4833-b6d1-dd15cb47660d.png)explain
    the excess returns and the risk premium associated with each factor. In our case,
    we have *N=17* portfolios and *M=5* factors, each with =96 periods of data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 更正式地，我们将有*i=1, ..., N*资产或组合在*t=1, ..., T*期间的回报，每个资产的超额期回报将被表示为![](img/65e5c37d-8bfd-47b8-85a9-07e538fd00f8.png)。目标是测试*j=1,
    ..., M*因子![](img/ca9ceac1-0c7c-4833-b6d1-dd15cb47660d.png)是否解释了超额回报以及与每个因子相关的风险溢价。在我们的情况下，我们有*N=17*个组合和*M=5*个因子，每个因子有96个数据期。
- en: Factor models are estimated for many stocks in a given period. Inference problems
    will likely arise in such cross-sectional regressions because the fundamental
    assumptions of classical linear regression may not hold. Potential violations
    include measurement errors, covariation of residuals due to heteroskedasticity
    and serial correlation, and multicollinearity.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定时期对许多股票进行因子模型估计。在这种横截面回归中可能会出现推断问题，因为经典线性回归的基本假设可能不成立。潜在的违规行为包括测量误差、由异方差和串扰引起的残差协变以及多重共线性。
- en: 'To address the inference problem caused by the correlation of the residuals,
    Fama and MacBeth proposed a two-step methodology for a cross-sectional regression
    of returns on factors. The two-stage Fama—Macbeth regression is designed to estimate
    the premium rewarded for the exposure to a particular risk factor by the market. The
    two stages consist of:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决残差相关引起的推断问题，Fama和MacBeth提出了一个用于对因子进行横截面回归的两步方法。两阶段Fama—Macbeth回归旨在估计市场对特定风险因子暴露所奖励的溢价。两个阶段包括：
- en: '**First stage**: *N* time-series regression, one for each asset or portfolio,
    of its excess returns on the factors to estimate the factor loadings. In matrix
    form, for each asset:'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第一阶段**：*N*时间序列回归，每个资产或组合一个，其超额回报对因子的估计因子载荷。以矩阵形式，对于每个资产：'
- en: '![](img/e187e1c1-3c7a-4dc4-a691-0e80d387a11b.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e187e1c1-3c7a-4dc4-a691-0e80d387a11b.png)'
- en: '**Second stage**: T cross-sectional regression, one for each time period, to
    estimate the risk premium. In matrix form, we obtain a vector ![](img/8a5b412f-8c0f-40f0-97d5-d3f50789362e.png) of
    risk premia for each period:'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第二阶段**：T横截面回归，每个时间段一个，以估计风险溢价。以矩阵形式，我们得到每个时期的风险溢价向量![](img/8a5b412f-8c0f-40f0-97d5-d3f50789362e.png)：'
- en: '![](img/ebf5ed03-1aaf-4cef-85aa-33cc4fb12ad1.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![](img/ebf5ed03-1aaf-4cef-85aa-33cc4fb12ad1.png)'
- en: Now we can compute the factor risk premia as the time average and get t-statistic
    to assess their individual significance, using the assumption that the risk premia
    estimates are independent over time:![](img/105fc0bb-9211-48d6-b2cb-c1ff1081bbf3.png).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以计算因子风险溢价作为时间平均值，并获得t统计量来评估它们的个别显著性，使用风险溢价估计在时间上是独立的假设:![](img/105fc0bb-9211-48d6-b2cb-c1ff1081bbf3.png)。
- en: If we had a very large and representative data sample on traded risk factors
    we could use the sample mean as a risk premium estimate. However, we typically
    do not have a sufficiently long history to and the margin of error around the
    sample mean could be quite large. The Fama—Macbeth methodology leverages the covariance
    of the factors with other assets to determine the factor premia. The second moment
    of asset returns is easier to estimate than the first moment, and obtaining more
    granular data improves estimation considerably, which is not true of mean estimation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有一个非常大且具有代表性的交易风险因子的数据样本，我们可以使用样本均值作为风险溢价估计。然而，我们通常没有足够长的历史记录，样本均值周围的误差范围可能相当大。Fama—Macbeth方法利用因子与其他资产的协方差来确定因子溢价。资产回报的二阶矩易于估计，而获得更精细的数据显著改善了估计，这在均值估计中并不成立。
- en: 'We can implement the first stage to obtain the 17 factor loading estimates
    as follows:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以实施第一阶段，以获得17个因子载荷估计，如下所示：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For the second stage, we run 96 regressions of the period returns for the cross
    section of portfolios on the factor loadings:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二阶段，我们对组合的期间回报进行96次回归，以估计因子载荷：
- en: '[PRE8]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Finally, we compute the average for the 96 periods to obtain our factor risk
    premium estimates:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '最后，我们计算96个期间的平均值，以获得我们的因子风险溢价估计:'
- en: '[PRE9]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `linear_models` library extends `statsmodels` with various models for panel
    data and also implements the two-stage Fama—MacBeth procedure:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '`linear_models`库通过各种面板数据模型扩展了`statsmodels`，并实现了两阶段Fama—MacBeth程序：'
- en: '[PRE10]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This provides us with the same result:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '这为我们提供了相同的结果:'
- en: '![](img/74d5d23a-9727-43c3-b1a1-3cb8ece117dd.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![](img/74d5d23a-9727-43c3-b1a1-3cb8ece117dd.png)'
- en: LinearFactorModel Estimation Summary
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: LinearFactorModel估计摘要
- en: The accompanying notebook illustrates the use of categorical variables by using
    industry dummies when estimating risk premia for a larger panel of individual
    stocks.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 随附的笔记本通过使用行业虚拟变量来估计更大的个体股票面板的风险溢价，说明了分类变量的使用。
- en: 'Shrinkage methods: regularization for linear regression'
  id: totrans-199
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收缩方法：线性回归的正则化
- en: The least squares methods to train a linear regression model will produce the
    best, linear, and unbiased coefficient estimates when the Gauss—Markov assumptions
    are met. Variations like GLS fare similarly well even when OLS assumptions about
    the error covariance matrix are violated. However, there are estimators that produce
    biased coefficients to reduce the variance to achieve a lower generalization error
    overall.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 当高斯—马尔可夫假设得到满足时，最小二乘法用于训练线性回归模型将产生最佳、线性和无偏的系数估计。即使OLS关于误差协方差矩阵的假设被违反，GLS等变体也能表现出色。然而，有些估计器会产生偏倚系数，以减少方差以实现更低的总体泛化误差。
- en: When a linear regression model contains many correlated variables, their coefficients
    will be poorly determined because the effect of a large positive coefficient on
    the RSS can be canceled by a similarly large negative coefficient on a correlated
    variable. Hence, the model will have a tendency for high variance due to this
    wiggle room of the coefficients that increases the risk that the model overfits
    to the sample.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当线性回归模型包含许多相关变量时，它们的系数将确定不足，因为大正系数对RSS的影响可能会被相关变量上的同样大的负系数抵消。因此，由于系数的这种摆动空间增加了模型对样本过度拟合的风险，模型将具有高方差的倾向。
- en: How to hedge against overfitting
  id: totrans-202
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何对冲过度拟合
- en: One popular technique to control overfitting is that of **regularization**,
    which involves the addition of a penalty term to the error function to discourage
    the coefficients from reaching large values. In other words, size constraints
    on the coefficients can alleviate the resultant potentially negative impact on
    out-of-sample predictions. We will encounter regularization methods for all models
    since overfitting is such a pervasive problem.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 控制过度拟合的一种流行技术是**正则化**，它涉及向误差函数添加惩罚项，以阻止系数达到较大值。换句话说，对系数的大小施加约束可以减轻对样本外预测的潜在负面影响。由于过度拟合是如此普遍的问题，我们将遇到所有模型的正则化方法。
- en: 'In this section, we will introduce shrinkage methods that address two motivations
    to improve on the approaches to linear models discussed so far:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将介绍收缩方法，以解决迄今为止讨论的线性模型的两个改进动机：
- en: '**Prediction accuracy**: The low bias but high variance of least squares estimates
    suggests that the generalization error could be reduced by shrinking or setting
    some coefficients to zero, thereby trading off a slightly higher bias for a reduction
    in the variance of the model.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测准确性**：最小二乘估计的低偏差但高方差表明，通过缩小或将一些系数设为零，可以减少广义误差，从而以略微增加的偏差换取模型方差的减少。'
- en: '**Interpretation**: A large number of predictors may complicate the interpretation
    or communication of the big picture of the results. It may be preferable to sacrifice
    some detail to limit the model to a smaller subset of parameters with the strongest
    effects.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**解释**：大量预测变量可能会使结果的解释或传达变得复杂。牺牲一些细节以将模型限制为具有最强效果的较小参数子集可能更可取。'
- en: 'Shrinkage models restrict the regression coefficients by imposing a penalty
    on their size. These models achieve this goal by adding a term to the objective function
    so that the coefficients of a shrinkage model minimize the RSS plus a penalty
    that is positively related to the (absolute) size of the coefficients. The added
    penalty turns finding the linear regression coefficients into a constrained minimization
    problem that, in general, takes the following Lagrangian form:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过对回归系数施加惩罚来限制它们的大小。这些模型通过向目标函数添加一个项来实现这一目标，以便收缩模型的系数最小化RSS加上与系数的（绝对）大小正相关的惩罚。添加的惩罚将线性回归系数的查找转变为受限制的最小化问题，通常采用以下拉格朗日形式：
- en: '![](img/2dd72b9d-c072-47ce-834f-356b6c948b14.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2dd72b9d-c072-47ce-834f-356b6c948b14.png)'
- en: The regularization parameter λ determines the size of the penalty effect, that
    is, the strength of the regularization. As soon as λ is positive, the coefficients
    will differ from the unconstrained least squared parameters, which implies a biased
    estimate. The hyperparameter λ should be adaptively chosen using cross-validation
    to minimize an estimate of expected prediction error.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化参数λ确定了惩罚效应的大小，即正则化的强度。一旦λ为正，系数将与无约束的最小二乘参数不同，这意味着有偏估计。超参数λ应该通过交叉验证进行自适应选择，以最小化预期预测误差的估计。
- en: Shrinkage models differ by how they calculate the penalty, that is, the functional
    form of S. The most common versions are the ridge regression that uses the sum
    of the squared coefficients, whereas the lasso model bases the penalty on the
    sum of the absolute values of the coefficients.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 收缩模型通过计算惩罚的方式不同，即S的函数形式不同。最常见的版本是使用系数平方和的岭回归，而套索模型则基于系数的绝对值之和进行惩罚。
- en: How ridge regression works
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 岭回归的工作原理
- en: 'The ridge regression shrinks the regression coefficients by adding a penalty
    to the objective function that equals the sum of the squared coefficients, which
    in turn corresponds to the L² norm of the coefficient vector:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归通过向目标函数添加一个惩罚来缩小回归系数，该惩罚等于系数的平方和，这又对应于系数向量的L²范数：
- en: '![](img/119120f8-5beb-4dd6-9aaf-d613fb2edb63.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](img/119120f8-5beb-4dd6-9aaf-d613fb2edb63.png)'
- en: 'Hence, the ridge coefficients are defined as:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，岭系数定义为：
- en: '![](img/b2783010-31ca-4a32-8997-dd5c559c40e6.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b2783010-31ca-4a32-8997-dd5c559c40e6.png)'
- en: The intercept ![](img/71cf85ed-96c5-49f5-b91d-07099b5ed007.png) has been excluded
    from the penalty to make the procedure independent of the origin chosen for the
    output variable—otherwise, adding a constant to all output values would change
    all slope parameters as opposed to a parallel shift.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 拦截![](img/71cf85ed-96c5-49f5-b91d-07099b5ed007.png)已被排除在处罚之外，使得该程序独立于选择的输出变量的原点-否则，将常数添加到所有输出值将改变所有斜率参数，而不是平行移位。
- en: 'It is important to standardize the inputs by subtracting from each input the
    corresponding mean and dividing the result by the input''s standard deviation because
    the ridge solution is sensitive to the scale of the inputs. There is also a closed
    solution for the ridge estimator that resembles the OLS case:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从每个输入中减去相应的均值并将结果除以输入的标准差来标准化输入是很重要的，因为岭解决方案对输入的规模敏感。岭估计器也有一个封闭解，类似于OLS案例：
- en: '![](img/4d2c6a4a-0e95-4314-932e-9cdec5694253.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4d2c6a4a-0e95-4314-932e-9cdec5694253.png)'
- en: The solution adds the scaled identity matrix λ*I* to *X^TX* before inversion,
    which guarantees that the problem is non-singular, even if *X^T**X* does not have full
    rank. This was one of the motivations for using this estimator when it was originally
    introduced.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在求逆之前，解决方案在*X^TX*之前添加了缩放的单位矩阵λ*I*，这保证了问题是非奇异的，即使*X^T**X*没有完全秩。这是最初引入此估计量时的动机之一。
- en: 'The ridge penalty results in proportional shrinkage of all parameters. In the
    case of **orthonormal inputs**, the ridge estimates are just a scaled version
    of the least squares estimates, that is:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚导致所有参数按比例收缩。在**正交输入**的情况下，岭估计只是最小二乘估计的缩放版本，即：
- en: '![](img/bba72082-ca29-4704-a72d-d811aa84a7c2.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![](img/bba72082-ca29-4704-a72d-d811aa84a7c2.png)'
- en: Using the **singular value decomposition** (**SVD**) of the input matrix *X*,
    we can gain insight into how the shrinkage affects inputs in the more common case
    where they are not orthonormal. The SVD of a centered matrix represents the principal
    components of a matrix (refer to [Chapter 11](2fbfa6b5-87f3-49c3-b13a-5ead63471370.xhtml),
    *Gradient Boosting Machines*, on unsupervised learning) that capture uncorrelated
    directions in the column space of the data in descending order of variance.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 通过输入矩阵*X*的**奇异值分解**（**SVD**），我们可以了解收缩如何影响输入，更常见的情况是输入不是正交的。中心矩阵的SVD表示了矩阵的主要成分（参见[第11章](2fbfa6b5-87f3-49c3-b13a-5ead63471370.xhtml)，*梯度提升机*，关于无监督学习），按方差降序捕获数据的列空间中的不相关方向。
- en: Ridge regression shrinks coefficients on input variables that are associated
    with directions in the data that have less variance more than input variables
    that correlate with directions that exhibit more variance. Hence, the implicit
    assumption of ridge regression is that the directions in the data that vary the
    most will be most influential or most reliable when predicting the output.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 岭回归缩小了与数据中方差较小的方向相关的输入变量的系数，而不是与表现更大方差的方向相关的输入变量。因此，岭回归的隐含假设是，在数据中变化最大的方向在预测输出时最具影响力或最可靠。
- en: How lasso regression works
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 套索回归的工作原理
- en: 'The lasso, known as basis pursuit in signal processing, also shrinks the coefficients
    by adding a penalty to the sum of squares of the residuals, but the lasso penalty
    has a slightly different effect. The lasso penalty is the sum of the absolute
    values of the coefficient vector, which corresponds to its L¹ norm. Hence, the
    lasso estimate is defined by:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 套索，也称为信号处理中的基 Pursuit，通过向残差平方和添加惩罚来缩小系数，但套索惩罚的效果略有不同。套索惩罚是系数向量的绝对值之和，对应于其L¹范数。因此，套索估计由以下公式定义：
- en: '![](img/c05889b1-7c7b-415e-b0eb-280833978de1.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c05889b1-7c7b-415e-b0eb-280833978de1.png)'
- en: Similarly to ridge regression, the inputs need to be standardized. The lasso
    penalty makes the solution nonlinear, and there is no closed-form expression for
    the coefficients as in ridge regression. Instead, the lasso solution is a quadratic
    programming problem and there are available efficient algorithms that compute
    the entire path of coefficients that result for different values of λ with the
    same computational cost as for ridge regression.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 与岭回归类似，输入需要标准化。套索惩罚使解决方案非线性，并且与岭回归不同，套索回归的系数没有封闭形式的表达式。相反，套索解决方案是一个二次规划问题，并且有有效的算法可以计算出对于不同λ值的系数路径，其计算成本与岭回归相同。
- en: The lasso penalty had the effect ofgradually reducing some coefficients to zero
    as the regularization increases. For this reason, the lasso can be used for the
    continuous selection of a subset of features.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 随着正则化的增加，套索惩罚逐渐将一些系数减少到零。因此，套索可以用于连续选择一组特征。
- en: How to use linear regression to predict returns
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用线性回归预测收益
- en: The notebook `linear_regression.ipynb` contains examples for the prediction
    of stock prices using OLS with `statsmodels` and `sklearn`, as well as ridge and
    lasso models. It is designed to run as a notebook on the Quantopian research platform
    and relies on the `factor_library` introduced in [Chapter 4](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml), *Alpha
    Factors Research*.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 笔记本`linear_regression.ipynb`包含使用`statsmodels`和`sklearn`进行OLS预测股票价格的示例，以及岭回归和套索模型。它旨在作为Quantopian研究平台上的笔记本运行，并依赖于[第4章](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml)中介绍的`factor_library`，*Alpha
    Factors Research*。
- en: Prepare the data
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备数据
- en: We need to select a universe of equities and a time horizon, build and transform
    alpha factors that we will use as features, calculate forward returns that we
    aim to predict, and potentially clean our data.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择一组股票和一个时间跨度，构建和转换我们将用作特征的alpha因子，计算我们的目标预测的前瞻收益，并可能清理我们的数据。
- en: Universe creation and time horizon
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 宇宙创建和时间跨度
- en: 'We will use equity data for the years 2014 and 2015 from a custom `Q100US`
    universe that uses built-in filters, factors, and classifiers to select the 100
    stocks with the highest average dollar volume of the last 200 trading days filtered
    by additional default criteria (see Quantopian docs linked on GitHub for detail).
    The universe dynamically updates based on the filter criteria so that, while there
    are 100 stocks at any given point, there may be more than 100 distinct equities
    in the sample:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用2014年和2015年的股票数据，这些数据来自一个自定义的`Q100US`宇宙，该宇宙使用内置的过滤器、因子和分类器来选择最近200个交易日的平均美元成交量最高的100只股票，并通过额外的默认标准进行过滤（有关详细信息，请参阅GitHub上的Quantopian文档）。该宇宙根据过滤条件动态更新，因此在任何给定时间点，可能有超过100个不同的股票：
- en: '[PRE11]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Target return computation
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标收益计算
- en: 'We will test predictions for various `lookahead` periods to identify the best
    holding periods that generate the best predictability, measured by the information
    coefficient. More specifically, we compute returns for 1, 5, 10, and 20 days using
    the built-in `Returns` function, resulting in over 50,000 observations for the
    universe of 100 stocks over two years (that include approximately 252 trading
    days each):'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试各种`lookahead`期间的预测，以确定产生最佳可预测性的最佳持有期。更具体地说，我们使用内置的`Returns`函数计算1、5、10和20天的回报，从而在两年内为100只股票的宇宙中获得了超过50,000次观察（每年包括大约252个交易日）：
- en: '[PRE12]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Alpha factor selection and transformation
  id: totrans-239
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alpha因子选择和转换
- en: We will use over 50 features that cover a broad range of factors based on market,
    fundamental, and alternative data. The notebook also includes custom transformations
    to convert fundamental data that is typically available in quarterly reporting
    frequency to rolling annual totals or averages to avoid excessive season fluctuations.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用超过50个特征，涵盖市场、基本和替代数据的广泛范围。笔记本还包括自定义转换，将通常以季度报告频率提供的基本数据转换为滚动年度总数或平均数，以避免过度季节波动。
- en: 'Once the factors have been computed through the various pipelines outlined
    in [Chapter 4](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml), *Alpha Factors Research*,
    we combine them using `pd.concat()`, assign index names, and create a categorical
    variable that identifies the asset for each data point:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦通过[第4章](31520630-da72-4cf6-8d84-6a74b7f4f259.xhtml)中概述的各种流程计算出因子，*Alpha因子研究*，我们使用`pd.concat()`将它们组合起来，分配索引名称，并创建一个分类变量，用于标识每个数据点的资产：
- en: '[PRE13]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Data cleaning – missing data
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据清理-缺失数据
- en: 'In a next step, we remove rows and columns that lack more than 20 percent of
    the observations, resulting in a loss of six percent of the observations and three
    columns:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们删除缺少超过20%观察的行和列，导致损失了6%的观察和三列：
- en: '[PRE14]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'At this point, we have 51 features and the categorical identifier of the stock:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们有51个特征和股票的分类标识：
- en: '[PRE15]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Data exploration
  id: totrans-248
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据探索
- en: For linear regression models, it is important to explore the correlation among
    the features to identify multicollinearity issues, and to check the correlation
    between the features and the target. The notebook contains a seaborn clustermap
    that shows the hierarchical structure of the feature correlation matrix. It identifies
    a small number of highly correlated clusters.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对于线性回归模型，探索特征之间的相关性以识别多重共线性问题以及检查特征与目标之间的相关性是很重要的。笔记本包含一个seaborn clustermap，显示了特征相关性矩阵的分层结构。它识别了一小部分高度相关的集群。
- en: Dummy encoding of categorical variables
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类变量的虚拟编码
- en: 'We need to convert the categorical `stock` variable into a numeric format so
    that the linear regression can process it. For this purpose, we use dummy encoding
    that creates individual columns for each category level and flags the presence
    of this level in the original categorical column with an entry of `1`, and `0`
    otherwise. The pandas function `get_dummies()` automates dummy encoding. It detects
    and properly converts columns of type objects as illustrated next. If you need
    dummy variables for columns containing integers, for instance, you can identify
    them using the keyword `columns`:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将分类变量`stock`转换为数字格式，以便线性回归可以处理它。为此，我们使用虚拟编码，为每个类别级别创建单独的列，并使用`1`标记原始分类列中该级别的存在，否则使用`0`。pandas函数`get_dummies()`自动化了虚拟编码。它检测并正确转换对象类型的列，如下所示。如果您需要包含整数的列的虚拟变量，例如，您可以使用关键字`columns`来识别它们：
- en: '[PRE16]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'When converting all categories to dummy variables and estimating the model
    with an intercept (as you typically would), you inadvertently create multicollinearity:
    the matrix now contains redundant information and no longer has full rank, that
    is, becomes singular. It is simple to avoid this by removing one of the new indicator
    columns. The coefficient on the missing category level will now be captured by
    the intercept (which is always `1` when every other category dummy is `0`). Use
    the `drop_first` keyword to correct the dummy variables accordingly:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有类别转换为虚拟变量，并估计带有截距的模型（通常情况下），您无意中创建了多重共线性：矩阵现在包含冗余信息，不再具有完整的秩，即变得奇异。通过删除新的指示器列中的一个来避免这种情况是很简单的。现在，缺失类别级别上的系数将被截距捕获（当每个其他类别虚拟为`0`时，截距始终为`1`）。使用`drop_first`关键字来正确地校正虚拟变量：
- en: '[PRE17]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Applied to our combined features and returns, we obtain 181 columns because
    there are more than 100 stocks as the universe definition automatically updates
    the stock selection:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 应用于我们的组合特征和回报，我们获得了181列，因为股票的定义会自动更新股票选择，因此股票超过100只：
- en: '[PRE18]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Creating forward returns
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建前瞻回报
- en: 'The goal is to predict returns over a given holding period. Hence, we need
    to align the features with return values with the corresponding return data point
    1, 5, 10, or 20 days into the future for each equity. We achieve this by combining
    the pandas `.groupby()` method with the `.shift()` method as follows:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是预测给定持有期内的回报。因此，我们需要将特征与相应的回报数据点对齐，分别为每个股票的未来1、5、10或20天。我们通过将pandas的`.groupby()`方法与`.shift()`方法相结合来实现这一点：
- en: '[PRE19]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: There are now different numbers of observations for each return series as the
    forward shift has created missing values at the tail end for each equity.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 现在每个回报系列的观察次数不同，因为向前移位在每个股票的尾部创建了缺失值。
- en: Linear OLS regression using statsmodels
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用statsmodels进行线性OLS回归
- en: 'We can estimate a linear regression model using OLS with `statsmodels` as demonstrated
    previously. We select a forward return, for example for a 10-day holding period,
    remove outliers below the 2.5% and above the 97.5% percentiles, and fit the model
    accordingly:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`statsmodels`估计一个线性回归模型，如前面所示。例如，我们选择一个前瞻回报，比如10天的持有期，去除低于2.5%和高于97.5%百分位数的异常值，并相应地拟合模型：
- en: '[PRE20]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Diagnostic statistics
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 诊断统计
- en: The summary is available in the notebook to save some space due to the large
    number of variables. The diagnostic statistics show that, given the high p-value
    on the Jarque—Bera statistic, the hypothesis that the residuals are normally distributed
    cannot be rejected.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 由于变量数量较多，摘要可在笔记本中找到以节省空间。诊断统计数据显示，鉴于Jarque—Bera统计量的高p值，无法拒绝残差服从正态分布的假设。
- en: However, the Durbin—Watson statistic is low at 1.5 so we can reject the null
    hypothesis of no autocorrelation comfortably at the 5% level. Hence, the standard
    errors are likely positively correlated. If our goal were to understand which
    factors are significantly associated with forward returns, we would need to rerun
    the regression using robust standard errors (a parameter in `statsmodels .fit()`
    method), or use a different method altogether such as a panel model that allows
    for more complex error covariance.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，杜宾-沃森统计量为1.5，因此我们可以在5%的水平上舒适地拒绝无自相关的零假设。因此，标准误差可能呈正相关。如果我们的目标是了解哪些因素与未来收益显著相关，我们需要使用健壮标准误差重新运行回归（`statsmodels
    .fit()`方法中的一个参数），或者使用完全不同的方法，比如允许更复杂误差协方差的面板模型。
- en: Linear OLS regression using sklearn
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn进行线性OLS回归
- en: Since sklearn is tailored towards prediction, we will evaluate the linear regression
    model based on its predictive performance using cross-validation.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 由于sklearn专门针对预测，我们将根据其预测性能使用交叉验证评估线性回归模型。
- en: Custom time series cross-validation
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义时间序列交叉验证
- en: Our data consists of grouped time series data that requires a custom cross-validation
    function to provide the train and test indices that ensure that the test data
    immediately follows the training data for each equity and we do not inadvertently
    create a look-ahead bias or leakage.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据包括分组的时间序列数据，需要一个自定义交叉验证函数来提供确保测试数据紧随每个股票的训练数据的训练和测试索引，并且我们不会无意中创建前瞻性偏差或泄漏。
- en: 'We can achieve this using the following function that returns a `generator` yielding
    pairs of train and test dates. The set of train dates that ensure a minimum length
    of the training periods. The number of pairs depends on the parameter `nfolds`. The
    distinct test periods do not overlap and are located at the end of the period
    available in the data. After a test period is used, it becomes part of the training
    data that grow in size accordingly:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下函数实现这一点，该函数返回一个`generator`，产生一对训练和测试日期。训练日期集确保训练期的最小长度。一对的数量取决于参数`nfolds`。不同的测试期不重叠，并位于数据中可用的期末。使用测试期后，它将成为相应增长长度的训练数据的一部分：
- en: '[PRE21]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Select features and target
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择特征和目标
- en: 'We need to select the appropriate return series (we will again use a 10-day
    holding period) and remove outliers. We will also convert returns to log returns
    as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要选择适当的收益序列（我们将再次使用10天持有期）并去除异常值。我们还将将收益转换为对数收益如下：
- en: '[PRE22]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Cross-validating the model
  id: totrans-276
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证模型
- en: 'We will use 250 folds to generally predict about 2 days of forward returns
    following the historical training data that will gradually increase in length.
    Each iteration obtains the appropriate training and test dates from our custom
    cross-validation function, selects the corresponding features and targets, and
    then trains and predicts accordingly. We capture the root mean squared error as
    well as the Spearman rank correlation between actual and predicted values:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用250个折叠来通常预测大约2天的未来收益，遵循逐渐增加长度的历史训练数据。每次迭代都从我们的自定义交叉验证函数中获取适当的训练和测试日期，选择相应的特征和目标，然后进行训练和预测。我们捕获了均方根误差以及实际值和预测值之间的Spearman秩相关：
- en: '[PRE23]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Test results – information coefficient and RMSE
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试结果-信息系数和RMSE
- en: 'We have captured the test predictions from the 250 folds and can compute both
    the overall and a 21-day rolling average:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经从250个折叠中捕获了测试预测，并可以计算整体和21天滚动平均值：
- en: '[PRE24]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We obtain the following chart that highlights the negative correlation of IC
    and RMSE and their respective values:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 我们获得了以下图表，突出显示了IC和RMSE的负相关以及它们各自的值：
- en: '![](img/f2f699e8-ecac-49db-b305-7af3946654b3.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f2f699e8-ecac-49db-b305-7af3946654b3.png)'
- en: Chart highlighting the negative correlation of IC and RMSE
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 突出显示IC和RMSE的负相关的图表
- en: 'For the entire period, we see that the Information Coefficient measured by
    the rank correlation of actual and predicted returns is weakly positive and statistically
    significant:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 对于整个期间，我们看到通过实际和预测收益的秩相关测得的信息系数是微弱的正值且具有统计学意义：
- en: '![](img/33da13e6-51b6-4893-a3da-9a25c2f4dee5.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![](img/33da13e6-51b6-4893-a3da-9a25c2f4dee5.png)'
- en: Ridge regression using sklearn
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn进行岭回归
- en: For the ridge regression, we need to tune the regularization parameter with
    the keyword `alpha` that corresponds to the λ we used previously. We will try
    21 values from 10^(-5) to 10⁵ in logarithmic steps.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于岭回归，我们需要使用关键字`alpha`来调整正则化参数，该参数对应于我们之前使用的λ。我们将尝试从10^(-5)到10⁵的对数步长中的21个值。
- en: The scale sensitivity of the ridge penalty requires us to standardize the inputs
    using the `StandardScaler`. Note that we always learn the mean and the standard
    deviation from the training set using the `.fit_transform()` method and then apply
    these learned parameters to the test set using the `.transform()` method.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 岭惩罚的尺度敏感性要求我们使用`StandardScaler`对输入进行标准化。请注意，我们总是使用`.fit_transform()`方法从训练集中学习均值和标准差，然后使用这些学习到的参数在测试集上使用`.transform()`方法。
- en: Tuning the regularization parameters using cross-validation
  id: totrans-290
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用交叉验证调整正则化参数
- en: 'We then proceed to cross-validate the hyperparameter values again using `250`
    folds as follows:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们再次使用`250`个折叠交叉验证超参数值如下：
- en: '[PRE25]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-293
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭系数路径
- en: 'We can now plot the information coefficient obtained for each hyperparameter
    value and also visualize how the coefficient values evolve as the regularization
    increases. The results show that we get the highest IC value for a value of λ=10\.
    For this level of regularization, the right-hand panel reveals that the coefficients
    have been already significantly shrunk compared to the (almost) unconstrained
    model with *λ=10^(-5)*:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以绘制每个超参数值获得的信息系数，并可视化系数值随着正则化增加而发展的情况。结果显示，我们在*λ=10*的值获得了最高的IC值。对于这种正则化水平，右侧面板显示，与*λ=10^(-5)*的（几乎）无约束模型相比，系数已经显著收缩：
- en: '![](img/83c16cfe-0936-4705-a073-fa1849cd7d82.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![](img/83c16cfe-0936-4705-a073-fa1849cd7d82.png)'
- en: Cross-validation results and ridge coefficient paths
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证结果和岭系数路径
- en: Top 10 coefficients
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前10个系数
- en: 'The standardization of the coefficients allows us to draw conclusions about
    their relative importance by comparing their absolute magnitude. The 10 most relevant
    coefficients are:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 系数的标准化使我们能够通过比较它们的绝对大小来得出关于它们相对重要性的结论。最相关的10个系数是：
- en: '![](img/36b556ea-a0b2-46e1-b01a-ac2185ac20df.png)'
  id: totrans-299
  prefs: []
  type: TYPE_IMG
  zh: '![](img/36b556ea-a0b2-46e1-b01a-ac2185ac20df.png)'
- en: Top 10 coefficients
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 前10个系数
- en: Lasso regression using sklearn
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn的Lasso回归
- en: 'The lasso implementation looks very similar to the ridge model we just ran.
    The main difference is that lasso needs to arrive at a solution using iterative
    coordinate descent whereas ridge can rely on a closed-form solution:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: Lasso实现看起来与我们刚刚运行的岭模型非常相似。主要区别在于，Lasso需要使用迭代坐标下降来达到解决方案，而岭可以依赖封闭形式的解决方案：
- en: '[PRE26]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Cross-validated information coefficient and Lasso Path
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉验证信息系数和Lasso路径
- en: 'As before, we can plot the average information coefficient for all test sets
    used during cross-validation. We see again that regularization improves the IC
    over the unconstrained model, delivering the best out-of-sample result at a level
    of *λ=10^(-5)*. The optimal regularization value is quite different from ridge
    regression because the penalty consists of the sum of the absolute, not the squared
    values of the relatively small coefficient values. We can also see that for this
    regularization level, the coefficients have been similarly shrunk, as in the ridge
    regression case:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前一样，我们可以绘制在交叉验证期间使用的所有测试集的平均信息系数。我们再次看到，正则化改善了无约束模型的IC，在*λ=10^(-5)*水平上提供了最佳的样本外结果。最佳的正则化数值与岭回归非常不同，因为惩罚包括相对较小系数值的绝对值之和，而不是平方值。我们还可以看到，在这种正则化水平下，系数已经被类似地收缩，就像岭回归的情况一样：
- en: '![](img/013530cc-20f7-463a-ac1d-354825bd10e3.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
  zh: '![](img/013530cc-20f7-463a-ac1d-354825bd10e3.png)'
- en: Cross-validated information coefficient and Lasso Path
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证信息系数和Lasso路径
- en: In sum, ridge and lasso will produce similar results. Ridge often computes faster,
    but lasso also yields continuous features subset selection by gradually reducing
    coefficients to zero, hence eliminating features.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，岭和Lasso将产生类似的结果。岭通常计算更快，但Lasso也通过逐渐将系数减少到零来产生连续特征子集选择，从而消除特征。
- en: Linear classification
  id: totrans-309
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性分类
- en: The linear regression model discussed so far assumes a quantitative response
    variable. In this section, we will focus on approaches to modeling qualitative
    output variables for inference and prediction, a process that is known as **classification**
    and that occurs even more frequently than regression in practice.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的线性回归模型假设了一个定量的响应变量。在本节中，我们将专注于对推断和预测的定性输出变量进行建模的方法，这个过程被称为**分类**，在实践中比回归更频繁地发生。
- en: Predicting a qualitative response for a data point is called **classifying**
    that observation because it involves assigning the observation to a category,
    or class. In practice, classification methods often predict probabilities for
    each of the categories of a qualitative variable and then use this probability
    to decide on the proper classification.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为数据点预测定性响应被称为**分类**该观察，因为它涉及将观察分配到一个类别或类别。在实践中，分类方法通常预测定性变量的每个类别的概率，然后使用这个概率来决定适当的分类。
- en: We could approach the classification problem ignoring the fact that the output
    variable assumes discrete values, and apply the linear regression model to try
    to predict a categorical output using multiple input variables. However, it is
    easy to construct examples where this method performs very poorly. Furthermore,
    it doesn't make intuitive sense for the model to produce values larger than 1
    or smaller than 0 when we know that *y ∈ [0, 1]*.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以忽略输出变量取离散值的事实来处理分类问题，并应用线性回归模型来尝试使用多个输入变量预测分类输出。然而，很容易构造出这种方法表现非常糟糕的例子。此外，当我们知道*y
    ∈ [0, 1]*时，模型产生大于1或小于0的值并不直观。
- en: There are many different classification techniques, or classifiers, that are
    available to predict a qualitative response. In this section, we will introduce
    the widely used logistic regression which is closely related to linear regression. We
    will address more complex methods in the following chapters, on generalized additive
    models that include decision trees and random forests, as well as gradient boosting
    machines and neural networks.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多不同的分类技术或分类器可用于预测定性响应。在本节中，我们将介绍广泛使用的逻辑回归，它与线性回归密切相关。在接下来的章节中，我们将介绍更复杂的方法，包括包括决策树和随机森林的广义加性模型，以及梯度提升机和神经网络。
- en: The logistic regression model
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑回归模型
- en: The logistic regression model arises from the desire to model the probabilities
    of the output classes given a function that is linear in *x*, just like the linear
    regression model, while at the same time ensuring that they sum to one and remain
    in the [0, 1] as we would expect from probabilities.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归模型源于希望对输出类的概率进行建模，给定一个在*x*中是线性的函数，就像线性回归模型一样，同时确保它们总和为1，并保持在[0, 1]的范围内，正如我们从概率中所期望的那样。
- en: In this section, we introduce the objective and functional form of the logistic
    regression model and describe the training method. We then illustrate how to use
    logistic regression for statistical inference with macro data using statsmodels,
    and how to predict price movements using the regularized logistic regression implemented
    by sklearn.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了逻辑回归模型的目标和函数形式，并描述了训练方法。然后，我们说明了如何使用statsmodels对宏观数据进行统计推断，并使用sklearn实现的正则化逻辑回归来预测价格走势。
- en: Objective function
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标函数
- en: 'For illustration, we''ll use the output variable y that takes on the value
    1 if a stock return is positive over a given time horizon d, and 0 otherwise:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，我们将使用输出变量y，如果股票回报在给定时间范围d内为正，则取值为1，否则为0：
- en: '![](img/959b63ca-ea20-4c97-bc7c-154d2341e74a.png)'
  id: totrans-319
  prefs: []
  type: TYPE_IMG
  zh: '![](img/959b63ca-ea20-4c97-bc7c-154d2341e74a.png)'
- en: 'We could easily extend y to three categories, where 0 and 2 reflect negative
    and positive price moves beyond a certain threshold, and 1 otherwise. Rather than
    modeling the output variable *y*, however, logistic regression models the probability
    that y belongs to either of the categories given a vector of alpha factors or
    features ![](img/90185215-12e0-4ea9-9ab1-2b277832e26c.png). In other words, the logistic
    regression models the probability that the stock price goes up, conditional on
    the values of the variables included in the model:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以很容易地将y扩展到三个类别，其中0和2反映了超出一定阈值的负面和正面价格变动，否则为1。然而，逻辑回归并不是对输出变量*y*进行建模，而是对给定一组alpha因子或特征![](img/90185215-12e0-4ea9-9ab1-2b277832e26c.png)的情况下*y*属于这些类别的概率进行建模。换句话说，逻辑回归模型了股价上涨的概率，条件是模型中包含的变量的值：
- en: '![](img/767f64a0-9327-4123-8a14-68b4aa0fab23.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
  zh: '![](img/767f64a0-9327-4123-8a14-68b4aa0fab23.png)'
- en: The logistic function
  id: totrans-322
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逻辑函数
- en: 'To prevent the model from producing values outside the [0, 1] interval, we
    must model *p(x)* using a function that only gives outputs between 0 and 1 over
    the entire domain of *x*. The logistic function meets this requirement and always
    produces an S-shaped curve (see notebook examples), and so, regardless of the
    value of X, we will obtain a sensible prediction:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止模型产生超出[0,1]区间的值，我们必须使用一个只在整个x的定义域上给出0和1之间输出的函数来建模*p(x)*。逻辑函数满足这一要求，并且始终产生S形曲线（请参见笔记本示例），因此，无论X的值如何，我们都将得到一个合理的预测：
- en: '![](img/5ca89660-1107-4c0a-a57d-adae0541bcee.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5ca89660-1107-4c0a-a57d-adae0541bcee.png)'
- en: 'Here, the vector *x* includes a 1 for the intercept captured by the first component
    of ![](img/5218aa4d-ecfa-4abb-970a-67b11c0c557a.png), ![](img/565b1832-0731-474d-8eb8-9ad248442204.png).
    We can transform this expression to isolate the part that looks like a linear
    regression to arrive at:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，向量*x*包括一个拦截项，由![](img/5218aa4d-ecfa-4abb-970a-67b11c0c557a.png)的第一个分量捕获，![](img/565b1832-0731-474d-8eb8-9ad248442204.png)。我们可以转换这个表达式，以隔离看起来像线性回归的部分，得到：
- en: '![](img/30e97c9b-97c4-44a5-a528-d1e54384d4bc.png)'
  id: totrans-326
  prefs: []
  type: TYPE_IMG
  zh: '![](img/30e97c9b-97c4-44a5-a528-d1e54384d4bc.png)'
- en: The quantity *p(x)/[1−p(x)]* is called the **odds**, an alternative way to express
    probabilities that may be familiar from gambling, and can take on any value odds
    between 0 and ∞, where low values also imply low probabilities and high values
    imply high probabilities.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 数量*p(x)/[1−p(x)]*被称为**赔率**，这是一种表达概率的替代方式，可能在赌博中很熟悉，并且可以在0到∞之间取任何值的赔率，其中低值也意味着低概率，高值意味着高概率。
- en: The logit is also called log-odds (since it is the logarithm of the odds). Hence,
    the logistic regression represents a logit that is linear in *x* and looks a lot
    like the preceding linear regression.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 对数几率也称为对数赔率（因为它是赔率的对数）。因此，逻辑回归表示一个在*x*中线性的对数，看起来很像前面的线性回归。
- en: Maximum likelihood estimation
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最大似然估计
- en: 'The coefficient vector ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) must
    be estimated using the available training data. Although we could use (non-linear)
    least squares to fit the logistic regression model, the more general method of
    maximum likelihood is preferred, since it has better statistical properties. As
    we have just discussed, the basic intuition behind using maximum likelihood to
    fit a logistic regression model is to seek estimates for ![](img/67a36c05-1101-4552-92e7-a069bab53116.png)
    such that the predicted probability ![](img/86fcfb37-c25d-4cbd-b39d-a72674162df0.png)
    corresponds as closely as possible to the actual outcome. In other words, we try
    to find ![](img/6754827d-5689-4136-b222-c162c910b0c7.png) such that these estimates
    yield a number close to 1 for all cases where the stock price went up, and a number
    close to 0 otherwise. More formally, we are seeking to maximize the likelihood
    function:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 必须使用可用的训练数据估计系数向量![](img/67a36c05-1101-4552-92e7-a069bab53116.png)。虽然我们可以使用（非线性）最小二乘法来拟合逻辑回归模型，但更一般的最大似然方法更受青睐，因为它具有更好的统计特性。正如我们刚才讨论的，使用最大似然来拟合逻辑回归模型的基本直觉是寻找![](img/67a36c05-1101-4552-92e7-a069bab53116.png)的估计值，使得预测概率![](img/86fcfb37-c25d-4cbd-b39d-a72674162df0.png)尽可能接近实际结果。换句话说，我们试图找到![](img/6754827d-5689-4136-b222-c162c910b0c7.png)，使得这些估计值在股价上涨的所有情况下产生接近1的数字，否则产生接近0的数字。更正式地说，我们正在寻求最大化似然函数：
- en: '![](img/9ee6262d-4015-4968-a752-11c1a87ef6ba.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9ee6262d-4015-4968-a752-11c1a87ef6ba.png)'
- en: 'It is easier to work with sums than with products, so let''s take logs on both
    sides to get the log-likelihood function and the corresponding definition of the
    logistic regression coefficients:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 使用求和比使用乘积更容易处理，因此让我们两边取对数，得到对数似然函数和逻辑回归系数的相应定义：
- en: '![](img/598f2e46-7876-403f-a502-2f045e6161e1.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![](img/598f2e46-7876-403f-a502-2f045e6161e1.png)'
- en: Maximizing this equation by setting the derivatives of ![](img/a4a91a01-a2c2-47a4-8ed3-a2ba2408d686.png) with
    respect to ![](img/67a36c05-1101-4552-92e7-a069bab53116.png) to zero yields p+1
    so-called score equations that are nonlinear in the parameters that can be solved
    using iterative numerical methods for the concave log-likelihood function.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将对![](img/a4a91a01-a2c2-47a4-8ed3-a2ba2408d686.png)对![](img/67a36c05-1101-4552-92e7-a069bab53116.png)的导数设为零来最大化这个方程，得到了p+1个所谓的得分方程，这些方程在参数中是非线性的，可以使用迭代数值方法来求解凹对数似然函数。
- en: How to conduct inference with statsmodels
  id: totrans-335
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用statsmodels进行推断
- en: We will illustrate how to use logistic regression with `statsmodels` based on
    a simple built-in dataset containing quarterly US macro data from 1959 – 2009
    (see the notebook `logistic_regression_macro_data.ipynb` for detail).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将演示如何使用`statsmodels`进行逻辑回归，基于一个包含1959年至2009年季度美国宏观数据的简单内置数据集（详细信息请参见笔记本`logistic_regression_macro_data.ipynb`）。
- en: 'The variables and their transformations are listed in the following table:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 变量及其转换列在下表中：
- en: '| **Variable** | **Description** | **Transformation** |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '| **变量** | **描述** | **转换** |'
- en: '| `realgdp` | Real gross domestic product | Annual Growth Rate |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '| `realgdp` | 实际国内生产总值 | 年增长率 |'
- en: '| `realcons` | Real personal consumption expenditures | Annual Growth Rate
    |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '| `realcons` | 实际个人消费支出 | 年增长率 |'
- en: '| `realinv` | Real gross private domestic investment | Annual Growth Rate |'
  id: totrans-341
  prefs: []
  type: TYPE_TB
  zh: '| `realinv` | 实际国内私人投资 | 年增长率 |'
- en: '| `realgovt` | Real federal expenditures and gross investment | Annual Growth
    Rate |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| `realgovt` | 实际联邦支出和总投资 | 年增长率 |'
- en: '| `realdpi` | Real private disposable income | Annual Growth Rate |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| `realdpi` | 实际私人可支配收入 | 年增长率 |'
- en: '| `m1` | M1 nominal money stock | Annual Growth Rate |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| `m1` | M1名义货币存量 | 年增长率 |'
- en: '| `tbilrate` | Monthly 3 treasury bill rate | Level |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| `tbilrate` | 月度3个国库券利率 | 水平 |'
- en: '| `unemp` | Seasonally adjusted unemployment rate (%) | Level |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| `unemp` | 季节性调整后的失业率（%） | 水平 |'
- en: '| `infl` | Inflation rate | Level |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| `infl` | 通货膨胀率 | 水平 |'
- en: '| `realint` | Real interest rate | Level |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| `realint` | 实际利率 | 水平 |'
- en: To obtain a binary target variable, we compute the 20-quarter rolling average
    of the annual growth rate of quarterly real GDP. We then assign 1 if current growth
    exceeds the moving average and 0 otherwise. Finally, we shift the indicator variables
    to align next quarter's outcome with the current quarter.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得二元目标变量，我们计算了季度实际GDP年增长率的20个季度滚动平均值。然后，如果当前增长超过移动平均值，则分配1，否则为0。最后，我们将指标变量移位，以使下一季度的结果与当前季度对齐。
- en: 'We use an intercept and convert the quarter values to dummy variables and train
    the logistic regression model as follows:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个截距，并将季度值转换为虚拟变量，并按以下方式训练逻辑回归模型：
- en: '[PRE27]'
  id: totrans-351
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'This produces the following summary for our model with 198 observations and
    13 variables, including intercept:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型总结了我们的模型，包括198个观察和13个变量，包括截距：
- en: '![](img/d8e2376b-b48e-4f53-8694-0f337f29b986.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8e2376b-b48e-4f53-8694-0f337f29b986.png)'
- en: Logit Regression results
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: Logit回归结果
- en: The summary indicates that the model has been trained using maximum likelihood
    and provides the maximized value of the log-likelihood function at -67.9.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 总结表明，该模型已经使用最大似然进行了训练，并提供了对数似然函数的最大化值为-67.9。
- en: The LL-Null value of -136.42 is the result of the maximized log-likelihood function
    when only an intercept is included. It forms the basis for the pseudo-R² statisticand
    the Log-**Likelihood Ratio** (**LLR**) test.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 当只包括截距时，LL-Null值为-136.42，这是最大化对数似然函数的结果。它构成了伪R²统计量和对数似然比（LLR）测试的基础。
- en: 'The pseudo-R^(2 )statistic is a substitute for the familiar R² available under
    least squares. It is computed based on the ratio of the maximized log-likelihood
    function for the null model m[0] and the full model m[1] as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 伪R²统计量是最小二乘法下可用的熟悉R²的替代品。它是基于空模型m[0]和完整模型m[1]的最大化对数似然函数的比率计算如下：
- en: '![](img/58c66c64-3260-4ce4-83a2-6ed4ec540c23.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![](img/58c66c64-3260-4ce4-83a2-6ed4ec540c23.png)'
- en: The values vary from 0 (when the model does not improve the likelihood) to 1
    where the model fits perfectly and the log-likelihood is maximized at 0\. Consequently,
    higher values indicate a better fit.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值从0（当模型不改善似然时）变化到1（当模型完全拟合时，对数似然最大化为1）。因此，较高的值表示更好的拟合。
- en: 'The LLR test generally compares a more restricted model and is computed as:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: LLR测试通常比较更受限制的模型，并计算如下：
- en: '![](img/0849e323-b0ee-4890-9cdd-9d93940804de.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0849e323-b0ee-4890-9cdd-9d93940804de.png)'
- en: The null hypothesis is that the restricted model performs better but the low
    p-value suggests that we can reject this hypothesis and prefer the full model
    over the null model. This is similar to the F-test for linear regression (where
    we can also use the LLR test when we estimate the model using MLE).
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 零假设是受限模型的表现更好，但低p值表明我们可以拒绝这一假设，更喜欢完整模型而不是空模型。这类似于线性回归的F检验（当我们使用MLE估计模型时，也可以使用LLR检验）。
- en: 'The z-statistic plays the same role as the t-statistic in the linear regression
    output and is equally computed as the ratio of the coefficient estimate and its
    standard error. The p-values also indicate the probability of observing the test
    statistic assuming the null hypothesis *H[0] : β = 0* that the population coefficient
    is zero. We can reject this hypothesis for the `intercept`, `realcons`, `realinv`,
    `realgovt`, `realdpi`, and `unemp`.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 'z统计量在线性回归输出中扮演与t统计量相同的角色，并且与系数估计和其标准误的比率一样计算。p值也指示了在假设空假设*H[0] : β = 0*下观察检验统计量的概率，即总体系数为零的概率。我们可以拒绝`intercept`，`realcons`，`realinv`，`realgovt`，`realdpi`和`unemp`的这一假设。'
- en: How to use logistic regression for prediction
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用逻辑回归进行预测
- en: The lasso L[1] penalty and the ridge L[2] penalty can both be used with logistic
    regression. They have the same shrinkage effect as we have just discussed, and
    the lasso can again be used for variable selection with any linear regression
    model.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: lasso L[1]惩罚和ridge L[2]惩罚都可以与逻辑回归一起使用。它们具有与我们刚刚讨论的相同的收缩效应，lasso可以再次用于任何线性回归模型的变量选择。
- en: Just as with linear regression, it is important to standardize the input variables
    as the regularized models are scale sensitive. The regularization hyperparameter
    also requires tuning using cross-validation as in the linear regression case.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 与线性回归一样，重要的是要对输入变量进行标准化，因为正则化模型对比例敏感。正则化超参数也需要使用交叉验证进行调整，就像线性回归的情况一样。
- en: How to predict price movements using sklearn
  id: totrans-367
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使用sklearn预测价格走势
- en: 'We continue the price prediction example but now we binarize the outcome variable
    so that it takes on the value 1 whenever the 10-day return is positive and 0 otherwise;
    see the notebook `logistic_regression.ipynb` in the sub directory `stock_price_prediction`:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续价格预测的例子，但现在我们将二值化结果变量，使其在10天回报为正时取值为1，否则为0；请参阅子目录`stock_price_prediction`中的笔记本`logistic_regression.ipynb`：
- en: '[PRE28]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'With this new categorical outcome variable, we can now train a logistic regression
    using the default L[2] regularization. For logistic regression, the regularization
    is formulated inversely to linear regression: higher values for λ imply less regularization
    and vice versa. We evaluate 11 parameter values using cross validation as follows:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个新的分类结果变量，我们现在可以使用默认的L[2]正则化来训练逻辑回归。对于逻辑回归，正则化的制定与线性回归相反：λ的值越高，意味着正则化越少，反之亦然。我们使用交叉验证评估11个参数值，如下所示：
- en: '[PRE29]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We then use the `roc_auc_score` discussed in the previous chapter to compare
    the predictive accuracy across the various regularization parameters:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用在上一章中讨论的`roc_auc_score`来比较各种正则化参数的预测准确性：
- en: '[PRE30]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can again plot the AUC result for the range of hyperparameter values alongside
    the coefficient path that shows the improvements in predictive accuracy as the
    coefficients are a bit shrunk at the optimal regularization value 10²:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以再次绘制AUC结果的超参数值范围，以及系数路径，显示在最佳正则化值10²处系数略微收缩时预测准确性的改善：
- en: '![](img/e2e88587-b9b2-4e2d-a204-712534c693d7.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e2e88587-b9b2-4e2d-a204-712534c693d7.png)'
- en: AUC and Logistic Ridge path
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: AUC和Logistic Ridge路径
- en: Summary
  id: totrans-377
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced the first machine learning models using the important
    baseline case of linear models for regression and classification. We explored
    the formulation of the objective functions for both tasks, learned about various
    training methods, and learned how to use the model for both inference and prediction.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了使用线性模型作为回归和分类的重要基线案例的第一个机器学习模型。我们探讨了两个任务的目标函数的制定，学习了各种训练方法，并学习了如何将模型用于推断和预测。
- en: We applied these new machine learning techniques to estimate linear factor models
    that are very useful to manage risks, assess new alpha factors, and attribute
    performance. We also applied linear regression and classification to accomplish
    the first predictive task of predicting stock returns in absolute and directional
    terms.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应用了这些新的机器学习技术来估计线性因子模型，这些模型对于管理风险、评估新的阿尔法因子和归因绩效非常有用。我们还应用线性回归和分类来完成第一个预测任务，即在绝对和方向性方面预测股票回报。
- en: In the next chapter, we will look at the important topic of linear time series
    models that are designed to capture serial correlation patterns in the univariate
    and multivariate case. We will also learn about new trading strategies as we explore
    pairs trading based on the concept of cointegration that captures dynamic correlation
    among two stock price series.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将研究重要的线性时间序列模型的主题，这些模型旨在捕捉单变量和多变量情况下的串行相关模式。我们还将学习关于基于协整概念的配对交易的新交易策略，该概念捕捉了两个股价序列之间的动态相关性。
