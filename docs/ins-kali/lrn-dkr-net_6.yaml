- en: 'Chapter 6. Next Generation Networking Stack for Docker: libnetwork'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。Docker的下一代网络堆栈：libnetwork
- en: 'In this chapter, we will learn about a new networking stack for Docker: libnetwork,
    which provides a pluggable architecture with a default implementation for single
    and multi-host virtual networking:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习关于Docker的新网络堆栈：libnetwork，它提供了一个可插拔的架构，具有单主机和多主机虚拟网络的默认实现：
- en: Introduction
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍
- en: Goal
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标
- en: Design
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计
- en: CNM objects
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNM对象
- en: CNM attributes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNM属性
- en: CNM lifecycle
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CNM生命周期
- en: Drivers
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动程序
- en: Bridge driver
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 桥接驱动程序
- en: Overlay network driver
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖网络驱动程序
- en: Using overlay network with Vagrant
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Vagrant进行覆盖网络
- en: Overlay network with Docker Machine and Docker Swarm
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Machine和Docker Swarm的覆盖网络
- en: Creating an overlay network manually and using it for containers
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手动创建覆盖网络并将其用于容器
- en: Container network interface
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器网络接口
- en: Calico's libnetwork driver
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico的libnetwork驱动程序
- en: Goal
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 目标
- en: 'libnetwork which is written in go language is a new way for connecting Docker
    containers. The aim is to provide a container network model that helps programmers
    and provides the abstraction of network libraries. The long-term goal of libnetwork
    is to follow the Docker and Linux philosophy to deliver modules that work independently.
    libnetwork has the aim to provide a composable need for networking in containers.
    It also aims to modularize the networking logic in Docker Engine and libcontainer
    into a single, reusable library by:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork是用go语言编写的，是连接Docker容器的新方法。其目标是提供一个容器网络模型，帮助程序员并提供网络库的抽象。libnetwork的长期目标是遵循Docker和Linux的哲学，提供独立工作的模块。libnetwork的目标是为容器提供网络的可组合需求。它还旨在通过以下方式将Docker
    Engine和libcontainer中的网络逻辑模块化为单一可重用库：
- en: Replacing the networking module of Docker Engine with libnetwork
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用libnetwork替换Docker Engine的网络模块
- en: Being a model that allows local and remote drivers to provide networking to
    containers
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为一个允许本地和远程驱动程序为容器提供网络的模型
- en: Providing a tool dnet for managing and testing libnetwork—still a work in progress
    (reference from [https://github.com/docker/libnetwork/issues/45](https://github.com/docker/libnetwork/issues/45)).
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供一个用于管理和测试libnetwork的工具dnet-仍在进行中的工作（参考自[https://github.com/docker/libnetwork/issues/45](https://github.com/docker/libnetwork/issues/45)）。
- en: Design
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计
- en: libnetwork implements a **container network model** (**CNM**). It formalizes
    the steps required to provide networking for containers, while providing an abstraction
    that can be used to support multiple network drivers. Its endpoint APIs are primarily
    used for managing the corresponding object and book-keeps them in order to provide
    a level of abstraction as required by the CNM model.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork实现了**容器网络模型**（**CNM**）。它规范了为容器提供网络所需的步骤，同时提供了一个抽象，可用于支持多个网络驱动程序。其端点API主要用于管理相应的对象，并对其进行簿记，以提供CNM模型所需的抽象级别。
- en: 'The CNM is built on three main components. The following figure shows the network
    sandbox model of libnetwork:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: CNM建立在三个主要组件上。下图显示了libnetwork的网络沙盒模型：
- en: '![Design](../images/00046.jpeg)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![设计](../images/00046.jpeg)'
- en: CNM objects
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNM对象
- en: Let's discuss the CNM objects in detail.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细讨论CNM对象。
- en: Sandbox
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 沙盒
- en: This contains the configuration of a container's network stack, which includes
    management of routing tables, the container's interface, and DNS settings. An
    implementation of a sandbox can be a Linux network namespace, a FreeBSD jail,
    or other similar concept. A sandbox may contain many endpoints from multiple networks.
    It also represents a container's network configuration such as IP-address, MAC
    address, and DNS entries. libnetwork makes use of the OS-specific parameters to
    populate the network configuration represented by sandbox. libnetwork provides
    a framework to implement sandbox in multiple operating systems. Netlink is used
    to manage the routing table in namespace, and currently two implementations of
    sandbox exist, `namespace_linux.go` and `configure_linux.go`, to uniquely identify
    the path on the host filesystem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这包含容器网络堆栈的配置，包括管理路由表、容器接口和DNS设置。沙箱的实现可以是Linux网络命名空间、FreeBSD监狱或其他类似的概念。一个沙箱可以包含来自多个网络的许多端点。它还表示容器的网络配置，如IP地址、MAC地址和DNS条目。libnetwork利用特定于操作系统的参数来填充沙箱所代表的网络配置。libnetwork提供了在多个操作系统中实现沙箱的框架。Netlink用于管理命名空间中的路由表，目前存在两种沙箱的实现，`namespace_linux.go`和`configure_linux.go`，以唯一标识主机文件系统上的路径。
- en: 'A sandbox is associated with a single Docker container. The following data
    structure shows the runtime elements of a sandbox:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 沙箱与单个Docker容器相关联。以下数据结构显示了沙箱的运行时元素：
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A new sandbox is instantiated from a network controller (which is explained
    in more detail later):'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 新的沙箱是从网络控制器实例化的（稍后将更详细地解释）。
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Endpoint
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 端点
- en: 'An endpoint joins a sandbox to the network and provides connectivity for services
    exposed by a container to the other containers deployed in the same network. It
    can be an internal port of Open vSwitch or a similar veth pair. An endpoint can
    belong to only one network but may only belong to one sandbox. An endpoint represents
    a service and provides various APIs to create and manage the endpoint. It has
    a global scope but gets attached to only one network, as shown in the following
    figure:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 端点将沙箱连接到网络，并为容器公开的服务提供与部署在同一网络中的其他容器的连接。它可以是Open vSwitch的内部端口或类似的veth对。一个端点只能属于一个网络，但可能只属于一个沙箱。端点代表一个服务，并提供各种API来创建和管理端点。它具有全局范围，但只附加到一个网络，如下图所示：
- en: '![Endpoint](../images/00047.jpeg)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![端点](../images/00047.jpeg)'
- en: 'An endpoint is specified by the following data structure:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 端点由以下数据结构指定：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: An endpoint is associated with a unique ID and name. It is attached to a network
    and a sandbox ID. It is also associated with an IPv4 and IPv6 address space. Each
    endpoint is associated with an `endpointInterface` struct.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 端点与唯一ID和名称相关联。它附加到网络和沙箱ID。它还与IPv4和IPv6地址空间相关联。每个端点都与`endpointInterface`结构相关联。
- en: Network
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络
- en: A network is a group of endpoints that are able to communicate with each other
    directly. It provides the required connectivity within the same host or multiple
    hosts, and whenever a network is created or updated, the corresponding driver
    is notified. An example is a VLAN or Linux bridge, which has a global scope within
    a cluster.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是能够直接相互通信的端点组。它在同一主机或多个主机之间提供所需的连接，并在创建或更新网络时通知相应的驱动程序。例如，VLAN或Linux桥，在集群中具有全局范围。
- en: 'Networks are controlled from a network controller, which we will discuss in
    the next section. Every network has a name, address space, ID, and network type:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 网络由网络控制器控制，我们将在下一节中讨论。每个网络都有名称、地址空间、ID和网络类型：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Network controller
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络控制器
- en: 'A network controller object provides APIs to create and manage a network object.
    It is an entry point in the libnetwork by binding a particular driver to a given
    network, and it supports multiple active drivers, both in-built and remote. Network
    controller allows users to bind a particular driver to a given network:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 网络控制器对象提供API来创建和管理网络对象。它是libnetwork中的入口点，通过将特定的驱动程序绑定到给定的网络，支持多个活动驱动程序，包括内置和远程驱动程序。网络控制器允许用户将特定的驱动程序绑定到给定的网络：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Each network controller has reference to the following:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每个网络控制器都引用以下内容：
- en: One or more drivers in the data structure driverTable
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构driverTable中有一个或多个驱动程序
- en: One or more sandboxes in the data structure
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据结构中有一个或多个沙盒
- en: DataStore
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储库
- en: ipamTable
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ipamTable
- en: 'The following figure shows how **Network Controller** sits between the **Docker
    Engine** and the containers and networks they are attached to:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了**网络控制器**如何位于**Docker引擎**和其连接的容器和网络之间：
- en: '![Network controller](../images/00048.jpeg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![网络控制器](../images/00048.jpeg)'
- en: CNM attributes
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNM属性
- en: 'There are two types of attributes, as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种类型的属性，如下：
- en: '**Options**: They are not end-user visible but are the key-value pairs of data
    to provide a flexible mechanism to pass driver-specific configuration from user
    to driver directly. libnetwork operates on the options only if the key matches
    a well-known label as a result value is picked up, which is represented by a generic
    object.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**选项**：它们对终端用户不可见，但是提供了一种灵活的机制，可以直接从用户传递驱动程序特定的配置数据的键值对。只有当键匹配一个众所周知的标签时，libnetwork才会处理选项，结果值被选中，这由一个通用对象表示。'
- en: '**Labels**: They are a subset of options that are end-user variables represented
    in the UI using the `–labels` option. Their main function is to perform driver-specific
    operations and they are passed from the UI.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：它们是选项的一个子集，是终端用户变量，使用`-labels`选项在UI中表示。它们的主要功能是执行特定于驱动程序的操作，并且它们从UI传递。'
- en: CNM lifecycle
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNM生命周期
- en: Consumers of the container network model interact through the CNM objects and
    its APIs to network the containers that they manage.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 容器网络模型的消费者通过CNM对象及其API进行交互，以网络管理他们管理的容器。
- en: Drivers register with network controller. Built-in drivers register inside of
    libnetwork, while remote drivers register with libnetwork via a plugin mechanism
    (WIP). Each driver handles a particular network type.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动程序在网络控制器中注册。内置驱动程序在libnetwork内部注册，而远程驱动程序通过插件机制（WIP）在libnetwork中注册。每个驱动程序处理特定的网络类型。
- en: A network controller object is created using the `libnetwork.New()` API to manage
    the allocation of networks and optionally configure a driver with driver-specific
    options.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`libnetwork.New()` API创建一个网络控制器对象来管理网络的分配，并可选择使用特定于驱动程序的选项配置驱动程序。
- en: The network is created using the controller's `NewNetwork()` API by providing
    a name and `networkType`. The `networkType` parameter helps to choose a corresponding
    driver and binds the created network to that driver. From this point, any operation
    on the network will be handled by that driver.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用控制器的`NewNetwork()` API通过提供名称和`networkType`来创建网络。`networkType`参数有助于选择相应的驱动程序，并将创建的网络绑定到该驱动程序。从这一点开始，对网络的任何操作都将由该驱动程序处理。
- en: The `controller.NewNetwork()` API also takes in optional options parameters
    that carry driver-specific options and labels, which the drivers can make use
    for its purpose.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '`controller.NewNetwork()` API还接受可选的选项参数，其中包含驱动程序特定的选项和标签，驱动程序可以用于其目的。'
- en: '`network.CreateEndpoint()` can be called to create a new endpoint in a given
    network. This API also accepts optional options parameters that vary with the
    driver.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`network.CreateEndpoint()`可以调用以在给定网络中创建新的端点。此API还接受可选的选项参数，这些参数随驱动程序而异。'
- en: Drivers will be called with `driver.CreateEndpoint` and it can choose to reserve
    IPv4/IPv6 addresses when an endpoint is created in a network. The driver will
    assign these addresses using the `InterfaceInfo` interface defined in the `driver`
    API. The IPv4/IPv6 addresses are needed to complete the endpoint as a service
    definition along with the ports the endpoint exposes. A service endpoint is a
    network address and the port number that the application container is listening
    on.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当在网络中创建端点时，将调用驱动程序的`driver.CreateEndpoint`，它可以选择在网络中创建端点时保留IPv4/IPv6地址。驱动程序将使用`driver`
    API中定义的`InterfaceInfo`接口来分配这些地址。IPv4/IPv6地址是完成端点作为服务定义所需的，以及端点公开的端口。服务端点是应用程序容器正在侦听的网络地址和端口号。
- en: '`endpoint.Join()` can be used to attach a container to an endpoint. The `Join`
    operation will create a sandbox if it doesn''t exist for that container. The drivers
    make use of the sandbox key to identify multiple endpoints attached to the same
    container.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`endpoint.Join()`可用于将容器附加到端点。`Join`操作将为该容器创建一个沙盒（如果不存在）。驱动程序利用沙盒键来标识附加到同一容器的多个端点。'
- en: There is a separate API to create an endpoint and another to join the endpoint.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个单独的API用于创建端点，另一个用于加入端点。
- en: An endpoint represents a service that is independent of the container. When
    an endpoint is created, it has resources reserved for the container to get attached
    to the endpoint later. It gives a consistent networking behavior.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 端点表示独立于容器的服务。创建端点时，为容器保留了资源，以便稍后附加到端点。这提供了一致的网络行为。
- en: '`endpoint.Leave()` is invoked when a container is stopped. The driver can clean
    up the states that it allocated during the `Join()` call. libnetwork will delete
    the sandbox when the last referencing endpoint leaves the network.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器停止时，将调用`endpoint.Leave()`。驱动程序可以清理在`Join()`调用期间分配的状态。当最后一个引用端点离开网络时，libnetwork将删除沙盒。
- en: libnetwork keeps holding on to IP addresses as long as the endpoint is still
    present. These will be reused when the container (or any container) joins again.
    It ensures that the container's resources are re-used when they are stopped and
    started again.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 只要端点仍然存在，libnetwork将继续持有IP地址。当容器（或任何容器）再次加入时，这些地址将被重用。这确保了在容器停止和重新启动时重用容器的资源。
- en: '`endpoint.Delete()` is used to delete an endpoint from a network. This results
    in deleting the endpoint and cleaning up the cached `sandbox.Info`.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`endpoint.Delete()`用于从网络中删除端点。这将导致删除端点并清理缓存的`sandbox.Info`。'
- en: '`network.Delete()` is used to delete a network. Delete is allowed if there
    are no endpoints attached to the network.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`network.Delete()`用于删除网络。如果没有端点附加到网络上，则允许删除。'
- en: Driver
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 驱动程序
- en: A driver owns a network and is responsible for making the network work and manages
    it. Network controller provides an API to configure the driver with specific labels/options
    that are not directly visible to the user but are transparent to libnetwork and
    can be handled by drivers directly. Drivers can be both in-built (such as bridge,
    host, or overlay) and remote (from plugin providers) to be deployed in various
    use cases and deployment scenarios.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动程序拥有一个网络，并负责使网络工作并管理它。网络控制器提供了一个API，用于使用特定标签/选项配置驱动程序，这些标签/选项对用户不可见，但对libnetwork透明，并且可以由驱动程序直接处理。驱动程序可以是内置的（如桥接、主机或覆盖）和远程的（来自插件提供者），可以部署在各种用例和部署场景中。
- en: 'The driver owns the network implementation and is responsible for managing
    it, including **IP Address Management (IPAM)**. The following figure explains
    the process:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动程序拥有网络实现，并负责管理它，包括**IP地址管理（IPAM）**。以下图解释了这个过程：
- en: '![Driver](../images/00049.jpeg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![Driver](../images/00049.jpeg)'
- en: 'The following are the in-built drivers:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是内置驱动程序：
- en: '**Null**: In order to provide backward compatibility with old `docker --net=none`,
    this option exists primarily in the case when no networking is required.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Null**：为了与旧的`docker --net=none`向后兼容，存在这个选项，主要是在不需要网络的情况下。'
- en: '**Bridge**: It provides a Linux-specific bridging implementation driver.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**桥**：它提供了一个特定于Linux的桥接实现驱动程序。'
- en: '**Overlay**: The overlay driver implements networking that can span multiple
    hosts network encapsulation such as VXLAN. We will be doing a deep-dive on two
    of its implementations: basic setup with Consul and Vagrant setup to deploy the
    overlay driver.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**覆盖**：覆盖驱动程序实现了可以跨多个主机网络封装的网络。我们将深入研究其中两种实现：与Consul的基本设置和使用Vagrant部署覆盖驱动程序的设置。'
- en: '**Remote**: It provides a means of supporting drivers over a remote transport
    and a specific driver can be written as per choice.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**远程**：它提供了一种支持远程传输的驱动程序的手段，可以根据选择编写特定的驱动程序。'
- en: Bridge driver
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 桥驱动程序
- en: 'A bridge driver represents a wrapper on a Linux bridge acting as a network
    for libcontainer. It creates a veth pair for each network created. One end is
    connected to the container and the other end is connected to the bridge. The following
    data structure represents a bridge network:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 桥驱动程序代表了一个在Linux桥上充当libcontainer网络的包装器。它为每个创建的网络创建一个veth对。一个端点连接到容器，另一个端点连接到桥。以下数据结构表示了一个桥接网络：
- en: '[PRE5]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Some of the actions performed in a bridge driver:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在桥驱动程序中执行的一些操作：
- en: Configuring IPTables
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置IPTables
- en: Managing IP forwarding
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理IP转发
- en: Managing Port Mapping
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理端口映射
- en: Enabling Bridge Net Filtering
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用桥网过滤
- en: Setting up IPv4 and IPv6 on the bridge
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在桥上设置IPv4和IPv6
- en: 'The following diagram shows how the network is represented using `docker0`
    and `veth` pairs to connect endpoints with the `docker0` bridge:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了如何使用`docker0`和`veth`对来表示网络，以连接端点和`docker0`桥：
- en: '![Bridge driver](../images/00050.jpeg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![桥驱动程序](../images/00050.jpeg)'
- en: Overlay network driver
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖网络驱动程序
- en: 'Overlay network in libnetwork uses VXLan along with a Linux bridge to create
    an overlaid address space. It supports multi-host networking:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: libnetwork中的覆盖网络使用VXLan和Linux桥来创建叠加的地址空间。它支持多主机网络：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Using overlay network with Vagrant
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Vagrant使用覆盖网络
- en: Overlay network is created between two containers, and VXLan tunnel connects
    the containers through a bridge.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖网络是在两个容器之间创建的，VXLan隧道通过桥接连接容器。
- en: Overlay network deployment Vagrant setup
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 覆盖网络部署Vagrant设置
- en: 'This setup has been deployed using the Docker experimental version, which keeps
    on updating regularly and might not support some of the features:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这个设置是使用Docker实验版本部署的，它会定期更新，可能不支持一些功能：
- en: 'Clone the official libnetwork repository and switch to the `docs` folder:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆官方的libnetwork存储库，并切换到`docs`文件夹：
- en: '[PRE7]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The Vagrant script pre-exists in the repository; we will deploy the three-node
    setup for our Docker overlay network driver testing by using the following command:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Vagrant脚本已经存在于存储库中；我们将使用以下命令为我们的Docker覆盖网络驱动程序测试部署三节点设置：
- en: '[PRE8]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can list the deployed machine by Vagrant as follows:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以按照Vagrant列出已部署的机器如下：
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The setup is complete thanks to the Vagrant script; now, we can SSH to the
    Docker hosts and start the testing containers:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 感谢Vagrant脚本，设置已经完成；现在，我们可以SSH到Docker主机并启动测试容器：
- en: '[PRE10]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can create a new Docker container, and inside the container we can list
    the contents of the `/etc/hosts` file in order to verify that it has the overlay
    bridge specification, which was previously deployed, and it automatically connects
    to it on the launch:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以创建一个新的Docker容器，在容器内部我们可以列出`/etc/hosts`文件的内容，以验证它是否具有先前部署的覆盖桥规范，并且在启动时自动连接到它：
- en: '[PRE11]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Similarly, we can create the Docker container in the other host `net-2` as well
    and can verify the working of the overlay network driver as both the containers
    will be able to ping each other in spite of being deployed on different hosts.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，我们也可以在另一个主机`net-2`中创建Docker容器，并验证覆盖网络驱动程序的工作，因为尽管部署在不同的主机上，但这两个容器都能够相互ping通。
- en: In the previous example, we started the Docker container with the default options
    and they got automatically added to a multi-host network of type overlay.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用默认选项启动了Docker容器，并且它们自动添加到了覆盖类型的多主机网络中。
- en: 'We can also creat a separate overlay bridge and add containers to it manually
    using the `--publish-service` option, which is part of Docker experimental:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以创建一个单独的覆盖桥，并使用`--publish-service`选项手动将容器添加到其中，该选项是Docker实验的一部分：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The second host will also see this network and we can create containers added
    to the overlay network in both of these hosts by using the following option in
    the Docker command:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个主机也将看到此网络，我们可以使用Docker命令中的以下选项在这两个主机中的覆盖网络中创建容器：
- en: '[PRE13]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We will be able to verify the working of the overlay driver as both the containers
    will be able to ping each other. Also, tools such as tcpdump, wireshark, smartsniff,
    and so on can be used to capture the vXLAN package.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将能够验证覆盖驱动程序的工作，因为这两个容器都能够相互ping通。此外，还可以使用tcpdump、wireshark、smartsniff等工具来捕获vXLAN数据包。
- en: Overlay network with Docker Machine and Docker Swarm
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Machine和Docker Swarm创建覆盖网络
- en: 'This section explains the basics of creating a multi-host network. The Docker
    Engine supports multi-host networking through the overlay network driver. Overlay
    drivers need the following pre-requisites to work:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了创建多主机网络的基础知识。Docker引擎通过覆盖网络驱动程序支持多主机网络。覆盖驱动程序需要以下先决条件才能工作：
- en: 3.16 Linux kernel or higher
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3.16 Linux内核或更高版本
- en: Access to a key-value store
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问键值存储
- en: 'Docker supports the following key-value stores: Consul, etcd, and ZooKeeper'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker支持以下键值存储：Consul、etcd和ZooKeeper
- en: A cluster of hosts connected to the key-value store
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接到键值存储的主机集群
- en: Docker Engine daemon on each host in the cluster
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群中每个主机上的Docker引擎守护程序
- en: This example uses Docker Machine and Docker Swarm to create the multi-network
    host.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 此示例使用Docker Machine和Docker Swarm来创建多网络主机。
- en: Docker Machine is used to create the key-value store server and the cluster.
    The cluster created is a Docker Swarm cluster.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Machine用于创建键值存储服务器和集群。创建的集群是Docker Swarm集群。
- en: 'The following diagram explains how three VMs are set up using Docker Machine:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图解释了如何使用Docker Machine设置三个虚拟机：
- en: '![Overlay network with Docker Machine and Docker Swarm](../images/00051.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker Machine和Docker Swarm创建覆盖网络](../images/00051.jpeg)'
- en: Prerequisites
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 先决条件
- en: Vagrant
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vagrant
- en: Docker Engine
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker引擎
- en: Docker Machine
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Machine
- en: Docker Swarm
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm
- en: Key-value store installation
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 键值存储安装
- en: An overlay network requires a key-value store. The key-value store stores information
    about the network state such as discovery, networks, endpoints, IP addresses,
    and so on. Docker supports various key-value stores such as Consul, etcd, and
    Zoo Keeper. This section has been implemented using Consul.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 覆盖网络需要一个键值存储。键值存储存储有关网络状态的信息，例如发现、网络、端点、IP地址等。Docker支持各种键值存储，如Consul、etcd和Zoo
    Keeper。本节已使用Consul实现。
- en: 'The following are the steps to install key-value store:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是安装键值存储的步骤：
- en: Provision a VirtualBox virtual machine called `mh-keystore`.
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建名为`mh-keystore`的VirtualBox虚拟机。
- en: 'When a new VM is provisioned, the process adds the Docker Engine to the host.
    Consul instance will be using the consul image from the Docker Hub account ([https://hub.docker.com/r/progrium/consul/](https://hub.docker.com/r/progrium/consul/)):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 当新的虚拟机被配置时，该过程会将Docker Engine添加到主机上。Consul实例将使用Docker Hub帐户中的consul镜像（[https://hub.docker.com/r/progrium/consul/](https://hub.docker.com/r/progrium/consul/)）：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Start the `progrium/consul` container created previously running on the `mh-keystore`
    virtual machine:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mh-keystore`虚拟机上启动先前创建的`progrium/consul`容器：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: A bash expansion `$(docker-machine config mh-keystore)` is used to pass the
    connection configuration to the Docker `run` command. The client starts a program
    from the `progrium/consul` image running in the `mh-keystore` machine. The container
    is called `consul` (flag `–h`) and is listening on port `8500` (you can choose
    any other port as well).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 使用bash扩展`$(docker-machine config mh-keystore)`将连接配置传递给Docker `run`命令。客户端从在`mh-keystore`机器中运行的`progrium/consul`镜像启动程序。容器名为`consul`（标志`-h`），并监听端口`8500`（您也可以选择任何其他端口）。
- en: 'Set the local environment to the `mh-keystore` virtual machine:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将本地环境设置为`mh-keystore`虚拟机：
- en: '[PRE16]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Execute the `docker ps` command to make sure the Consul container is up:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行`docker ps`命令，确保Consul容器已启动：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Create a Swarm cluster with two nodes
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建具有两个节点的Swarm集群
- en: In this step, we will use Docker Machine to provision two hosts for your network.
    We will create two virtual machines in VirtualBox. One of the machines will be
    Swarm master, which will be created first.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将使用Docker Machine为您的网络配置两个主机。我们将在VirtualBox中创建两个虚拟机。其中一个机器将是Swarm主节点，将首先创建。
- en: 'As each host is created, options for the overlay network driver will be passed
    to the Docker Engine using Swarm using the following steps:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 创建每个主机时，将使用覆盖网络驱动程序的选项通过Swarm传递给Docker Engine，具体步骤如下：
- en: 'Create a Swarm master virtual machine `mhs-demo0`:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个Swarm主节点虚拟机`mhs-demo0`：
- en: '[PRE18]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: At creation time, you supply the engine daemon with the `--cluster-store` option.
    This option tells the engine the location of the key-value store for the overlay
    network. The bash expansion `$(docker-machine ip mh-keystore)` resolves to the
    IP address of the Consul server you created in step 1 of the preceding section.
    The `--cluster-advertise` option advertises the machine on the network.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建时，您提供引擎守护程序`--cluster-store`选项。此选项告诉引擎覆盖网络的键值存储位置。bash扩展`$(docker-machine
    ip mh-keystore)`解析为您在前一节的第1步中创建的Consul服务器的IP地址。`--cluster-advertise`选项会在网络上宣传该机器。
- en: 'Create another virtual machine `mhs-demo1` and add it to the Docker Swarm cluster:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建另一个虚拟机`mhs-demo1`并将其添加到Docker Swarm集群：
- en: '[PRE19]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'List virtual machines using Docker Machine to confirm that they are all up
    and running:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Docker Machine列出虚拟机，以确认它们都已启动并运行：
- en: '[PRE20]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: At this point, virtual machines are running. We are ready to create a multi-host
    network for containers using these virtual machines.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，虚拟机正在运行。我们准备使用这些虚拟机为容器创建多主机网络。
- en: Creating an overlay network
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建覆盖网络
- en: 'The following command is used to create an overlay network:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令创建覆盖网络：
- en: '[PRE21]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We will only need to create the network on a single host in the Swarm cluster.
    We used the Swarm master but this command can run on any host in the Swarm cluster:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只需要在Swarm集群中的一个主机上创建网络。我们使用了Swarm主节点，但此命令可以在Swarm集群中的任何主机上运行：
- en: 'Check that the overlay network is running using the following command:'
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查覆盖网络是否正在运行，使用以下命令：
- en: '[PRE22]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Since we are using the Swarm master environment, we are able to see all the
    networks on all the Swarm agents: the default networks on each engine and the
    single overlay network. In this case, there are two engines running on `mhs-demo0`
    and `mhs-demo1`.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们正在使用Swarm主环境，我们能够看到所有Swarm代理上的所有网络：每个引擎上的默认网络和单个覆盖网络。在这种情况下，有两个引擎在`mhs-demo0`和`mhs-demo1`上运行。
- en: Each `NETWORK ID` is unique.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`NETWORK ID`都是唯一的。
- en: 'Switch to each Swarm agent in turn and list the networks:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 依次切换到每个Swarm代理并列出网络：
- en: '[PRE23]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Both agents report they have the `my-net` network with the overlay driver. We
    have a multi-host overlay network running.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 两个代理都报告它们具有使用覆盖驱动程序的`my-net`网络。我们有一个运行中的多主机覆盖网络。
- en: 'The following figure shows how two containers will have containers created
    and tied together using the overlay `my-net`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了如何使用覆盖`my-net`创建并连接两个容器：
- en: '![Creating an overlay network](../images/00052.jpeg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![创建覆盖网络](../images/00052.jpeg)'
- en: Creating containers using an overlay network
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用覆盖网络创建容器
- en: 'The following are the steps for creating containers using an overlay network:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用覆盖网络创建容器的步骤：
- en: 'Create a container `c0` on `mhs-demo0` and connect to the `my-net` network:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mhs-demo0`上创建一个名为`c0`的容器，并连接到`my-net`网络：
- en: '[PRE24]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Execute `ifconfig` to find the IPaddress of `c0`. In this case, it is `10.0.0.4`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`ifconfig`以查找`c0`的IP地址。在这种情况下，它是`10.0.0.4`：
- en: '[PRE25]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create a container, `c1` on `mhs-demo1,` and connect to the `my-net` network:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`mhs-demo1`上创建一个名为`c1`的容器，并连接到`my-net`网络：
- en: '[PRE26]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Execute `ifconfig` to find the IP address of `c1`. In this case, it is `10.0.0.3`:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行`ifconfig`以查找`c1`的IP地址。在这种情况下，它是`10.0.0.3`：
- en: '[PRE27]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Ping `c1` (`10.0.0.3`) from `c0` (`10.0.0.4`) and vice versa:'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从`c0`(`10.0.0.4`) ping `c1`(`10.0.0.3`)，反之亦然：
- en: '[PRE28]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Container network interface
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器网络接口
- en: '**Container network interface** (**CNI**) is a specification that defines how
    executable plugins can be used to configure network interfaces for Linux application
    containers. The official GitHub repository of CNI explains how a go library explains
    the implementing specification.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器网络接口**（**CNI**）是一个规范，定义了可执行插件如何用于配置Linux应用容器的网络接口。CNI的官方GitHub存储库解释了一个go库如何解释实施规范。'
- en: The container runtime first creates a new network namespace for the container
    in which it determines which network this container should belong to and which
    plugins to be executed. The network configuration is in the JSON format and defines
    on the container startup which plugin should be executed for the network. CNI
    is actually an evolving open source technology that is derived from the rkt networking
    protocol. Each CNI plugin is implemented as an executable and is invoked by a
    container management system, docker, or rkt.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 容器运行时首先为容器创建一个新的网络命名空间，在其中确定该容器应属于哪个网络以及应执行哪些插件。网络配置以JSON格式定义，并在容器启动时定义应为网络执行哪个插件。CNI实际上是一个源自rkt网络协议的不断发展的开源技术。每个CNI插件都被实现为可执行文件，并由容器管理系统、docker或rkt调用。
- en: After inserting the container in the network namespace, namely by attaching
    one end of a veth pair to a container and attaching the other end to a bridge,
    it then assigns an IP to the interface and sets up routes consistent with IP address
    management by invoking an appropriate IPAM plugin.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 将容器插入网络命名空间，即将veth对的一端连接到容器，将另一端连接到桥接，然后分配一个IP给接口，并通过调用适当的IPAM插件设置与IP地址管理一致的路由。
- en: The CNI model is currently used for the networking of kubelets in the Kubernetes
    model. Kubelets are the most important components of Kubernetes nodes, which takes
    the load of running containers on top of them.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: CNI模型目前用于Kubernetes模型中kubelet的网络。Kubelet是Kubernetes节点的最重要组件，负责在其上运行容器的负载。
- en: 'The package CNI for kubelet is defined in the following Kubernetes package:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet的CNI包定义在以下Kubernetes包中：
- en: '[PRE29]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'The following figure shows the CNI placement:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了CNI的放置：
- en: '![Container network interface](../images/00053.jpeg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![容器网络接口](../images/00053.jpeg)'
- en: CNI plugin
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CNI插件
- en: 'As per the official GitHub repository ([https://github.com/appc/cni](https://github.com/appc/cni)),
    the parameters that the CNI plugin need in order to add a container to the network
    are:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 根据官方GitHub存储库（[https://github.com/appc/cni](https://github.com/appc/cni)），CNI插件需要的参数以便将容器添加到网络中为：
- en: '**Version**: The version of CNI spec that the caller is using (container call
    invoking the plugin).'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本**：调用者使用的CNI规范的版本（调用插件的容器调用）。'
- en: '**Container ID**: This is optional, but recommended, and defines that there
    should be a unique ID across an administrative domain while the container is live.
    For example, the IPAM system may require that each container is allocated a unique
    ID so that it can be correlated properly to a container running in the background.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器ID**：这是可选的，但建议使用，并定义了容器在活动时在管理域中应该有一个唯一的ID。例如，IPAM系统可能要求为每个容器分配一个唯一的ID，以便可以正确地将其与后台运行的容器相关联。'
- en: '**Network namespace path**: This represents the path to the network namespace
    to be added, for example, `/proc/[pid]/ns/net` or a `bind-mount/link` to it.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络命名空间路径**：这表示要添加的网络命名空间的路径，例如`/proc/[pid]/ns/net`或`bind-mount/link`到它。'
- en: '**Network configuration**: It is the JSON document that describes a network
    to which a container can be joined and is explained in the following section.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络配置**：这是描述容器可以加入的网络的JSON文档，并在以下部分中进行了解释。'
- en: '**Extra arguments**: It allows granular configuration of CNI plugins on a per-container
    basis.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**额外参数**：它允许根据每个容器的需求对CNI插件进行细粒度配置。'
- en: '**Name of the interface inside the container**: It is the name that gets assigned
    to the container and complies with Linux restriction, which exists for interface
    names.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器内部接口的名称**：这是分配给容器的名称，并符合Linux对接口名称的限制。'
- en: 'The results achieved are as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 实现的结果如下：
- en: '**IPs assigned to the interface**: This is either an IPv4 address or an IPv6
    address assigned to the network as per requirements.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分配给接口的IP地址**：这是根据要求分配给网络的IPv4地址或IPv6地址。'
- en: '**List of DNS nameservers**: This is a priority-ordered address list of DNS
    name servers.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DNS名称服务器列表**：这是DNS名称服务器的优先顺序地址列表。'
- en: Network configuration
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络配置
- en: 'The network configuration is in the JSON format that can be stored on disk
    or generated from other sources by container runtime. The following fields in
    the JSON have importance, as explained in the following:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 网络配置以JSON格式呈现，可以存储在磁盘上或由容器运行时从其他来源生成。以下JSON中的字段很重要，如下所述：
- en: '**cniVersion (string)**: It is Semantic Version 2.0 of the CNI specification
    to which this configuration meets.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**cniVersion（字符串）**：这是此配置符合的CNI规范的语义版本2.0。'
- en: '**name (string)**: It is the network name. It is unique across all containers
    on the host (or other administrative domain).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**name（字符串）**：这是网络名称。它在主机（或其他管理域）上的所有容器中是唯一的。'
- en: '**type (string)**: Refers to the filename of the CNI plugin executable.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**type（字符串）**：指的是CNI插件可执行文件的文件名。'
- en: '**ipMasq (boolean)**: Optional, sets up an IP masquerade on the host as it
    is necessary for the host to act as a gateway to subnets that are not able to
    route to the IP assigned to the container.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ipMasq（布尔值）**：可选，设置主机上的IP伪装，因为主机需要作为无法路由到容器分配的IP的子网的网关。'
- en: '**ipam**: Dictionary with IPAM-specific values.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ipam**：具有IPAM特定值的字典。'
- en: '**type (string)**: Refers to the filename of the IPAM plugin executable.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**type（字符串）**：指的是IPAM插件可执行文件的文件名。'
- en: '**routes (list)**: List of subnets (in CIDR notation) that the CNI plugin should
    make sure are reachable by routing through the network. Each entry is a dictionary
    containing:'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**routes（列表）**：CNI插件应确保通过网络路由可达的子网列表（以CIDR表示）。每个条目都是包含的字典：'
- en: '**dst (string)**: A subnet in CIDR notation'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**dst（字符串）**：CIDR表示法中的子网'
- en: '**gw (string)**: It is the IP address of the gateway to use. If not specified,
    the default gateway for the subnet is assumed (as determined by the IPAM plugin).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**gw（字符串）**：要使用的网关的IP地址。如果未指定，则假定子网的默认网关（由IPAM插件确定）。'
- en: 'An example configuration for plugin-specific OVS is as follows:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 插件特定OVS的示例配置如下：
- en: '[PRE30]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: IP allocation
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IP分配
- en: The CNI plugin assigns an IP address to the interface and installs necessary
    routes for the interface, thus it provides great flexibility for the CNI plugin
    and many CNI plugins internally have the same code to support several IP management
    schemes.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: CNI插件为接口分配IP地址并为接口安装必要的路由，因此它为CNI插件提供了很大的灵活性，并且许多CNI插件在内部具有支持多种IP管理方案的相同代码。
- en: To lessen the burden on the CNI plugin, a second type of plugin, **IP address
    management plugin** (**IPAM**), is defined, which determines the interface IP/subnet,
    gateway, and routes and returns this information to the main plugin to apply.
    The IPAM plugin obtains information via a protocol, `ipam` section defined in
    the network configuration file, or data stored on the local filesystem.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻CNI插件的负担，定义了第二种类型的插件，**IP地址管理插件**（**IPAM**），它确定接口IP/子网、网关和路由，并将此信息返回给主要插件以应用。
    IPAM插件通过网络配置文件中定义的`ipam`部分或存储在本地文件系统上的数据获取信息。
- en: IP address management interface
  id: totrans-217
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IP地址管理界面
- en: The IPAM plugin is invoked by running an executable, which is searched in a
    predefined path and is indicated by a CNI plugin via `CNI_PATH`. The IPAM plugin
    receives all the system environment variables from this executable, which are
    passed to the CNI plugin.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: IPAM插件通过运行可执行文件来调用，该文件在预定义路径中搜索，并由CNI插件通过`CNI_PATH`指示。 IPAM插件从此可执行文件接收所有系统环境变量，这些变量传递给CNI插件。
- en: 'IPAM receives a network configuration file via stdin. Success is indicated
    by a zero return code and the following JSON, which gets printed to stdout (in
    the case of the `ADD` command):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: IPAM通过stdin接收网络配置文件。成功的指示是零返回代码和以下JSON，它被打印到stdout（在`ADD`命令的情况下）：
- en: '[PRE31]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The following is an example of running Docker networking with CNI:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用CNI运行Docker网络的示例：
- en: 'First, install Go Lang 1.4+ and jq (command line JSON processor) to build the
    CNI plugins:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，安装Go Lang 1.4+和jq（命令行JSON处理器）以构建CNI插件：
- en: '[PRE32]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Clone the official CNI GitHub repository:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆官方CNI GitHub存储库：
- en: '[PRE33]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We will now create a `netconf` file in order to describe the network:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将创建一个`netconf`文件，以描述网络：
- en: '[PRE34]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Build the CNI plugins:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建CNI插件：
- en: '[PRE35]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now we will execute the `priv-net-run.sh` script in order to create the private
    network with the CNI plugin:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们将执行`priv-net-run.sh`脚本，以创建带有CNI插件的私有网络：
- en: '[PRE36]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Run a Docker container with the network namespace, which was set up previously
    using the CNI plugin:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用之前使用CNI插件设置的网络命名空间运行Docker容器：
- en: '[PRE37]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Project Calico's libnetwork driver
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Project Calico的libnetwork驱动程序
- en: Calico provides a scalable networking solution for connecting containers, VMs,
    or bare metal. Calico provides connectivity using the scalable IP networking principle
    as a layer 3 approach. Calico can be deployed without overlays or encapsulation.
    The Calico service should be deployed as a container on each node and provides
    each container with its own IP address. It also handles all the necessary IP routing,
    security policy rules, and distribution of routes across a cluster of nodes.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Calico为连接容器、虚拟机或裸金属提供可扩展的网络解决方案。 Calico使用可扩展的IP网络原则作为第3层方法提供连接。 Calico可以在不使用覆盖或封装的情况下部署。
    Calico服务应该作为每个节点上的一个容器部署，并为每个容器提供其自己的IP地址。 它还处理所有必要的IP路由、安全策略规则和在节点集群中分发路由。
- en: 'The Calico architecture contains four important components in order to provide
    a better networking solution:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Calico架构包含四个重要组件，以提供更好的网络解决方案：
- en: Felix, the Calico worker process, is the heart of Calico networking, which primarily
    routes and provides desired connectivity to and from the workloads on host. It
    also provides the interface to kernels for outgoing endpoint traffic.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Felix，Calico工作进程，是Calico网络的核心，主要路由并提供所需的连接到主机上的工作负载。 它还为出站端点流量提供内核接口。
- en: BIRD, the route distribution open source BGP, exchanges routing information
    between hosts. The kernel endpoints, which are picked up by BIRD, are distributed
    to BGP peers in order to provide inter-host routing. Two BIRD processes run in
    the calico-node container, IPv4 (bird) and one for IPv6 (bird6).
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BIRD，路由分发开源BGP，交换主机之间的路由信息。 BIRD捕获的内核端点分布给BGP对等体，以提供主机之间的路由。 calico-node容器中运行两个BIRD进程，一个用于IPv4（bird），一个用于IPv6（bird6）。
- en: Confd, a templating process to auto-generate configuration for BIRD, monitors
    the etcd store for any changes to BGP configuration such as log levels and IPAM
    information. Confd also dynamically generates BIRD configuration files based on
    data from etcd and triggers automatically as updates are applied to data. Confd
    triggers BIRD to load new files whenever a configuration file is changed.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Confd，一个模板化进程，用于自动生成BIRD的配置，监视etcd存储中对BGP配置的任何更改，如日志级别和IPAM信息。 Confd还根据etcd中的数据动态生成BIRD配置文件，并在数据应用更新时自动触发。
    Confd在配置文件更改时触发BIRD加载新文件。
- en: 'calicoctl, the command line used to configure and start the Calico service,
    even allows the datastore (etcd) to define and apply security policy. The tool
    also provides the simple interface for general management of Calico configuration
    irrespective of whether Calico is running on VMs, containers, or bare metal. The
    following commands are supported at calicoctl:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: calicoctl是用于配置和启动Calico服务的命令行工具，甚至允许数据存储（etcd）定义和应用安全策略。 该工具还提供了通用管理Calico配置的简单界面，无论Calico是在虚拟机、容器还是裸金属上运行。
    calicoctl支持以下命令：
- en: '[PRE38]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'As per the official GitHub page of the Calico repository ([https://github.com/projectcalico/calico-containers](https://github.com/projectcalico/calico-containers)),
    the following integration of Calico exists:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Calico存储库的官方GitHub页面（[https://github.com/projectcalico/calico-containers](https://github.com/projectcalico/calico-containers)），存在以下Calico集成：
- en: Calico as a Docker network plugin
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico作为Docker网络插件
- en: Calico without Docker networking
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不使用Docker网络的Calico
- en: Calico with Kubernetes
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Kubernetes
- en: Calico with Mesos
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Mesos
- en: Calico with Docker Swarm
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico与Docker Swarm
- en: 'The following figure shows the Calico architecture:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图显示了Calico架构：
- en: '![Project Calico''s libnetwork driver](../images/00054.jpeg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![Project Calico的libnetwork驱动程序](../images/00054.jpeg)'
- en: 'In the following tutorial we will run the manual set up of Calico on a single
    node machine with Docker 1.9, which finally brings libnetwork out of its experimental
    version to main release, and Calico can be configured directly without the need
    of other Docker experimental versions:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的教程中，我们将在单节点机器上运行Calico的手动设置，该机器使用Docker 1.9，这最终将libnetwork从实验版本带到主要发布版本，并且可以直接配置Calico，而无需其他Docker实验版本的需要：
- en: 'Get the etcd latest release and configure it on the default port 2379:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取etcd的最新版本并在默认端口2379上进行配置：
- en: '[PRE39]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Open the new terminal and configure the Docker daemon with the etcd key-value
    store by running the following commands:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开新的终端，并通过运行以下命令将Docker守护程序配置为etcd键值存储：
- en: '[PRE40]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Now, in the new terminal, start the Calico container in the following way:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在新的终端中，以以下方式启动Calico容器：
- en: '[PRE41]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Create the Calico bridge using the `docker network` command recently introduced
    in the Docker CLI:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用最近在Docker CLI中引入的`docker network`命令创建Calico桥接：
- en: '[PRE42]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Start the `busybox` container connected to the Calico `net1` bridge:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动连接到Calico `net1`桥接的`busybox`容器：
- en: '[PRE43]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Inside the container we can see that the container is now connected to the Calico
    bridge and can connect to the other containers deployed on the same bridge.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内部，我们可以看到容器现在连接到了Calico桥接，并且可以连接到同一桥接上部署的其他容器。
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we looked into some of the deeper and more conceptual aspects
    of Docker networking, one of them being libnetworking, the future Docker network
    model that is already getting into shape with the release of Docker 1.9\. While
    explaining libnetworking, we also studied the CNM model and its various objects
    and components with its implementation code snippets. Next, we looked into drivers
    of CNM, the prime one being the overlay driver, in detail, with deployment as
    part of the Vagrant setup. We also looked at the stand-alone integration of containers
    with the overlay network and as well with Docker Swarm and Docker Machine. In
    the next section, we explained about the CNI interface, its executable plugins,
    and a tutorial of configuring Docker networking with the CNI plugin.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们深入研究了Docker网络的一些更深层次和更概念性的方面之一，其中之一是libnetworking，这是未来的Docker网络模型，已经随着Docker
    1.9的发布而开始成形。在解释libnetworking的同时，我们还研究了CNM模型及其各种对象和组件以及其实现代码片段。接下来，我们详细研究了CNM的驱动程序，主要是覆盖驱动程序，并作为Vagrant设置的一部分进行部署。我们还研究了容器与覆盖网络的独立集成，以及与Docker
    Swarm和Docker Machine的集成。在接下来的部分中，我们解释了CNI接口、其可执行插件以及使用CNI插件配置Docker网络的教程。
- en: In the last section, project Calico is explained in detail, which provides a
    scalable networking solution based out of libnetwork and provides integration
    with Docker, Kubernetes, Mesos, bare-metal, and VMs primarily.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一节中，详细解释了Calico项目，它提供了一个基于libnetwork的可扩展网络解决方案，并与Docker、Kubernetes、Mesos、裸机和虚拟机进行集成。
