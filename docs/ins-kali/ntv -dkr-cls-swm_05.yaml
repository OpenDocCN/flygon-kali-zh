- en: Chapter 5. Administer a Swarm Cluster
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。管理Swarm集群
- en: We're now going to see how to administer a running Swarm cluster. We will discuss
    in detail topics such as scaling of cluster size (adding and removing nodes),
    updating the cluster and node information; handling the node status (promotion
    and demotion), troubleshooting, and graphical interfaces (UI).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看到如何管理运行中的Swarm集群。我们将详细讨论诸如扩展集群大小（添加和删除节点）、更新集群和节点信息；处理节点状态（晋升和降级）、故障排除和图形界面（UI）等主题。
- en: 'In this chapter, we will take a look at the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看一下以下主题：
- en: Docker Swarm standalone
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm独立
- en: Docker Swarm Mode
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm模式
- en: Cluster management
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群管理
- en: Swarm health
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm健康
- en: Graphical interfaces for Swarm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm的图形界面
- en: Docker Swarm standalone
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm独立
- en: In standalone mode, cluster operations need to be done directly inside the container
    `swarm`.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在独立模式下，集群操作需要直接在`swarm`容器内完成。
- en: In this chapter, we are not going to cover every option in detail. Swarm v1
    will be deprecated soon, as it has already been declared obsolete by Swarm Mode.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们不会详细介绍每个选项。Swarm v1很快将被弃用，因为Swarm模式已经被宣布为过时。
- en: '![Docker Swarm standalone](images/image_05_001.jpg)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![Docker Swarm独立模式](images/image_05_001.jpg)'
- en: 'The commands to administer a Docker Swarm standalone cluster are as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 管理Docker Swarm独立集群的命令如下：
- en: 'Create (`c`): As we saw in [Chapter 1](ch01.html "Chapter 1. Welcome to Docker
    Swarm"), *Welcome to Docker Swarm* this is how we can generate the UUID token,
    in case the token mechanism is going to be used. Typically, in production, people
    use Consul or Etcd, so this command has no relevance for production.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建（`c`）：正如我们在[第1章](ch01.html "第1章。欢迎来到Docker Swarm")中所看到的，*欢迎来到Docker Swarm*，这是我们生成UUID令牌的方式，以防令牌机制将被使用。通常，在生产环境中，人们使用Consul或Etcd，因此这个命令对生产环境没有相关性。
- en: 'List (`l`): This shows the list of cluster nodes based on an iteration through
    Consul or Etcd, that is, the Consul or Etcd must be passed as an argument.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列表（`l`）：这显示了基于对Consul或Etcd的迭代的集群节点列表，也就是说，Consul或Etcd必须作为参数传递。
- en: 'Join (`j`): Joins the node on which the swarm container is running to the cluster.
    Here, we need to pass a discovery mechanism at the command line.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加入（`j`）：将运行swarm容器的节点加入到集群中。在这里，我们需要在命令行中传递一个发现机制。
- en: 'Manage (`m`): This is the core of the Standalone mode. Managing a cluster deals
    with changing cluster properties, such as Filters, Schedulers, external CA URLs,
    and timeouts. We will talk more about the application of these options to Swarm
    mode in [Chapter 6](ch06.html "Chapter 6. Deploy Real Applications on Swarm"),
    *Deploy Real Applications on Swarm* when we''ll work with a real application deployment.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理（`m`）：这是独立模式的核心。管理集群涉及更改集群属性，例如过滤器、调度程序、外部CA URL和超时。当我们在[第6章](ch06.html "第6章。在Swarm上部署真实应用程序")中使用真实应用程序部署时，我们将更多地讨论这些选项在Swarm模式中的应用。
- en: Docker Swarm Mode
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm模式
- en: In this section, we will continue exploring Swarm Mode commands for managing
    a cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将继续探索Swarm模式命令，以管理集群。
- en: Manually adding nodes
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 手动添加节点
- en: You can choose to create new Swarm nodes, so Docker hosts, either way you prefer.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择创建新的Swarm节点，即Docker主机，无论您喜欢哪种方式。
- en: If Docker Machine is used, it will reach its limit very soon. You will have
    to be very patient while listing machines and wait for several seconds for Machine
    to get and print the information as a whole.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用Docker Machine，它很快就会达到极限。在列出机器时，您将不得不非常耐心地等待几秒钟，直到Machine获取并打印整个信息。
- en: 'A method to add nodes manually is to use Machine with the generic driver; so,
    delegate host provisioning (Operating System installation, network and security
    groups configurations, and so on) to something else (such as Ansible), and later
    exploit Machine to install Docker in a proper manner. This is how it can be done:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 手动添加节点的方法是使用通用驱动程序的Machine；因此，将主机配置（操作系统安装、网络和安全组配置等）委托给其他东西（比如Ansible），然后利用Machine以适当的方式安装Docker。这就是如何做到的：
- en: Manually configure the cloud environment (security groups, networks, and so
    on.)
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 手动配置云环境（安全组、网络等）。
- en: Provision Ubuntu hosts with a third party tool.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用第三方工具为Ubuntu主机提供支持。
- en: Run Machine with the generic driver on these hosts with the only goal to properly
    install Docker.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这些主机上使用通用驱动程序运行机器，唯一的目标是正确安装Docker。
- en: Manage hosts with the tool at part 2, or even others.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用第2部分的工具管理主机，甚至其他的。
- en: 'If you use Machine''s generic driver, it will select the latest stable Docker
    binaries. While working on this book, in order to use Docker 1.12, we sometimes
    overcame this by giving Machine the option to get the latest unstable version
    of Docker with the `--engine-install-url` option:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用Machine的通用驱动程序，它将选择最新稳定的Docker二进制文件。在撰写本书时，为了使用Docker 1.12，我们有时通过使用`--engine-install-url`选项，让Machine选择获取最新的不稳定版本的Docker：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: At the moment of reading this book, for a production Swarm (mode), 1.12 will
    be stable; so this trick will not be necessary anymore, unless you need to use
    some of the latest Docker features.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在阅读本书时，对于生产Swarm（模式），1.12将是稳定的；因此，除非你需要使用一些最新的Docker功能，否则这个技巧将不再必要。
- en: Managers
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理者
- en: While planning a Swarm, some considerations regarding the number of managers
    have to be kept in mind, as we saw in [Chapter 4](ch04.html "Chapter 4. Creating
    a Production-Grade Swarm"), *Creating a Production-Grade Swarm* . The theory of
    HA suggests that the number of managers must be odd and equal or more than 3\.
    To grant a quorum in high availability means that the majority of the nodes agree
    on the part of node that is leading the operations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划Swarm时，必须牢记一些关于管理者数量的考虑，正如我们在[第4章](ch04.html "第4章。创建生产级Swarm")中所看到的，*创建生产级Swarm*。高可用性的理论建议管理者数量必须是奇数，并且等于或大于3。为了在高可用性中获得法定人数，大多数节点必须同意领导操作的部分。
- en: If there are two managers and one goes down and comes back, it's possible that
    both will be considered leaders. This causes a logical crash in the cluster organization,
    which is called a split brain.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有两个管理者，其中一个宕机然后恢复，可能会导致两者都被视为领导者。这会导致集群组织中的逻辑崩溃，这被称为分裂脑。
- en: The more managers you have, the higher is the resistance ratio to failures.
    Take a look at the following table.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你拥有的管理者越多，对故障的抵抗比就越高。看一下下表。
- en: '| **Number of managers** | **Quorum (majority)** | **Maximum possible failures**
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| **管理者数量** | **法定人数（多数）** | **最大可能故障数** |'
- en: '| 3 | 2 | 1 |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 2 | 1 |'
- en: '| 5 | 3 | 2 |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 3 | 2 |'
- en: '| 7 | 4 | 3 |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 4 | 3 |'
- en: '| 9 | 5 | 4 |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 5 | 4 |'
- en: 'Also, in the Swarm Mode, an **ingress** overlay network is created automatically
    and associated to the nodes as ingress traffic. Its purpose is to be used with
    containers:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在Swarm模式下，**ingress**覆盖网络会自动创建，并与节点关联为入口流量。它的目的是与容器一起使用：
- en: '![Managers](images/image_05_002.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![管理者](images/image_05_002.jpg)'
- en: You will want your containers to be associated to an internal overlay (VxLAN
    meshed) network to communicate with each other, rather than using public or other
    external networks. Thus, Swarm creates this for you and it is ready to use.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你希望你的容器与内部覆盖（VxLAN meshed）网络关联，以便彼此通信，而不是使用公共或其他外部网络。因此，Swarm会为您创建这个网络，并且它已经准备好使用。
- en: Workers number
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作者数量
- en: You can add an arbitrary number of workers. This is the elastic part of the
    Swarm. It's totally fine to have 5, 15, 200, 2300, or 4700 running workers. This
    is the easiest part to handle; you can add and remove workers with no burdens,
    at any time, at any size.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以添加任意数量的工作节点。这是Swarm的弹性部分。拥有5、15、200、2300或4700个运行中的工作节点都是完全可以的。这是最容易处理的部分；您可以随时以任何规模添加和删除工作节点。
- en: Scripted nodes addition
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本化节点添加
- en: The easiest way to add nodes, if you plan to not go a 100-nodes total, is to
    use basic scripting.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您计划不超过100个节点，最简单的添加节点的方法是使用基本脚本。
- en: When executing `docker swarm init`, just copy-paste the lines printed as the
    output.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行`docker swarm init`时，只需复制粘贴输出的行。
- en: '![Scripted nodes addition](images/image_05_003.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![脚本化节点添加](images/image_05_003.jpg)'
- en: 'Then, create a certain bunch of workers with a loop:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，使用循环创建一组特定的工作节点：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After this, it will only be necessary to go through the list of machines, `ssh`
    into them and `join` the nodes:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，只需要浏览机器列表，`ssh`进入它们并`join`节点即可：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This script runs through the machines and for each, with a name starting with
    s`warm-worker-`, it will `ssh` into and join the node to the existing Swarm and
    to the leader manager, which is `172.31.10.250`.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本将遍历机器，并对于每个以`s`warm-worker-`开头的名称，它将`ssh`进入并将节点加入现有的Swarm和领导管理者，即`172.31.10.250`。
- en: Note
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 注意
- en: See [https://github.com/swarm2k/swarm2k/tree/master/amazonec2](https://github.com/swarm2k/swarm2k/tree/master/amazonec2)
    for further details or to download the one liners.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有关更多详细信息或下载一行命令，请参阅[https://github.com/swarm2k/swarm2k/tree/master/amazonec2](https://github.com/swarm2k/swarm2k/tree/master/amazonec2)。
- en: Belt
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Belt
- en: Belt is another variant for provisioning Docker Engines massively. It is basically
    a SSH wrapper on steroids and it requires you to prepare provider-specific images
    as well as provision templates before `go` massively. In this section, we'll learn
    how to do so.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Belt是用于大规模配置Docker Engines的另一种变体。它基本上是一个SSH包装器，需要您在`go`大规模之前准备提供程序特定的映像和配置模板。在本节中，我们将学习如何做到这一点。
- en: You can compile Belt yourself by getting its source from Github.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过从Github获取其源代码来自行编译Belt。
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Currently, Belt supports only the DigitalOcean driver. We can prepare our template
    for provisioning inside `config.yml`.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Belt仅支持DigitalOcean驱动程序。我们可以在`config.yml`中准备我们的配置模板。
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Then, we can create hundreds of nodes with a couple of commands.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以用几个命令创建数百个节点。
- en: First, we create three manager hosts of 16 GB each, namely `mg0`, `mg1`, and
    `mg2`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建三个管理主机，每个主机有16GB内存，分别是`mg0`，`mg1`和`mg2`。
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then we can use the `status` command to wait for all nodes being active:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以使用`status`命令等待所有节点都处于活动状态：
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We''ll do this again for 10 worker nodes:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将再次为10个工作节点执行此操作：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Use Ansible
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Ansible
- en: You can alternatively use Ansible (as I like, and it's becoming very popular)
    to make things more repeatable. We have created some Ansible modules to work with
    Machine and Swarm (Mode) directly; it is also compatible with Docker 1.12 ([https://github.com/fsoppelsa/ansible-swarm](https://github.com/fsoppelsa/ansible-swarm)).
    They require Ansible 2.2+, the very first version of Ansible that is compatible
    with binary modules.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用Ansible（我喜欢，而且它变得非常流行）来使事情更具重复性。我们已经创建了一些Ansible模块，可以直接与Machine和Swarm（Mode）一起使用；它还与Docker
    1.12兼容（[https://github.com/fsoppelsa/ansible-swarm](https://github.com/fsoppelsa/ansible-swarm)）。它们需要Ansible
    2.2+，这是与二进制模块兼容的第一个Ansible版本。
- en: You will need to compile the modules (written in `go`) and then pass them to
    the `ansible-playbook -M` parameter.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要编译这些模块（用`go`编写），然后将它们传递给`ansible-playbook -M`参数。
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: There are some example plays in playbooks. Ansible's plays syntax is so easy
    to understand that it is superfluous to even explain in detail.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: playbooks中有一些示例play。Ansible的plays语法非常容易理解，甚至不需要详细解释。
- en: 'I used this play to join 10 workers to the **Swarm2k** experiment:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用这个命令将10个工作节点加入到**Swarm2k**实验中：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Basically, it invokes the `docker_swarm` module after loading some host facts
    from Machine:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，它在加载一些主机信息后调用了`docker_swarm`模块：
- en: The operation done is `join`
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作是`join`
- en: The role of the new node is `worker`
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新节点的角色是`worker`
- en: The new node joins `tcp://104.236.78.154:2377`, which was the leader manager
    at the moment of joining. This argument takes an array of managers, such as [`tcp://104.236.78.154:2377`,
    `104.236.18.183:2377`, `tcp://104.236.87.10:2377`]
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新节点加入了`tcp://104.236.78.154:2377`，这是加入时的领导管理者。这个参数接受一个管理者数组，比如[`tcp://104.236.78.154:2377`,
    `104.236.18.183:2377`, `tcp://104.236.87.10:2377`]
- en: It passes the password `(secret)`
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它传递了密码`(secret)`
- en: It specifies some basic engine connection facts and the module will connect
    to the `dockerurl` using the certificates at `tlspath`.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它指定了一些基本的引擎连接事实，模块将使用`tlspath`上的证书连接到`dockerurl`。
- en: 'After the `docker_swarm.go` is compiled in the library, joining the workers
    to the Swarm is as easy as:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在库中编译了`docker_swarm.go`之后，将工作节点加入到Swarm就像这样简单：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![Use Ansible](images/image_05_004.jpg)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![使用Ansible](images/image_05_004.jpg)'
- en: Cluster management
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群管理
- en: 'To illustrate cluster operations better, let''s take a look at an example made
    up of three managers and ten workers. The first basic operation is listing nodes,
    with `docker node ls` command:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地说明集群操作，让我们看一个由三个管理者和十个工作节点组成的例子。第一个基本操作是列出节点，使用`docker node ls`命令：
- en: '![Cluster management](images/image_05_005.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![集群管理](images/image_05_005.jpg)'
- en: You can reference to the nodes by calling them either by their hostname (**manager1**)
    or by their ID (**ctv03nq6cjmbkc4v1tc644fsi**). The other columns in this list
    statement describes the properties of the cluster nodes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过主机名（**manager1**）或者ID（**ctv03nq6cjmbkc4v1tc644fsi**）来引用节点。列表中的其他列描述了集群节点的属性。
- en: '**STATUS** is about the physical reachability of the node. If the node is up,
    it''s Ready, otherwise it''s Down.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**状态**是节点的物理可达性。如果节点正常，它是就绪的，否则是下线的。'
- en: '**AVAILABILITY** is the node availability. A node state can either be Active
    (participating in the cluster operations), Pause (in standby, suspended, not accepting
    tasks), or Drain (waiting to be evacuated its tasks).'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性**是节点的可用性。节点状态可以是活动的（参与集群操作）、暂停的（待机，暂停，不接受任务）或者排空的（等待被排空任务）。'
- en: '**MANAGER STATUS** is the current status of manager. If a node is not the manager,
    this field will be empty. If a node is manager, this field can either be Reachable
    (one of the managers present to guarantee high availability) or Leader (the host
    leading all operations).![Cluster management](images/image_05_006.jpg)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理状态**是管理者的当前状态。如果一个节点不是管理者，这个字段将为空。如果一个节点是管理者，这个字段可以是可达的（保证高可用性的管理者之一）或者领导者（领导所有操作的主机）。![集群管理](images/image_05_006.jpg)'
- en: Nodes operations
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点操作
- en: The `docker node` command comes with a few possible options.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker node`命令有一些可能的选项。'
- en: '![Nodes operations](images/image_05_007.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![节点操作](images/image_05_007.jpg)'
- en: As you see, you have all the possible commands for nodes management, but `create`.
    We are often asked when a create option will be added to the `node` command, but
    there is still no answer.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，你有所有可能的节点管理命令，但没有`create`。我们经常被问到`node`命令何时会添加`create`选项，但目前还没有答案。
- en: So far, create new nodes is a manual operation and the responsibility of cluster
    operators.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，创建新节点是一个手动操作，是集群操作员的责任。
- en: Demotion and promotion
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 降级和晋升
- en: Promotion is possible for worker nodes (transforming them into managers), while
    demotion is possible for manager nodes (transforming them into workers).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点可以晋升为管理节点，而管理节点可以降级为工作节点。
- en: Always remember the table to guarantee high availability when managing the a
    lot of managers and workers (odd number, more than or equal to three).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理大量管理者和工作者（奇数，大于或等于三）时，始终记住表格以确保高可用性。
- en: 'Use the following syntax to `promote worker0` and `worker1` to managers:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下语法将`worker0`和`worker1`提升为管理者：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: There is nothing magical behind the curtain. Just, Swarm attempts to change
    the node role with on-the-fly instructions.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 幕后没有什么神奇的。只是，Swarm试图通过即时指令改变节点角色。
- en: '![Demotion and promotion](images/image_05_008.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![降级和晋升](images/image_05_008.jpg)'
- en: Demote is the same (docker node demote **worker1**). But be careful to avoid
    accidentally demoting the node you're working from, otherwise you'll get locked
    out.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 降级是一样的（docker node demote **worker1**）。但要小心，避免意外降级您正在使用的节点，否则您将被锁定。
- en: And finally, what happens if you try to demote a Leader manager? In this case,
    the Raft algorithm will start an election and a new leader will be selected among
    the active managers.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您尝试降级领导管理者会发生什么？在这种情况下，Raft算法将开始选举，并且新的领导者将在活动管理者中选择。
- en: Tagging nodes
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 给节点打标签
- en: You may have noticed, in the preceding screenshot, that **worker9** is in **Drain**
    availability. This means that the node is in the process of evacuating its tasks
    (if any), which will be rescheduled somewhere else on the cluster.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，在前面的屏幕截图中，**worker9**处于**排水**状态。这意味着该节点正在疏散其任务（如果有的话），这些任务将在集群的其他地方重新安排。
- en: 'You can change node availability by updating its status, using `docker node
    update` command:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过使用`docker node update`命令来更改节点的可用性状态：
- en: '![Tagging nodes](images/image_05_009.jpg)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![给节点打标签](images/image_05_009.jpg)'
- en: The availability option can be either `active`, `pause`, or `drain`. Here we
    just restored **worker9** to the active state.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 可用性选项可以是`活动`、`暂停`或`排水`。在这里，我们只是将**worker9**恢复到了活动状态。
- en: The `active` state means that the node is running and ready to accept tasks
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`活动`状态意味着节点正在运行并准备接受任务'
- en: The `pause` state means that the node is running, but not accepting tasks
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`暂停`状态意味着节点正在运行，但不接受任务'
- en: The `drain` state means that the node is running and not accepting tasks, but
    its currently draining its tasks that are getting rescheduled somewhere else
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`排水`状态意味着节点正在运行并且不接受任务，但它目前正在疏散其任务，这些任务正在被重新安排到其他地方。'
- en: Another powerful update argument is about labels. There are `--label-add` and
    `--label-rm` that allow us to add labels to Swarm nodes, respectively.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个强大的更新参数是关于标签。有`--label-add`和`--label-rm`，分别允许我们向Swarm节点添加标签。
- en: Docker Swarm labels do not affect the Engine labels. It's possible to specify
    labels when starting the Docker Engine (`dockerd [...] --label "staging" --label
    "dev" [...]`). But Swarm has no power to edit or change them. Labels we see here
    only affect the Swarm behavior.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm标签不影响引擎标签。在启动Docker引擎时可以指定标签（`dockerd [...] --label "staging" --label
    "dev" [...]`）。但Swarm无权编辑或更改它们。我们在这里看到的标签只影响Swarm的行为。
- en: 'Labels are useful for categorizing nodes. When you start services, you can
    filter and decide where to physically spawn containers, using labels. For instance,
    if you want to dedicate a bunch of nodes with SSD to host MySQL, you can actually:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 标签对于对节点进行分类很有用。当您启动服务时，您可以使用标签来过滤和决定在哪里物理生成容器。例如，如果您想要将一堆带有SSD的节点专门用于托管MySQL，您实际上可以：
- en: '[PRE13]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Later, when you will start a service with the replica factor, say three, you''ll
    be sure that it will start MySQL containers exactly on worker1, worker2, and worker3,
    if you filter by `node.type`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，当您使用副本因子启动服务，比如三个，您可以确保它将在`node.type`过滤器上准确地在worker1、worker2和worker3上启动MySQL容器：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Remove nodes
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除节点
- en: Node removal is a delicate operation. It's not just about excluding a node from
    the Swarm, but also about its role and the tasks it's running.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 节点移除是一个微妙的操作。这不仅仅是排除Swarm中的一个节点，还涉及到它的角色和正在运行的任务。
- en: Remove workers
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除工作节点
- en: 'If a worker has the status as Down (for example, because it was physically
    shut down), then it''s currently running nothing, so it can be safely removed:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个工作节点的状态是下线（例如，因为它被物理关闭），那么它目前没有运行任何任务，因此可以安全地移除：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If a worker is in has the status as Ready, instead, then the previous command
    will raise an error, refusing to remove it. The node availability (Active, Pause
    or Drain) doesn't really matter, because it can still be potentially running tasks
    at the moment, or when resumed.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个工作节点的状态是就绪，那么先前的命令将会引发错误，拒绝移除它。节点的可用性（活跃、暂停或排空）并不重要，因为它仍然可能在运行任务，或者在恢复时运行任务。
- en: 'So, in this case an operator must manually drain the node. This means forcing
    it to release its tasks that will be rescheduled and moved to other workers:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，操作员必须手动排空节点。这意味着强制释放节点上的任务，这些任务将被重新调度并移动到其他工作节点：
- en: '[PRE16]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Once drained, the node can be shutdown and then removed when its status is Down.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 排空后，节点可以关闭，然后在其状态为下线时移除。
- en: Remove managers
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 移除管理者
- en: 'Managers can''t be removed. Before removing a manager node, it must be properly
    demoted to worker, eventually drained, and then shut down:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 管理者不能被移除。在移除管理者节点之前，必须将其适当地降级为工作节点，最终排空，然后关闭：
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When a manager has to be removed, another worker node should be identified as
    a new manager and promoted later, in order to maintain an odd number of managers.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当必须移除一个管理者时，应该确定另一个工作节点作为新的管理者，并在以后提升，以保持管理者的奇数数量。
- en: Tip
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: '**Remove with**:  `docker node rm --force`'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用以下命令移除**：`docker node rm --force`'
- en: The `--force` flag removes a node, no matter what. This option must be used
    very carefully and it's usually the last resort in the presence of stuck nodes.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`--force`标志会移除一个节点，无论如何。这个选项必须非常小心地使用，通常是在节点卡住的情况下才会使用。'
- en: Swarm health
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm健康状况
- en: Swarm health depends, essentially, on the availability of the nodes in cluster
    and on the reliability of the managers (odd number, available, up).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm的健康状况基本上取决于集群中节点的可用性以及管理者的可靠性（奇数个、可用、运行中）。
- en: 'Nodes can be listed with the usual:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 节点可以用通常的方式列出：
- en: '[PRE18]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This can use the `--filter` option to filter the output. For example:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以使用`--filter`选项来过滤输出。例如：
- en: '[PRE19]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To get details about a specific node, use inspect as shown:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取有关特定节点的详细信息，请使用inspect命令，如下所示：
- en: '[PRE20]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Also, filtering options are available to extract specific data from the output
    JSON:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，过滤选项可用于从输出的JSON中提取特定数据：
- en: '[PRE21]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Outputting the number of cores (one) and the quantity of assigned memory (`1044140032`
    bytes, or 995M).
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 输出核心数量（一个）和分配内存的数量（`1044140032`字节，或995M）。
- en: Backing up the cluster configuration
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份集群配置
- en: 'The important data on managers is stored in `/var/lib/docker/swarm`. Here we
    have:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 管理者的重要数据存储在`/var/lib/docker/swarm`中。这里有：
- en: The certificates in `certificates/`
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`certificates/`中的证书'
- en: The Raft status with Etcd logs and snapshots in `raft/`
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`raft/`中的Raft状态与Etcd日志和快照
- en: The tasks database in `worker/`
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`worker/`中的任务数据库
- en: Other less crucial information, such as the current manager status, the current
    connection socket, and so on.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他不太关键的信息，比如当前管理者状态、当前连接套接字等。
- en: It's a good idea to set up a periodical backup of this data, in case recovery
    is needed.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最好设置定期备份这些数据，以防需要恢复。
- en: The space used by the Raft log depends on the number of tasks spawned onto the
    cluster and on how frequently their states change. For 200,000 containers, the
    Raft log can grow up to around 1GB of disk space every three hours. A log entry
    of each task occupies around 5 KB. Consequently, the log rotation policies for
    the Raft log directory, `/var/lib/docker/swarm/raft`, should be calibrated more
    or less aggressively, which depends on the available disk space.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: Raft日志使用的空间取决于集群上生成的任务数量以及它们的状态变化频率。对于20万个容器，Raft日志可以在大约三个小时内增长约1GB的磁盘空间。每个任务的日志条目占用约5KB。因此，Raft日志目录`/var/lib/docker/swarm/raft`的日志轮换策略应该更或多或少地根据可用磁盘空间进行校准。
- en: Disaster recovery
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 灾难恢复
- en: If the swarm directory content is lost or corrupted on a manager, it's required
    to immediately remove that manager out of the cluster using the `docker node remove
    nodeID` command (and use `--force` in case it gets stuck temporarily).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果管理器上的swarm目录内容丢失或损坏，则需要立即使用`docker node remove nodeID`命令将该管理器从集群中移除（如果暂时卡住，则使用`--force`）。
- en: The cluster administrator should not start a manager or join it to the cluster
    with an out-of-date swarm directory. Joining the cluster with the out-of-date
    swarm directory brings the cluster to an inconsistent state, as all managers will
    try to synchronize wrong data during the process.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员不应该使用过时的swarm目录启动管理器或加入集群。使用过时的swarm目录加入集群会导致集群处于不一致的状态，因为在此过程中所有管理器都会尝试同步错误的数据。
- en: After bringing down the manager with the corrupted directory, it's necessary
    to delete the `/var/lib/docker/swarm/raft/wal` and `/var/lib/docker/swarm/raft/snap`
    directories. Only after this step can the manager safely re-join the cluster.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在删除具有损坏目录的管理器后，需要删除`/var/lib/docker/swarm/raft/wal`和`/var/lib/docker/swarm/raft/snap`目录。只有在此步骤之后，管理器才能安全地重新加入集群。
- en: Graphical interfaces for Swarm
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm的图形界面
- en: At the moment of writing, Swarm mode is so young, that the existing Docker graphical
    user interfaces support is yet to come or is in progress.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Swarm模式还很年轻，现有的Docker图形用户界面支持尚未到来或正在进行中。
- en: Shipyard
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Shipyard
- en: '**Shipyard** ([https://shipyard-project.com/](https://shipyard-project.com/)),
    which has a nice support for Swarm (v1) operations, is now updated to use Swarm
    mode. At the of writing (August 2016), there is a 1.12 branch on Github, that
    makes this workable.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**Shipyard** ([https://shipyard-project.com/](https://shipyard-project.com/))，它对Swarm（v1）操作有很好的支持，现在已更新为使用Swarm模式。在撰写本文时（2016年8月），Github上有一个1.12分支，使其可行。'
- en: At the time this book will be published, probably a stable version will be available
    for automated deployment already. You can take a look at the instructions at [https://shipyard-project.com/docs/deploy/automated/](https://shipyard-project.com/docs/deploy/automated/).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书出版时，可能已经有一个稳定的版本可用于自动部署。您可以查看[https://shipyard-project.com/docs/deploy/automated/](https://shipyard-project.com/docs/deploy/automated/)上的说明。
- en: 'It will be something similar to going in SSH to the leader manager host and
    run a one liner, such as:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 这将类似于通过SSH进入领导管理器主机并运行一行命令，例如：
- en: '[PRE22]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In case we still need to install a specific non-stable branch, download it from
    Github to the leader manager host and install Docker Compose.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仍然需要安装特定的非稳定分支，请从Github下载到领导管理器主机并安装Docker Compose。
- en: '[PRE23]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And finally start with `compose`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 最后从`compose`开始：
- en: '[PRE24]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This command will bring up a number of containers, which, in the very end, by
    default expose port `8080` so that you can connect to the public manager IP at
    port `8080` to get into the Shipyard UI.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将启动多个容器，最终默认公开端口`8080`，以便您可以连接到公共管理器IP的端口`8080`以进入Shipyard UI。
- en: '![Shipyard](images/image_05_010.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![Shipyard](images/image_05_010.jpg)'
- en: As you can see in the following screenshot, Docker Swarm features are already
    supported in UI (there are **Services**, **Nodes**, and so on.), and operations,
    such as **Promote**, **D**emote**** , and so on, which we outlined in this chapter
    are available for each node.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在下面的屏幕截图中所见，Docker Swarm功能已经在UI中得到支持（有**服务**、**节点**等），并且我们在本章中概述的操作，如**提升**、**降级**等，对每个节点都是可用的。
- en: '![Shipyard](images/image_05_011.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![Shipyard](images/image_05_011.jpg)'
- en: Portainer
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Portainer
- en: An alternative UI supporting Swarm Mode, and our preferred choice,  is **Portainer**
    ([https://github.com/portainer/portainer/](https://github.com/portainer/portainer/)).
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 支持Swarm Mode的另一种UI，也是我们的首选，是**Portainer**（[https://github.com/portainer/portainer/](https://github.com/portainer/portainer/)）。
- en: 'Deploying it is as easy as starting it as a container on the leader manager:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将其部署起来就像在领导管理者上启动容器一样简单：
- en: '[PRE25]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![Portainer](images/image_005_012.jpg)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![Portainer](images/image_005_012.jpg)'
- en: The UI has the expected options, including nice list of templates for quickly
    launching containers, such as MySQL or a private registry, Portainer supports
    Swarm services, with `-s` option when launching it.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: UI具有预期的选项，包括一个很好的模板列表，用于快速启动容器，例如MySQL或私有注册表，Portainer在启动时支持Swarm服务，使用`-s`选项。
- en: Portainer, at time of writing, is about to launch the UI authentication feature,
    which is the first step towards full roles based access control, which is due
    in the start of 2017\. Later the RBAC will be extended to support Microsoft Active
    Directory as the directory source. Further, Portainer will also support multi-cluster
    (or multi-host) management by end of 2016\. Additional features being added at
    the start of 2017 are Docker Compose (YAML) support, and private registry management.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Portainer，在撰写本文时，即将推出UI身份验证功能，这是实现完整基于角色的访问控制的第一步，预计将在2017年初实现。随后，RBAC将扩展支持Microsoft
    Active Directory作为目录源。此外，Portainer还将在2016年底之前支持多集群（或多主机）管理。在2017年初添加的其他功能包括Docker
    Compose（YAML）支持和私有注册表管理。
- en: Summary
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we went through the typical Swarm administration procedures
    and options. After showing how to add managers and workers to the cluster, we
    explained, in detail, how to update clusters and node properties, how to check
    the Swarm health and we encountered Shipyard and Portainer as UIs. After this
    we focussed on infrastructure, it's now time to use our Swarms. We'll turn the
    key and put in motion some real application in the next chapter, by creating real
    services and tasks.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们通过了典型的Swarm管理程序和选项。在展示了如何向集群添加管理者和工作者之后，我们详细解释了如何更新集群和节点属性，如何检查Swarm的健康状况，并遇到了Shipyard和Portainer作为UI。在此之后，我们将重点放在基础设施上，现在是时候使用我们的Swarm了。在下一章中，我们将启动一些真实的应用程序，通过创建真实的服务和任务来实现。
