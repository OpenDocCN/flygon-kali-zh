- en: Cluster Administration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群管理
- en: We've learned most of our basic DevOps skills with Kubernetes in previous chapters,
    from how to containerize our application to deploying our containerized software
    into Kubernetes seamlessly via continuous deployment. Now, it's time to have a
    deeper insight into how to administer a Kubernetes cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们学习了Kubernetes中大部分基本的DevOps技能，从如何将应用程序容器化到通过持续部署将我们的容器化软件无缝部署到Kubernetes。现在，是时候更深入地了解如何管理Kubernetes集群了。
- en: 'In this chapter, we''ll learn:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习：
- en: How to utilize namespaces to set administrative boundaries
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何利用命名空间设置管理边界
- en: Using kubeconfig to switch between multiple clusters
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用kubeconfig在多个集群之间切换
- en: Kubernetes authentication
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes身份验证
- en: Kubernetes authorization
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes授权
- en: While minikube is a fairly simple environment, we will use the **Google Container
    Engine** (**GKE**) and self-hosted cluster in AWS as the example, instead of minikube
    in this chapter. For the detailed setting, please refer to [Chapter 9](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on AWS*, and [Chapter 10](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on GCP*.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然minikube是一个相当简单的环境，但在本章中，我们将以**Google容器引擎**（**GKE**）和AWS中的自托管集群作为示例，而不是minikube。有关详细设置，请参阅[第9章](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e)，*AWS上的Kubernetes*，以及[第10章](part0247.html#7BHQU0-6c8359cae3d4492eb9973d94ec3e4f1e)，*GCP上的Kubernetes*。
- en: Kubernetes namespaces
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes命名空间
- en: 'Kubernetes has a namespace concept to divide the resources from a physical
    cluster to multiple virtual clusters. In this way, different groups could share
    the same physical cluster with isolation. Each namespace provides:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes具有命名空间概念，将物理集群中的资源划分为多个虚拟集群。这样，不同的组可以共享同一个物理集群并实现隔离。每个命名空间提供：
- en: A scope of names; object name in each namespace is unique
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一组名称范围；每个命名空间中的对象名称是唯一的
- en: Policies to ensure trusted authentication
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保受信任身份验证的策略
- en: Ability to set up resource quotas for resource management
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置资源配额以进行资源管理
- en: Namespaces are ideal for different teams or projects in the same company, so
    different groups can have their own virtual clusters, which have the resource
    isolation but share the same physical cluster. Resources in one namespace are
    invisible from other namespaces. Different resource quotas could be set to different
    namespaces and provide different levels of QoS. Note that not all objects are
    in a namespace, such as nodes and Persistent Volumes, which belong to entire clusters.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间非常适合同一公司中的不同团队或项目，因此不同的组可以拥有自己的虚拟集群，这些集群具有资源隔离但共享同一个物理集群。一个命名空间中的资源对其他命名空间是不可见的。可以为不同的命名空间设置不同的资源配额，并提供不同级别的QoS。请注意，并非所有对象都在命名空间中，例如节点和持久卷，它们属于整个集群。
- en: Default namespaces
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认命名空间
- en: 'By default, Kubernetes has three namespaces: `default`, `kube-system` and `kube-public`.
    The `default` namespace contains the objects which are created without specifying
    any namespace, and `kube-system` contains the objects which are created by Kubernetes
    systems, usually used by the system components, such as Kubernetes dashboard or
    Kubernetes DNS. The `kube-public` is newly introduced in 1.6, which intends to
    locate the resources that everybody can access. It mainly focuses on public ConfigMap
    now, such as cluster info.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes有三个命名空间：`default`，`kube-system`和`kube-public`。`default`命名空间包含未指定任何命名空间创建的对象，而`kube-system`包含由Kubernetes系统创建的对象，通常由系统组件使用，例如Kubernetes仪表板或Kubernetes
    DNS。`kube-public`是在1.6中新引入的，旨在定位每个人都可以访问的资源。它现在主要关注公共ConfigMap，如集群信息。
- en: Create a new namespace
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建新的命名空间
- en: 'Let''s see how to create a namespace. A namespace is also a Kubernetes object.
    We could just specify the kind as a namespace like other objects. Below is the
    example to create one namespace, `project1`:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何创建一个命名空间。命名空间也是Kubernetes对象。我们可以像其他对象一样指定种类为命名空间。下面是创建一个命名空间`project1`的示例：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then let''s try to start two nginx containers via deployment in `project1`
    namespace:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后让我们尝试通过`project1`命名空间中的部署启动两个nginx容器：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'When we list pods by `kubectl get pods`, we''ll see nothing in our cluster.
    Why? Because Kubernetes uses the current context to decide which namespace is
    current. If we don''t explicitly specify namespace in the context or `kubectl`
    command line, the `default` namespace will be used:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们通过`kubectl get pods`列出pod时，我们会在我们的集群中看不到任何内容。为什么？因为Kubernetes使用当前上下文来决定哪个命名空间是当前的。如果我们在上下文或`kubectl`命令行中不明确指定命名空间，则将使用`default`命名空间：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You could use `--namespace <namespace_name>`, `--namespace=<namespace_name>`,
    `-n <namespace_name>` or `-n=<namespace_name>` to specify the namespace for a
    command. To list the resources across namespaces, use `--all-namespaces` parameter.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`--namespace <namespace_name>`，`--namespace=<namespace_name>`，`-n <namespace_name>`或`-n=<namespace_name>`来指定命令的命名空间。要列出跨命名空间的资源，请使用`--all-namespaces`参数。
- en: Another way is changing the current context to point to the desired namespace
    rather than the default namespace.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是将当前上下文更改为指向所需命名空间，而不是默认命名空间。
- en: Context
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 上下文
- en: '**Context** is a concept of the combination of cluster information, a user
    for authentication and a namespace. For example, the following is the context
    information for one of our clusters in GKE:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文**是集群信息、用于身份验证的用户和命名空间的组合概念。例如，以下是我们在GKE中一个集群的上下文信息：'
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We could use the `kubectl config current-context` command to see the current
    context:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`kubectl config current-context`命令查看当前上下文：
- en: '[PRE4]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To list all config info including contexts, you could use the `kubectl config
    view` command; to checkout what context is currently in use, use `kubectl config
    get-contexts` command.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要列出所有配置信息，包括上下文，您可以使用`kubectl config view`命令；要检查当前正在使用的上下文，使用`kubectl config
    get-contexts`命令。
- en: Create a context
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建上下文
- en: 'The next step is to create a context. As in the preceding example, we''ll need
    to set a user and cluster name for the context. If we don''t specify those, the
    empty value will be set. The command to create a context is:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建上下文。与前面的示例一样，我们需要为上下文设置用户和集群名称。如果我们不指定这些，将设置为空值。创建上下文的命令是：
- en: '[PRE5]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Multiple contexts could be created in the same cluster. The following is an
    example of how to create a context for `project1` in my GKE cluster `gke_devops-with-kubernetes_us-central1-b_cluster`:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一集群中可以创建多个上下文。以下是如何在我的GKE集群`gke_devops-with-kubernetes_us-central1-b_cluster`中为`project1`创建上下文的示例：
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Switch the current context
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 切换当前上下文
- en: 'Then we could switch the context by the `use-context` sub-command:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以通过`use-context`子命令切换上下文：
- en: '[PRE7]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'After the context is switched, every command we invoke via `kubectl` is under
    the `project1` context. We don''t need to explicitly specify the namespace to
    see our pods:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文切换后，我们通过`kubectl`调用的每个命令都在`project1`上下文下。我们不需要明确指定命名空间来查看我们的pod：
- en: '[PRE8]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ResourceQuota
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源配额
- en: By default, pods in Kubernetes are resource-unbounded. Then the running pods
    might use up all the compute or storage resources in a cluster. ResourceQuota
    is a resource object that allows us to restrict the resource consumption that
    a namespace could use. By setting up the resource limit, we could reduce the noisy
    neighbor symptom. The team working for `project1` won't use up all the resources
    in the physical cluster.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，默认情况下，pod是无限制的资源。然后运行的pod可能会使用集群中的所有计算或存储资源。ResourceQuota是一个资源对象，允许我们限制命名空间可以使用的资源消耗。通过设置资源限制，我们可以减少嘈杂的邻居症状。为`project1`工作的团队不会耗尽物理集群中的所有资源。
- en: 'Then we can ensure the quality of service for other teams working in other
    projects which share the same physical cluster. There are three kinds of resource
    quotas supported in Kubernetes 1.7\. Each kind includes different resource names,
    ([https://kubernetes.io/docs/concepts/policy/resource-quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas)):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以确保其他项目中工作的团队在共享同一物理集群时的服务质量。Kubernetes 1.7支持三种资源配额。每种类型包括不同的资源名称（[https://kubernetes.io/docs/concepts/policy/resource-quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas)）。
- en: Compute resource quota (CPU, memory)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算资源配额（CPU，内存）
- en: Storage resource quota (requested storage, Persistent Volume Claims)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储资源配额（请求的存储、持久卷索赔）
- en: Object count quotas (pods, RCs, ConfigMaps, services, LoadBalancers)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对象计数配额（pod、RCs、ConfigMaps、services、LoadBalancers）
- en: Created resources won't be affected by newly created resource quotas. If the
    resource creation request exceeds the specified ResourceQuota, the resources won't
    be able to start up.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的资源不会受到新创建的资源配额的影响。如果资源创建请求超过指定的ResourceQuota，资源将无法启动。
- en: Create a ResourceQuota for a namespace
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为命名空间创建资源配额
- en: 'Now, let''s learn the syntax of `ResourceQuota`. Below is one example:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习`ResourceQuota`的语法。以下是一个例子：
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The template is like other objects, just this kind becomes `ResourceQuota`.
    The quota we specified is valid across the pods which are in a succeeded or failed
    state (that is, non-terminal state). There are several resource constraints that
    are supported. In the preceding example, we demonstrate how to set compute ResourceQuota,
    storage ResourceQuota and object CountQuota. Any time, we could still use the
    `kubectl` command to check the quota we set: `kubectl describe resourcequota <resource_quota_name>`.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 模板与其他对象一样，只是这种类型变成了`ResourceQuota`。我们指定的配额适用于处于成功或失败状态的pod（即非终端状态）。支持几种资源约束。在前面的例子中，我们演示了如何设置计算ResourceQuota、存储ResourceQuota和对象CountQuota。随时，我们仍然可以使用`kubectl`命令来检查我们设置的配额：`kubectl
    describe resourcequota <resource_quota_name>`。
- en: Right now let's modify our existing nginx Deployment by the command `kubectl
    edit deployment nginx`, changing replica from `2` to `4` and save. Let's list
    the state now.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过命令`kubectl edit deployment nginx`修改我们现有的nginx部署，将副本从`2`更改为`4`并保存。现在让我们列出状态。
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It indicates some pods failed on creation. If we check the corresponding ReplicaSet,
    we could find out the reason:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 它指示一些pod在创建时失败。如果我们检查相应的ReplicaSet，我们可以找出原因：
- en: '[PRE11]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Since we''ve specified the request limits on memory and CPU, Kubernetes doesn''t
    know the default request limits on the newly desired three pods. We could see
    the original two pods are still up and running, since the resource quota doesn''t
    apply to existing resources. We now then use `kubectl edit deployment nginx` to
    modify container specs as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经在内存和CPU上指定了请求限制，Kubernetes不知道新期望的三个pod的默认请求限制。我们可以看到原来的两个pod仍在运行，因为资源配额不适用于现有资源。然后我们使用`kubectl
    edit deployment nginx`来修改容器规范如下：
- en: '![](../images/00116.jpeg)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](../images/00116.jpeg)'
- en: 'Here, we specify the requests and limits for CPU and memory in the pod spec.
    It indicates the pod can''t exceed the specified quota, otherwise it will be unable
    to start:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们在pod规范中指定了CPU和内存的请求和限制。这表明pod不能超过指定的配额，否则将无法启动：
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Available pods become four instead of two, but still not equal to our desired
    four. What went wrong? If we take a step back and check our resource quota, we
    can find we''ve used all the quota of pods. Since Deployments use the rolling
    update deployment mechanism by default, it''ll require pod numbers larger than
    four, which is exact object limit we set earlier:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的pod变成了四个，而不是两个，但仍然不等于我们期望的四个。出了什么问题？如果我们退一步检查我们的资源配额，我们会发现我们已经使用了所有的pod配额。由于部署默认使用滚动更新部署机制，它将需要大于四的pod数量，这正是我们之前设置的对象限制：
- en: '[PRE13]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: After modifying the pods quota from `4` to `8` by `kubectl edit resourcequota
    project1-resource-quota` command, the Deployment has sufficient resource to launch
    the pods. Once the `Used` quota exceeds the `Hard` quota, the request will be
    rejected by the ResourceQuota admission controller, otherwise, the resource quota
    usage will be updated to ensure sufficient resource allocation.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`kubectl edit resourcequota project1-resource-quota`命令将pod配额从`4`修改为`8`后，部署有足够的资源来启动pod。一旦`Used`配额超过`Hard`配额，请求将被资源配额准入控制器拒绝，否则，资源配额使用将被更新以确保足够的资源分配。
- en: Since ResourceQuota won't affect already created resources, sometimes we might
    need to tweak the failed resources, such as deleting an empty change set of RS
    or scale up and down Deployment, in order to let Kubernetes create new pods or
    RS which will soak the latest quota limits.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 由于资源配额不会影响已创建的资源，有时我们可能需要调整失败的资源，比如删除一个RS的空更改集或者扩展和缩小部署，以便让Kubernetes创建新的pod或RS，这将吸收最新的配额限制。
- en: Request pods with default compute resource limits
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请求具有默认计算资源限制的pod
- en: We could also specify default resource requests and limits for a namespace.
    Default setting will be used if we don't specify the requests and limits during
    pod creation. The trick is using `LimitRange` resource object. A `LimitRange`
    object contains a set of `defaultRequest` (request) and `default` (limits).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以为命名空间指定默认的资源请求和限制。如果在创建pod时不指定请求和限制，将使用默认设置。关键是使用`LimitRange`资源对象。`LimitRange`对象包含一组`defaultRequest`（请求）和`default`（限制）。
- en: LimitRange is controlled by the LimitRanger admission controller plugin. Be
    sure you enable it if you launch a self-hosted solution. For more information,
    check out the admission controller section in this chapter.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: LimitRange由LimitRanger准入控制器插件控制。如果启动自托管解决方案，请确保启用它。有关更多信息，请查看本章的准入控制器部分。
- en: 'Below is an example where we set `cpu.request` as `250m` and `limits` as `500m`,
    `memory.request` as `256Mi` and `limits` as `512Mi`:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个示例，我们将`cpu.request`设置为`250m`，`limits`设置为`500m`，`memory.request`设置为`256Mi`，`limits`设置为`512Mi`：
- en: '[PRE14]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: When we launch pods inside this namespace, we don't need to specify the `cpu`
    and `memory` requests and `limits` anytime, even if we have a total limitation
    set inside ResourceQuota.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在此命名空间内启动pod时，即使在ResourceQuota中设置了总限制，我们也不需要随时指定`cpu`和`memory`请求和`limits`。
- en: The unit of CPU is core, which is an absolute quantity. It can be an AWS vCPU,
    a GCP core or a hyperthread on a machine with hyperthreading processor equipped.
    The unit of memory is a byte. Kubernetes uses the first alphabet or power-of-two
    equivalents. For example, 256M would be written as 256,000,000, 256 M or 244 Mi.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: CPU的单位是核心，这是一个绝对数量。它可以是AWS vCPU，GCP核心或者装备了超线程处理器的机器上的超线程。内存的单位是字节。Kubernetes使用字母或二的幂的等价物。例如，256M可以写成256,000,000，256
    M或244 Mi。
- en: Additionally, we can set minimum and maximum CPU and memory values for a pod
    in LimitRange. It acts differently as default values. Default values are only
    used if a pod spec doesn't contain any requests and limits. The minimum and maximum
    constraint is used for verifying if a pod requests too much resource. The syntax
    is `spec.limits[].min` and `spec.limits[].max`. If the request exceeds the minimum
    and maximum values, forbidden will be thrown from the server.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以在LimitRange中为pod设置最小和最大的CPU和内存值。它与默认值的作用不同。默认值仅在pod规范不包含任何请求和限制时使用。最小和最大约束用于验证pod是否请求了太多的资源。语法是`spec.limits[].min`和`spec.limits[].max`。如果请求超过了最小和最大值，服务器将抛出forbidden错误。
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Quality of service for pods: There are three QoS classes for pods in Kubernetes:
    Guaranteed, Burstable and BestEffort. It''s tied together with the namespace and
    resource management concept we learned above. We also learned QoS in [Chapter
    4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e), *Working with Storage
    and Resources*. Please refer to the last section *Kubernetes Resource Management*
    in [Chapter 4](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e), *Working
    with Storage and Resources* for recap.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Pod的服务质量：Kubernetes中的pod有三个QoS类别：Guaranteed、Burstable和BestEffort。它与我们上面学到的命名空间和资源管理概念密切相关。我们还在[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)中学习了QoS，*使用存储和资源*。请参考[第4章](part0103.html#3279U0-6c8359cae3d4492eb9973d94ec3e4f1e)中的最后一节*使用存储和资源*进行复习。
- en: Delete a namespace
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除一个命名空间
- en: Just like any other resources, deleting a namespace is `kubectl delete namespace
    <namespace_name>`. Please be aware that if a namespace is deleted, all the resources
    associated with that namespace will be evicted.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他资源一样，删除一个命名空间是`kubectl delete namespace <namespace_name>`。请注意，如果删除一个命名空间，与该命名空间关联的所有资源都将被清除。
- en: Kubeconfig
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubeconfig
- en: Kubeconfig is a file that you can use to switch multiple clusters by switching
    context. We can use `kubectl config view` to view the setting. The following is
    an example of a minikube cluster in a `kubeconfig` file.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeconfig是一个文件，您可以使用它来通过切换上下文来切换多个集群。我们可以使用`kubectl config view`来查看设置。以下是`kubeconfig`文件中minikube集群的示例。
- en: '[PRE16]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Just like what we learned previously. We could use `kubectl config use-context`
    to switch the cluster to manipulate. We could also use `kubectl config --kubeconfig=<config
    file name>` to specify which `kubeconfig` file we''d like to use. Only the specified
    file will be used. We could also specify `kubeconfig` files by the environment
    variable `$KUBECONFIG`. In this way, config files could be merged. For example,
    the following command will merge `kubeconfig-file1` and `kubeconfig-file2`:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们之前学到的一样。我们可以使用`kubectl config use-context`来切换要操作的集群。我们还可以使用`kubectl config
    --kubeconfig=<config file name>`来指定要使用的`kubeconfig`文件。只有指定的文件将被使用。我们还可以通过环境变量`$KUBECONFIG`指定`kubeconfig`文件。这样，配置文件可以被合并。例如，以下命令将合并`kubeconfig-file1`和`kubeconfig-file2`：
- en: '[PRE17]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: You might find we didn't do any specific setting previously. Then where does
    the output of `kubectl config view` come from? By default, it exists under `$HOME/.kube/config`.
    This file will be loaded if none of the preceding are set.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会发现我们之前没有进行任何特定的设置。那么`kubectl config view`的输出来自哪里呢？默认情况下，它存在于`$HOME/.kube/config`下。如果没有设置前面的任何一个，将加载此文件。
- en: Service account
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务账户
- en: 'Unlike normal users, **service account** is used by processes inside a pod
    to contact the Kubernetes API server. By default, a Kubernetes cluster creates
    different service accounts for different purposes. In GKE, there are bunch of
    service accounts that have been created:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 与普通用户不同，**服务账户**是由pod内的进程用来联系Kubernetes API服务器的。默认情况下，Kubernetes集群为不同的目的创建不同的服务账户。在GKE中，已经创建了大量的服务账户：
- en: '[PRE18]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Kubernetes will create a default service account in each namespace, which will
    be used if no service account is specified in pod spec during pod creation. Let''s
    take a look at how the default service account acts for our `project1` namespace:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes将在每个命名空间中创建一个默认的服务账户，如果在创建pod时未指定服务账户，则将使用该默认服务账户。让我们看看默认服务账户在我们的`project1`命名空间中是如何工作的：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We could see a service account is basically using mountable secrets as a token.
    Let''s dig into what contents are inside the token:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，服务账户基本上是使用可挂载的密钥作为令牌。让我们深入了解令牌中包含的内容：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The secret will be automatically mounted to the directory `/var/run/secrets/kubernetes.io/serviceaccount`.
    When the pod accesses the API server, the API server will check the cert and token
    to do the authentication. The concept of a service account will be with us in
    the following sections.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 密钥将自动挂载到目录`/var/run/secrets/kubernetes.io/serviceaccount`。当pod访问API服务器时，API服务器将检查证书和令牌进行认证。服务账户的概念将在接下来的部分中与我们同在。
- en: Authentication and authorization
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 认证和授权
- en: Authentication and authorization are important from DevOps' point of view. Authentication
    verifies users and checks if the users are really who they represent themselves
    to be. Authorization, on the other hand, checks what permission levels users have.
    Kubernetes supports different authentication and authorization modules.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 从DevOps的角度来看，认证和授权非常重要。认证验证用户并检查用户是否真的是他们所代表的身份。另一方面，授权检查用户拥有哪些权限级别。Kubernetes支持不同的认证和授权模块。
- en: The following is an illustration that shows how the Kubernetes API server processes
    the access control when it receives a request.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例，展示了当Kubernetes API服务器收到请求时如何处理访问控制。
- en: '![](../images/00117.jpeg)Access control in API server'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../images/00117.jpeg)API服务器中的访问控制'
- en: When the request comes to API server, firstly, it establishes a TLS connection
    by validating the clients' certificate with the **certificate authority** (**CA**)
    in the API server. The CA in the API server is usually at `/etc/kubernetes/`,
    and the clients' certificate is usually at `$HOME/.kube/config`. After the handshake,
    it goes to the authentication stage. In Kuberentes, authentication module are
    chain-based. We could use more than one authentication and authorization modules.
    When the request comes, Kubernetes will try all the authenticators one by one
    until it succeeds. If the request fails on all authentication modules, it will
    be rejected as HTTP 401 Unauthorized. Otherwise, one of the authenticators verifies
    the user's identity and the requests are authenticated. Then Kubernetes authorization
    modules will come into play. It will verify if the user has the permission to
    do the action that they request to do by a set of policies. Authorization modules
    are also chain-based. It keeps trying every module until it succeeds. If the request
    fails on all the modules, it'll get a HTTP 403 Forbidden response. Admission control
    is a set of configurable plugins in an API server that determine if a request
    is admitted or denied. At this stage, if the request doesn't pass through one
    of the plugins, then the request is denied immediately.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求发送到API服务器时，首先，它通过使用API服务器中的**证书颁发机构**（**CA**）验证客户端的证书来建立TLS连接。API服务器中的CA通常位于`/etc/kubernetes/`，客户端的证书通常位于`$HOME/.kube/config`。握手完成后，进入身份验证阶段。在Kubernetes中，身份验证模块是基于链的。我们可以使用多个身份验证和授权模块。当请求到来时，Kubernetes将依次尝试所有的身份验证器，直到成功。如果请求在所有身份验证模块上失败，将被拒绝为HTTP
    401未经授权。否则，其中一个身份验证器验证用户的身份并对请求进行身份验证。然后Kubernetes授权模块将发挥作用。它将验证用户是否有权限执行他们请求的操作，通过一组策略。授权模块也是基于链的。它将不断尝试每个模块，直到成功。如果请求在所有模块上失败，将得到HTTP
    403禁止的响应。准入控制是API服务器中一组可配置的插件，用于确定请求是否被允许或拒绝。在这个阶段，如果请求没有通过其中一个插件，那么请求将立即被拒绝。
- en: Authentication
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 身份验证
- en: By default, a service account is token-based. When you create a service account
    or a namespace with default service account, Kubernetes creates the token and
    stores it as a secret which is encoded by base64, and mounts the secret as a volume
    into the pod. Then the processes inside the pod have the ability to talk to the
    cluster. The user account, on the other hand, represents a normal user, who might
    use `kubectl` to manipulate the resource directly.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，服务账户是基于令牌的。当您创建一个服务账户或一个带有默认服务账户的命名空间时，Kubernetes会创建令牌并将其存储为一个由base64编码的秘密，并将该秘密作为卷挂载到pod中。然后pod内的进程有能力与集群通信。另一方面，用户账户代表一个普通用户，可能使用`kubectl`直接操作资源。
- en: Service account authentication
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务账户身份验证
- en: When we create a service account, a signed bearer token will be created automatically
    by the Kubernetes service account admission controller plugin.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建一个服务账户时，Kubernetes服务账户准入控制器插件会自动创建一个签名的令牌。
- en: 'In [Chapter 7](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e), *Continuous
    Delivery*, in the example that we demonstrated how to do the deployment of `my-app`,
    we created a namespace named `cd`, and we used the script `get-sa-token.sh` ([https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh))
    to export the token for us. Then we create a user `mysa` via `kubectl config set-credentials
    <user> --token=$TOKEN` command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e)，*持续交付*中，在我们演示了如何部署`my-app`的示例中，我们创建了一个名为`cd`的命名空间，并且我们使用了脚本`get-sa-token.sh`（[https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh](https://github.com/DevOps-with-Kubernetes/examples/blob/master/chapter7/get-sa-token.sh)）来为我们导出令牌。然后我们通过`kubectl
    config set-credentials <user> --token=$TOKEN`命令创建了一个名为`mysa`的用户：
- en: '[PRE21]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we set the context to bind with user and namespace:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将上下文设置为与用户和命名空间绑定：
- en: '[PRE22]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we set our context `myctxt` as default context:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将把我们的上下文`myctxt`设置为默认上下文：
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: When the service account sends a request, the token will be verified by the
    API server to check if the requester is eligible and it is what it claims to be.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当服务账户发送请求时，API服务器将验证令牌，以检查请求者是否有资格以及它所声称的身份是否属实。
- en: User account authentication
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用户账户认证
- en: There are several implementations for user account authentication. From client
    certificates, bearer tokens, static files to OpenID connect tokens. You can choose
    more than one as authentication chains. Here, we'll demonstrate how client certificates
    works.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种用户账户认证的实现方式。从客户端证书、持有者令牌、静态文件到OpenID连接令牌。您可以选择多种身份验证链。在这里，我们将演示客户端证书的工作原理。
- en: In [Chapter 7](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e), *Continuous
    Delivery* we've learned how to export cert and token for service account. Now,
    let's learn how to do it for a user. Assume we are still inside `project1` namespace,
    and we want to create a user for our new DevOps member Linda, who will help us
    to do the Deployment for my-app.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第7章](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e)，*持续交付*中，我们学习了如何为服务账户导出证书和令牌。现在，让我们学习如何为用户做这件事。假设我们仍然在`project1`命名空间中，并且我们想为我们的新DevOps成员琳达创建一个用户，她将帮助我们为`my-app`进行部署。
- en: 'First, we''ll generate a private key by OpenSSL ([https://www.openssl.org](https://www.openssl.org)):'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将通过OpenSSL（[https://www.openssl.org](https://www.openssl.org)）生成一个私钥：
- en: '[PRE24]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Next, we''ll create a certificate sign request (`.csr`) for Linda:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将为琳达创建一个证书签名请求（`.csr`）：
- en: '[PRE25]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Now, `linda.key` and `linda.csr` should be located in the current folder. For
    approving the sign request, we'll need to locate the CA of our Kubernetes cluster.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`linda.key`和`linda.csr`应该位于当前文件夹中。为了批准签名请求，我们需要找到我们Kubernetes集群的CA。
- en: In minikube, it's under `~/.minikube/`. For other self-hosted solutions, normally
    it's under `/etc/kubernetes/`. If you use kops to deploy the cluster, the location
    is under `/srv/kubernetes`, where you could find the path in `/etc/kubernetes/manifests/kube-apiserver.manifest`
    file.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在minikube中，它位于`~/.minikube/`。对于其他自托管解决方案，通常位于`/etc/kubernetes/`下。如果您使用kops部署集群，则位置位于`/srv/kubernetes`下，您可以在`/etc/kubernetes/manifests/kube-apiserver.manifest`文件中找到路径。
- en: 'Assume we have `ca.crt` and `ca.key` under the current folder, we could generate
    the cert by our sign request. Using the `-days` parameter we could define the
    expired date:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在当前文件夹下有`ca.crt`和`ca.key`，我们可以通过我们的签名请求生成证书。使用`-days`参数，我们可以定义过期日期：
- en: '[PRE26]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: After we have cert signed by our cluster, we could set a user in the cluster.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的集群中有证书签名后，我们可以在集群中设置一个用户。
- en: '[PRE27]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Remember the concept of context: it''s the combination of cluster information,
    a user for authentication and a namespace. Now, we''ll set a context entry in
    `kubeconfig`. Remember to replace your cluster name, namespace and user from the
    following example:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 记住上下文的概念：它是集群信息、用于认证的用户和命名空间的组合。现在，我们将在`kubeconfig`中设置一个上下文条目。请记住从以下示例中替换您的集群名称、命名空间和用户：
- en: '[PRE28]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, Linda should have zero permission:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，琳达应该没有任何权限：
- en: '[PRE29]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Linda now passes the authentication stage while Kubernetes knows she is Linda.
    However, to make Linda have the permission to do the Deployment, we need to set
    up the polices in authorization modules.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 琳达现在通过了认证阶段，而Kubernetes知道她是琳达。但是，为了让琳达有权限进行部署，我们需要在授权模块中设置策略。
- en: Authorization
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 授权
- en: 'Kubernetes supports several authorization modules. At the time we''re writing,
    it supports:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes支持多个授权模块。在撰写本文时，它支持：
- en: ABAC
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ABAC
- en: RBAC
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RBAC
- en: Node authorization
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点授权
- en: Webhook
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Webhook
- en: Custom modules
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义模块
- en: '**Attribute-based access control** (**ABAC**) was the major authorization mode
    before **role-based access control** (**RBAC**) was introduced. Node authorization
    is used by kubelet to make a request to the API server. Kubernetes supports webhook
    authorization mode to establish a HTTP callback with an external RESTful service.
    It''ll do a POST whenever it faces an authorization decision. Another common way
    is you could implement your in-house module by following along the pre-defined
    authorizer interface. For more implementation information, refer to [https://kubernetes.io/docs/admin/authorization/#custom-modules](https://kubernetes.io/docs/admin/authorization/#custom-modules).
    In this section, we''ll describe more details for ABAC and RBAC.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于属性的访问控制**（**ABAC**）是在**基于角色的访问控制**（**RBAC**）引入之前的主要授权模式。节点授权被kubelet用于向API服务器发出请求。Kubernetes支持webhook授权模式，以与外部RESTful服务建立HTTP回调。每当面临授权决定时，它都会进行POST。另一种常见的方式是按照预定义的授权接口实现自己的内部模块。有关更多实现信息，请参阅[https://kubernetes.io/docs/admin/authorization/#custom-modules](https://kubernetes.io/docs/admin/authorization/#custom-modules)。在本节中，我们将更详细地描述ABAC和RBAC。'
- en: Attribute-based access control (ABAC)
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于属性的访问控制（ABAC）
- en: ABAC allows admin to define a set of user authorization polices into a file
    with one JSON per line format. The major drawback of ABAC mode is the policy file
    has to exist when launching the API server. Any change in the file requires restarting
    the API server with `--authorization-policy-file=<policy_file_name>` command.
    Another authorization method RBAC was introduced since Kubernetes 1.6\. which
    is more flexible and doesn't require restarting the API server. RBAC has now become
    the most common authorization mode.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: ABAC允许管理员将一组用户授权策略定义为每行一个JSON格式的文件。ABAC模式的主要缺点是策略文件在启动API服务器时必须存在。文件中的任何更改都需要使用`--authorization-policy-file=<policy_file_name>`命令重新启动API服务器。自Kubernetes
    1.6以来引入了另一种授权方法RBAC，它更灵活，不需要重新启动API服务器。RBAC现在已成为最常见的授权模式。
- en: 'The following is an example of how ABAC works. The format of the policy file
    is one JSON object per line. The configuration file of the policy is similar to
    our other configuration files. Just with different syntax in spec. There are four
    main properties in ABAC:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是ABAC工作原理的示例。策略文件的格式是每行一个JSON对象。策略的配置文件类似于我们的其他配置文件。只是在规范中有不同的语法。ABAC有四个主要属性：
- en: '| **Properties type** | **Supported values** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **属性类型** | **支持的值** |'
- en: '| Subject-matching | user, group |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 主题匹配 | 用户，组 |'
- en: '| Resource-matching | `apiGroup`, namespace, and resource |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 资源匹配 | `apiGroup`，命名空间和资源 |'
- en: '| Non-resource-matching | Used for non-resource type requests, such as `/version`,
    `/apis`, `/cluster` |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 非资源匹配 | 用于非资源类型请求，如`/version`，`/apis`，`/cluster` |'
- en: '| readonly | true or false |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| 只读 | true或false |'
- en: 'The following are some examples:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些示例：
- en: '[PRE30]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the preceding example, we have a user admin who could access everything.
    Another user named `linda` who can only read the Deployment and ReplicaSets in
    the namespace `project1`.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们有一个名为admin的用户，可以访问所有内容。另一个名为`linda`的用户只能在命名空间`project1`中读取部署和副本集。
- en: Role-based access control (RBAC)
  id: totrans-143
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于角色的访问控制（RBAC）
- en: RBAC was in beta in Kubernetes 1.6, which is enabled by default. In RBAC, admin
    creates several `Roles` or `ClusterRoles`, which define the fine-grained permissions
    that specifies a set of resources and actions (verbs) that roles could access
    and manipulate. After that, admin grants the `Role` permission to users by `RoleBinding`
    or `ClusterRoleBindings`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: RBAC在Kubernetes 1.6中处于beta阶段，默认情况下是启用的。在RBAC中，管理员创建了几个`Roles`或`ClusterRoles`，这些角色定义了细粒度的权限，指定了一组资源和操作（动词），角色可以访问和操作这些资源。之后，管理员通过`RoleBinding`或`ClusterRoleBindings`向用户授予`Role`权限。
- en: If you're running a minikube, add `--extra-config=apiserver.Authorization.Mode=RBAC`
    when doing `minikube start`. If you're running self-hosted cluster on AWS via
    kops, adding `--authorization=rbac` when launching the cluster. Kops launches
    API server as a pod; using `kops edit cluster` command could modify the spec of
    the containers.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在运行minikube，在执行`minikube start`时添加`--extra-config=apiserver.Authorization.Mode=RBAC`。如果你通过kops在AWS上运行自托管集群，则在启动集群时添加`--authorization=rbac`。Kops会将API服务器作为一个pod启动；使用`kops
    edit cluster`命令可以修改容器的规范。
- en: Roles and ClusterRoles
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 角色和集群角色
- en: A `Role` in Kubernetes is bound within a namespace, a `ClusterRole`, on the
    other hand, is cluster-wide. The following is an example of `Role`, which could
    do all the operations, including `get`, `watch`, `list`, `create`, `update`, `delete`,
    `patch` to the resources Deployment, ReplicaSet and pods.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，`Role`绑定在命名空间内，而`ClusterRole`是全局的。以下是一个`Role`的示例，可以对部署、副本集和pod资源执行所有操作，包括`get`、`watch`、`list`、`create`、`update`、`delete`、`patch`。
- en: '[PRE31]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `apiVersion` is still `v1beta1` at the time we wrote the book. If it happens
    that the API version changes, Kubernetes will throw the error and remind you to
    change. In `apiGroups`, an empty string indicates the core API group. The API
    group is part of the RESTful API call. The core indicates original API call path,
    such as `/api/v1`. The newer REST path has the group name and API version in it,
    such as `/apis/$GROUP_NAME/$VERSION`; for looking up API groups you''d like to
    use, check out API References at [https://kubernetes.io/docs/reference](https://kubernetes.io/docs/reference).
    Under resources you could add the resources you''d like to grant the access to,
    and under verbs lists an array of actions that this role could perform. Let''s
    get into a more advanced example for `ClusterRoles`, which we used in previous
    chapter as Continuous Delivery role:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们写这本书的时候，`apiVersion`仍然是`v1beta1`。如果API版本发生变化，Kubernetes会抛出错误并提醒您进行更改。在`apiGroups`中，空字符串表示核心API组。API组是RESTful
    API调用的一部分。核心表示原始API调用路径，例如`/api/v1`。新的REST路径中包含组名和API版本，例如`/apis/$GROUP_NAME/$VERSION`；要查找您想要使用的API组，请查看[https://kubernetes.io/docs/reference](https://kubernetes.io/docs/reference)中的API参考。在资源下，您可以添加您想要授予访问权限的资源，在动词下列出了此角色可以执行的操作数组。让我们来看一个更高级的`ClusterRoles`示例，我们在上一章中使用了持续交付角色：
- en: '[PRE32]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '`ClusterRole` is cluster-wide. Some resources don''t belong to any namespace,
    such as nodes, only could be controlled by `ClusterRole`. The namespaces it could
    access depends on the `namespaces` field in `ClusterRoleBinding` it associates
    with. We could see we grant the permission to allow this role read and write Deployments,
    ReplicaSets and ingresses in both extensions and apps groups. In the core API
    group, we grant only access for namespace and events, and all permission for other
    resources, such as pods and services.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`ClusterRole`是集群范围的。一些资源不属于任何命名空间，比如节点，只能由`ClusterRole`控制。它可以访问的命名空间取决于它关联的`ClusterRoleBinding`中的`namespaces`字段。我们可以看到，我们授予了该角色读取和写入Deployments、ReplicaSets和ingresses的权限，它们分别属于extensions和apps组。在核心API组中，我们只授予了对命名空间和事件的访问权限，以及对其他资源（如pods和services）的所有权限。'
- en: RoleBinding and ClusterRoleBinding
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RoleBinding和ClusterRoleBinding
- en: 'A `RoleBinding` is used to bind a `Role` or `ClusterRole` to a list of users
    or service accounts. If a `ClusterRole` is bound with a `RoleBinding` instead
    of a `ClusterRoleBinding`, it''ll be only granted the permissions within the namespace
    that `RoleBinding` specified. The following is an example of `RoleBinding` spec:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoleBinding`用于将`Role`或`ClusterRole`绑定到一组用户或服务账户。如果`ClusterRole`与`RoleBinding`绑定而不是`ClusterRoleBinding`，它将只被授予`RoleBinding`指定的命名空间内的权限。以下是`RoleBinding`规范的示例：'
- en: '[PRE33]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'In this example, we bind a `Role` with a user by `roleRef`. Kubernetes supports
    different kind of `roleRef`; we could replace the kind from `Role` to `ClusterRole`
    here:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们通过`roleRef`将`Role`与用户绑定。Kubernetes支持不同类型的`roleRef`；我们可以在这里将`Role`的类型替换为`ClusterRole`：
- en: '[PRE34]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Then `cd-role` can only access the resources in namespace `project1`.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然后`cd-role`只能访问`project1`命名空间中的资源。
- en: 'On the other hand, a `ClusterRoleBinding` is used to grant permission in all
    namespace. Let''s review what we did in [Chapter 7](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Continuous Delivery*. We first created a service account named `cd-agent`, then
    create a `ClusterRole` named `cd-role`. At the end, we created a `ClusterRoleBinding`
    for `cd-agent` and `cd-role`. We then used `cd-agent` to do the Deployment on
    our behalf:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`ClusterRoleBinding`用于在所有命名空间中授予权限。让我们回顾一下我们在[第7章](part0163.html#4REBM0-6c8359cae3d4492eb9973d94ec3e4f1e)中所做的事情，*持续交付*。我们首先创建了一个名为`cd-agent`的服务账户，然后创建了一个名为`cd-role`的`ClusterRole`。最后，我们为`cd-agent`和`cd-role`创建了一个`ClusterRoleBinding`。然后我们使用`cd-agent`代表我们进行部署：
- en: '[PRE35]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The `cd-agent` is bound with a `ClusterRole` via `ClusterRoleBinding`, so it
    can have the permission specified in `cd-role` across namespaces. Since a service
    account is created in a namespace, we''ll need to specify its full name including
    namespace:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`cd-agent`通过`ClusterRoleBinding`与`ClusterRole`绑定，因此它可以跨命名空间拥有`cd-role`中指定的权限。由于服务账户是在命名空间中创建的，我们需要指定其完整名称，包括命名空间：'
- en: '[PRE36]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Let's launch the `Role` and `RoleBinding` via `8-5-2_role.yml` and `8-5-2_rolebinding_user.yml:`
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过`8-5-2_role.yml`和`8-5-2_rolebinding_user.yml`启动`Role`和`RoleBinding`：
- en: '[PRE37]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now, we don''t get forbidden anymore:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们不再被禁止了：
- en: '[PRE38]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'What about if Linda wants to list namespaces, is it allowed?:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Linda想要列出命名空间，允许吗？：
- en: '[PRE39]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: The answer is no, since Linda is not granted permission for listing namespaces.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是否定的，因为Linda没有被授予列出命名空间的权限。
- en: Admission control
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准入控制
- en: Admission control takes place before Kubernetes processes the request and after
    authentication and authorization are passed. It's enabled when launching API server
    by adding `--admission-control` parameter. Kubernetes recommends officially to
    have the following plugins with the cluster if the cluster version is >= 1.6.0.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 准入控制发生在Kubernetes处理请求之前，经过身份验证和授权之后。在启动API服务器时，通过添加`--admission-control`参数来启用它。如果集群版本>=1.6.0，Kubernetes建议在集群中使用以下插件。
- en: '[PRE40]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The following introduces the usage of these plugins, and why should we need
    them. For more latest information about supported admission control plugins, please
    visit official document [https://kubernetes.io/docs/admin/admission-controllers](https://kubernetes.io/docs/admin/admission-controllers).
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下介绍了这些插件的用法，以及为什么我们需要它们。有关支持的准入控制插件的更多最新信息，请访问官方文档[https://kubernetes.io/docs/admin/admission-controllers](https://kubernetes.io/docs/admin/admission-controllers)。
- en: Namespace life cycle
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 命名空间生命周期
- en: As we learned earlier, when a namespace is deleted, all objects in that namespace
    will be evicted as well. This plugin ensures no new object creation requests could
    be made in the namespace that is terminating or non-existed. It also prevents
    Kubernetes native namespaces from deletion.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所了解的，当命名空间被删除时，该命名空间中的所有对象也将被驱逐。此插件确保在终止或不存在的命名空间中无法发出新的对象创建请求。它还防止了Kubernetes本机命名空间的删除。
- en: LimitRanger
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 限制范围
- en: This plugin ensures `LimitRange` could work properly. With `LimitRange`, we
    could set default requests and limits in a namespace, which will be used when
    launching a pod without specifying the requests and limits.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件确保`LimitRange`可以正常工作。使用`LimitRange`，我们可以在命名空间中设置默认请求和限制，在启动未指定请求和限制的Pod时将使用这些设置。
- en: Service account
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务帐户
- en: The service account plugin must be added if you use service account objects.
    For more information about service account, revisit again service account section
    in this chapter.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用服务帐户对象，则必须添加服务帐户插件。有关服务帐户的更多信息，请再次查看本章中的服务帐户部分。
- en: PersistentVolumeLabel
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PersistentVolumeLabel
- en: '`PersistentVolumeLabel` adds labels to newly-created PV, based on the labels
    provided by the underlying cloud provider. This admission controller has been
    deprecated from 1.8.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolumeLabel`根据底层云提供商提供的标签，为新创建的PV添加标签。此准入控制器已从1.8版本中弃用。'
- en: DefaultStorageClass
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认存储类
- en: This plugin ensures default storage classes could work expectedly if no `StorageClass`
    is set in a Persistent Volume Claim. Different provisioning tools with different
    cloud providers will leverage `DefaultStorageClass` (such as GKE uses Google Cloud
    Persistent Disk). Be sure you have this enabled.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在持久卷索赔中未设置`StorageClass`，此插件确保默认存储类可以按预期工作。不同的云提供商使用不同的供应工具来利用`DefaultStorageClass`（例如GKE使用Google
    Cloud持久磁盘）。请确保您已启用此功能。
- en: ResourceQuota
  id: totrans-183
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源配额
- en: Just like the `LimitRange`, if you're using the `ResourceQuota` object to administer
    different level of QoS, this plugin must be enabled. The ResourceQuota should
    be always be put at the end of the admission control plugin list. As we mentioned
    in the ResourceQuota section, if used quota is less than hard quota, resource
    quota usage will be updated to ensure cluster have the sufficient resource for
    accepting request. Putting it into the end of admission controller list could
    prevent the request from increasing quota usage prematurely if it eventually gets
    rejected by the following controllers.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`LimitRange`一样，如果您正在使用`ResourceQuota`对象来管理不同级别的QoS，则必须启用此插件。资源配额应始终放在准入控制插件列表的末尾。正如我们在资源配额部分提到的，如果使用的配额少于硬配额，资源配额使用将被更新，以确保集群具有足够的资源来接受请求。将其放在准入控制器列表的末尾可以防止请求在被以下控制器拒绝之前过早增加配额使用。
- en: DefaultTolerationSeconds
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 默认容忍秒
- en: Before introducing this plugin, we have to learn what **taints** and **tolerations**
    are.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在介绍此插件之前，我们必须了解**污点**和**容忍**是什么。
- en: Taints and tolerations
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 污点和容忍
- en: Taints and toleration are used to prevent a set of pods from scheduling running
    on some nodes. Taints are applied to nodes, while tolerations are specified to
    pods. The value of taints could be `NoSchedule` or `NoExecute`. If pods running
    one tainted node have no matching toleration, the pods will be evicted.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 污点和忍受度用于阻止一组Pod在某些节点上调度运行。污点应用于节点，而忍受度则指定给Pod。污点的值可以是`NoSchedule`或`NoExecute`。如果在运行一个带有污点的节点上的Pod时没有匹配的忍受度，那么这些Pod将被驱逐。
- en: 'Let''s say we have two nodes:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有两个节点：
- en: '[PRE41]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Let's run a nginx pod now by `kubectl run nginx --image=nginx:1.12.0 --replicas=1
    --port=80` command.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在通过`kubectl run nginx --image=nginx:1.12.0 --replicas=1 --port=80`命令运行一个nginx
    Pod。
- en: 'The pod is running on the first node `ip-172-20-56-91.ec2.internal`:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 该Pod正在第一个节点`ip-172-20-56-91.ec2.internal`上运行：
- en: '[PRE42]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'By the pod description, we can see there are two default tolerations attached
    to the pod. It means if the node is not ready or unreachable yet, wait for 300
    s before the pod is evicted from the node. These two tolerations are applied by
    DefaultTolerationSeconds admission controller plugin. We''ll talk about this later.
    Next, we''ll set a taint to the first node:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通过Pod描述，我们可以看到有两个默认的忍受度附加到Pod上。这意味着如果节点尚未准备好或不可达，那么在Pod从节点中被驱逐之前等待300秒。这两个忍受度由DefaultTolerationSeconds准入控制器插件应用。我们稍后会谈论这个。接下来，我们将在第一个节点上设置一个taint：
- en: '[PRE43]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Since we set the action as `NoExecute`, and `experimental=true` doesn''t match
    any tolerations on our pod, the pod will be removed from the node immediately
    and reschedule. Multi-taints could be applied to a node. The pods must match all
    the tolerations in order to run on that node. The following is an example that
    could pass the tainted node:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们将操作设置为`NoExecute`，并且`experimental=true`与我们的Pod上的任何忍受度不匹配，因此Pod将立即从节点中删除并重新调度。可以将多个taints应用于一个节点。Pod必须匹配所有忍受度才能在该节点上运行。以下是一个可以通过的带污染节点的示例：
- en: '[PRE44]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Other than `Equal` operator, we could use `Exists` as well. In that case, we
    don't need to specify the value. As long as the key presents and effect matches,
    then the pod is eligible to run on that tainted node.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`Equal`运算符，我们也可以使用`Exists`。在这种情况下，我们不需要指定值。只要键存在并且效果匹配，那么Pod就有资格在带污染的节点上运行。
- en: The `DefaultTolerationSeconds` plugin is used to set those pods without any
    toleration set. It will then apply for the default toleration for the taints `notready:NoExecute`
    and `unreachable:NoExecute` for 300 s. If you don't want this behavior to occur
    in the cluster, disabling this plugin could work.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '`DefaultTolerationSeconds`插件用于设置那些没有设置任何忍受度的Pod。然后将应用于`taints`的默认忍受度`notready:NoExecute`和`unreachable:NoExecute`，持续300秒。如果您不希望在集群中发生此行为，禁用此插件可能有效。'
- en: PodNodeSelector
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PodNodeSelector
- en: 'This plugin is used to set `node-selector` annotation to the namespace. When
    the plugin is enabled, passing along a configuration file with `--admission-control-config-file`
    command using the following format:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 此插件用于将`node-selector`注释设置为命名空间。当启用插件时，使用以下格式通过`--admission-control-config-file`命令传递配置文件：
- en: '[PRE45]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Then the `node-selector` annotation will be applied to namespace. The pods on
    that namespace will then run on those matched nodes.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 然后`node-selector`注释将应用于命名空间。然后该命名空间上的Pod将在这些匹配的节点上运行。
- en: AlwaysAdmit
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AlwaysAdmit
- en: This always admits all the requests, its possible to use for test only.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这总是允许所有请求，可能仅用于测试。
- en: AlwaysPullImages
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AlwaysPullImages
- en: Pull policy defines the behavior when kubelet pulling the images. The default
    pull policy is `IfNotPresent`, that is, it will pull the image if it is not present
    locally. If this plugin is enabled, the default pull policy will become `Always`,
    which is, always pull the latest image. This plugin also brings another benefit
    if your cluster is shared by different teams. Whenever a pod is scheduled, it'll
    always pull the latest image whether the image exists locally or not. Then we
    can ensure pod creation request always go through authorization check against
    the image.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 拉取策略定义了kubelet拉取镜像时的行为。默认的拉取策略是`IfNotPresent`，也就是说，如果本地不存在镜像，它将拉取镜像。如果启用了这个插件，那么默认的拉取策略将变为`Always`，也就是说，总是拉取最新的镜像。这个插件还带来了另一个好处，如果你的集群被不同的团队共享。每当一个pod被调度，它都会拉取最新的镜像，无论本地是否存在该镜像。这样我们就可以确保pod创建请求始终通过对镜像的授权检查。
- en: AlwaysDeny
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AlwaysDeny
- en: This always denies all the requests. It may only be used for testing only.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这总是拒绝所有请求。它只能用于测试。
- en: DenyEscalatingExec
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DenyEscalatingExec
- en: This plugin denies any `kubectl exec` and `kubectl attach` command to be escalated
    privilege mode. Pods with privilege mode have the access of host namespace, which
    could become a security risk.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这个插件拒绝任何`kubectl exec`和`kubectl attach`命令升级特权模式。具有特权模式的pod具有主机命名空间的访问权限，这可能会带来安全风险。
- en: Other admission controller plugins
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他准入控制器插件
- en: There are many more other admission controller plugins we could use, such as
    NodeRestriciton to limit kubelet's permission, ImagePolicyWebhook to establish
    a webhook to control the access of the images, SecurityContextDeny for controlling
    the privilege for a pod or a container. Please refer to official documents at
    ([https://kubernetes.io/docs/admin/admission-controllers)](https://kubernetes.io/docs/admin/admission-controllers/))
    to find out other plugins.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多其他的准入控制器插件可以使用，比如NodeRestriciton来限制kubelet的权限，ImagePolicyWebhook来建立一个控制对镜像访问的webhook，SecurityContextDeny来控制pod或容器的权限。请参考官方文档([https://kubernetes.io/docs/admin/admission-controllers)](https://kubernetes.io/docs/admin/admission-controllers/))以了解其他插件。
- en: Summary
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned what is namespace and context and how do they work,
    how to switch between physical cluster and virtual cluster by setting the context.
    We then learned about the important object—service account, which provides to
    identify the processes running within a pod. Then we get to know how to control
    access flow in Kubernetes. We learned what the difference are between authentication
    and authorization, and how they work in Kubernetes. We also learn how to leverage
    RBAC to have fine-grained permission to users. At the end, we learned a couple
    of admission controller plugins, which are the last goalkeepers in the access
    control flow.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了命名空间和上下文是什么以及它们是如何工作的，如何通过设置上下文在物理集群和虚拟集群之间切换。然后我们了解了重要的对象——服务账户，它用于识别在pod内运行的进程。然后我们了解了如何在Kubernetes中控制访问流程。我们了解了认证和授权之间的区别，以及它们在Kubernetes中的工作方式。我们还学习了如何利用RBAC为用户提供细粒度的权限。最后，我们学习了一些准入控制器插件，它们是访问控制流程中的最后一道防线。
- en: AWS is the most major player in public IaaS providers. We've used it lots as
    self-hosted cluster examples in this chapter. In next chapter [Chapter 9](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e),
    *Kubernetes on AWS*, we'll finally learn how to deploy the cluster on AWS and
    basic concept when using AWS.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: AWS是公共IaaS提供商中最重要的参与者。在本章中，我们在自托管集群示例中经常使用它。在下一章[第9章](part0226.html#6NGV40-6c8359cae3d4492eb9973d94ec3e4f1e)，*在AWS上使用Kubernetes*，我们将最终学习如何在AWS上部署集群以及在使用AWS时的基本概念。
