- en: Orchestrating Distributed Solutions with Docker Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Swarm编排分布式解决方案
- en: You can run Docker on a single PC, which is what I've done so far in this book,
    and it's how you would work with Docker in development and basic test environments.
    In more advanced test environments and in production, a single server isn't suitable.
    For high availability and to give you the flexibility to scale your solutions,
    you need multiple servers running as a cluster. Docker has cluster support built
    into the platform, and you can join several Docker hosts together using Docker
    Swarm mode.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在单台PC上运行Docker，这是我在本书中迄今为止所做的，也是您在开发和基本测试环境中使用Docker的方式。在更高级的测试环境和生产环境中，单个服务器是不合适的。为了实现高可用性并为您提供扩展解决方案的灵活性，您需要多台作为集群运行的服务器。Docker在平台中内置了集群支持，您可以使用Docker
    Swarm模式将多个Docker主机连接在一起。
- en: All the concepts you've learned so far (images, containers, registries, networks,
    volumes, and services) still apply in swarm mode. Docker Swarm is an orchestration
    layer. It presents the same API as the standalone Docker Engine, with additional
    functions to manage aspects of distributed computing. When you run a service in
    swarm mode, Docker determines which hosts to run the containers on; it manages
    secure communication between containers on different hosts, and it monitors the
    hosts. If a server in a swarm goes down, Docker schedules the containers it was
    running to start on different hosts to maintain the service level of the application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您学到的所有概念（镜像、容器、注册表、网络、卷和服务）在集群模式下仍然适用。Docker Swarm是一个编排层。它提供与独立的Docker引擎相同的API，还具有额外的功能来管理分布式计算的各个方面。当您在集群模式下运行服务时，Docker会确定在哪些主机上运行容器；它管理不同主机上容器之间的安全通信，并监视主机。如果集群中的服务器宕机，Docker会安排它正在运行的容器在不同的主机上启动，以维持应用程序的服务水平。
- en: Swarm mode has been available in Docker since version 1.12, released in 2015,
    and provides production-hardened enterprise-grade service orchestration. All communication
    in a swarm is secured with mutual TLS, so network traffic between nodes is always
    encrypted. You can store application secrets securely in the swarm, and Docker
    presents them only to those containers that need access. Swarms are scaleable,
    so you can easily add nodes to increase capacity or remove nodes for maintenance.
    Docker can also run automated rolling service updates in swarm mode, so you can
    upgrade your application with zero downtime.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 自2015年发布的Docker 1.12版本以来，集群模式一直可用，并提供经过生产硬化的企业级服务编排。集群中的所有通信都使用相互TLS进行安全保护，因此节点之间的网络流量始终是加密的。您可以安全地在集群中存储应用程序机密，并且Docker只向那些需要访问的容器提供它们。集群是可扩展的，因此您可以轻松添加节点以增加容量，或者移除节点进行维护。Docker还可以在集群模式下运行自动滚动服务更新，因此您可以在零停机的情况下升级应用程序。
- en: 'In this chapter, I''ll set up a Docker Swarm and run NerdDinner across multiple
    nodes. I''ll start by creating individual services and then move on to deploying
    the whole stack from a Compose file. You''ll learn all about:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将设置一个Docker Swarm，并在多个节点上运行NerdDinner。我将首先创建单个服务，然后转而从Compose文件部署整个堆栈。您将学习以下内容：
- en: Creating a swarm and managing nodes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建集群和管理节点
- en: Creating and managing services in swarm mode
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在集群模式下创建和管理服务
- en: Managing application configuration in Docker Swarm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Docker Swarm中管理应用程序配置
- en: Deploying stacks to Docker Swarm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将堆栈部署到Docker Swarm
- en: Deploying updates with zero downtime
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无停机部署更新
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need Docker running on Windows 10 update 18.09, or Windows Server 2019
    to follow along with the examples. The code for this chapter is available at [https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch07](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch07)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要在Windows 10更新18.09或Windows Server 2019上运行Docker才能跟随示例。本章的代码可在[https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch07](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch07)找到。
- en: Creating a swarm and managing nodes
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个群集并管理节点
- en: Docker Swarm mode uses a manager-worker architecture with high availability
    for managers and workers. Managers are administrator-facing, and you use the active
    manager to manage the cluster and the resources running on the cluster. Workers
    are user-facing, and they run the containers for your application services.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm模式使用具有管理者和工作者高可用性的管理者-工作者架构。管理者面向管理员，您可以使用活动管理者来管理集群和运行在集群上的资源。工作者面向用户，并且他们运行您的应用程序服务的容器。
- en: Swarm managers can also run containers for your applications, which is unusual
    in manager-worker architectures. The overhead of managing a small swarm is relatively
    low, so if you have 10 nodes and 3 are managers, the managers can also run a share
    of the application workload (but in production you need to be aware of the risks
    of starving your managers of compute if you're running lots of application workloads
    on them).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 群集管理者也可以运行您的应用程序的容器，这在管理者-工作者架构中是不寻常的。管理小型群集的开销相对较低，因此如果您有10个节点，其中3个是管理者，管理者也可以运行一部分应用程序工作负载（但在生产环境中，您需要意识到在它们上运行大量应用程序工作负载可能会使管理者计算资源不足的风险）。
- en: You can have a mixture of Windows and Linux nodes in the same swarm, which is
    a great way to manage mixed workloads. It's recommended that you have all nodes
    running the same version of Docker, but it can be Docker CE or Docker Enterprise—Docker
    Swarm functionality is built into the core Docker Engine.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在同一个群集中拥有Windows和Linux节点的混合，这是管理混合工作负载的好方法。建议所有节点运行相同版本的Docker，但可以是Docker
    CE或Docker Enterprise——Docker Swarm功能内置于核心Docker引擎中。
- en: Many enterprises running Docker in production have a swarm with Linux nodes
    as the managers, and a mixture of Windows and Linux nodes as the workers. That
    means you can run Windows and Linux apps in containers in a single cluster, using
    the least-cost option for the node operating system.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在生产中运行Docker的企业都有一个具有Linux节点作为管理者的群集，以及Windows和Linux节点混合作为工作者。这意味着您可以在单个集群中使用节点操作系统的最低成本选项来运行Windows和Linux应用程序容器。
- en: Initializing the swarm
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 初始化群集
- en: 'Swarms can be practically any size. You can run a single-node swarm on your
    laptop to test the functionality, and you can scale up to thousands of nodes.
    You start by initializing the swarm with the `docker swarm init` command:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 群集可以是任何规模。您可以在笔记本电脑上运行单节点群集来测试功能，也可以扩展到数千个节点。您可以通过使用`docker swarm init`命令来初始化群集：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This creates the swarm with a single node—the Docker Engine where you run the
    command, and that node becomes the swarm manager. My machine has multiple IP addresses,
    so I've specified the `listen-addr` and `advertise-addr` options that tell Docker
    which network interface to use for swarm communication. It's a good practice to
    always specify the IP address and to use static addresses for the manager nodes.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个具有单个节点的群集——即您运行命令的Docker引擎，并且该节点将成为群集管理器。我的机器有多个IP地址，因此我已经指定了`listen-addr`和`advertise-addr`选项，告诉Docker要使用哪个网络接口进行群集通信。始终指定IP地址并为管理节点使用静态地址是一个良好的做法。
- en: You can keep your swarm secure using an internal private network for the swarm
    traffic, so that communication is not on the public network. You can even keep
    your managers off the public network completely. Only worker nodes with public-facing
    workloads need to be connected to the public network in addition to the internal
    network - and you can even avoid that if you're using a load-balancer as the public
    entrypoint to your infrastructure.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用内部私有网络来保护您的集群，以便通信不在公共网络上。您甚至可以完全将管理节点保持在公共网络之外。只有具有面向公共的工作负载的工作节点需要连接到公共网络，除了内部网络之外-如果您正在使用负载均衡器作为基础架构的公共入口点，甚至可以避免这种情况。
- en: Adding workers to the swarm
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将工作节点添加到集群
- en: The output from `docker swarm init` tells you how to expand the swarm by joining
    other nodes. Nodes can belong to only one swarm, and to join, they need to use
    the joining token. The token prevents rogue nodes joining your swarm if the network
    is compromised, so you need to treat it as a secure secret. Nodes can join as
    workers or managers, and there are different tokens for each. You can view and
    rotate the tokens with the `docker swarm join-token` command.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker swarm init`的输出告诉您如何通过加入其他节点来扩展集群。节点只能属于一个集群，并且要加入，它们需要使用加入令牌。该令牌可以防止恶意节点加入您的集群，如果网络受到损害，因此您需要将其视为安全秘密。节点可以作为工作节点或管理节点加入，并且每个节点都有不同的令牌。您可以使用`docker
    swarm join-token`命令查看和旋转令牌。'
- en: 'On a second machine running the same version of Docker, I can run the `swarm
    join` command to join the swarm:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行相同版本的Docker的第二台机器上，我可以运行`swarm join`命令加入集群：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now my Docker host is running in swarm mode, there are more commands available
    to me when I''m connected to the manager node. The `docker node` commands manage
    the nodes in the swarm, so I can list all the nodes in the swarm and see their
    current status with `docker node ls`:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我的Docker主机正在运行在集群模式下，当我连接到管理节点时，我可以使用更多的命令。`docker node`命令管理集群中的节点，因此我可以列出集群中的所有节点，并使用`docker
    node ls`查看它们的当前状态：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `STATUS` value tells you whether the node is online in the swarm, and the
    `AVAILABILITY` value tells you whether the node is able to run containers. The
    `MANAGER STATUS` field has three options:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`状态`值告诉您节点是否在线在集群中，`可用性`值告诉您节点是否能够运行容器。`管理节点状态`字段有三个选项：'
- en: '`Leader`: The active manager controlling the swarm.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`领导者`：控制集群的活跃管理节点。'
- en: '`Reachable`: A backup manager; it can become the leader if the current leader
    goes down.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`可达`：备用管理节点；如果当前领导者宕机，它可以成为领导者。'
- en: '`No value`: A worker node.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`无值`：工作节点。'
- en: Multiple managers support high availability. Docker Swarm uses the Raft protocol
    to elect a new leader if the current leader is lost, so with an odd number of
    managers, your swarm can survive hardware failure. For production, you should
    have three manager nodes, which is all you need, even for large swarms with hundreds
    of worker nodes.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 多个管理节点支持高可用性。Docker Swarm使用Raft协议在当前领导者丢失时选举新领导者，因此具有奇数个管理节点，您的集群可以在硬件故障时生存。对于生产环境，您应该有三个管理节点，这就是您所需要的，即使对于具有数百个工作节点的大型集群也是如此。
- en: Worker nodes do not automatically get promoted to managers, so if all your managers
    are lost, then you cannot administer the swarm. In that situation, the containers
    on the worker nodes continue running, but there are no managers to monitor the
    worker nodes or the services you have running.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点不会自动晋升为管理节点，因此如果所有管理节点丢失，那么您将无法管理集群。在这种情况下，工作节点上的容器继续运行，但没有管理节点来监视工作节点或您正在运行的服务。
- en: Promoting and removing swarm nodes
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 晋升和删除集群节点
- en: You can make worker nodes into managers with `docker node promote` and make
    manager nodes into workers with `docker node demote`; these are commands you run
    on a manager node.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`docker node promote`将工作节点转换为管理节点，并使用`docker node demote`将管理节点转换为工作节点；这些是您在管理节点上运行的命令。
- en: 'To leave a swarm, you need to run the `docker swarm leave` command on the node
    itself:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要离开Swarm，您需要在节点本身上运行`docker swarm leave`命令：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you have a single-node swarm, you can exit swarm mode with the same command,
    but you need to use the `--force` flag, as this effectively switched you from
    swarm mode back into single Docker Engine mode.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有单节点Swarm，您可以使用相同的命令退出Swarm模式，但是您需要使用`--force`标志，因为这实际上将您从Swarm模式切换回单个Docker
    Engine模式。
- en: The `docker swarm` and `docker node` commands manage the swarm. When you're
    running in swarm mode, you use swarm-specific commands to manage your container
    workload.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker swarm`和`docker node`命令管理着Swarm。当您在Swarm模式下运行时，您将使用特定于Swarm的命令来管理容器工作负载。'
- en: You will see references to *Docker Swarm* and *swarm mode*. Technically, they
    are different things. Docker Swarm was an early orchestrator that was later built
    into the Docker Engine as swarm mode. The *classic* Docker Swarm only ran on Linux,
    so when you're talking about swarm with Windows nodes, it's always swarm mode—but
    it's usually called Docker Swarm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到关于*Docker Swarm*和*Swarm模式*的引用。从技术上讲，它们是不同的东西。Docker Swarm是一个早期的编排器，后来被构建到Docker
    Engine中作为Swarm模式。*经典*的Docker Swarm只在Linux上运行，因此当您谈论带有Windows节点的Swarm时，它总是Swarm模式，但通常被称为Docker
    Swarm。
- en: Running Docker Swarm in the cloud
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中运行Docker Swarm
- en: Docker has a minimal set of infrastructure requirements, so you can easily spin
    up a Docker host or a clustered Docker Swarm in any cloud. All you need to run
    Windows containers at scale is the capacity to run Windows Server virtual machines
    and connect them on a network.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Docker具有最小的基础设施要求，因此您可以轻松在任何云中快速启动Docker主机或集群Docker Swarm。要大规模运行Windows容器，您只需要能够运行Windows
    Server虚拟机并将它们连接到网络。
- en: The cloud is a great place to run Docker, and Docker is a great way to move
    to the cloud. Docker gives you the power of a modern application platform, without
    the restrictions of a **Platform as a Service** (**PaaS**) product. PaaS options
    typically have proprietary deployment systems, proprietary integrations in your
    code, and the developer experience will not use the same runtime.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 云是运行Docker的好地方，而Docker是迁移到云的好方法。Docker为您提供了现代应用程序平台的强大功能，而不受**平台即服务**（**PaaS**）产品的限制。PaaS选项通常具有专有的部署系统、代码中的专有集成，并且开发人员体验不会使用相同的运行时。
- en: Docker lets you package your applications and define your solution structure
    in a portable way that will run the same way on any machine and on any cloud.
    You can use basic **Infrastructure as a Service** (**IaaS**) services, which all
    cloud providers support, and have a consistent deployment, management, and runtime
    experience in every environment.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Docker允许您打包应用程序并以便携方式定义解决方案结构，这样可以在任何机器和任何云上以相同的方式运行。您可以使用所有云提供商支持的基本**基础设施即服务**（**IaaS**）服务，并在每个环境中实现一致的部署、管理和运行时体验。
- en: The major clouds also provide managed container services, but these have centralized
    on Kubernetes—AKS on Azure, EKS on Amazon Web Services, and GKE on Google Cloud.
    At the time of writing, they're all 100% Linux offerings. Windows support for
    Kubernetes is being actively worked on, and the cloud services will begin to offer
    Windows once it's supported, but Kubernetes is a far more complex orchestrator
    than swarm, and I won't cover it here.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的云还提供托管的容器服务，但这些服务已经集中在Kubernetes上——Azure上的AKS，Amazon Web Services上的EKS和Google
    Cloud上的GKE。在撰写本文时，它们都是100%的Linux产品。对于Kubernetes的Windows支持正在积极开发中，一旦支持，云服务将开始提供Windows支持，但Kubernetes比Swarm更复杂，我不会在这里涵盖它。
- en: One of the simplest ways to deploy Docker Swarm in the cloud is to use Terraform,
    which is a powerful **Infrastructure-as-Code** (**IaC**) technology that's typically
    much easier to use than the cloud providers' own templating language or scripting
    tools. With a few dozens lines of configuration, you can define VMs for the manager
    and worker nodes, along with the networking setup, load balancers, and any other
    services you need.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在云中部署Docker Swarm的最简单方法之一是使用Terraform，这是一种强大的基础设施即代码（IaC）技术，通常比云提供商自己的模板语言或脚本工具更容易使用。通过几十行配置，您可以定义管理节点和工作节点的虚拟机，以及网络设置、负载均衡器和任何其他所需的服务。
- en: Docker Certified Infrastructure
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker认证基础设施
- en: Docker uses Terraform to power **Docker Certified Infrastructure** (**DCI**),
    which is a single tool for deploying Docker Enterprise on the major cloud providers
    and the major on-premises virtualization tools. It uses the relevant services
    from each provider to set up enterprise-grade deployments of the Docker Enterprise
    platform, including Universal Control Plane and Docker Trusted Registry.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用Terraform来支持Docker认证基础设施（DCI），这是一个用于在主要云提供商和主要本地虚拟化工具上部署Docker企业的单一工具。它使用每个提供商的相关服务来设置Docker企业平台的企业级部署，包括通用控制平面和Docker可信注册表。
- en: DCI is detailed in a series of Reference Architecture guides from Docker, available
    on the **Docker Success Center** ([https://success.docker.com](https://success.docker.com)).
    It's worth bookmarking that site—you'll also find great guides on modernizing
    traditional applications and best practice documentation for logging, monitoring,
    storage, and networking in containers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: DCI在Docker的一系列参考架构指南中有详细介绍，可在Docker成功中心（[https://success.docker.com](https://success.docker.com)）找到。这个网站值得收藏，你还可以在那里找到关于现代化传统应用程序的指南，以及有关容器中日志记录、监控、存储和网络的最佳实践文档。
- en: Creating and managing services in swarm mode
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在swarm模式下创建和管理服务
- en: In the previous chapter, you saw how to use Docker Compose to organize a distributed
    solution. In a Compose file, you define the parts of your application as services
    using networks to connect them together. The same Docker Compose file format and
    the same service concept is used in swarm mode. In swarm mode, the containers
    that make up a service are called **replicas**. You use the Docker command line
    to create services on the swarm, and the swarm manager creates replicas running
    as containers on the swarm nodes.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您看到了如何使用Docker Compose来组织分布式解决方案。在Compose文件中，您可以使用网络将应用程序的各个部分定义为服务并将它们连接在一起。在swarm模式中，使用相同的Docker
    Compose文件格式和相同的服务概念。在swarm模式中，构成服务的容器被称为副本。您可以使用Docker命令行在swarm上创建服务，而swarm管理器会在swarm节点上作为容器运行副本。
- en: 'I''ll deploy the NerdDinner stack by creating services. All the services will
    run in the same Docker network on my cluster. In swarm mode, Docker has a special
    type of network called **overlay network**. Overlay networks are virtual networks
    that span multiple physical hosts, so containers running on one swarm node can
    reach containers running on another node. Service discovery works in the same
    way: containers access one another by the service name, and Docker''s DNS server
    directs them to a container.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我将通过创建服务来部署NerdDinner堆栈。所有服务将在我的集群上的同一个Docker网络中运行。在swarm模式下，Docker有一种特殊类型的网络称为覆盖网络。覆盖网络是跨多个物理主机的虚拟网络，因此运行在一个swarm节点上的容器可以访问在另一个节点上运行的容器。服务发现的工作方式也是一样的：容器通过服务名称相互访问，Docker的DNS服务器将它们指向一个容器。
- en: 'To create an overlay network, you need to specify the driver to be used and
    give the network a name. The Docker CLI returns with the ID of the new network,
    as it does with other resources:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建覆盖网络，您需要指定要使用的驱动程序并给网络命名。Docker CLI将返回新网络的ID，就像其他资源一样：
- en: '[PRE4]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can list the networks, and you''ll see that the new network uses the overlay
    driver and is scoped to the swarm, which means any containers using this network
    can communicate with one another, whichever node they''re running on:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以列出网络，您会看到新网络使用覆盖驱动程序，并且范围限定为群集，这意味着使用此网络的任何容器都可以相互通信，无论它们在哪个节点上运行：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The output here also shows the default `nat` network, which has a local scope,
    so containers can only reach one another on the same host. There's another network
    created in swarm mode called `ingress`, which is the default network for services
    created with published ports.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的输出还显示了默认的`nat`网络，它具有本地范围，因此容器只能在同一主机上相互访问。在群集模式下创建的另一个网络称为`ingress`，这是具有发布端口的服务的默认网络。
- en: 'I''ll use the new network for the NerdDinner services, because that will segregate
    my app from others on the swarm that will use their own networks. I''ll use a
    Docker Compose file to deploy the whole solution later in this chapter, but I''ll
    start by manually creating services with the `docker service create` command,
    so you can see how services are different than containers. This is how to deploy
    the NATS message queue as a service in Docker Swarm:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用新网络来部署NerdDinner服务，因为这将使我的应用与群集中将使用自己网络的其他应用隔离开来。我将在本章后面使用Docker Compose文件来部署整个解决方案，但我将首先通过手动使用`docker
    service create`命令来创建服务，以便您可以看到服务与容器的不同之处。这是如何在Docker Swarm中将NATS消息队列部署为服务的方法：
- en: '[PRE6]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'There are no required options for `docker service create` other than the image
    name, but for a distributed application, you will want to specify the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker service create`的必需选项除了镜像名称外，但对于分布式应用程序，您需要指定以下内容：'
- en: '`network`: The Docker network to connect to the service containers'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`network`：要连接到服务容器的Docker网络'
- en: '`name`: The service name used as the DNS entry for other components'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：用作其他组件DNS条目的服务名称'
- en: Docker supports different types of DNS resolution for containers. The default
    is Virtual IP `vip` mode, which you should use because it's the most performant.
    `vip` mode is only supported from Windows Server 2019, so for earlier versions
    you will see examples where the endpoint mode is set to `dnsrr`. That's DNS round-robin
    mode, which is less efficient and can cause issues when clients cache DNS responses,
    so avoid it, unless you have to work with containers on Windows Server 2016.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: Docker支持容器的不同类型的DNS解析。默认值是虚拟IP `vip` 模式，您应该使用它，因为它是最高性能的。 `vip` 模式仅支持从Windows
    Server 2019开始，因此对于较早版本，您将看到端点模式设置为`dnsrr`的示例。这是DNS轮询模式，效率较低，并且可能会在客户端缓存DNS响应时引起问题，因此除非必须与Windows
    Server 2016上的容器一起工作，否则应避免使用它。
- en: You run the `service create` command from a Docker CLI connected to the swarm
    manager. The manager looks at all the nodes in the swarm and determines which
    have the capacity to run a replica, and then it schedules the tasks to be created
    as containers on the node(s). The default replica level is *o**ne*, so this command
    just creates a single container—but it could be running on any node in the swarm.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从连接到群集管理器的Docker CLI中运行`service create`命令。管理器查看群集中的所有节点，并确定哪些节点有能力运行副本，然后安排任务在节点上创建为容器。默认副本级别为*one*，因此此命令只创建一个容器，但它可以在群集中的任何节点上运行。
- en: '`docker service ps` shows the replicas that are running the service, including
    the name of the node hosting each container:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker service ps`显示正在运行服务的副本，包括托管每个容器的节点的名称：'
- en: '[PRE7]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In this case, the manager has scheduled a container to run on node `win2019-02`,
    which is the single worker node in my swarm. It looks as if I would get the same
    result if I ran a Docker container on that node directly, but running it as a
    Docker Swarm service gives me all the extra benefits of orchestration:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，经理已经安排了一个容器在节点`win2019-02`上运行，这是我集群中唯一的工作节点。看起来如果我直接在该节点上运行Docker容器，我会得到相同的结果，但是将其作为Docker
    Swarm服务运行给了我编排的所有额外好处：
- en: '**Application reliability**: If this container stops, the manager will schedule
    a replacement to start immediately.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用程序可靠性**：如果此容器停止，经理将安排立即启动替代容器。'
- en: '**Infrastructure reliability**: If the worker node goes down, the manager will
    schedule a new container to run on a different node.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施可靠性**：如果工作节点宕机，经理将安排在不同节点上运行新的容器。'
- en: '**Discoverability**: This container is attached to an overlay network, so it
    can communicate with containers running on other nodes using the service name
    (Windows containers can even talk to Linux containers in the same swarm, and vice
    versa).'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可发现性**：该容器连接到一个覆盖网络，因此可以使用服务名称与在其他节点上运行的容器进行通信（Windows容器甚至可以与同一集群中运行的Linux容器进行通信，反之亦然）。'
- en: There are many more benefits to running services in Docker Swarm over containers
    on individual Docker servers, including security, scalability, and reliable application
    updates. I'll cover them all in this chapter.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在Docker Swarm中运行服务比在单个Docker服务器上运行容器有更多的好处，包括安全性、可扩展性和可靠的应用程序更新。我将在本章中涵盖它们。
- en: In the source code repository, the `ch07-create-services` folder has a script
    that starts all the services for NerdDinner in the correct order. The options
    for each `service create` command are the equivalent of the service definition
    in the Compose file for [Chapter 6](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml),
    *Organizing Distributed Solutions with Docker Compose*. There are just a couple
    of differences in the frontend services and the Traefik reverse proxy.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在源代码存储库中，`ch07-create-services`文件夹中有一个脚本，按正确的顺序启动NerdDinner的所有服务。每个`service
    create`命令的选项相当于[第6章](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml)中Compose文件的服务定义，*使用Docker
    Compose组织分布式解决方案*。前端服务和Traefik反向代理中只有一些差异。
- en: 'Traefik runs just fine in Docker Swarm—it connects to the Docker API to build
    its frontend-routing map, and proxies content from backend containers in exactly
    the same way as it does on a single server running Docker Engine. To register
    services with Traefik in swarm mode, you also need to tell Traefik which port
    the application in the container is using, because it can''t determine that itself.
    The REST API service definition adds the `traefik.port` label:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: Traefik在Docker Swarm中运行得很好——它连接到Docker API来构建其前端路由映射，并且以与在单个运行Docker Engine的服务器上完全相同的方式代理来自后端容器的内容。要在swarm模式下向Traefik注册服务，您还需要告诉Traefik容器中的应用程序使用的端口，因为它无法自行确定。REST
    API服务定义添加了`traefik.port`标签：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Traefik itself is the most complex service to create, with a few extra options
    in swarm mode:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Traefik本身是在swarm模式下创建的最复杂的服务，具有一些额外的选项：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: You can only get information about swarm services from the Docker API running
    on a manager node—that's why you need to connect your Docker CLI to a manager
    to work with swarm resources. The `constraint` option for services ensures Docker
    will only schedule containers to run on nodes that meet the constraint. In this
    case, the service replicas will run only on manager nodes. This isn't the only
    option - you can run Traefik on a worker node if you have configured secure remote
    access to the Docker API.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你只能从运行在管理节点上的Docker API获取有关集群服务的信息，这就是为什么你需要将Docker CLI连接到管理节点以处理集群资源。服务的`constraint`选项确保Docker只会将容器调度到满足约束条件的节点上运行。在这种情况下，服务副本只会在管理节点上运行。这不是唯一的选择
    - 如果你已经配置了对Docker API的安全远程访问，你可以在工作节点上运行Traefik。
- en: To connect Traefik to the Docker API, I previously used a volume to mount the
    Windows named *pipe*, but that feature isn't supported yet in Docker Swarm. So,
    instead, I use a TCP connection to the API, specifying the DNS name of the manager
    `win2019-dev-02`. I've secured my Docker Engine with TLS (as I explained in [Chapter
    1](59b504fb-1012-4118-aa49-c5e0efce06d3.xhtml), *Getting Started with Docker on
    Windows*), so I also provide the client certificates to use the connection securely.
    The certificates are stored on my manager node in `C:\certs\client`, which I mount
    as a directory inside the container.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将Traefik连接到Docker API，我以前使用卷来挂载Windows命名的*pipe*，但是这个功能在Docker Swarm中还不支持。所以，我改用TCP连接到API，指定管理者的DNS名称`win2019-dev-02`。我已经用TLS保护了我的Docker引擎（就像我在[第1章](59b504fb-1012-4118-aa49-c5e0efce06d3.xhtml)中解释的那样，在Windows上使用Docker入门），所以我还提供了客户端证书来安全地使用连接。证书存储在我的管理节点上的`C:\certs\client`中，我将其挂载为容器内的一个目录。
- en: '*Named pipe support for service mounts* means you can use the approach of mounting
    the pipe, which is much easier, as you don''t need to specify the host name of
    the manager, or supply the TLS certificates. That feature is planned for Docker
    19.03, and will probably be available by the time you read this book. The great
    thing about Docker is that it''s built from open source components, so features
    such as this are all discussed in the open—[https://github.com/moby/moby/issues/34795](https://github.com/moby/moby/issues/34795)
    will tell you the background and the current status.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务挂载的命名管道支持*意味着你可以使用挂载管道的方法，这样做更容易，因为你不需要指定管理者的主机名，或者提供TLS证书。这个功能计划在Docker
    19.03中推出，并且可能在你阅读本书时已经可用。Docker的好处在于它是由开源组件构建的，因此诸如此类的功能都是公开讨论的 - [https://github.com/moby/moby/issues/34795](https://github.com/moby/moby/issues/34795)会告诉你背景和当前状态。'
- en: 'When I run the script on my swarm, I get a list of service IDs as the output:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当我在我的集群上运行脚本时，我会得到一个服务ID列表作为输出：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now I can see all the running services with `docker service ls`:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我可以用`docker service ls`看到所有正在运行的服务：
- en: '[PRE11]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Each of the services is listed as having a replica status of `1/1`, which means
    one replica is running out of a requested service level of one replica. That''s
    the number of containers used to run the service. Swarm mode supports two types
    of distributed service: replicated and global . The default is to have a distributed
    service with a single replica, which means one container on the swarm. The `service
    create` commands in my script don''t specify a replica count, so they all use
    the default of *one*.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务都列出了一个`1/1`的副本状态，这意味着一个副本正在运行，而请求的服务级别是一个副本。这是用于运行服务的容器数量。Swarm模式支持两种类型的分布式服务：复制和全局。默认情况下，分布式服务只有一个副本，这意味着在集群上只有一个容器。我的脚本中的`service
    create`命令没有指定副本计数，所以它们都使用默认值*one*。
- en: Running services across many containers
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跨多个容器运行服务
- en: 'Replicated services are how you scale in swarm mode, and you can update running
    services to add or remove containers. Unlike Docker Compose, you don''t need a
    Compose file that defines the desired state of each service; that detail is already
    stored in the swarm from the `docker service create` command. To add more message
    handlers, I use `docker service scale`, passing the name of one or more services
    and the desired service level:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 复制的服务是你如何在集群模式下扩展的方式，你可以更新正在运行的服务来添加或删除容器。与Docker Compose不同，你不需要一个定义每个服务期望状态的Compose文件；这些细节已经存储在集群中，来自`docker
    service create`命令。要添加更多的消息处理程序，我使用`docker service scale`，传递一个或多个服务的名称和期望的服务级别：
- en: '[PRE12]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The message handler services were created with the default single replica,
    so this adds two more containers to share the work of the SQL Server-handler service.
    In a multi-node swarm, the manager can schedule the containers to run on any node
    with a capacity. I don''t need to know or care which server is actually running
    the containers, but I can drill down into the service list with `docker service
    ps` to see where the containers are running:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 消息处理程序服务是使用默认的单个副本创建的，因此这将添加两个容器来共享SQL Server处理程序服务的工作。在多节点集群中，管理器可以安排容器在任何具有容量的节点上运行。我不需要知道或关心哪个服务器实际上在运行容器，但我可以通过`docker
    service ps`深入了解服务列表，看看容器在哪里运行：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In this case, I'm running a two-node swarm, and the replicas are split between
    the nodes `win2019-dev-02` and `win2019-02`. Swarm mode refers to service processes
    as replicas, but they're actually just containers. You can log on to the nodes
    of the swarm and administer service containers with the same `docker ps`, `docker
    logs` and `docker top` commands, as usual.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我正在运行一个双节点集群，副本分布在节点`win2019-dev-02`和`win2019-02`之间。集群模式将服务进程称为副本，但它们实际上只是容器。你可以登录到集群的节点，并像往常一样使用`docker
    ps`、`docker logs`和`docker top`命令管理服务容器。
- en: 'Typically, you won''t do that. The nodes running replicas are just black boxes
    that are managed for you by the swarm; you work with your services through the
    manager node. Just as Docker Compose presents a consolidated view of logs for
    a service, you can get the same from the Docker CLI connected to a swarm manager:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，你不会这样做。运行副本的节点只是由集群为你管理的黑匣子；你通过管理节点与你的服务一起工作。就像Docker Compose为服务提供了日志的整合视图一样，你可以通过连接到集群管理器的Docker
    CLI获得相同的视图：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Replicas are how the swarm provides fault tolerance to services. When you specify
    the replica level for a service with the `docker service create` , `docker service
    update`, or `docker service scale` command, the value is recorded in the swarm.
    The manager node monitors all the tasks for the service. If containers stop and
    the number of running services falls below the desired replica level, new tasks
    are scheduled to replace the stopped containers. Later in the chapter, I'll demonstrate
    that when I run the same solution on a multi-node swarm, I can then take a node
    out of the swarm, without causing any loss of service.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 副本是集群为服务提供容错的方式。当你使用`docker service create`、`docker service update`或`docker
    service scale`命令为服务指定副本级别时，该值将记录在集群中。管理节点监视服务的所有任务。如果容器停止并且运行服务的数量低于期望的副本级别，新任务将被安排以替换停止的容器。在本章后面，我将演示当我在多节点集群上运行相同的解决方案时，我可以从集群中取出一个节点，而不会造成任何服务的丢失。
- en: Global services
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 全局服务
- en: An alternative to replicated services is **global services**. In some cases,
    you may want the same service running on every node of the swarm as a single container
    on each server. To do that, you can run a service in global mode—Docker schedules
    exactly one task on each node, and any new nodes that join will also have a task
    scheduled.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 替代复制服务的选择是全局服务。在某些情况下，您可能希望同一个服务在集群的每个节点上作为单个容器运行。为此，您可以以全局模式运行服务——Docker在每个节点上精确安排一个任务，并且任何加入的新节点也将安排一个任务。
- en: Global services can be useful for high availability with components that are
    used by many services, but, again, you don't get a clustered application just
    by running many instances of it. The NATS message queue can run as a cluster across
    several servers, and it could be a good candidate to run as a global service.
    To run NATS as a cluster, though, each instance needs to know the address of other
    instances—which doesn't work well with dynamic virtual IP addresses allocated
    by the Docker Engine.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 全局服务对于具有许多服务使用的组件的高可用性可能很有用，但是再次强调，并不是通过运行许多实例来获得集群化的应用程序。NATS消息队列可以在多台服务器上作为集群运行，并且可以作为全局服务运行的一个很好的候选。但是，要将NATS作为集群运行，每个实例都需要知道其他实例的地址，这与Docker
    Engine分配的动态虚拟IP地址不兼容。
- en: 'Instead, I can run my Elasticsearch message handler as a global service, so
    every node will have an instance of the message handler running. You can''t change
    the mode of a running service, so, first, I need to remove the original service:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我可以将我的Elasticsearch消息处理程序作为全局服务运行，因此每个节点都将运行一个消息处理程序的实例。您无法更改正在运行的服务的模式，因此首先需要删除原始服务。
- en: '[PRE15]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, I can create a new global service:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我可以创建一个新的全局服务。
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now I have one task running on each node in the swarm, and the total number
    of tasks will grow if nodes are added to the cluster, and shrink if the nodes
    are removed. This can be useful for services that you want to distribute for fault
    tolerance, and you want the total capacity of the service to be proportionate
    to the size of the cluster.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我在集群中的每个节点上都有一个任务在运行，如果节点被添加到集群中，任务的总数将增加，如果节点被移除，任务的总数将减少。这对于您想要分发以实现容错的服务可能很有用，并且您希望服务的总容量与集群的大小成比例。
- en: Global services are also useful in monitoring and auditing functions. If you
    have a centralized monitoring system such as Splunk, or you're using Elasticsearch
    Beats for infrastructure data capture, you could run an agent on each node as
    a global service.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 全局服务在监控和审计功能中也很有用。如果您有诸如Splunk之类的集中式监控系统，或者正在使用Elasticsearch Beats进行基础设施数据捕获，您可以将代理作为全局服务在每个节点上运行。
- en: With global and replicated services, Docker Swarm provides the infrastructure
    to scale your application and maintain specified service levels. This works well
    for on-premises deployments if you have a fixed-size swarm but variable workloads.
    You can scale application components up and down to meet the demand, provided
    they don't all require peak processing at the same time. You have more flexibility
    in the cloud, where you can increase the total capacity of your cluster, just
    by adding new nodes to the swarm, allowing you to scale your application services
    more widely.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 通过全局和复制服务，Docker Swarm提供了扩展应用程序和维护指定服务水平的基础设施。如果您有固定大小的集群但可变的工作负载，这对于本地部署非常有效。您可以根据需求扩展应用程序组件，只要它们不都需要在同一时间进行峰值处理。在云中，您有更多的灵活性，可以通过向集群添加新节点来增加集群的总容量，从而更广泛地扩展应用程序服务。
- en: Running applications at scale across many instances typically adds complexity—you
    need to have a way of registering all the active instances, a way of sharing load
    between them, and a way of monitor all the instances, so that if any fail, they
    don't have any load sent to them. This is all built-in functionality in Docker
    Swarm, which transparently provides service discovery, load-balancing, fault-tolerance
    and the infrastructure for self-healing applications.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多实例中扩展运行应用程序通常会增加复杂性 - 您需要一种注册所有活动实例的方式，一种在它们之间共享负载的方式，以及一种监视所有实例的方式，以便如果有任何实例失败，它们不会有任何负载发送到它们。这一切都是Docker
    Swarm中内置的功能，它透明地提供服务发现、负载均衡、容错和自愈应用程序的基础设施。
- en: Load-balancing and scale in swarm mode
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm模式中的负载均衡和扩展
- en: Docker uses DNS for service discovery, so containers can find one another with
    standard networking. Applications use server names in their client connection
    configuration, and when the application makes a DNS query to find the target,
    Docker responds with the container's IP address. It's the same in Docker Swarm
    when your target **server** name could actually be the name of a Docker service
    running with dozens of replicas across the cluster.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用DNS进行服务发现，因此容器可以通过标准网络找到彼此。应用程序在其客户端连接配置中使用服务器名称，当应用程序进行DNS查询以找到目标时，Docker会响应容器的IP地址。在Docker
    Swarm中也是一样的，当您的目标**服务器**名称实际上可能是在集群中运行着数十个副本的Docker服务的名称。
- en: 'There are two ways for Docker to respond to manage DNS for a service with multiple
    replicas. The default is to use **VIP**: a **virtual IP address**. Docker uses
    a single IP address for the service, and relies on the networking stack in the
    host operating system to route a request on the VIP to an actual container. VIP
    takes care of load-balancing and health. Requests are shared among all the healthy
    containers in the service. This feature has long been established in Linux, and
    is new to Windows with Server 2019.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Docker有两种方式来管理具有多个副本的服务的DNS响应。默认情况下是使用**VIP**：虚拟IP地址。Docker为服务使用单个IP地址，并依赖于主机操作系统中的网络堆栈将VIP上的请求路由到实际的容器。VIP负责负载均衡和健康。请求被分享给服务中的所有健康容器。这个功能在Linux中已经存在很久了，在Windows
    Server 2019中是新功能。
- en: 'The alternative to VIP is **DNSRR**: **DNS round-robin**, which you specify
    in the `endpoint_mode` setting in the service configuration. DNSRR returns a list
    of the IP addresses of all the healthy containers in the service, and the order
    of the list is rotated to provide load-balancing. DNSRR was the only option for
    Windows containers before Server 2019, and you will see it in lots of examples,
    but VIP is a better option. Clients have a tendency to cache DNS query responses.
    With DNSRR, you can update a service and find clients have cached the IP address
    of an old container that has been replaced, so their connection fails. That doesn''t
    happen with VIP, where there''s a single IP address in the DNS response, and clients
    can safely cache it because it will always route to a healthy container.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: VIP的替代方案是**DNSRR**：**DNS轮询**，您可以在服务配置中的`endpoint_mode`设置中指定。DNSRR返回服务中所有健康容器的IP地址列表，并且列表的顺序会轮换以提供负载均衡。在Windows
    Server 2019之前，DNSRR是Windows容器的唯一选项，并且您会在许多示例中看到它，但VIP是更好的选择。客户端有缓存DNS查询响应的倾向。使用DNSRR，您可以更新一个服务并发现客户端已经缓存了一个已被替换的旧容器的IP地址，因此它们的连接失败。这在VIP中不会发生，在VIP中，DNS响应中有一个单一的IP地址，客户端可以安全地缓存它，因为它总是会路由到一个健康的容器。
- en: Docker Swarm takes care of load-balancing network traffic between service replicas,
    but it also load-balances external traffic coming into the swarm. In the new NerdDinner
    architecture, there is only one component that is publicly accessible—the **Traefik
    reverse proxy**. We know a port can only be used by a single process on a machine,
    so that should mean we can only scale the proxy service to a maximum of one container
    for each node in the cluster. But Docker Swarm lets us over provision or under
    provision the service, using the same port on the machine for zero or many replicas.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm负责在服务副本之间负载平衡网络流量，但它也负责负载平衡进入集群的外部流量。在新的NerdDinner架构中，只有一个组件是公开访问的——Traefik反向代理。我们知道一个端口在一台机器上只能被一个进程使用，所以这意味着我们只能将代理服务扩展到集群中每个节点的最大一个容器。但是Docker
    Swarm允许我们过度或不足地提供服务，使用机器上的相同端口来处理零个或多个副本。
- en: A swarm service attached to an overlay network behaves differently to standard
    containers when you publish ports. Every node in the swarm listens on the published
    port, and when traffic is received, it gets directed to a healthy container. That
    container could be running on the node that received the request, or on a different
    node.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 附加到覆盖网络的集群服务在发布端口时与标准容器的行为不同。集群中的每个节点都监听发布的端口，当接收到流量时，它会被定向到一个健康的容器。该容器可以在接收请求的节点上运行，也可以在不同的节点上运行。
- en: 'In this example, the client makes an HTTP GET request on standard port `80`
    for a service running in Docker Swarm:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，客户端在Docker Swarm中运行的服务的标准端口`80`上进行了HTTP GET请求：
- en: '![](Images/f379e589-aa28-4882-9d1f-d8aa739e6e2f.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/f379e589-aa28-4882-9d1f-d8aa739e6e2f.png)'
- en: The client request reaches a node that is not running any of the service replicas.
    The node has no containers listening on port `80`, so it cannot handle the request
    directly.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端请求到达一个没有运行任何服务副本的节点。该节点没有在端口`80`上监听的容器，因此无法直接处理请求。
- en: The receiving node forwards on the request to another node in the swarm that
    does have a container listening on port `80`—this is all invisible to the original
    client.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接收节点将请求转发到集群中另一个具有在端口`80`上监听的容器的节点——这对原始客户端来说是不可见的。
- en: The new node forwards the request on to the running container, which processes
    it and sends the response.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新节点将请求转发到正在运行的容器，该容器处理请求并发送响应。
- en: This is called **ingress networking**, and it's an extremely powerful feature.
    It means you can run a low-scale service on a large cluster, or a high-scale service
    on a small cluster, and they will work in the same way. If the service is running
    with fewer replicas than there are nodes in the cluster, that isn't an issue,
    because Docker will transparently send the request to another node. If the service
    is running with more replicas than there are nodes, that isn't an issue, because
    every node can handle the request and Docker load-balances traffic between containers
    on the nodes.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这被称为**入口网络**，它是一个非常强大的功能。这意味着您可以在大型集群上运行低规模的服务，或者在小型集群上运行高规模的服务，它们将以相同的方式工作。如果服务的副本少于集群中的节点数，这不是问题，因为Docker会透明地将请求发送到另一个节点。如果服务的副本多于节点数，这也不是问题，因为每个节点都可以处理请求，Docker会在节点上的容器之间负载平衡流量。
- en: Networking in Docker Swarm is a topic that's worth understanding in detail,
    because it will help you design and deliver scaleable and resilient systems. I
    have authored a Pluralsight course called **Managing Load Balancing and Scale
    in Docker Swarm Mode Clusters** that covers all the key topics for Linux and Windows
    containers.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm中的网络是一个值得详细了解的主题，因为它将帮助您设计和交付可扩展和具有弹性的系统。我编写了一门名为**在Docker Swarm模式集群中管理负载平衡和扩展**的Pluralsight课程，涵盖了Linux和Windows容器的所有关键主题。
- en: Load-balancing and service discovery is all based on healthy containers, and
    it's a Docker Swarm feature that doesn't need any special setup from my side.
    A service running on an overlay network in swarm mode defaults to VIP service
    discovery and ingress networking for published ports. When I run NerdDinner in
    Docker Swarm, I don't need any changes to my deployment to gain high availability
    and scale in a production environment, and I can focus on my own application's
    configuration.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡和服务发现都基于健康的容器，并且这是Docker Swarm的一个功能，不需要我进行任何特殊设置。在群集模式下运行的服务默认为VIP服务发现和用于发布端口的入口网络。当我在Docker
    Swarm中运行NerdDinner时，我不需要对我的部署进行任何更改，就可以在生产环境中获得高可用性和扩展性，并且可以专注于自己应用程序的配置。
- en: Managing application configuration in Docker Swarm
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker Swarm中管理应用程序配置
- en: I spent some time in [Chapter 5](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml), *Adopting
    Container-First Solution Design* building a flexible configuration system into
    my Docker images for the NerdDinner stack. The core principle of that was to bundle
    the default configuration for development into each image, but allow settings
    to be overridden when you run a container. That means we'll use the same Docker
    image in every environment, just swapping out the configuration settings to change
    behavior.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[第5章](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml)中花了一些时间，*采用基于容器的解决方案设计*，为NerdDinner堆栈构建了一个灵活的配置系统。其中的核心原则是将开发的默认配置捆绑到每个镜像中，但允许在运行容器时覆盖设置。这意味着我们将在每个环境中使用相同的Docker镜像，只是交换配置设置以更改行为。
- en: That works for a single Docker Engine where I can use environment variables
    to override individual settings and volume mounts to replace whole configuration
    files. You can do much more with configuration in Docker Swarm—using Docker config
    objects and Docker secrets to store data in the swarm that can be delivered to
    containers. This is a much neater way of dealing with configuration and sensitive
    data than using environment variables and files, but it means I still use the
    same Docker image in every environment.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这适用于单个Docker引擎，我可以使用环境变量来覆盖单个设置，并使用卷挂载来替换整个配置文件。在Docker Swarm中，您可以使用Docker配置对象和Docker秘密来存储可以传递给容器的群集中的数据。这比使用环境变量和文件更加整洁地处理配置和敏感数据，但这意味着我在每个环境中仍然使用相同的Docker镜像。
- en: Storing configuration in Docker config objects
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker配置对象中存储配置
- en: There are several new resources in swarm mode—as well as nodes and services,
    there are stacks, secrets, and configs. Config objects are just text files that
    are created in the swarm and have surfaced as files inside service containers.
    They're a great way of managing configuration settings, because they give you
    a single place to store the settings for all your applications.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在群集模式中有几种新资源 - 除了节点和服务外，还有堆栈、秘密和配置。配置对象只是在群集中创建的文本文件，并在服务容器内部作为文件出现。它们是管理配置设置的绝佳方式，因为它们为您提供了一个存储所有应用程序设置的单一位置。
- en: You use config objects in two ways. You create and manage them with `docker
    config` commands, and you make them available to services in Docker service commands
    and Docker Compose files. This clean separation means your application definition
    is separate from your configuration—the definition is the same everywhere, and
    the configuration is loaded by Docker from the environment.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以以两种方式使用配置对象。您可以使用`docker config`命令创建和管理它们，并在Docker服务命令和Docker Compose文件中使其对服务可用。这种清晰的分离意味着您的应用程序定义与配置分开
    - 定义在任何地方都是相同的，而配置是由Docker从环境中加载的。
- en: Docker surfaces a config object as a text file inside a container at the path
    you specify, so you could have a secret called `my-app-config` in the swarm that
    appears as `C:\my-app\config\appSettings.config`. Docker doesn't care about the
    file contents, so it could be XML, JSON, key-value pairs, or anything else. It's
    up to your application to actually do something with the file, which could be
    using the complete file as config, or merging the file contents with some default
    configuration baked into the Docker image.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Docker将配置对象表面化为容器内的文本文件，位于您指定的路径，因此您可以在swarm中拥有一个名为`my-app-config`的秘密，显示为`C:\my-app\config\appSettings.config`。Docker不关心文件内容，因此它可以是XML、JSON、键值对或其他任何内容。由您的应用程序实际执行文件的操作，这可以是使用完整文件作为配置，或将文件内容与Docker镜像中内置的一些默认配置合并。
- en: 'In my modernization of NerdDinner, I''ve moved to the .NET Core configuration
    framework for my application settings. I use the same `Config` class in all the
    .NET Framework and .NET Core apps that make up NerdDinner. The `Config` class
    adds custom file locations for configuration providers:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在我现代化NerdDinner时，我已经为我的应用程序设置转移到了.NET Core配置框架。我在组成NerdDinner的所有.NET Framework和.NET
    Core应用程序中都使用相同的`Config`类。`Config`类为配置提供程序添加了自定义文件位置：
- en: '[PRE17]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The configuration providers are listed in reverse-order of precedence. First,
    they're loaded from the `config/appsettings.json` file that is part of the application
    image. Then, any environment variables are merged in—adding new keys, or replacing
    the values of existing keys. Next, if a file exists at the path `config/config.json`
    its contents get merged in—overriding any existing settings. And lastly if a file
    exists at `config/secrets.json` then its values are merged in.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 配置提供程序按优先顺序倒序列出。首先，它们从应用程序镜像的`config/appsettings.json`文件中加载。然后，合并任何环境变量-添加新键，或替换现有键的值。接下来，如果路径`config/config.json`处存在文件，则其内容将被合并-覆盖任何现有设置。最后，如果路径`config/secrets.json`处存在文件，则其值将被合并。
- en: This pattern lets me use a hierarchy of configuration sources. The default values
    for the app are all present in the Docker image. At runtime, users can specify
    overrides with environment variables or environment variable files—which is easy
    for developers working on single Docker hosts. In a clustered environment, the
    deployment can use Docker config objects and secrets, which override the default
    values and any environment variables.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这种模式让我可以使用一系列配置源。应用程序的默认值都存在于Docker镜像中。在运行时，用户可以使用环境变量或环境变量文件指定覆盖值-这对于在单个Docker主机上工作的开发人员来说很容易。在集群环境中，部署可以使用Docker配置对象和秘密，这将覆盖默认值和任何环境变量。
- en: As a simple example, I can change the logging level for the new REST API. In
    the `appsettings.json` file in the Docker image, the logging level is set to `Warning`.
    The app writes information-level logs every time there's a `GET` request, so if
    I change the logging level in config, I'll be able to see those log entries.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 举个简单的例子，我可以更改新REST API的日志级别。在Docker镜像的`appsettings.json`文件中，日志级别设置为`Warning`。每次有`GET`请求时，应用程序都会写入信息级别的日志，因此如果我在配置中更改日志级别，我将能够看到这些日志条目。
- en: 'I have the settings I want to use in a file called `nerd-dinner-api-config.json`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要在名为`nerd-dinner-api-config.json`的文件中使用我想要的设置：
- en: '[PRE18]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'First, I need to store that as a config object in the swarm, so containers
    don''t need access to the original file. I do that with `docker config create`,
    giving the object a name and the path to the source of the configuration:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我需要将其存储为swarm中的配置对象，因此容器不需要访问原始文件。我使用`docker config create`来实现这一点，给对象一个名称和配置源的路径。
- en: '[PRE19]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You only need access to the file when you create the config object. Now the
    data is stored in the swarm. Any node in the swarm can get the config data and
    supply it to containers, and anyone with access to the Docker Engine can see the
    config data without needing that source file. `docker config inspect` shows you
    the contents of the config object:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 您只需要在创建配置对象时访问该文件。现在数据存储在swarm中。swarm中的任何节点都可以获取配置数据并将其提供给容器，任何具有对Docker Engine访问权限的人都可以查看配置数据，而无需该源文件。`docker
    config inspect`会显示配置对象的内容。
- en: '[PRE20]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You can see the plain-text value of the config object by inspecting it. This
    is great for troubleshooting application issues, but bad for security—you should
    always use Docker secrets for sensitive configuration values, never config objects.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过检查来查看配置对象的纯文本值。这对于故障排除应用程序问题非常有用，但对于安全性来说不好——您应该始终使用Docker secrets来存储敏感配置值，而不是配置对象。
- en: Using Docker config objects in swarm services
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在swarm服务中使用Docker配置对象
- en: You make config objects available to containers when you create the service,
    using the `--config` option. You should then be able to use them directly in your
    application, but there may be a catch. When config objects are presented as files
    to the container, they're secured so only administrative accounts can read them.
    If your application is running as a least-privileged user, it can see the config
    file, but it can't read it. This is a security feature, intended to keep your
    configuration files safe if someone gains access to the filesystem in the container.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建服务时，您可以使用`--config`选项将配置对象提供给容器。然后，您应该能够直接在应用程序中使用它们，但可能会有一个陷阱。当将配置对象作为文件呈现给容器时，它们受到保护，只有管理帐户才能读取它们。如果您的应用程序以最低特权用户身份运行，它可以看到配置文件，但无法读取它。这是一个安全功能，旨在在某人获得对容器中文件系统的访问权限时保护您的配置文件。
- en: This is different in Linux containers, where you can specify the ID of the user
    who has file ownership inside the container, so you can give least-privileged
    accounts access to the file. Windows containers don't support that feature, but
    Windows containers are evolving to be feature-complete with Linux containers,
    so this should come in a future release. At the time of writing, to use config
    objects, the application needs to be running as an administrator account, or as
    an account with local system access.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux容器中情况就不同了，您可以指定在容器内具有文件所有权的用户ID，因此可以让最低特权帐户访问该文件。Windows容器不支持该功能，但Windows容器正在不断发展，以实现与Linux容器功能完备，因此这应该会在未来的版本中实现。在撰写本文时，要使用配置对象，应用程序需要以管理员帐户或具有本地系统访问权限的帐户运行。
- en: Running your application with elevated permissions is not a good idea from a
    security perspective, but it is less of a concern when you run in a container.
    I cover this in [Chapter 9](ea2edfd1-c625-4599-8ec2-d5ae811941ef.xhtml), *Understanding
    the Security Risks and Benefits of Docker*.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以提升的权限运行应用程序在安全角度不是一个好主意，但当您在容器中运行时，这就不那么值得关注了。我在《第9章》中涵盖了这一点，*了解Docker的安全风险和好处*。
- en: 'I''ve updated the Dockerfile for the REST API from [Chapter 5](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml),
    *Adopting Container-First Solution Design*, to use the built-in admin account
    in the container:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经更新了来自《第5章》*采用基于容器的解决方案设计*的REST API的Dockerfile，以使用容器中的内置管理员帐户：
- en: '[PRE21]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'All that''s changed is the `USER` instruction, which sets the user for the
    rest of the Dockerfile and for container startup. The code is exactly the same:
    I''m still using the builder image from [Chapter 5](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml),
    *Adopting Container-First Solution Design*. I''ve built this new image as `dockeronwindows/ch07-nerd-dinner-api:2e`,
    and I can upgrade my running API service and apply the new configuration with
    `docker service update`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 改变的只是`USER`指令，它设置了Dockerfile的其余部分和容器启动的用户。代码完全相同：我仍然使用来自[第5章](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml)的构建器镜像，*采用面向容器的解决方案设计*。我已将此新镜像构建为`dockeronwindows/ch07-nerd-dinner-api:2e`，并且可以升级正在运行的API服务并应用新配置与`docker
    service update`：
- en: '[PRE22]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Updating a service replaces the running replicas with the new configuration,
    in this case, using a new image and applying the config object. Now when I make
    a `GET` request to the REST API, it''s logging at an information level, and I
    can see a lot more detail in the service logs:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 更新服务将正在运行的副本替换为新配置，在本例中，使用新镜像并应用配置对象。现在，当我对REST API进行`GET`请求时，它会以信息级别记录日志，并且我可以在服务日志中看到更多细节：
- en: '[PRE23]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You can use this approach for feature flags and behavior settings that change
    between environments. It's a really flexible approach to application configuration.
    Developers using a single Docker Engine can run the container with the default
    settings in the image, or override them with environment variables, or replace
    the whole config files by mounting a local volume. In test-and-production environments
    using Docker Swarm, admins can manage configuration centrally with config objects—still
    using the exact same Docker image in every environment.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用此方法来处理在不同环境之间更改的功能标志和行为设置。这是一种非常灵活的应用程序配置方法。使用单个Docker引擎的开发人员可以使用镜像中的默认设置运行容器，或者使用环境变量覆盖它们，或者通过挂载本地卷替换整个配置文件。在使用Docker
    Swarm的测试和生产环境中，管理员可以使用配置对象集中管理配置，而在每个环境中仍然使用完全相同的Docker镜像。
- en: Storing sensitive data in Docker secrets
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker secrets中存储敏感数据
- en: Swarm mode is inherently secure. Communication among all the nodes is encrypted,
    and the swarm provides an encrypted data store that is distributed among the manager
    nodes. You can use this store for application **secrets**. Secrets work in exactly
    the same way as config objects—you create them in the swarm, and then you make
    them available to services. The difference is that the secret is encrypted in
    the swarm's data store, and it's encrypted in transit from the manager to the
    worker node. It's only decrypted inside the container running the replica, where
    it gets surfaced as a file in the same way as config objects.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式本质上是安全的。所有节点之间的通信都是加密的，并且swarm提供了分布在管理节点之间的加密数据存储。您可以将此存储用于应用程序**秘密**。秘密的工作方式与配置对象完全相同-您在swarm中创建它们，然后使它们对服务可用。不同之处在于，秘密在swarm的数据存储中是加密的，并且在从管理节点到工作节点的传输中也是加密的。它只在运行副本的容器内解密，然后以与配置对象相同的方式作为文件显示。
- en: Secrets are created with a name and the contents of the secret, which can be
    read from a file or entered into the command-line. I'm going to move my sensitive
    data to secrets, starting with the SQL Server administrator account password.
    In the `ch07-app-config` folder, I have a folder called `secrets` that contains
    a secret files for the database password. I'll use that to securely store the
    password in the swarm, but I need to do some work to my database image before
    it can support secrets.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密是通过名称和秘密内容创建的，可以从文件中读取或输入到命令行中。我打算将我的敏感数据移动到secrets中，首先是SQL Server管理员帐户密码。在`ch07-app-config`文件夹中，我有一个名为`secrets`的文件夹，其中包含数据库密码的秘密文件。我将使用它来安全地存储密码在swarm中，但在数据库镜像支持秘密之前，我需要对其进行一些工作。
- en: I packaged my latest SQL Server database schema in the Docker image `dockeronwindows/ch06-nerd-dinner-db`.
    That image uses environment variables to set the administrator password, which
    is fine for developers, but not good in a test environment where you want to restrict
    access. I have a new version for this chapter with an updated Dockerfile and startup
    script for the database, so I can read in the password from a secret file.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我将最新的SQL Server数据库架构打包到Docker镜像`dockeronwindows/ch06-nerd-dinner-db`中。该映像使用环境变量来设置管理员密码，这对开发人员来说很好，但在测试环境中不太好，因为您希望限制访问。我为本章准备了一个更新的版本，其中包括用于数据库的更新的Dockerfile和启动脚本，因此我可以从秘密文件中读取密码。
- en: 'In the `InitializeDatabase.ps1` script for `ch07-nerd-dinner-db`, I''ve added
    a new parameter called `sa_password_path` and some simple logic to read the password
    from the file, if one exists in that path:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ch07-nerd-dinner-db`的`InitializeDatabase.ps1`脚本中，我添加了一个名为`sa_password_path`的新参数，并添加了一些简单的逻辑，以从文件中读取密码，如果该路径中存在文件：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This is a completely different approach to the one taken in the REST API. Applications
    have their own expectations about configuration, and you'll need to integrate
    that with Docker's approach of surfacing config data in files. In most cases,
    you can do it all in the Dockerfile, so you shouldn't need to change code to read
    config from a file directly.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种完全不同的方法，与REST API中采用的方法相反。应用程序对配置有自己的期望，您需要将其与Docker的方法整合起来，以在文件中显示配置数据。在大多数情况下，您可以在Dockerfile中完成所有操作，因此不需要更改代码直接从文件中读取配置。
- en: 'The Dockerfile uses an environment variable with a default value for the path
    to the password file:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile使用具有密码文件路径的默认值的环境变量：
- en: '[PRE25]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This still supports different ways of running the database. Developers can run
    it without specifying any configuration settings, and it will use the default
    password built into the image—which is the same default built into the connection
    strings for the application images. In a clustered environment, admins can create
    the secret separately from deploying the app and secure access to the database
    container.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这仍然支持以不同方式运行数据库。开发人员可以在不指定任何配置设置的情况下运行它，并且它将使用内置于映像中的默认密码，这与应用程序映像的连接字符串中的相同默认密码相同。在集群环境中，管理员可以单独创建秘密，而无需部署应用程序，并安全地访问数据库容器。
- en: 'I need to create the secret and then update the database service to use the
    secret and the new image that applies the password from the secret:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我需要创建秘密，然后更新数据库服务以使用秘密和应用密码的新映像：
- en: '[PRE26]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now the database is using a strong password that is protected by Docker Swarm.
    Users with access to the Docker Engine can''t see the contents of the secret,
    as it''s only ever decrypted inside a container for a service that explicitly
    uses the secret. I can inspect the secret, but I only see metadata:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据库正在使用由Docker Swarm保护的强密码。可以访问Docker引擎的用户无法看到秘密的内容，因为它只在明确使用秘密的服务的容器内解密。我可以检查秘密，但我只能看到元数据：
- en: '[PRE27]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Right now my application is broken, because I've updated the database password
    without updating the connection strings in the applications that use the database.
    This is the danger of managing distributed applications imperatively, by issuing
    commands to the Docker Swarm. Instead, you should manage your applications declaratively,
    using a Docker Compose file to define all the services and other resources and
    deploying them as a Docker stack.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我的应用程序出现了问题，因为我已更新了数据库密码，但没有更新使用数据库的应用程序中的连接字符串。这是通过向Docker Swarm发出命令来管理分布式应用程序的危险。相反，您应该使用Docker
    Compose文件以声明方式管理应用程序，定义所有服务和其他资源，并将它们部署为Docker堆栈。
- en: Deploying stacks to Docker Swarm
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将堆栈部署到Docker Swarm
- en: Stacks in Docker Swarm address the limitations of using Docker Compose with
    a single host, or creating services manually on a Docker Swarm. You create a stack
    from a Compose file, and Docker stores all the metadata for the stack's services
    in the swarm. This means Docker is aware that the set of resources represents
    one application, and you can manage services from any Docker client without needing
    the Compose file.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm中的堆栈解决了在单个主机上使用Docker Compose或在Docker Swarm上手动创建服务的限制。您可以从Compose文件创建堆栈，并且Docker将堆栈服务的所有元数据存储在Swarm中。这意味着Docker知道这组资源代表一个应用程序，您可以在任何Docker客户端上管理服务，而无需Compose文件。
- en: A *stack* is an abstraction over all the objects that make up your application.
    It contains services, volumes, and networks just like a standard Docker Compose
    file, but it also supports Docker Swarm objects—configs and secrets—and additional
    deployment settings for running applications at scale.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*堆栈*是对构成您的应用程序的所有对象的抽象。它包含服务、卷和网络，就像标准的Docker Compose文件一样，但它还支持Docker Swarm对象——配置和密码——以及用于在规模上运行应用程序的附加部署设置。'
- en: Stacks can even abstract the orchestrator you're using. Docker Enterprise supports
    both Docker Swarm and Kubernetes on the same cluster, and you can deploy and manage
    applications as stacks to either orchestrator, using the simple Docker Compose
    format and the Docker CLI.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 堆栈甚至可以抽象出您正在使用的编排器。Docker Enterprise同时支持Docker Swarm和Kubernetes在同一集群上，并且您可以使用简单的Docker
    Compose格式和Docker CLI将应用程序部署和管理为堆栈到任一编排器。
- en: Defining a stack using Docker Compose files
  id: totrans-168
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose文件定义堆栈
- en: The Docker Compose file schema has evolved from supporting client-side deployments
    on single Docker hosts to stack deployments across Docker Swarm. Different sets
    of attributes are relevant in different scenarios, and the tools enforce that.
    Docker Compose will ignore attributes that apply only to stack deployments, and
    Docker Swarm will ignore attributes that apply only to single-node deployments.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose文件模式已经从支持单个Docker主机上的客户端部署发展到Docker Swarm上的堆栈部署。不同的属性集在不同的场景中是相关的，并且工具会强制执行。Docker
    Compose将忽略仅适用于堆栈部署的属性，而Docker Swarm将忽略仅适用于单节点部署的属性。
- en: 'I can make use of multiple Compose files to exploit this, defining the basic
    setup of my application in one file, adding local settings in one override file
    and swarm settings in another override file. I''ve done that with the Compose
    files in the `ch07-docker-compose` folder. The core service definitions in `docker-compose.yml`
    are very simple now—they only include attributes that apply to every deployment
    mode. Even the reverse proxy definition for Traefik is simple:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以利用多个Compose文件来实现这一点，在一个文件中定义应用程序的基本设置，在一个覆盖文件中添加本地设置，并在另一个覆盖文件中添加Swarm设置。我已经在`ch07-docker-compose`文件夹中的Compose文件中这样做了。`docker-compose.yml`中的核心服务定义现在非常简单，它们只包括适用于每种部署模式的属性。甚至Traefik的反向代理定义也很简单：
- en: '[PRE28]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'In the `docker-compose.local.yml` override file, I add the attributes that
    are relevant when I''m developing the application on my laptop and deploying with
    Docker Compose. For Traefik, I need to configure the command to run and the ports
    to publish and mount a volume for the Docker Engine named pipe:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在`docker-compose.local.yml`覆盖文件中，我添加了在我的笔记本电脑上开发应用程序和使用Docker Compose部署时相关的属性。对于Traefik，我需要配置要运行的命令以及要发布的端口，并挂载一个用于Docker
    Engine命名管道的卷：
- en: '[PRE29]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In the `docker-compose.swarm.yml` override file, I have the attribute to apply
    when I''m running in a clustered Docker Swarm environment—which could be a two-node
    swarm in test and a 200-node swarm in production; the Compose file would be the
    same. I set up the Traefik command to connect to the swarm manager using TCP,
    and I''m using secrets to store the TLS certificates in the swarm:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `docker-compose.swarm.yml` 覆盖文件中，我有一个属性，当我在集群化的 Docker Swarm 环境中运行时应用——这可能是测试中的两节点
    swarm 和生产中的 200 节点 swarm；Compose 文件将是相同的。 我设置了 Traefik 命令以使用 TCP 连接到 swarm 管理器，并且我正在使用
    secrets 在 swarm 中存储 TLS 证书：
- en: '[PRE30]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The only part of this application manifest that isn't portable is the DNS name
    of my swarm manager, `win2019-dev-02`. I explained in [Chapter 6](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml),
    *Organizing Distributed Solutions with Docker Compose,* that you can't mount the
    named pipe in swarm mode yet, but it's coming soon. When that feature arrives,
    I can use the named pipe for Traefik in swarm mode in the same way as on a single
    Docker Engine, and my Compose files will work on any Docker cluster.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序清单的唯一不可移植部分是我的 swarm 管理器的 DNS 名称 `win2019-dev-02`。 我在[第6章](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml)中解释过，*使用Docker
    Compose组织分布式解决方案*，在 swarm 模式下还不能挂载命名管道，但很快就会推出。 当该功能到来时，我可以在 swarm 模式下像在单个 Docker
    引擎上一样使用命名管道来使用 Traefik，并且我的 Compose 文件将在任何 Docker 集群上运行。
- en: 'The pattern is the same for the rest of the services: there''s a basic definition
    in docker: `compose.yml`, a set of overrides for developers in the local file,
    and an alternative set of overrides in the swarm file. The core Compose file can''t
    be used on its own, because it doesn''t have all the configuration specified,
    which is a different approach from [Chapter 6](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml), *Organizing
    Distributed Solutions with Docker Compose,* where my Docker Compose file was set
    up for development. You can use whichever approach works best for you, but the
    advantage of this way is that the setup for every environment is captured in its
    own override file.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 其余服务的模式相同：`compose.yml` 中有基本定义，本地文件中有开发人员的一组覆盖，以及一组替代覆盖在 swarm 文件中。 核心 Compose
    文件不能单独使用，因为它没有指定的所有配置，这与[第6章](83637474-1791-48b6-8ce1-5aa07f00b46c.xhtml)中的不同，*使用Docker
    Compose组织分布式解决方案*，我的Docker Compose文件是为开发设置的。 您可以使用最适合您的任何方法，但这种方式的优势在于每个环境的设置都在其自己的覆盖文件中。
- en: 'There are a couple of service options that are worth looking at in more detail.
    The REST API is defined in the core Compose file with just the image and network
    settings. The local override adds the labels used to register the API with the
    proxy, and it also captures the dependency on the database service:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有几个值得更详细查看的服务选项。 REST API 在核心 Compose 文件中定义，只需图像和网络设置。 本地覆盖添加了用于向代理注册 API 的标签，并且还捕获了对数据库服务的依赖关系：
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Swarm mode does not support the `depends_on` attribute. When you deploy a stack,
    there is no guarantee which order the services will start in. If your application
    components are resilient and have `retry` logic for any dependencies, then the
    service startup order doesn't matter. If your components are not resilient and
    crash when they can't access dependencies, then Docker will restart failed containers,
    and the application should be ready after a few retries.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm 模式不支持 `depends_on` 属性。 当您部署堆栈时，无法保证服务将以何种顺序启动。 如果您的应用程序组件具有 `retry` 逻辑以解决任何依赖关系，那么服务启动顺序就无关紧要。
    如果您的组件不具有弹性，并且在无法访问依赖项时崩溃，那么 Docker 将重新启动失败的容器，并且经过几次重试后应用程序应该准备就绪。
- en: Resilience is often missing from legacy applications, which assume that their
    dependencies are always available and able to respond immediately. This is not
    the case if you move to cloud services, and this is also true of containers. Docker
    will keep replacing failed containers, but you can add resilience even to legacy
    apps by building startup checks and health checks into the Dockerfile.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 传统应用程序通常缺乏弹性，它们假设它们的依赖始终可用并能立即响应。如果您转移到云服务，容器也是如此。Docker将不断替换失败的容器，但即使对传统应用程序，您也可以通过在Dockerfile中构建启动检查和健康检查来增加弹性。
- en: 'The swarm definition adds the secret and config setup, and there is also a
    difference in how the container labels are applied for Traefik:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm定义添加了秘密和配置设置，容器标签的应用方式也有所不同。
- en: '[PRE32]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Configs and secrets only apply in swarm mode, but you can include them in any
    Compose file—Docker Compose will ignore them when you run on a single Docker Engine.
    The `deploy` section is also only for swarm mode, and this captures the infrastructure
    setup for the replicas. Here, I have a replica count of 2, meaning the swarm will
    run two containers for this service. I also have the labels for Traefik under
    the `deploy` section, which ensures the labels are applied to the containers,
    and not to the service itself.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 配置和秘密只适用于Swarm模式，但可以在任何Compose文件中包含它们——当您在单个Docker引擎上运行时，Docker Compose会忽略它们。`deploy`部分也只适用于Swarm模式，它捕获了副本的基础架构设置。在这里，我有一个副本计数为2，这意味着Swarm将为此服务运行两个容器。我还在`deploy`部分下有Traefik的标签，这确保了标签被应用到容器上，而不是服务本身。
- en: Docker uses labels for annotating any type of object—volumes, nodes, services,
    secrets, containers, and any other Docker resource can have labels added or removed,
    and they are exposed as key-value pairs in the Docker Engine API. Traefik only
    looks for container labels, which are applied in swarm mode in the `deploy` section
    of the compose file. If you have labels directly under the service section, then
    they get added to the service and not to the containers. In this case, that would
    mean no labels on the containers, and so Traefik would not register any routes.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Docker使用标签来注释任何类型的对象——卷、节点、服务、秘密、容器和任何其他Docker资源都可以添加或删除标签，并且它们以键值对的形式暴露在Docker
    Engine API中。Traefik只查找容器标签，这些标签在Compose文件的`deploy`部分中在Swarm模式下应用。如果您直接在服务部分下有标签，那么它们将被添加到服务而不是容器。在这种情况下，这意味着容器上没有标签，因此Traefik不会注册任何路由。
- en: Defining swarm resources in Docker Compose files
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Docker Compose文件中定义Swarm资源
- en: In this chapter, the core `docker-compose.yml` file only contains a `services`
    section; there are no other resources specified. That's because the resources
    for my app are all different between single Docker Engines deployments and Docker
    Swarm.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，核心的`docker-compose.yml`文件只包含一个`services`部分；没有指定其他资源。这是因为我的应用程序的资源在单个Docker引擎部署和Docker
    Swarm之间都是不同的。
- en: 'The local override file uses the existing `nat` network, and it uses default
    specifications for the volumes used in SQL Server and Elasticsearch:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 本地覆盖文件使用现有的`nat`网络，并对SQL Server和Elasticsearch使用默认规范的卷。
- en: '[PRE33]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The swarm override maps the same `nd-net` network that all the services are
    attached to as an external network called `nd-swarm`, which will need to exist
    before I can deploy this stack:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm覆盖将所有服务附加到的相同`nd-net`网络映射为一个名为`nd-swarm`的外部网络，这个网络需要在我部署此堆栈之前存在。
- en: '[PRE34]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: There are no volumes defined in the swarm override. You can use volumes in swarm
    mode in the same way that you use them on a single Docker Engine, but you have
    the option to use different drivers and connect storage devices in the datacenter
    or cloud-storage services to your container volumes.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群覆盖中没有定义卷。在集群模式下，您可以像在单个Docker引擎上使用卷一样使用它们，但您可以选择使用不同的驱动程序，并将存储设备连接到数据中心或云存储服务以连接到您的容器卷。
- en: Storage in Docker is a complete topic in itself. I cover it in detail in my
    Pluralsight course, **Handling Data and Stateful Applications in Docker**. In
    that course, I demonstrate how to run stateful apps and databases in containers
    on the desktop, and with high availability and scale in Docker Swarm.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Docker中的存储本身就是一个完整的主题。我在我的Pluralsight课程**在Docker中处理数据和有状态应用程序**中详细介绍了它。在那门课程中，我演示了如何在桌面上以及在Docker
    Swarm中以高可用性和规模的方式运行有状态的应用程序和数据库。
- en: 'There are two other sections in the swarm override file, covering my app configuration:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群覆盖文件中有另外两个部分，涵盖了我的应用程序配置：
- en: '[PRE35]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: If you're looking at that and thinking it's a lot of `configs` and `secrets`
    to manage, remember that this is configuration data your app needs anyway, whatever
    platform you run it on. The advantage of Docker is that all these settings are
    stored and managed centrally, and you have the option to stored and transport
    them securely, if they contain sensitive data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您看到这些并认为这是很多需要管理的`configs`和`secrets`，请记住，这些是您的应用程序无论在哪个平台上都需要的配置数据。Docker的优势在于所有这些设置都被集中存储和管理，并且如果它们包含敏感数据，您可以选择安全地存储和传输它们。
- en: 'All my config and secret objects are defined as external resources, so they
    need to exist in the swarm before I can deploy my app. There is a script in the
    `ch07-docker-stack` directory called `apply-configuration.ps1` that has all the
    `docker config create` and `docker secret create` commands:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 我的所有配置和秘密对象都被定义为外部资源，因此它们需要在集群中存在才能部署我的应用程序。在`ch07-docker-stack`目录中有一个名为`apply-configuration.ps1`的脚本，其中包含所有的`docker
    config create`和`docker secret create`命令：
- en: '[PRE36]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The output is a list of the new object IDs. Now that the resources all exist,
    I can deploy my application as a stack.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是新对象ID的列表。现在所有资源都存在，我可以将我的应用程序部署为一个堆栈。
- en: Deploying a swarm stack from a Docker Compose file
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从Docker Compose文件部署集群堆栈
- en: 'I can deploy the application with Docker Compose on a development laptop by
    specifying multiple Compose files—the core file and the local override. In swarm
    mode, you use the standard `docker` command, rather than `docker-compose` to deploy
    a stack. The Docker CLI doesn''t support multiple files for stack deployment,
    but I can generate a single stack file by using Docker Compose to join the source
    files together. This command generates a single Compose file called `docker-stack.yml`
    from the two Compose files for the stack deployment:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以通过在开发笔记本上指定多个Compose文件（核心文件和本地覆盖）来使用Docker Compose部署应用程序。在集群模式下，您使用标准的`docker`命令，而不是`docker-compose`来部署堆栈。Docker
    CLI不支持堆栈部署的多个文件，但我可以使用Docker Compose将源文件合并成一个单独的堆栈文件。这个命令从两个Compose文件中生成一个名为`docker-stack.yml`的单个Compose文件，用于堆栈部署：
- en: '[PRE37]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Docker Compose joins the input files and checks whether the output configuration
    is valid. I capture the output in a file called `docker-stack.yml`. This is an
    extra step that would easily fit into your deployment pipeline. Now I can deploy
    my stack on the swarm, using the stack file that contains the core service descriptions,
    plus the secrets and deployment configuration.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose合并输入文件并检查输出配置是否有效。我将输出保存在一个名为`docker-stack.yml`的文件中。这是一个额外的步骤，可以轻松地融入到您的部署流程中。现在我可以使用包含核心服务描述、秘密和部署配置的堆栈文件在集群上部署我的堆栈。
- en: 'You deploy a stack from a Compose file with a single command, `docker stack
    deploy`. You need to pass the location of the Compose file and a name for the
    stack, and then Docker creates all the resources in the Compose file:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用单个命令`docker stack deploy`从Compose文件中部署堆栈。您需要传递Compose文件的位置和堆栈的名称，然后Docker将创建Compose文件中的所有资源：
- en: '[PRE38]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The result is a set of resources that are logically grouped together to form
    the stack. Unlike Docker Compose, which relies on naming conventions and labels
    to identify the grouping, the stack is a first-class citizen in Docker. I can
    list all stacks, which gives me the basic details—the stack name and the number
    of services—in the stack:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一组资源被逻辑地组合在一起形成堆栈。与Docker Compose不同，后者依赖命名约定和标签来识别分组，堆栈在Docker中是一等公民。我可以列出所有堆栈，这给我基本的细节——堆栈名称和堆栈中的服务数量：
- en: '[PRE39]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'There are 10 services in my stack, deployed from a single Docker Compose file
    that is 137 lines of YAML. That''s a tiny amount of configuration for such a complex
    system: two databases, a reverse proxy, multiple front-ends, a RESTful API, a
    message queue, and multiple message handlers. A system of that size would typically
    be described in a Word-deployment document running to hundreds of pages, and it
    would require a weekend of manual work to run all the steps. I deployed this with
    one command.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我的堆栈中有10个服务，从一个包含137行YAML的单个Docker Compose文件部署。对于这样一个复杂的系统来说，这是一个很小的配置量：两个数据库，一个反向代理，多个前端，一个RESTful
    API，一个消息队列和多个消息处理程序。这样大小的系统通常需要一个运行数百页的Word部署文档，并且需要一个周末的手动工作来运行所有步骤。我只用了一个命令来部署这个系统。
- en: 'I can also drill down into the containers running the stack to see the status
    and the node they''re running on with `docker stack ps`, or get a higher-level
    view of the services in the stack with `docker stack services`:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我还可以深入了解运行堆栈的容器的状态和它们所在的节点，使用`docker stack ps`，或者使用`docker stack services`来获得堆栈中服务的更高级视图。
- en: '[PRE40]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The output here shows that I have multiple replicas running the frontend containers
    and the message handlers. In total, there are 15 containers running on my two-node
    swarm, which is two VMs with a combined total of four CPU cores and 8 GB of RAM.
    At idle, the containers use very few compute resources, and I have plenty of capacity
    to run extra stacks on here. I could even deploy a copy of the same stack, using
    a different port for the proxy, and then I would have two completely separate
    test environments running on the same set of hardware.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的输出显示我有多个副本运行前端容器和消息处理程序。总共，在我的两节点集群上有15个容器在运行，这是两个虚拟机，总共有四个CPU核心和8GB的RAM。在空闲时，容器使用的计算资源很少，我有足够的容量来运行额外的堆栈。我甚至可以部署相同堆栈的副本，为代理使用不同的端口，然后我可以在相同的硬件上运行两个完全独立的测试环境。
- en: Grouping services into stacks makes it much easier to manage your application,
    especially when you have multiple apps running with multiple services in each.
    The stack is an abstraction over a set of Docker resources, but you can still
    manage the individual resources directly. If I run `docker service rm`, it will
    remove a service, even if the service is part of a stack. When I run `docker stack
    deploy` again, Docker will see that a service is missing from the stack and will
    recreate it.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 将服务分组到堆栈中可以更轻松地管理应用程序，特别是当您有多个应用程序在运行，每个应用程序中有多个服务时。堆栈是对一组Docker资源的抽象，但您仍然可以直接管理单个资源。如果我运行`docker
    service rm`，它将删除一个服务，即使该服务是堆栈的一部分。当我再次运行`docker stack deploy`时，Docker会发现堆栈中缺少一个服务，并重新创建它。
- en: When it comes to updating your application with new image versions or changes
    to service attributes, you can take the imperative approach and modify the services
    directly, or you stay declarative by modifying the stack file and deploying it
    again. Docker doesn't force a process on you, but it's better to stay declarative
    and use compose files as the single source of truth.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到使用新的镜像版本或更改服务属性来更新应用程序时，您可以采取命令式方法直接修改服务，或者通过修改堆栈文件并再次部署来保持声明性。Docker不会强加给您任何流程，但最好保持声明性，并将Compose文件用作唯一的真相来源。
- en: I can scale up the message handlers in my solution either by adding `replicas
    :2` to the deploy section of the stack file and deploying it again or by running
    `docker service update --replicas=2 nerd-dinner_nerd-dinner-save-handler`. If
    I update the service and don't change the stack file as well, the next time I
    deploy the stack, my handler will go down to one replica. The stack file is viewed
    as the desired final state, and if the current state has deviated, it will be
    corrected when you deploy again.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '我可以通过在堆栈文件的部署部分添加`replicas: 2`并再次部署它，或者通过运行`docker service update --replicas=2
    nerd-dinner_nerd-dinner-save-handler`来扩展解决方案中的消息处理程序。如果我更新了服务但没有同时更改堆栈文件，那么下次部署堆栈时，我的处理程序将减少到一个副本。堆栈文件被视为期望的最终状态，如果当前状态偏离了，那么在再次部署时将进行纠正。'
- en: Using the declarative approach means you always make these sorts of changes
    in the Docker Compose file(s), and update your app by deploying the stack again.
    The Compose files live in source control alongside your Dockerfiles and the application
    source code, so they can be versioned, compared, and labelled. That means when
    you pull the source code for any particular version of your app, you'll have everything
    you need to build and deploy it.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 使用声明性方法意味着您始终在Docker Compose文件中进行这些更改，并通过再次部署堆栈来更新应用程序。Compose文件与您的Dockerfiles和应用程序源代码一起保存在源代码控制中，因此它们可以进行版本控制、比较和标记。这意味着当您拉取应用程序的任何特定版本的源代码时，您将拥有构建和部署所需的一切。
- en: Secrets and configurations are the exception, you would keep them in a more
    secure location than the central source repository, and only admin users would
    have access to the plain text. The Compose files just reference external secrets,
    so you get the benefit of a single source of truth for your app manifest inside
    source control, with sensitive data kept outside.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密和配置是例外，您应该将它们保存在比中央源代码库更安全的位置，并且只有管理员用户才能访问明文。Compose文件只是引用外部秘密，因此您可以在源代码控制中获得应用程序清单的唯一真相来源的好处，而敏感数据则保留在外部。
- en: Running a single node or a two-node swarm is fine for development and test environments.
    I can run the full NerdDinner suite as a stack, verifying that the stack file
    is correctly defined, and I can scale up and down to check the behavior of the
    app. This doesn't give me high availability, because the swarm has a single manager
    node, so if the manager goes offline, then I can't administer the stack. In the
    datacenter you can run a swarm with many hundreds of nodes, and get full high
    availability with three managers.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发和测试环境中运行单个节点或双节点集群是可以的。我可以将完整的NerdDinner套件作为一个堆栈运行，验证堆栈文件是否正确定义，并且可以扩展和缩小以检查应用程序的行为。这并不会给我带来高可用性，因为集群只有一个管理节点，所以如果管理节点下线，那么我就无法管理堆栈。在数据中心，您可以运行一个拥有数百个节点的集群，并且通过三个管理节点获得完整的高可用性。
- en: You can build a swarm with greater elasticity for high availability and scale
    by running it in the cloud. All the major cloud operators support Docker in their
    IaaS services, so you can easily spin up Linux and Windows VMs with Docker pre-installed,
    and join them to a swarm with the simple commands you've seen in this chapter.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在云中运行它，构建具有更高可用性和规模弹性的群集。所有主要的云运营商都支持其IaaS服务中的Docker，因此您可以轻松地启动预安装了Docker的Linux和Windows
    VM，并使用本章中所见的简单命令将它们加入到群集中。
- en: Docker Swarm isn't just about running applications at scale across a cluster.
    Running across multiple nodes gives me high availability, so my application keeps
    running in the case of failure, and I can take advantage of that to support the
    application life cycle, with zero-downtime rolling updates and automated rollbacks.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm不仅仅是在集群中规模化运行应用程序。在多个节点上运行使我具有高可用性，因此在发生故障时我的应用程序可以继续运行，并且我可以利用它来支持应用程序生命周期，实现零停机滚动更新和自动回滚。
- en: Deploying updates with zero downtime
  id: totrans-220
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无停机部署更新
- en: Docker Swarm has two features that enable updates of the whole stack without
    application downtime—rolling updates and node draining. Rolling updates replace
    application containers with new instances from a new image when you have a new
    version of a component to release. Updates are staged, so provided you have multiple
    replicas, there will always be tasks running to serve requests while other tasks
    are being upgraded.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm具有两个功能，可以在不影响应用程序的情况下更新整个堆栈-滚动更新和节点排空。滚动更新在您有一个组件的新版本要发布时，用新图像的新实例替换应用程序容器。更新是分阶段进行的，因此只要您有多个副本，就会始终有任务在运行以提供请求，同时其他任务正在升级。
- en: Application updates will occur frequently, but less frequently you will also
    need to update the host, either to upgrade Docker or to apply Windows patches.
    Docker Swarm supports draining a node, which means all the containers running
    on the node are stopped and no more will be scheduled. If the replica level drops
    for any services when the node is drained, tasks are started on other nodes. When
    the node is drained, you can update the host and then join it back into the swarm.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序更新将频繁发生，但您还需要定期更新主机，无论是升级Docker还是应用Windows补丁。Docker Swarm支持排空节点，这意味着在节点上运行的所有容器都将停止，并且不会再安排更多容器。如果在排空节点时服务的副本级别下降，任务将在其他节点上启动。当节点排空时，您可以更新主机，然后将其加入到群集中。
- en: I'll finish this chapter by covering both of these scenarios.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我将通过覆盖这两种情况来完成本章。
- en: Updating application services
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新应用程序服务
- en: 'I have my stack running on Docker Swarm, and now I''m going to deploy an application
    update—a new home-page component with a restyled UI, which is a nice, easy change
    to validate. I''ve built that as `dockeronwindows/ch07-nerd-dinner-homepage:2e`.
    To make the update, I have a new Docker Compose override file, which just contains
    the new image name for the existing service:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我在Docker Swarm上运行我的堆栈，现在我要部署一个应用程序更新-一个具有重新设计的UI的新主页组件，这是一个很好的、容易验证的变化。我已经构建了`dockeronwindows/ch07-nerd-dinner-homepage:2e`。为了进行更新，我有一个新的Docker
    Compose覆盖文件，其中只包含现有服务的新图像名称：
- en: '[PRE41]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: In a normal release, you wouldn't use an override file to update one service.
    You would update the image tag in the core Docker Compose file and save the file
    in source control. I'm using an override file to make it easier to follow along
    the examples from this chapter.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在正常发布中，您不会使用覆盖文件来更新一个服务。您将更新核心Docker Compose文件中的图像标签，并将文件保存在源代码控制中。我使用覆盖文件是为了更容易地跟随本章的示例。
- en: 'There are two steps to this update. First, I need to generate a new application
    manifest by combining the Compose file and all the override files:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 此更新有两个步骤。首先，我需要通过组合Compose文件和所有覆盖文件来生成新的应用程序清单：
- en: '[PRE42]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Now I can deploy the stack:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我可以部署这个堆栈：
- en: '[PRE43]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The command output shows all services are `Updating`, but Docker Swarm will
    only actually change services where the desired state in the Compose file is different
    than the running state. In this deployment, it will update the home-page service,
    using the new image name in the Compose file.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 命令输出显示所有服务都在 `Updating`，但 Docker Swarm 只会实际更改 Compose 文件中期望状态与运行状态不同的服务。在这个部署中，它将使用
    Compose 文件中的新镜像名称更新主页服务。
- en: The update doesn't have any restrictions on the image you're upgrading to. It
    doesn't need to be a new tag from the same repository name; it can be a completely
    different image. This is very flexible, but it means you need to be careful that
    you don't accidentally update your message handlers with a new version of the
    web application, or vice versa.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 更新对您要升级的镜像没有任何限制。它不需要是同一存储库名称的新标签；它可以是完全不同的镜像。这是非常灵活的，但这意味着您需要小心，不要意外地用新版本的
    Web 应用程序更新您的消息处理程序，反之亦然。
- en: 'Docker updates one container at a time, and you can configure the delay interval
    between updates and the behavior to take if updates fail. While the update is
    in process, I can run `docker service ps` and see that the original containers
    are in the `Shutdown` state and the replacement containers are `Running` or `Starting`:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 一次更新一个容器，您可以配置更新之间的延迟间隔以及更新失败时要采取的行为。在更新过程中，我可以运行 `docker service ps`
    命令，并看到原始容器处于 `Shutdown` 状态，替换容器处于 `Running` 或 `Starting` 状态：
- en: '[PRE44]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'The Dockerfile for the new NerdDinner home page application has a health check,
    and Docker waits until the health check on the new container passes before it
    moves on to replacing the next container. During the rolling update, some users
    will see the old home page, and some users will see the stylish new home page:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 NerdDinner 主页应用程序的 Dockerfile 具有健康检查，Docker 会等到新容器的健康检查通过后才会继续替换下一个容器。在滚动更新期间，一些用户将看到旧的主页，而一些用户将看到时尚的新主页：
- en: '![](Images/c490a14f-6719-4859-8377-c5232d8783cd.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/c490a14f-6719-4859-8377-c5232d8783cd.png)'
- en: The communication between Traefik and the home page containers uses VIP networking,
    so it will only send traffic to hosts that have running containers—users will
    get a response from a container that has been updated and is running the `ch07`
    image, or one that is due to be updated and is running the `ch03` image. If this
    was a high-traffic application, I would need to ensure there's enough capacity
    in the service, so when one task is being updated, the remaining tasks can handle
    the load.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: Traefik 与主页容器之间的通信使用 VIP 网络，因此它只会将流量发送到运行容器的主机 - 用户将从已更新并运行 `ch07` 镜像的容器或者即将更新并运行
    `ch03` 镜像的容器中获得响应。如果这是一个高流量的应用程序，我需要确保服务中有足够的容量，这样当一个任务正在更新时，剩余的任务可以处理负载。
- en: Rolling updates give you zero downtime, but that doesn't necessarily mean your
    app will function correctly during the update. This process is only suitable for
    stateless applications—if tasks store any session state, then the user experience
    will be impacted. When the container holding state is replaced, the state will
    be lost. If you have stateful applications, you will need to plan a more careful
    upgrade process—or preferably modernize those components to store state in a shared
    component running in containers.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动更新可以实现零停机时间，但这并不一定意味着您的应用程序在更新期间将正常运行。这个过程只适用于无状态应用程序 - 如果任务存储任何会话状态，那么用户体验将受到影响。当包含状态的容器被替换时，状态将丢失。如果您有有状态的应用程序，您需要计划一个更谨慎的升级过程
    - 或者最好是将这些组件现代化，以便在容器中运行的共享组件中存储状态。
- en: Rolling back service updates
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务更新回滚
- en: 'When you update a service in swarm mode, the swarm stores the configuration
    of the previous deployment. If you find a problem with the release, you can roll
    back to the previous state with a single command:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在群集模式下更新服务时，群集会存储先前部署的配置。如果您发现发布存在问题，可以使用单个命令回滚到先前的状态：
- en: '[PRE45]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The rollback is a specialized form of service update. Instead of passing an
    image name for tasks to update to, the `rollback` flag does a rolling update to
    the previous image used by the service. Again, the rollback happens one task at
    a time, so this is a zero-downtime process. You can use this command to rollback
    to, no matter how you applied the update—whether you used `docker stack deploy`
    or `docker service update`.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚是服务更新的一种特殊形式。`rollback`标志不是传递任务要更新的镜像名称，而是对服务使用的先前镜像进行滚动更新。同样，回滚是一次只更新一个任务，因此这是一个零停机过程。无论您如何应用更新，都可以使用此命令回滚到之前的状态，无论您是使用`docker
    stack deploy`还是`docker service update`。
- en: Rollbacks are one of the few scenarios where you might want to use imperative
    commands to manage your applications instead of declarative Docker Compose files.
    If you find a problem with a service update, it's great to be able to roll it
    back to the previous state with just a single command.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 回滚是少数几种情况之一，您可能希望使用命令式命令来管理应用程序，而不是声明式的Docker Compose文件。如果您发现服务更新存在问题，只需使用单个命令即可将其回滚到先前状态，这非常棒。
- en: Service updates retain only one prior service configuration for rollbacks. If
    you update from version 1 to version 2 and then to version 3, the configuration
    of version 1 is lost. You can roll back from version 3 to version 2—but if you
    roll back again from version 2, it will be to the previous version, which will
    take you in a circle back to version 3.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 服务更新仅保留一个先前的服务配置用于回滚。如果您从版本1更新到版本2，然后再更新到版本3，版本1的配置将丢失。您可以从版本3回滚到版本2，但如果再次从版本2回滚，将回到先前的版本，这将使您在版本3之间循环。
- en: Configuring update behavior
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置更新行为
- en: 'For large-scale deployments, you can change the default update behavior, either
    to complete the roll-out more quickly or to run a more conservative roll-out strategy.
    The default behavior updates one task at a time, with no delay between task updates,
    and if a task update fails, the roll-out is paused. The configuration can be overridden
    with three parameters:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大规模部署，可以更改默认的更新行为，以便更快地完成滚动更新，或者运行更保守的滚动更新策略。默认行为是一次只更新一个任务，任务更新之间没有延迟，如果任务更新失败，则暂停滚动更新。可以使用三个参数覆盖配置：
- en: '`update-parallelism`: The number of tasks to update concurrently'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`update-parallelism`：同时更新的任务数量'
- en: '`update-delay`: The period to wait between task updates; can be specified as
    hours, minutes, and seconds'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`update-delay`：任务更新之间等待的时间段；可以指定为小时、分钟和秒'
- en: '`update-failure-action`: The action to take if a task update fails, either
    to continue or stop the roll out'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`update-failure-action`：如果任务更新失败，要采取的操作，是继续还是停止滚动更新'
- en: 'You can specify the default parameters in the Dockerfile so they''re baked
    into the image, or the Compose file so they''re set at deployment time or with
    the service commands. For a production deployment of NerdDinner, I might have
    nine instances of the SQL message handler, with `update_config` in the Compose
    file set to update in batches of three, with a 10-second delay:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在Dockerfile中指定默认参数，以便将其嵌入到镜像中，或者在Compose文件中指定默认参数，以便在部署时或使用服务命令时设置。对于NerdDinner的生产部署，我可能有九个SQL消息处理程序实例，Compose文件中的`update_config`设置为以三个为一批进行更新，并设置为10秒的延迟：
- en: '[PRE46]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The update configuration for a service can also be changed with the `docker
    service update` command, so you can alter the update parameters and initiate a
    rolling upgrade with a single command.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 服务的更新配置也可以通过`docker service update`命令进行更改，因此您可以修改更新参数并通过单个命令启动滚动升级。
- en: Health checks are especially important in service updates. If a health check
    fails for a new task in a service update, that could mean there's a problem with
    the image. Completing the roll-out could result in 100% unhealthy tasks and a
    broken application. The default update configuration prevents this, so if an updated
    task does not enter the running state, the roll-out is paused. The update will
    not go ahead, but that's a better outcome than having an updated app that is broken.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 健康检查在服务更新中尤为重要。如果服务更新中的新任务健康检查失败，这可能意味着镜像存在问题。完成部署可能导致100%的不健康任务和一个破损的应用程序。默认的更新配置可以防止这种情况发生，因此如果更新的任务没有进入运行状态，部署将被暂停。更新将不会继续进行，但这比拥有一个破损的更新应用程序要好。
- en: Updating swarm nodes
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新集群节点
- en: Application updates are one part of the update routine, and host updates are
    the other. Your Windows Docker hosts should be running a minimal operating system,
    preferably Windows Server 2019 Core. This version has no UI, so there's a much
    smaller surface area for updates, but there will still be some Windows updates
    that require a reboot.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序更新是更新例程的一部分，主机更新是另一部分。您的Windows Docker主机应该运行一个最小的操作系统，最好是Windows Server
    2019 Core。这个版本没有用户界面，因此更新的表面积要小得多，但仍然会有一些需要重新启动的Windows更新。
- en: 'Rebooting the server is an invasive process—it stops the Docker Engine Windows
    Service, killing all running containers. Upgrading Docker is equally invasive
    for the same reason: It means a restart of the Docker Engine. In swarm mode, you
    can manage this by taking nodes out of service for the update period, without
    impacting service levels.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 重新启动服务器是一个侵入性的过程——它会停止Docker Engine Windows服务，杀死所有正在运行的容器。出于同样的原因，升级Docker同样具有侵入性：这意味着需要重新启动Docker
    Engine。在集群模式中，您可以通过在更新期间将节点从服务中移除来管理此过程，而不会影响服务水平。
- en: 'I''ll show this with my swarm. If I need to work on `win2019-02`, I can gracefully
    reschedule the tasks it is running with `docker node update` to put it into drain
    mode:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我将用我的集群来展示这一点。如果我需要在`win2019-02`上工作，我可以通过`docker node update`优雅地重新安排它正在运行的任务，将其置于排水模式：
- en: '[PRE47]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Putting a node into drain mode means all containers are stopped, and as these
    are service task containers, they will be replaced with new containers on the
    other nodes. When the drain completes, I have no running tasks on `win-node02`:
    they have all been shut down. You can see that the tasks have been deliberately
    shut down, as `Shutdown` is listed as the desired state:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 将节点置于排水模式意味着所有容器都将被停止，由于这些是服务任务容器，它们将在其他节点上被新容器替换。当排水完成时，`win-node02`上将没有正在运行的任务：它们都已经被关闭。您可以看到任务已被故意关闭，因为“关闭”被列为期望状态：
- en: '[PRE48]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'I can check the service list and see that every service is still at the required
    replica level:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以检查服务列表，并看到每个服务仍然处于所需的副本级别：
- en: '[PRE49]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The swarm has created new containers to replace the replicas that were running
    on `win2019-02`. In fact, all my replicas are running on a single node now, but
    with ingress networking and VIP load-balancing, the application continues to work
    in the same way. The Docker Engine still runs in drain mode, so if any external
    traffic reaches the drained nodes, they still forward it to containers on active
    nodes.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 集群已经创建了新的容器来替换在`win2019-02`上运行的副本。实际上，现在所有的副本都在单个节点上运行，但通过入口网络和VIP负载平衡，应用程序仍然以相同的方式工作。Docker
    Engine仍然以排水模式运行，因此如果任何外部流量到达排水节点，它们仍然会将其转发到活动节点上的容器。
- en: Nodes in the drain mode are considered to be unavailable, so if the swarm needs
    to schedule new tasks, none will be allocated to drained nodes. `win-node02` is
    effectively out of commission now, so I could log on and run a Windows update
    with the `sconfig` tool, or update the Docker Engine.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 处于排水模式的节点被视为不可用，因此如果群需要安排新任务，则不会分配任何任务给排水节点。`win-node02`现在有效地停用了，所以我可以登录并使用`sconfig`工具运行Windows更新，或者更新Docker
    Engine。
- en: 'Updating the node may mean restarting the Docker Engine or rebooting the server.
    When that''s done, I can bring the server back online in the swarm with another
    `docker node update` command:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 更新节点可能意味着重新启动Docker Engine或重新启动服务器。完成后，我可以使用另一个`docker node update`命令将服务器重新上线到群中：
- en: '[PRE50]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This makes the node available again. When nodes join the swarm, Docker doesn't
    automatically rebalance running services, so the containers all stay on `win2019-dev02`
    , even though `win-node02` is available again and has more capacity.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得节点再次可用。当节点加入群时，Docker不会自动重新平衡运行的服务，因此所有容器仍然留在`win2019-dev02`上，即使`win-node02`再次可用并且容量更大。
- en: In a high-throughput environment, where services are regularly started, stopped,
    and scaled, any nodes that join the swarm will soon be running their share of
    tasks. In a more static environment, you can manually rebalance services by running
    the Docker service `update --force`. This doesn't change the configuration of
    the service, but it replaces all replicas and will use all active nodes when it
    schedules the new containers to run.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在高吞吐量环境中，服务经常启动、停止和扩展，加入群的任何节点很快就会运行其份额的任务。在更静态的环境中，您可以通过运行Docker服务`update --force`来手动重新平衡服务。这不会更改服务的配置，但它会替换所有副本，并在安排新容器运行时使用所有活动节点。
- en: This is a disruptive action, because it forces Docker to stop healthy containers.
    You need to be confident that you don't impact the availability of your application
    if you force a rebalance. Docker can't guarantee that without knowing the architecture
    of your app, which is why services aren't automatically rebalanced when nodes
    join the swarm.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种破坏性的行为，因为它迫使Docker停止健康的容器。您需要确信如果强制重新平衡不会影响应用程序的可用性。Docker无法保证不知道您的应用程序的架构，这就是为什么当节点加入群时服务不会自动重新平衡。
- en: Swarm mode gives you the power to update any component of your application and
    the nodes running the swarm, without any downtime. You may need to commission
    additional nodes in the swarm during updates to ensure you have enough capacity
    to cover nodes that are taken out of service, but these can be removed afterward.
    You don't need any additional tooling to get rolling updates, automated rollback,
    and routing to healthy containers—that's all built into Docker.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式使您有权更新应用程序的任何组件和运行群的节点，而无需任何停机时间。在更新期间，您可能需要在群中委托额外的节点，以确保您有足够的容量来覆盖被停用的节点，但之后可以将其移除。您无需任何额外的工具即可进行滚动更新、自动回滚和路由到健康容器——这一切都内置在Docker中。
- en: Mixing hosts in hybrid swarms
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合主机在混合群中
- en: There's one more feature of swarm mode that makes it hugely powerful. Nodes
    in the swarm communicate using the Docker API, and the API is cross-platform—which
    means you can have a single swarm running a mixture of Windows and Linux servers.
    Docker also runs on different CPU architectures, so you can mix traditional 64-bit
    Intel servers with efficient new ARM boards.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm模式的另一个功能使其非常强大。群中的节点使用Docker API进行通信，而API是跨平台的，这意味着您可以在单个群中运行混合的Windows和Linux服务器。Docker还可以在不同的CPU架构上运行，因此您可以将传统的64位Intel服务器与高效的新ARM板混合使用。
- en: Linux isn't the focus of this book, but I will cover hybrid swarms briefly because
    they open up a new range of possibilities. A hybrid swarm can have Linux and Windows
    nodes as managers and workers. You administer the nodes and the services they're
    running in the same way, using the exact same Docker CLI.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: Linux不是本书的重点，但我会简要介绍混合群集，因为它们开启了新的可能性范围。混合群集可以将Linux和Windows节点作为管理节点和工作节点。您可以使用完全相同的Docker
    CLI以相同的方式管理节点和它们运行的服务。
- en: One use case for hybrid swarms is to run your manager nodes on Linux, to reduce
    licensing costs or running costs if you have your swarm in the cloud. A production
    swarm will need at least three manager nodes. Even if all your workloads are Windows-based,
    it may be more cost effective to run Linux nodes as managers - on ARM if that
    is an option - and save the Windows nodes for user workloads.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 混合群集的一个用例是在Linux上运行您的管理节点，以减少许可成本或如果您的群集在云中运行则减少运行成本。生产群集将需要至少三个管理节点。即使您的所有工作负载都是基于Windows的，也可能更具成本效益地运行Linux节点作为管理节点
    - 如果有这个选项的话 - 并将Windows节点保留给用户工作负载。
- en: The other use case is for mixed workloads. My NerdDinner solution is using open
    source software that is available as Linux Docker images, but which I've had to
    package myself for Windows Server 2019 containers. I could migrate any cross-platform
    components to run in Linux containers on a hybrid swarm. That could be the .NET
    Core components from [Chapter 5](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml),
    *Adopting Container-First Solution Design*, as well as Traefik, the NATS message
    queue, Elasticsearch, Kibana, and even SQL Server. Linux images are typically
    much smaller and lighter than Windows images, so you should be able to run with
    greater density, packing more containers on to each host.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个用例是用于混合工作负载。我的NerdDinner解决方案使用的是作为Linux Docker镜像可用的开源软件，但我不得不自己为Windows Server
    2019容器打包。我可以将任何跨平台组件迁移到混合群集中的Linux容器中运行。这可能是来自[第5章](e279ed60-09a9-4024-8e30-e5f08074c66a.xhtml)的.NET
    Core组件，以及Traefik、NATS消息队列、Elasticsearch、Kibana，甚至SQL Server。Linux镜像通常比Windows镜像小得多，更轻巧，因此您应该能够以更高的密度运行，将更多的容器打包到每个主机上。
- en: The great benefit of the hybrid swarm is that you manage all these components
    in the same way, from the same user interface. You can connect your local Docker
    CLI to the swarm manager and administer the Traefik proxy on Linux and the ASP.NET
    application on Windows with exactly the same commands.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 混合群集的巨大好处在于，您可以以相同的方式从相同的用户界面管理所有这些组件。您可以将本地的Docker CLI连接到群集管理器，并使用完全相同的命令管理Linux上的Traefik代理和Windows上的ASP.NET应用程序。
- en: Summary
  id: totrans-278
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter was all about Docker Swarm mode, the native clustering option built
    right into Docker. You learned how to create a swarm, how to add and remove swarm
    nodes, and how to deploy services on the swarm connected with an overlay network.
    I showed that you have to create services for high availability and also discussed
    how to use configs and secrets to store sensitive application data securely in
    the swarm.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 本章主要介绍了Docker Swarm模式，这是内置在Docker中的本地集群选项。您学会了如何创建一个群集，如何添加和删除群集节点，以及如何在连接了覆盖网络的群集上部署服务。我展示了您必须为高可用性创建服务，并讨论了如何使用配置和秘密在群集中安全存储敏感的应用程序数据。
- en: You can deploy your application as a stack on the swarm, using a Compose file,
    which makes it very easy to group and manage your application components. I demonstrated
    stack deployment on a single node swarm and on a multi-node swarm—and the process
    is the same for swarms with hundreds of nodes.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Compose文件将应用程序部署为群集上的堆栈，这样可以非常容易地对应用程序组件进行分组和管理。我演示了在单节点群集和多节点群集上的堆栈部署
    - 对于具有数百个节点的群集，流程是相同的。
- en: High availability in Docker Swarm means you can perform application updates
    and rollbacks without downtime. You can even take nodes out of commission when
    you need to update Windows or Docker and still have your application running with
    the same service level on the remaining nodes.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm中的高可用性意味着您可以在没有停机时间的情况下执行应用程序更新和回滚。甚至在需要更新Windows或Docker时，您也可以将节点停用，仍然可以在剩余节点上以相同的服务水平运行您的应用程序。
- en: In the next chapter I'll look more closely at the administration options for
    dockerized solutions. I'll start by looking at how to use your existing management
    tools with applications running in Docker. Then, I'll move on to managing swarms
    in production, with Docker Enterprise.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我将更仔细地研究docker化解决方案的管理选项。我将首先看看如何使用现有的管理工具来管理在Docker中运行的应用程序。然后，我将继续使用Docker
    Enterprise在生产环境中管理swarms。
