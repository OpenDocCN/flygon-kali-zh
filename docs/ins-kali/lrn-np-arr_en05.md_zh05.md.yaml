- en: Chapter 5. Signal Processing Techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五章：信号处理技术
- en: 'We will learn about some signal-processing techniques in this chapter, and
    we will analyze time-series data with these. As example data, we will use the
    sunspot data provided by a Belgian scientific institute. We can download this
    data from several places on the Internet, and it is also provided as sample data
    by the `statsmodels` library. There are a number of things we can do with the
    data, such as:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章中学习一些信号处理技术，并使用这些技术来分析时序数据。 作为示例数据，我们将使用比利时科学研究所提供的黑子数据。 我们可以从互联网上的多个位置下载此数据，并且`statsmodels`库也将其作为示例数据提供。
    我们可以对数据做很多事情，例如：
- en: Trying to determine periodic cycles within the data. This can be done, but this
    is a bit advanced, so we will just get you started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 试图确定数据中的周期性周期。 可以做到，但这有点高级，所以我们将帮助您入门。
- en: Smoothing the data to filter out noise.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平滑数据以过滤噪声。
- en: Forecasting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测。
- en: Introducing the Sunspot data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 太阳黑子数据简介
- en: Sunspots are dark spots visible on the Sun's surface. This phenomenon has been
    studied for many centuries by astronomers. Evidence has been found for periodic
    sunspot cycles. We can download up-to-date annual sunspot data from [http://www.quandl.com/SIDC/SUNSPOTS_A-Sunspot-Numbers-Annual](http://www.quandl.com/SIDC/SUNSPOTS_A-Sunspot-Numbers-Annual).
    This is provided by the Belgian Solar Influences Data Analysis Center. The data
    goes back to 1700 and contains more than 300 annual averages. In order to determine
    sunspot cycles, scientists successfully used the *Hilbert-Huang* transform (refer
    to [http://en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform](http://en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform)).
    A major part of this transform is the so-called **Empirical Mode Decomposition**
    (**EMD**) method. The entire algorithm contains many iterative steps, and we will
    cover only some of them here. EMD reduces data to a group of **Intrinsic Mode
    Functions** (**IMF**). You can compare this to the way Fast Fourier Transform
    decomposes a signal in a superposition of *sine* and *cosine* terms.
  prefs: []
  type: TYPE_NORMAL
  zh: 太阳黑子是在太阳表面可见的黑点。 天文学家已经对这种现象进行了数百年的研究。 已经发现周期性黑子周期的证据。 我们可以从[`www.quandl.com/SIDC/SUNSPOTS_A-Sunspot-Numbers-Annual`](http://www.quandl.com/SIDC/SUNSPOTS_A-Sunspot-Numbers-Annual)下载最新的年度黑子数据。
    这是由比利时太阳能影响数据分析中心提供的。 数据可追溯到 1700 年，其中包含超过 300 个年平均值。 为了确定太阳黑子的周期，科学家成功地使用了*希尔伯特-黄*（Hilbert-Huang）变换（参考[`en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform`](http://en.wikipedia.org/wiki/Hilbert%E2%80%93Huang_transform)）。 该变换的主要部分是所谓的**经验模式分解**（**EMD**）方法。
    整个算法包含许多迭代步骤，在这里我们将仅介绍其中的一些步骤。 EMD 将数据缩减为一组**本征模式函数**（**IMF**）。 您可以将其与快速傅立叶变换将*正弦*和*余弦*项叠加的信号分解方式进行比较。
- en: 'Extracting IMFs is done via a sifting process. The sifting of a signal is related
    to separating out components of a signal one at a time. The first step of this
    process is identifying local extrema. We will perform the first step and plot
    the data with the extrema we found. Let''s download the data in CSV format. In
    [Chapter 3](part0036_split_000.html#page "Chapter 3. Basic Data Analysis with
    NumPy"), *Basic Data Analysis with NumPy*, we learned how to load CSV files into
    NumPy arrays, so, if necessary, please go back to read up on that. We also need
    to reverse the array to have it in the correct chronological order (see [Chapter
    2](part0022_split_000.html#page "Chapter 2. NumPy Basics"), *NumPy Basics*, for
    details if needed). The following code snippet finds the indices of the local
    minima and maxima respectively:'
  prefs: []
  type: TYPE_NORMAL
  zh: 通过过滤过程完成的提取 IMF。 信号的过滤与一次分离一个信号的成分有关。 此过程的第一步是确定局部极值。 我们将执行第一步，并使用发现的极值绘制数据。
    让我们以 CSV 格式下载数据。 在第三章，“使用 NumPy 进行基本数据分析”中，我们学习了如何将 CSV 文件加载到 NumPy 数组中，因此，如有必要，请返回阅读。
    在那。 我们还需要反转数组以使其按正确的时间顺序排列（有关详细信息，请参阅第二章， “NumPy 基础知识”）。 以下代码段分别查找局部最小值和最大值的索引：
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now we need to concatenate these arrays and use the indices to select the corresponding
    values. The following code accomplishes that and also plots the data:'
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要连接这些数组，并使用索引选择相应的值。 以下代码完成了该任务并绘制了数据：
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We will see the following chart:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到以下图表：
- en: '![Introducing the Sunspot data](img/00039.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![太阳黑子数据简介](img/00039.jpeg)'
- en: In this plot, you can see the extrema is indicated with dots.
  prefs: []
  type: TYPE_NORMAL
  zh: 在该图中，您可以看到极点用点表示。
- en: Sifting continued
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 再谈过滤
- en: 'The next steps in the sifting process require us to interpolate with a cubic
    spline of the minima and maxima. This creates an upper envelope and a lower envelope,
    which should surround the data. The mean of the envelopes is needed for the next
    iteration of the EMD process. We can interpolate minima with the following code
    snippet:'
  prefs: []
  type: TYPE_NORMAL
  zh: 过滤过程中的后续步骤要求我们对最小值和最大值的三次样条进行插值。 这将创建一个上信封和一个下信封，它们应包围数据。 EMD 处理的下一次迭代需要包络线的平均值。
    我们可以使用以下代码片段对最小值进行插值：
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Similar code can be used to interpolate the maxima. We need to be aware that
    the interpolation results are only valid within the range over which we are interpolating.
    This range is defined by the first occurrence of a minima/maxima and ends at the
    last occurrence of a minima/maxima. Unfortunately, the interpolation ranges we
    can define in this way for the maxima and minima do not match perfectly. So, for
    the purpose of plotting, we need to extract a shorter range that lies within both
    the maxima and minima interpolation ranges. Have a look at the following code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用类似的代码对最大值进行插值。 我们需要注意，插值结果仅在我们插值的范围内有效。 该范围由最小值/最大值的首次出现定义，并在最小值/最大值的最后出现时结束。
    不幸的是，我们以这种方式定义的最大值和最小值的插值范围并不完全匹配。 因此，出于绘制目的，我们需要提取一个位于最大和最小插值范围内的较短范围。 看下面的代码：
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The code produces the following chart:'
  prefs: []
  type: TYPE_NORMAL
  zh: 该代码产生以下图表：
- en: '![Sifting continued](img/00040.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![再谈过滤](img/00040.jpeg)'
- en: What you see is the observed data, with computed envelopes and *mid* line. Obviously,
    negative values don't make any sense in this context. However, for the algorithm
    we only need to care about the mid line of the upper and lower envelopes. In these
    first two sections, we basically performed the first iteration of the EMD process.
    The algorithm is a bit more involved, so we will leave it up to you whether or
    not you want to continue with this analysis on your own.
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到观察到的数据，其中包括计算出的包络线和中线。 显然，在这种情况下，负值没有任何意义。 但是，对于该算法，我们只需要关心上下包络的中线即可。 在前两个部分中，我们基本上执行了
    EMD 过程的第一次迭代。 该算法涉及更多，因此无论您是否要自己继续进行此分析，我们都将由您决定。
- en: Moving averages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 移动平均线
- en: Moving averages are tools commonly used to analyze time-series data. A moving
    average defines a window of previously seen data that is averaged each time the
    window slides forward one period. The different types of moving average differ
    essentially in the weights used for averaging. The exponential moving average,
    for instance, has exponentially decreasing weights with time. This means that
    older values have less influence than newer values, which is sometimes desirable.
  prefs: []
  type: TYPE_NORMAL
  zh: 移动平均值是常用的分析时间序列数据的工具。 移动平均线定义了一个以前查看过的数据的窗口，该窗口在每次向前滑动一个周期时将其平均。 不同类型的移动平均线在平均权重方面本质上有所不同。
    例如，指数移动平均值的权重随时间呈指数下降。 这意味着较旧的值比较新的值具有较小的影响，这有时是理想的。
- en: 'We can express an equal-weight strategy for the simple moving average as follows
    in the NumPy code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 NumPy 代码中为简单移动平均线表示等权重策略：
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'A simple moving average uses equal weights which, in code, looks as follows:'
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的移动平均线使用相等的权重，该权重在代码中如下所示：
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following code plots the simple moving average for the 11- and 22-year
    sunspot cycle:'
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码绘制了 11 年和 22 年黑子周期的简单移动平均值：
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the following plot, we see the original data and the simple moving averages
    for 11- and 22-year periods. As you can see, moving averages are not a good fit
    for this data; this is generally the case for sinusoidal data.
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们看到了 11 年和 22 年期的原始数据和简单移动平均线。 如您所见，移动平均线不适用于此数据。 对于正弦数据通常是这种情况。
- en: '![Moving averages](img/00041.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![移动均值](img/00041.jpeg)'
- en: Smoothing functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 平滑函数
- en: Smoothing can help us get rid of noise and outliers in raw data. This, for instance,
    makes it easier to spot trends in the data. NumPy provides a number of smoothing
    functions.
  prefs: []
  type: TYPE_NORMAL
  zh: 平滑可以帮助我们消除原始数据中的噪声和离群值。 例如，这使得更容易发现数据趋势。 NumPy 提供了许多平滑函数。
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: These functions can calculate weights in a sliding window as we did in the previous
    example (for more background information, visit [http://en.wikipedia.org/wiki/Window_function](http://en.wikipedia.org/wiki/Window_function)).
  prefs: []
  type: TYPE_NORMAL
  zh: 这些函数可以像前面的示例一样在滑动窗口中计算权重（更多信息访问[`en.wikipedia.org/wiki/Window_function`](http://en.wikipedia.org/wiki/Window_function)）。
- en: These functions, except the `kaiser` function, require only one parameter—the
    size of the window, which we will set to 22 for the middle cycle of the sunspot
    data. The `kaiser` function also needs a `beta` parameter. With this parameter,
    the `kaiser` function can mimic the other functions.
  prefs: []
  type: TYPE_NORMAL
  zh: 除`kaiser`函数外，这些函数仅需要一个参数-窗口大小，对于黑子数据的中间周期，我们将其设置为 22。 `kaiser`函数还需要一个`beta`参数。
    使用此参数，`kaiser`函数可以模仿其他函数。
- en: 'The NumPy documentation recommends a starting value of 14 for the `beta` parameter,
    so that is what we are going to use too. The code is straightforward and given
    as follows (the data here is limited to the last 50 years only for easier comparison
    in the plots):'
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 文档建议`beta`参数的起始值为 14，这也是我们将要使用的值。 代码简单明了，给出如下（此处的数据仅限于最近 50 年，以方便在图中进行比较）：
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In the following plot, we can see that the result of the window functions doesn''t
    differ much:'
  prefs: []
  type: TYPE_NORMAL
  zh: 在下图中，我们可以看到窗口函数的结果相差不大：
- en: '![Smoothing functions](img/00042.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![平滑函数](img/00042.jpeg)'
- en: Forecasting with an ARMA model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 ARMA 模型进行预测
- en: In the previous chapter, [Chapter 4](part0047_split_000.html#page "Chapter 4. Simple
    Predictive Analytics with NumPy"), *Simple Predictive Analytics with NumPy*, we
    learned about autoregressive models. ARMA is a generalization of these models
    that adds an extra component—the moving average. ARMA models are frequently used
    to predict values of a time-series. These models combine autoregressive and moving-average
    models. Autoregressive models predict values by assuming that a linear combination
    is formed by the previously encountered values. For instance, we can consider
    a **linear combination**, which is formed from the previous value in the time-series
    and the value before that. This is also named an AR(2) model since we are using
    components that lag two periods. In our case, we would be looking at the number
    of sunspots one year before and two years before the period we are predicting.
    In an ARMA model, we try to model the residues that we cannot explain from the
    previous period data (also known as unexpected components). Here, a linear combination
    is assumed again. So an ARMA (ARMA (2, 1)) model, which we will attempt here is
    the sum of an AR(2) model and a linear combination of the first order residues
    (see [http://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model](http://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model)).
    Luckily, we can use the `statsmodels` functions for this analysis.
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，第四章，“NumPy 的简单预测分析”中，我们学习了自回归模型。 ARMA 是这些模型的概括，它为添加了额外的组成部分-移动平均值。 ARMA
    模型通常用于预测时间序列的值。 这些模型结合了自回归模型和移动平均模型。 自回归模型通过假设线性组合是由先前遇到的值组成来预测值的。 例如，我们可以考虑**线性组合**，它是由时间序列中的先前值和之前的值组成的。
    由于我们使用的是滞后两个周期的组件，因此也称为`AR(2)`模型。 在我们的案例中，我们将查看预测期之前一年和两年之前的黑子数。 在 ARMA 模型中，我们尝试对无法从上一时期的数据（也称为意外成分）无法解释的残渣进行建模。
    在此，再次假定为线性组合。 因此，我们将在这里尝试使用的 ARMA（`ARMA(2, 1)`）模型是`AR(2)`模型与[一阶残差的线性组合的总和](http://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model)。
    幸运的是，我们可以使用`statsmodels`函数进行此分析。
- en: 'We will also be using the sample sunspot data that is a part of the `statsmodels`
    distribution. This dataset might not be up to date depending on when you last
    installed `statsmodels`. In any case, you can always just use the dataset mentioned
    in the first section of this chapter. Forecasting can be done with the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用作为`statsmodels`分布一部分的样本黑子数据。 根据您上次安装`statsmodels`的时间，此数据集可能不是最新的。 无论如何，您都可以始终仅使用本章第一节中提到的数据集。
    可以通过以下步骤进行预测：
- en: 'Load the data in a `DataFrame` pandas. We also have to specify the available
    year ranges and get rid of the `Year` column using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将数据加载到`DataFrame`Pandas 中。 我们还必须指定可用的年份范围，并使用以下代码摆脱`Year`列：
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Fit the data to an ARMA(2,1) model using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码将数据拟合为`ARMA(2, 1)`模型：
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Do a forecast using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下代码进行预测：
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The following code is the complete code listing with plotting:'
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码是带有绘图的完整代码清单：
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Refer to the following chart of prediction and actual data:'
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下预测和实际数据图表：
- en: '![Forecasting with an ARMA model](img/00043.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![使用 ARMA 模型执行预测](img/00043.jpeg)'
- en: Filtering a signal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 过滤信号
- en: Another common signal processing technique is filtering. This is a big topic,
    and we could create all sorts of filters. We will only create a very basic filter
    here. Again, we will use the sunspot data as input.
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常见的信号处理技术是过滤。 这是一个很大的话题，我们可以创建各种过滤器。 我们只会在这里创建一个非常基本的过滤器。 同样，我们将使用黑子数据作为输入。
- en: The `iirdesign` function, as its name suggests, allows us to construct several
    types of analog and digital filters.
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，`iirdesign`函数使我们能够构造几种类型的模拟和数字过滤器。
- en: Designing the filter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计过滤器
- en: Design the filter with the `iirdesign` function of the `scipy.signal` module.
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`scipy.signal`模块的`iirdesign`函数设计过滤器。
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: '**IIR** stands for **Infinite Impulse Response**; for more information, visit
    [http://en.wikipedia.org/wiki/Infinite_impulse_response](http://en.wikipedia.org/wiki/Infinite_impulse_response).'
  prefs: []
  type: TYPE_NORMAL
  zh: '**IIR** 代表**无限冲激响应**； 有关更多信息，请访问[`en.wikipedia.org/wiki/Infinite_impulse_response`](http://en.wikipedia.org/wiki/Infinite_impulse_response)。'
- en: 'We are not going to go into all the details of the `iirdesign` function. Have
    a look at the documentation if necessary at [http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirdesign.html](http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirdesign.html).
    In short, the following are the parameters we will set:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将不涉及`iirdesign`函数的所有细节。 如果需要，请查看位于[`docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirdesign.html`](http://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.iirdesign.html)的文档。
    简而言之，以下是我们将设置的参数：
- en: Frequencies normalized from 0 to 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 频率标准化为从 0 到 1。
- en: Maximum loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最大损失。
- en: Minimum attenuation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小衰减。
- en: Filter type.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过滤器类型。
- en: 'Designing the filter can be done with the following code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下代码来设计过滤器：
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注意
- en: The configuration of this filter corresponds to a Butterworth bandpass filter
    ([http://en.wikipedia.org/wiki/Butterworth_filter](http://en.wikipedia.org/wiki/Butterworth_filter)).
  prefs: []
  type: TYPE_NORMAL
  zh: 该过滤器的配置与巴特沃斯带通过滤器（[`en.wikipedia.org/wiki/Butterworth_filter`](http://en.wikipedia.org/wiki/Butterworth_filter)）相对应。
- en: 'We can apply the filter with the `scipy.signal.lfilter` function. It accepts
    as arguments the values from the previous step and, of course, the data array,
    to filter, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`scipy.signal.lfilter`函数应用过滤器。 它接受上一步的值作为参数，当然也接受数据数组作为过滤参数，如以下代码所示：
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'If we plot the original data and the filtered data, we get the following plot:'
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们绘制原始数据和过滤后的数据，则会得到以下图表：
- en: '![Designing the filter](img/00044.jpeg)'
  prefs: []
  type: TYPE_IMG
  zh: '![设计过滤器](img/00044.jpeg)'
- en: Demonstrating cointegration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演示协整
- en: Cointegration is similar to correlation, but it is considered by many to be
    a better metric to define the relatedness of two time-series. The usual way to
    explain the difference between cointegration and correlation is to take the example
    of a drunken man and his dog. Correlation tells you something about the direction
    in which they are going. Cointegration relates to their distance over time, which
    in this case is constrained by the leash of the dog. We will demonstrate cointegration
    using computer-generated time-series and real data. The data can be downloaded
    from Quandl in CSV format.
  prefs: []
  type: TYPE_NORMAL
  zh: 协整与相关性相似，但许多人认为它是定义两个时间序列的相关性的较好度量。 解释协整和相关之间差异的通常方法是以一个醉酒的人和他的狗为例。 相关性告诉您有关它们前进方向的一些信息。
    协整与它们随时间的距离有关，在这种情况下，其受狗的牵引力约束。 我们将使用计算机生成的时间序列和真实数据演示协整。 可以从 Quandl 以 CSV 格式下载数据。
- en: 'The **Augmented Dickey Fuller (ADF)** test can be used to measure the cointegration
    of time-series; proceed with the following steps to demonstrate cointegration:'
  prefs: []
  type: TYPE_NORMAL
  zh: '**增强迪基·富勒（ADF）**测试可用于测量时间序列的协整； 继续执行以下步骤来演示协整：'
- en: Define the following function to calculate the ADF statistic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义以下函数以计算 ADF 统计量。
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Generate a `sine` value and calculate the cointegration of the value with itself:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一个`sin`值，并计算该值与自身的协整：
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'This should print the following:'
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该打印以下内容：
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The first value you see is the ADF metric itself. The second number is the p-value.
    As you can observe, the p-value is quite high. Then follow the lag and sample
    size. The dictionary gives t-distribution values for this particular sample size.
  prefs: []
  type: TYPE_NORMAL
  zh: 您看到的第一个值是 ADF 指标本身。 第二个数字是 P 值。 如您所见，P 值很高。 然后跟踪滞后和样本量。 字典给出了此特定样本大小的 T 分布值。
- en: 'Now add noise to the sine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在向正弦添加噪声：
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Adding noise gives the following results:'
  prefs: []
  type: TYPE_NORMAL
  zh: 添加噪声可获得以下结果：
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can pretty much reject cointegration on the basis of the found p-value here
    it seems.
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里看来，我们可以根据找到的 P 值来拒绝协整。
- en: 'Let''s generate a `cosine` value of a larger magnitude and offset. Again let''s
    add the noise to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们生成一个更大幅度和偏移量的`cos`值。 再次让我们添加噪音：
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This gives the following values:'
  prefs: []
  type: TYPE_NORMAL
  zh: 给出以下值：
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Again, here we see a strong rejection of cointegration.
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在这里我们看到对协整的强烈反对。
- en: 'Now on to real data that can be downloaded from URLs given in the following
    code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在介绍可以从以下代码片段中提供的 URL 下载的真实数据：
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Here, we have to make sure that the two time-series are aligned and in the
    proper order:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这里，我们必须确保两个时间序列对齐并且顺序正确：
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The results show some evidence of cointegration it seems:'
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明似乎有一些协整的证据：
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Please refer to the following code:'
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考以下代码：
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned a number of sophisticated signal processing techniques.
    Most of them were applied to a dataset of sunspot data. We looked at smoothing
    with window functions and moving averages. We also touched upon the sifting process
    used by scientists to derive sunspot cycles. Last but not least, a demonstration
    was given of cointegration.
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了许多复杂的信号处理技术。 其中大多数被应用于黑子数据集。 我们研究了使用窗口函数和移动平均值进行的平滑。 我们还谈到了科学家用于得出黑子周期的过滤过程。
    最后但并非最不重要的是，给出了协整的演示。
- en: In the next chapter, we will focus on debugging, profiling, and testing, including
    assert functions and various tools.
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将专注于调试，概要分析和测试，包括断言函数和各种工具。
