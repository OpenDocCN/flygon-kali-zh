- en: '*Chapter 9*: Basics of Machine Learning'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第9章*：机器学习基础'
- en: The **machine learning** (**ML**) field is growing bigger every day, with tons
    of research being done, and various types of smart/intelligent applications being
    built with ML algorithms. The field is gaining more interest and more people are
    fascinated to know how it works and how to make use of it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习**（**ML**）领域每天都在不断发展，进行大量研究，并利用机器学习算法构建各种智能应用。这个领域越来越受到关注，越来越多的人对它的工作原理和如何利用它感到着迷。'
- en: In this chapter, we will try to get a basic understanding of ML why and how
    it works, and also see various forms of its application to real-life situations.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将尝试基本了解机器学习的原理和工作方式，以及看到它在现实生活中的各种应用形式。
- en: 'In this chapter, we''ll look at the following topics to understand the basics
    of ML:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将研究以下主题，以了解机器学习的基础知识：
- en: Introduction to machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: Why machine learning works
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习为什么有效
- en: Machine learning problems/tasks
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习问题/任务
- en: Machine learning in JavaScript
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JavaScript中的机器学习
- en: Applications of machine learning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习应用
- en: Resources to understand machine learning in depth
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入理解机器学习的资源
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter introduces ML in a simple form, hence it requires no prior knowledge.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章以简单形式介绍了机器学习，因此不需要先前的知识。
- en: Introduction to machine learning
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习简介
- en: In this section, we will introduce ML by using a simple analogy that might serve
    as common ground to establish our explanation. We will also see why and how ML
    works.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用一个简单的类比来介绍机器学习，这可能作为建立我们解释的共同基础。我们还将看到机器学习为什么以及如何工作。
- en: We will start the section by using an information transfer system as a simple
    analogy for ML.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过使用信息传输系统作为机器学习的简单类比来开始本节。
- en: A simple analogy of a machine learning system
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习系统的简单类比
- en: I remember a time I was in a *Twitter* Space involving a discussion about ML
    and some other cool topics. I was told to give a brief introduction to ML for
    those who were interested but didn't fully get the gist.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得有一次我参加了一个关于机器学习和其他一些很酷的话题的*Twitter* Space讨论。有人让我给那些感兴趣但没有完全理解要点的人简要介绍一下机器学习。
- en: The majority of people in this Twitter Space were software engineers with no
    previous knowledge of math, statistics, or any topic related to ML, and I came
    across instances where people failed to understand the terminology of the topic
    due to the addition of some technical terms.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个Twitter Space中，大多数人是没有数学、统计学或与机器学习相关的任何知识的软件工程师，我遇到了一些人由于增加了一些技术术语而无法理解该主题的术语的情况。
- en: This section aims to explain ML by avoiding too many technical terms and finding
    a common ground through which ML can be explained.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在通过避免使用太多技术术语，并通过可以解释机器学习的共同基础来解释机器学习。
- en: Using an information transfer system, such as a phone, information is taken
    from a source then encoded into a digital signal and transferred via a transfer
    channel to the receiver, which decodes the signal into the source input, which
    can be a voice, an image, and so on.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 使用信息传输系统，比如电话，信息从源头获取，然后编码成数字信号，通过传输通道传输到接收器，接收器将信号解码成源输入，可以是声音、图像等等。
- en: 'The following diagram shows the full concept of information transfer:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示显示了信息传输的完整概念：
- en: '![Figure 9.1 – Information transfer'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.1 – 信息传输'
- en: '](img/B17076_09_01.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_01.jpg)'
- en: Figure 9.1 – Information transfer
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 – 信息传输
- en: The preceding definition is for an information transfer system whose sender
    and receiver are at different endpoints, but for systems such as a megaphone,
    the input voice is encoded into a digital signal, which is then decoded and amplified
    at the output.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的定义是指一个发送者和接收者位于不同端点的信息传输系统，但对于像扩音器这样的系统，输入声音被编码成数字信号，然后在输出端解码和放大。
- en: 'The following shows a diagram of a megaphone:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个扩音器的图示：
- en: '![Figure 9.2 – Simple information transfer system'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.2 – 简单信息传输系统'
- en: '](img/B17076_09_02.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_02.jpg)'
- en: Figure 9.2 – Simple information transfer system
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2 – 简单信息传输系统
- en: Using the preceding paragraph, we can establish an overview of ML. In the preceding
    paragraph, we mentioned some specific keywords, which are encoded and decoded.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用前面的段落，我们可以建立对机器学习的概述。在前面的段落中，我们提到了一些特定的关键词，这些关键词被编码和解码。
- en: In an information transfer system, a large body of information – either voice
    or image – is encoded or compressed into a digital signal at the source end and
    then decoded back to the source information at the output end.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在信息传输系统中，大量的信息（声音或图像）被编码或压缩成数字信号，然后在输出端被解码回源信息。
- en: The same thing described in the preceding paragraph goes for a ML system – a
    large body of information is encoded or compressed into *Forms of representation*
    (mind the highlighted words) and then decoded into conceptual or intelligent or
    decisional output.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 前面段落中描述的事情也适用于机器学习系统——大量信息被编码或压缩成*表示形式*（注意高亮显示的词），然后解码为概念性、智能或决策性输出。
- en: Note the terms *digital signal* and *form of representation* in the two preceding
    paragraphs. In an information transfer system, there is some information theory
    that is responsible for converting any input no matter the form (any type of image,
    any type of sound/voice) into a digital signal.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意前两个段落中的术语*数字信号*和*表示形式*。在信息传输系统中，有一些信息理论负责将任何形式的输入（任何类型的图像、任何类型的声音/语音）转换成数字信号。
- en: But in ML, we have some forms of theories and algorithms. These algorithms do
    not just process input information and give an output. First, a sample of information
    is obtained. This information is processed and used to build a form of representation
    that summarizes the whole information and maps it to a decision output.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但在机器学习中，我们有一些理论和算法。这些算法不仅仅是处理输入信息并给出输出。首先，获取一部分信息样本。这些信息被处理并用来构建一种总结整个信息并将其映射到决策输出的表示形式。
- en: This form of representation is used to build the final ML system, which takes
    an input source, compares it to the form of representation, and outputs a decoded
    decision (intelligent output) that matches the comparison between the source input
    and the form of representation.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这种表示形式被用来构建最终的机器学习系统，该系统接受一个输入源，将其与表示形式进行比较，并输出一个匹配源输入和表示形式之间比较的解码决策（智能输出）。
- en: 'The following diagram shows the conceptual illustration of the two preceding
    paragraphs:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了前两段的概念图示：
- en: '![Figure 9.3 – Conceptual illustration of machine learning'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.3 – 机器学习的概念图示'
- en: '](img/B17076_09_03.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_03.jpg)'
- en: Figure 9.3 – Conceptual illustration of machine learning
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – 机器学习的概念图示
- en: 'There are some key things about ML to note from the preceding paragraphs, as
    follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的段落中，有一些关于机器学习的关键事项需要注意，如下：
- en: First, we generate a form of representation from a large set of information.
    Also, note that the process of generating a form of representation from a set
    of information is called **Training**.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们从大量信息中生成一种表示形式。另外，需要注意的是，从一组信息中生成一种表示形式的过程被称为**训练**。
- en: The form of representation generated is then used to create the final ML system,
    and this process is called **Inference**.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后生成的表示形式被用来创建最终的机器学习系统，这个过程被称为**推理**。
- en: In the next sub-section, we will see how this form of representation is generated,
    the whole idea behind generating a form of representation from a large set of
    information, and then using this representation to build the final ML system.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一小节中，我们将看到如何生成这种形式的表示，从大量信息中生成一种表示形式的整个想法，然后使用这种表示形式来构建最终的机器学习系统。
- en: Why machine learning works
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么机器学习有效
- en: During our illustration of training the ML model, we talked about generating
    a form of representation that is used to build our ML system. One thing to note
    is that this information or the data used to generate the form of representation
    is the data representation of our future source of information. Why do we need
    the data representation of our future source of information? In this sub-section,
    we will look into this and see how it helps in creating ML models.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们训练机器学习模型的说明中，我们谈到了生成一种表示形式来构建我们的机器学习系统。需要注意的一点是，用于生成表示形式的这些信息或数据是我们未来信息源的数据表示。我们为什么需要未来信息源的数据表示？在这一小节中，我们将探讨这一点，并看看它如何帮助创建机器学习模型。
- en: Let's assume we are told to carry out research about product interest in a particular
    community. Imagine this community consists of a large number of people and we
    are only able to reach a few people – let's say 50% of the community population.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们被要求对特定社区的产品兴趣进行研究。想象一下，这个社区有大量的人，而我们只能接触到其中的一部分人——比如说社区人口的50%。
- en: The idea is that, from the information obtained from 50% of the population,
    we should be able to generalize for the remaining 50% of the population. We assume
    this because a set of people from the same community or population are assumed
    to share quite a number of the same attributes and beliefs. Therefore, if we use
    information obtained from 50% of the individuals of this population to train our
    model, our model should be able to distinguish any information that comes from
    any individual belonging to the same population.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法是，从我们获得的50%人口的信息中，我们应该能够推广到剩下的50%人口。我们之所以这样假设，是因为来自同一社区或人口的一组人被假定具有相当多的相同属性和信念。因此，如果我们使用从该人口50%个体获得的信息来训练我们的模型，我们的模型应该能够区分来自同一人口的任何个体的信息。
- en: In the worst-case scenario, there might be some outliers in the population –
    folks who don't have the same beliefs as the rest of the people, or the individual
    information we obtained from 50% of the population might not capture the attributes
    of the other 50% of the population. In this case, the model will fail if this
    information is passed into the model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在最坏的情况下，人群中可能会有一些离群值——那些与其他人不持相同信念的人，或者我们从50%的人群中获得的个人信息可能无法捕捉到另外50%人群的属性。在这种情况下，如果将这些信息传递到模型中，模型将会失败。
- en: 'The preceding paragraph shows why in ML by default, the more data there is,
    the better the ML model. The following diagram shows a sample distribution (our
    50%-of-individuals information) and the population itself:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的段落说明了为什么在机器学习中，默认情况下，数据量越大，机器学习模型就越好。下图显示了一个样本分布（我们获得的50%个人信息）和人群本身：
- en: '![Figure 9.4 – Population distribution'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.4 – 人口分布'
- en: '](img/B17076_09_04.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_04.jpg)'
- en: Figure 9.4 – Population distribution
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 – 人口分布
- en: From *Figure 9.3*, when we say we are training in ML, we mean the ML algorithm
    is learning the parameters that control and generalize the population from our
    sampled population (this parameter is the form of representation in this case).
    We have two parameters, beta and alpha, and the goal of our training is for the
    model to obtain the best value from these parameters that control the population.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从*图9.3*中，当我们说我们在机器学习中进行训练时，我们的意思是机器学习算法正在学习控制和推广我们抽样人口的参数（在这种情况下，这个参数就是表示形式）。我们有两个参数，beta和alpha，我们训练的目标是让模型从这些控制人口的参数中获得最佳值。
- en: 'Let''s see a more concrete example: we want to create an app that assigns a
    particular product to dogs alone. But as you know, we have different breeds of
    dogs and dogs also have some facial features that are similar to those of cats.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个更具体的例子：我们想要创建一个只将特定产品分配给狗的应用。但是你知道，我们有不同品种的狗，狗也有一些与猫相似的面部特征。
- en: To create the ML model for this app, we sample a number of dog images, but this
    sample does not capture all breeds of dogs. The goal of an ML model is to capture
    the unique attributes/parameters of dogs alone from the data given to it (these
    unique attributes/parameters are the forms of representation).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建这个应用的机器学习模型，我们抽样了一些狗的图像，但这个样本并没有捕捉到所有品种的狗。机器学习模型的目标是从给定的数据中捕捉到独特的狗的属性/参数（这些独特的属性/参数是表示形式）。
- en: 'If the model is good, it should be able to tell whether an input image is a
    dog or not. Then how do we measure how good the model is? The following methods
    are used to achieve that:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型很好，它应该能够判断输入图像是否是狗。那么我们如何衡量模型的好坏？以下方法用于实现这一点：
- en: '**Objective functions**'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客观函数**'
- en: '**Evaluation metrics**'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估指标**'
- en: In the following sub-sections, we will see how these methods work.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的子章节中，我们将看到这些方法是如何工作的。
- en: Objective functions
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 客观函数
- en: We've seen how to sample data from a large population and use that to train
    our model and hope that the model generalizes well. During the course of training,
    we want to measure how close our model is to our goals, and to do that we create
    an objective function. Some call this function by a different name, such as the
    loss function or error rate. The lower the score returned by this function, the
    better our model is.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到如何从大量人口中抽样数据，并用它来训练我们的模型，并希望模型能很好地泛化。在训练过程中，我们想要衡量我们的模型与我们的目标有多接近，为此我们创建了一个客观函数。有些人称这个函数为不同的名称，比如损失函数或错误率。这个函数返回的分数越低，我们的模型就越好。
- en: To classify whether an image is a dog or not, we have our dataset containing
    images of dogs and cats, for example. This dataset also contains labels. Each
    image in the dataset has a label, which informs us whether the image in the dataset
    is a dog image or a cat image.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分类图像是否是狗，我们有包含狗和猫图像的数据集，例如。这个数据集也包含标签。数据集中的每个图像都有一个标签，告诉我们数据集中的图像是狗图像还是猫图像。
- en: 'The following shows an example of what the dataset will look like:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是数据集的示例：
- en: '![Figure 9.5 – Dataset sample'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.5 - 数据集样本'
- en: '](img/B17076_09_05.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_05.jpg)'
- en: Figure 9.5 – Dataset sample
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.5 - 数据集样本
- en: During training, each of the images in the data, as shown in *Figure 9.5*, is
    passed as input into the model, and the model predicts the label. The label predicted
    by the model is compared with the labels shown in *Figure 9.4* by the objective
    function. We keep training the model until the model predicts the true label of
    each image in the dataset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，数据中的每个图像，如*图9.5*所示，都被输入到模型中，并且模型预测标签。模型预测的标签与*图9.4*中显示的标签通过客观函数进行比较。我们持续训练模型，直到模型预测数据集中每个图像的真实标签。
- en: The model might be able to classify all the images in the dataset properly based
    on the objective function, but that does not mean the model generalizes well,
    that is, the model might be able to classify some dog images correctly during
    training, but when given images are not available in the dataset, as shown in
    *Figure 9.4*, the model misclassifies the images. This leads us to the second
    method.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可能能够根据客观函数正确分类数据集中的所有图像，但这并不意味着模型泛化良好，也就是说，模型可能能够在训练期间正确分类一些狗图像，但当给出数据集中没有的图像时，如*图9.4*所示，模型会错误分类图像。这引出了第二种方法。
- en: Evaluation metrics
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估指标
- en: We've trained our model and it is giving us a very low loss score, which is
    good, but we will need to be sure of whether the model has captured the attributes
    for the whole population or just for the sampled population of the dataset used
    for training. What am I saying? It is possible for the model to perform well while
    training but actually be bad if we are to test it on other images containing dogs
    and cats.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经训练了我们的模型，并且它给出了一个非常低的损失分数，这是好的，但我们需要确定模型是否已经捕捉到了整个人口的属性，还是只是对用于训练的数据集的抽样人口。我在说什么？模型在训练时可能表现良好，但如果我们要在包含狗和猫的其他图像上进行测试，实际上可能是糟糕的。
- en: To check whether the model is good and has captured attributes unique to each
    population of dogs and cats, we test the model on a set of datasets, which is
    also a sample from the same population as the one used for training. If the model
    is able to give us a better score, then the model is good; if the score is bad
    compared to that from the objective function, then the model is bad. This process
    is called the evaluation process and we use different metrics to measure the performance
    of the model. The metrics are called **Evaluation metrics**.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查模型是否良好并且是否捕捉到了独特于狗和猫每个人口的属性，我们在一组数据集上测试模型，这组数据集也是从用于训练的相同人口中抽样得到的。如果模型能够给出更好的分数，那么模型是好的；如果分数与客观函数的相比较差，那么模型是不好的。这个过程称为评估过程，我们使用不同的指标来衡量模型的性能。这些指标称为**评估指标**。
- en: 'The following diagram shows the pipeline of a ML model:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了机器学习模型的流程：
- en: '![Figure 9.6 – Machine learning pipeline'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.6 - 机器学习流程'
- en: '](img/B17076_09_06.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_06.jpg)'
- en: Figure 9.6 – Machine learning pipeline
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.6 - 机器学习流程
- en: In this section, we discussed ML-based information transfer. We saw how an ML
    model works and the basic workflow of an ML model. In the next section, we will
    talk about the grouping of ML tasks into different categories.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们讨论了基于机器学习的信息传递。我们看到了机器学习模型的工作原理以及机器学习模型的基本工作流程。在下一节中，我们将讨论将机器学习任务分组到不同类别中。
- en: Machine learning problems/tasks
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习问题/任务
- en: ML problems or tasks such as classification problems can be categorized into
    different groups based on how the model learns.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基于模型学习方式的不同，诸如分类问题的机器学习问题或任务可以被归类到不同的组别中。
- en: 'In this section, we will look into two of the most popular categories of ML
    problems:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将研究机器学习问题中最流行的两个类别：
- en: '**Supervised learning**'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监督学习**'
- en: '**Unsupervised learning**'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无监督学习**'
- en: First, we will look into supervised learning.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将研究监督学习。
- en: Supervised learning
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督学习
- en: In this category, the model learns under supervision. By supervision, we mean
    the model knows whether it is doing well based on the provided label. While training,
    we provide the model with a dataset containing a set of labels, which are used
    to correct and improve the model. With this, we can measure how well the model
    performs.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个类别中，模型在监督下学习。通过监督，我们指的是模型知道根据提供的标签自己的表现如何。在训练时，我们提供了一个包含一组标签的数据集，这些标签用于纠正和改进模型。有了这个，我们就可以衡量模型的表现如何。
- en: 'The following ML problems/tasks belong to this category:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 以下机器学习问题/任务属于这个类别：
- en: '**Classification problems**: In this type of problem, the model is made to
    classify an input to a set of discrete categories, such as classifying whether
    the image is a dog or a cat.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类问题**：在这种类型的问题中，模型被制作成将输入分类到一组离散的类别，比如分类图像是狗还是猫。'
- en: '**Regression problems**: This involves the model mapping the input to a set
    of continuous values. For example, creating a model to predict the price of a
    house given some features of the house.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归问题**：这涉及模型将输入映射到一组连续值。例如，创建一个模型来预测房屋的价格，给定房屋的一些特征。'
- en: 'The following diagram shows what classification is:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了分类的示例：
- en: '![Figure 9.7 – Classification problem'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.7 – 分类问题'
- en: '](img/B17076_09_07.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_07.jpg)'
- en: Figure 9.7 – Classification problem
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.7 – 分类问题
- en: 'The following diagram shows the illustration of a regression problem:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了回归问题的示例：
- en: '![Figure 9.8 – Regression problem'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.8 – 回归问题'
- en: '](img/B17076_09_08.jpg)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_08.jpg)'
- en: Figure 9.8 – Regression problem
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.8 – 回归问题
- en: In summary, a supervised learning algorithm is used for problems in which there
    is a label provided with the dataset, where the label is used to measure the performance
    of the model. Sometimes we have data, but we don't have a ground truth that is
    a label to scale how the model performs. This leads us to unsupervised learning.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，监督学习算法用于数据集中提供了标签的问题，其中标签用于衡量模型的性能。有时我们有数据，但没有一个可以衡量模型表现的标签。这就引出了无监督学习。
- en: Unsupervised learning
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 无监督学习
- en: When we don't have labels, but we have our data, what can we do? The best thing
    to do is to draw insight from the data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们没有标签，但有数据时，我们可以做什么？最好的办法是从数据中获取见解。
- en: Remember the population example at the beginning of the section? Let's say we
    sample some set of entities from a population but have no prior knowledge of their
    behavior. The best thing is to study them for some time so we can understand their
    likes and dislikes and find out what makes them unique.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 还记得本节开头的人口例子吗？假设我们从人口中抽取了一些实体，但对他们的行为没有先验知识。最好的办法是研究一段时间，这样我们就可以了解他们的喜好和厌恶，并找出使他们独特的因素。
- en: Through this observation, we can group the population into categories based
    on their beliefs, occupation, food tastes, and so on.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种观察，我们可以根据他们的信仰、职业、食物口味等将人口分成不同的类别。
- en: 'The following ML problems belong to the unsupervised learning category:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下机器学习问题属于无监督学习类别：
- en: '**Clustering problems**: Clustering problems involve revealing some hidden
    attribute in a dataset (our sampled population) and then grouping each entity
    in the population based on this attribute.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**聚类问题**：聚类问题涉及在数据集（我们抽样的人口）中揭示一些隐藏的属性，然后根据这些属性将人口中的每个实体分组。'
- en: '**Association problems**: This involves the discovery association rule in a
    population. It involves knowing whether people that engage in one activity also
    engage in another activity.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关联问题**：这涉及在人口中发现关联规则。它涉及知道参与一项活动的人是否也参与另一项活动。'
- en: 'The main gist of this is that we want to obtain a hidden insight from this
    dataset as shown in the following diagram:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这主要是因为我们希望从数据集中获得隐藏的见解，如下图所示：
- en: '![Figure 9.9 – Unsupervised learning (clustering example)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![图9.9 – 无监督学习（聚类示例）'
- en: '](img/B17076_09_09.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B17076_09_09.jpg)'
- en: Figure 9.9 – Unsupervised learning (clustering example)
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.9 – 无监督学习（聚类示例）
- en: In this section, we looked into some categories of ML problems, and we also
    saw a scenario in which each ML problem category is important and the kind of
    tasks they are meant to be used for.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们研究了一些机器学习问题的类别，我们还看到了每个机器学习问题类别都很重要的场景，以及它们用于的任务类型。
- en: In the next section, we will talk about making ML more accessible.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何使机器学习更易于访问。
- en: Machine learning in JavaScript
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: JavaScript中的机器学习
- en: The web is the most accessible platform and JavaScript is the language used
    across the web, hence ML in JavaScript gives us more control and accessibility.
    In the *Why you need Danfo.js* section of [*Chapter 3*](B17076_03_ePub_RK.xhtml#_idTextAnchor066),
    *Getting Started with Danfo.js*, we talked about the importance of bringing ML
    the web. We also talked about how browsers' computational power is increasing
    and how this is a benefit to JavaScript for ML.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是最可访问的平台，JavaScript是网络上使用的语言，因此JavaScript中的机器学习给了我们更多的控制和可访问性。在[*第3章*](B17076_03_ePub_RK.xhtml#_idTextAnchor066)的*为什么需要Danfo.js*部分，*开始使用Danfo.js*，我们谈到了将机器学习带到网络的重要性。我们还谈到了浏览器的计算能力正在增加，这对JavaScript来说是一个好处。
- en: 'In this section, I will list some open source tools for ML tasks in the browser:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将列出一些用于浏览器中机器学习任务的开源工具：
- en: '**TensorFlow.js** (**tfjs**) ([https://github.com/tensorflow/tfjs](https://github.com/tensorflow/tfjs)):
    A WebGL accelerated JavaScript library for training and deploying ML models.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow.js** (**tfjs**) ([https://github.com/tensorflow/tfjs](https://github.com/tensorflow/tfjs))：用于训练和部署机器学习模型的WebGL加速JavaScript库。'
- en: '**datacook** ([https://github.com/imgcook/datacook](https://github.com/imgcook/datacook)):
    A JavaScript framework for feature engineering on datasets.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**datacook** ([https://github.com/imgcook/datacook](https://github.com/imgcook/datacook))：用于数据集特征工程的JavaScript框架。'
- en: '**Nlp.js** ([https://github.com/axa-group/nlp.js](https://github.com/axa-group/nlp.js)):
    A JavaScript framework for NLP tasks such as sentiment analysis, automatic language
    identity, entity extraction, and so on.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Nlp.js**（[https://github.com/axa-group/nlp.js](https://github.com/axa-group/nlp.js)）：用于NLP任务的JavaScript框架，如情感分析、自动语言识别、实体提取等。'
- en: '**Natural** ([https://github.com/NaturalNode/natural](https://github.com/NaturalNode/natural)):
    Also, NLP, it covers almost all the necessary algorithms for NLP tasks.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Natural**（[https://github.com/NaturalNode/natural](https://github.com/NaturalNode/natural)）：另外，NLP，它涵盖了几乎所有NLP任务所需的算法。'
- en: '**Pipcook** ([https://github.com/alibaba/pipcook](https://github.com/alibaba/pipcook)):
    A machine learning platform for web developers.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pipcook**（[https://github.com/alibaba/pipcook](https://github.com/alibaba/pipcook)）：面向Web开发人员的机器学习平台。'
- en: '**Jimp** ([https://github.com/oliver-moran/jimp](https://github.com/oliver-moran/jimp)):
    An image processing library written entirely in JavaScript.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jimp**（[https://github.com/oliver-moran/jimp](https://github.com/oliver-moran/jimp)）：一个完全用JavaScript编写的图像处理库。'
- en: '**Brain.js** ([https://github.com/BrainJS/brain.js](https://github.com/BrainJS/brain.js)):
    A GPU accelerated neural network in JavaScript for the browser and Node.js.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Brain.js**（[https://github.com/BrainJS/brain.js](https://github.com/BrainJS/brain.js)）：用于浏览器和Node.js的GPU加速神经网络。'
- en: The preceding tools are the most popular and have recent updates. By using these
    tools, you can integrate ML into your next web app.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 上述工具是最受欢迎的，并且有最新的更新。通过使用这些工具，您可以将ML集成到您的下一个Web应用程序中。
- en: In the next section, we will look into some applications of ML in the real world.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨ML在现实世界中的一些应用。
- en: Applications of machine learning
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的应用
- en: ML is transforming software development and is also making things more *automatic*,
    *self-driving*, and *self-operating*. In this section, we will look into some
    examples of ML applications.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: ML正在改变软件开发，并且也使事物更加*自动*、*自动驾驶*和*自动操作*。在本节中，我们将探讨一些ML应用的例子。
- en: 'The following are examples of machine learning applications:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是机器学习应用的例子：
- en: '**Machine translation**: ML enables us to build software that easily translates
    a language to another language.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**机器翻译**：ML使我们能够构建轻松将一种语言翻译成另一种语言的软件。'
- en: '**Games**: With some advanced ML algorithms, some software is becoming better
    at playing more complicated games such as the game Go and beating world champions
    at what they do best. For example, here''s a video about **AlphaGo**: [https://www.youtube.com/watch?v=WXuK6gekU1Y](https://www.youtube.com/watch?v=WXuK6gekU1Y).'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**游戏**：借助一些先进的ML算法，一些软件正在变得更擅长玩更复杂的游戏，比如围棋，并在他们最擅长的领域击败世界冠军。例如，这是一个关于**AlphaGo**的视频：[https://www.youtube.com/watch?v=WXuK6gekU1Y](https://www.youtube.com/watch?v=WXuK6gekU1Y)。'
- en: '**Vision**: Machines are getting better at seeing and providing meaning for
    what they see.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**视觉**：机器正在变得更擅长看和为他们所看到的提供意义。'
- en: 'a) **Self-driving cars**: ML is helping to create fully self-driving cars.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: a) **自动驾驶汽车**：ML正在帮助创建完全自动驾驶汽车。
- en: 'b) **Tesla demonstration of a self-driving car**: [https://www.youtube.com/watch?v=VG68SKoG7vE](https://www.youtube.com/watch?v=VG68SKoG7vE)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: b) **特斯拉展示自动驾驶汽车**：[https://www.youtube.com/watch?v=VG68SKoG7vE](https://www.youtube.com/watch?v=VG68SKoG7vE)
- en: '**Recommendation engines**: ML algorithms are improving recommendation engines
    and hooking customers.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**推荐引擎**：ML算法正在改进推荐引擎并吸引顾客。'
- en: 'How *Netflix* is using ML for personalized recommendations: [https://netflixtechblog.com/artwork-personalization-c589f074ad76](https://netflixtechblog.com/artwork-personalization-c589f074ad76)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '*Netflix*如何使用ML进行个性化推荐：[https://netflixtechblog.com/artwork-personalization-c589f074ad76](https://netflixtechblog.com/artwork-personalization-c589f074ad76)'
- en: '**Art**: ML is used to generate artworks, new stories, new paintings, and new
    images.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**艺术**：ML被用来生成艺术作品、新故事、新绘画和新图像。'
- en: 'a) Here is a website that generates images of people that never existed: [https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: a) 这是一个生成从未存在的人的图像的网站：[https://thispersondoesnotexist.com/](https://thispersondoesnotexist.com/)。
- en: 'b) A generated art gallery: [https://www.artaigallery.com/](https://www.artaigallery.com/).'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: b) 生成的艺术画廊：[https://www.artaigallery.com/](https://www.artaigallery.com/)。
- en: 'c) Architectural design with ML: [https://span-arch.org/](https://span-arch.org/)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: c) 使用ML的建筑设计：[https://span-arch.org/](https://span-arch.org/)
- en: In this section, we saw a few examples of how ML is being used for different
    purposes. In the next section, we will provide some materials to better understand
    ML.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了ML如何被用于不同的目的的一些例子。在下一节中，我们将提供一些材料来更好地理解ML。
- en: Resources to understand machine learning in depth
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入了解机器学习的资源
- en: In this section, we will provide resources to better understand ML in depth
    and get better at creating software making use of ML algorithms.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将提供资源，以更深入地了解ML，并更好地创建利用ML算法的软件。
- en: 'The following are resources that can be used to understand ML:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可以用来理解ML的资源：
- en: '**fastai** ([https://www.fast.ai/](https://www.fast.ai/)): This community provides
    courses, frameworks, and books for ML practitioners.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**fastai**（[https://www.fast.ai/](https://www.fast.ai/)）：这个社区为ML从业者提供课程、框架和书籍。'
- en: '**Cs231n** ([http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)): This
    course gives the fundamentals of **deep learning** and introduces you to computer
    vision.'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cs231n（[http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)）：这门课程介绍了**深度学习**的基础知识，并向您介绍了计算机视觉。
- en: '**Hugging Face**: Hugging Face provides the best framework for **natural language
    processing** and different transformer models. It also has a course ([https://huggingface.co/course/chapter1](https://huggingface.co/course/chapter1))
    that provides a full detail of transformer models and deployment.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Hugging Face**：Hugging Face提供了最好的**自然语言处理**框架和不同的变压器模型。它还有一个课程（[https://huggingface.co/course/chapter1](https://huggingface.co/course/chapter1)），提供了变压器模型和部署的详细信息。'
- en: '**Andrew Ng course**: A ML course on *YouTube* that also provides full ML details.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Andrew Ng课程**：YouTube上的一个ML课程，也提供了完整的ML细节。'
- en: There are tons of available materials to learn about ML online. Just follow
    one path and follow it to the end and avoid jumping from one lecture to another.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有大量的在线学习机器学习的材料可供学习。只需沿着一条路径走到底，避免跳来跳去。
- en: Summary
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked into ML using the concept of information transfer.
    We then looked into how and why it works. We also talked about the idea of sampling
    from a population to understand the population.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过信息传递的概念来研究机器学习。然后我们探讨了它是如何以及为什么起作用的。我们还谈到了从人口中进行抽样以了解人口的概念。
- en: We talked about different categories of ML problems and also discussed some
    tools needed for ML for the web platform, and we also showed some examples of
    real-world applications of ML.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了不同类别的机器学习问题，还讨论了在网络平台上进行机器学习所需的一些工具，并展示了一些机器学习在现实世界中的应用示例。
- en: The intention of this chapter was to get the whole idea of ML to aid understanding
    during personal learning.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是在个人学习过程中帮助理解机器学习的整体概念。
- en: In the next chapter, we will introduce **TensorFlow.js**. TensorFlow.js is useful
    when integrating ML into your web apps.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍**TensorFlow.js**。TensorFlow.js在将机器学习集成到您的Web应用程序中非常有用。
