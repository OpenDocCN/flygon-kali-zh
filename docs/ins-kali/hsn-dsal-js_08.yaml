- en: Big O Notation, Space, and Time Complexity
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大O符号、空间和时间复杂度
- en: 'In the previous chapters, we have often spoken about optimizing our code/algorithms
    and have briefly used the terms space and time complexity and how we want to reduce
    them. As the name suggests, it is the complexity of the code that we want to keep
    to a minimum, but what does that entail? What are the different levels of this
    said complexity? How do we calculate the space and time complexity of an algorithm?
    These are the questions that we will address in this chapter while discussing
    the following topics:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们经常谈到优化我们的代码/算法，并简要使用了空间和时间复杂度这些术语，以及我们希望将它们降到最低。顾名思义，我们希望将代码的复杂性保持在最低，但这意味着什么？这种复杂性有不同的级别吗？我们如何计算算法的空间和时间复杂度？这些是我们将在本章讨论的问题，同时讨论以下主题：
- en: Varying degrees of time complexity
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同程度的时间复杂度
- en: Space complexity and Auxiliary space
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空间复杂度和辅助空间
- en: Terminology
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语
- en: The terminology used when discussing the space and time complexity of an algorithm
    is something that one, as a developer, will come across very often. Popular terms
    such as **Big-O***, *also known as **O (something)***, *and some not-so-popular
    terms such as **Omega (something)** or **Theta (something)** are often used to
    describe the complexity of an algorithm. The O actually stands for Order, which
    represents the order of the function.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论算法的空间和时间复杂度时使用的术语是开发人员经常会遇到的。流行的术语，如**大O符号**，也被称为**O（something）**，以及一些不那么流行的术语，如**Omega（something）**或**Theta（something）**经常用来描述算法的复杂性。O实际上代表Order，表示函数的阶数。
- en: Let's first talk only about the time complexity of an algorithm. This basically
    boils down to us trying to figure out how long it will take for a system to execute
    our algorithm for a given dataset (D). We can technically run this algorithm on
    the said system and log its performance, but since not all systems are the same
    (for example, OS, number of processors, and read write speeds), we can't necessarily
    expect the result to truly represent the average time it would take to execute
    our algorithm for our dataset, D. At the same time, we would also need to know
    how our algorithm performs with the changing size of our dataset, D. Does it take
    the same time for 10 elements and 1000 elements? Or does the time taken increase
    exponentially?
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先只讨论算法的时间复杂度。基本上，这归结为我们试图弄清楚系统在给定数据集（D）上执行我们的算法需要多长时间。我们可以在所述系统上运行此算法并记录其性能，但由于并非所有系统都相同（例如，操作系统、处理器数量和读写速度），我们不能期望结果真正代表执行我们的算法所需的平均时间。同时，我们还需要知道我们的算法在数据集D的大小变化时的表现。它对于10个元素和1000个元素需要相同的时间吗？还是花费的时间呈指数增长？
- en: With all the above, how do we clearly understand the complexity of an algorithm?
    We do this by breaking down an algorithm into a set of basic operations and then
    combine them to get the overall number/complexity of each operation. This truly
    defines the time complexity of an algorithm as the rate of growth of time with
    the size of the input dataset, D.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有了上述所有内容，我们如何清楚地理解算法的复杂性呢？我们通过将算法分解为一组基本操作，然后将它们组合起来，得到每个操作的总体数量/复杂度。这真正定义了算法的时间复杂度，即随着输入数据集D的大小增长而增长的时间速率。
- en: Now, to calculate the time complexity in abstract terms, let's assume that we
    have a machine that takes one unit of time to perform some basic operations such
    as read, write, assignments, arithmetic, and logical calculations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了以抽象的方式计算时间复杂度，让我们假设我们有一台机器，它需要一个单位的时间来执行一些基本操作，比如读取、写入、赋值、算术和逻辑计算。
- en: 'With that said, let''s take a simple function that returns the square of a
    given number:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这里，让我们来看一个简单的函数，它返回给定数字的平方：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: We have defined our machine, which consumes one unit of time, to perform the
    multiplication and another 1 unit to return the result. Irrespective of the input,
    our algorithm always takes only 2 units of time, and since this is not changing,
    it is referred to as a constant time algorithm. It does not matter that the constant
    time taken here is k units of time. We can represent all the similar functions,
    which take a constant time to execute as a set of functions `O(1)` or `big-O(1)`.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经定义了我们的机器，它消耗一个单位的时间来执行乘法，另一个单位来返回结果。不考虑输入，我们的算法总是只需要2个单位的时间，因为这不会改变，所以被称为常数时间算法。这里所花费的常数时间是k个时间单位并不重要。我们可以将所有类似的函数表示为`O(1)`或`big-O(1)`的一组函数，这些函数执行需要恒定的时间。
- en: 'Let''s take another example in which we loop over a list of size n and multiply
    each of the elements by a factor:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再举一个例子，我们循环遍历一个大小为n的列表，并将每个元素乘以一个因子：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: To calculate the time complexity of this function, we will need to first calculate
    the cost to execute each statement in this function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算这个函数的时间复杂度，我们首先需要计算这个函数中每个语句的执行成本。
- en: 'The first statement executes *n + 1* times before it breaks out of it, and
    each time it is performed, it costs 1 unit to increment and 1 unit to make the
    comparison check among other things. In other words, we can assume that it costs
    us *C*[*1* ]units of time in each iteration, so the total cost is *C[1]*(n+1)*
    for the following line of code:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条语句在中断之前执行*n+1*次，并且每次执行时，增加1个单位的成本和进行比较检查等其他操作也需要1个单位的成本。换句话说，我们可以假设每次迭代中花费了*C*[1]个时间单位，因此下面这行代码的总成本是*C[1]*(n+1)*：
- en: '[PRE2]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'In the next statement, we will multiply the value in the array at a given index
    by a factor of 2\. Since this is within the loop, this statement is executed n times,
    and each time it does, let''s assume it costs us *C[2]* units. So, the total cost
    of execution of this line would be *C[2]* n*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一条语句中，我们将数组中给定索引处的值乘以2。由于这是在循环内部，这条语句执行了n次，每次执行时，我们假设它花费了*C[2]*个单位。因此，这行代码的总执行成本将是*C[2]*n*：
- en: '[PRE3]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, we finally have the return statement, which also takes a constant amount
    of time—*C[3]*—to return the final array to the caller. Putting all these costs
    together, we have the total cost of the method as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们最终有返回语句，它也需要花费一个常数的时间—*C[3]*—来将最终的数组返回给调用者。将所有这些成本加在一起，我们得到方法的总成本如下：
- en: '[PRE4]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: We can see that, in this case, the cost of the method is directly proportional
    to the size of the input array, `N`. Thus, this set of functions can be represented
    by `O(n)`, indicating that they are directly proportional to the input size.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在这种情况下，方法的成本与输入数组的大小`N`成正比。因此，这组函数可以用`O(n)`表示，表明它们与输入大小成正比。
- en: However, before we jump to more examples, let's first take a look at how we
    will represent the complexity without all the calculations.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在我们跳到更多的例子之前，让我们先看看如何在没有所有计算的情况下表示复杂度。
- en: Asymptotic Notations
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 渐近符号
- en: Asymptotic Notations come in handy when we want to derive and compare the time
    complexity of two or more algorithms. What Asymptotic Notations mean is that,
    once we have the time complexity of an algorithm calculated, we are simply going
    to start replacing *n* (the size of the input of our algorithm) with a very large
    number (tending toward infinity) and then get rid of the constant from the equation.
    Doing this would leave us with the only factors that truly affect our execution
    time.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要推导和比较两个或更多算法的时间复杂度时，渐近符号非常有用。渐近符号的意思是，一旦我们计算出一个算法的时间复杂度，我们只需要用一个非常大的数（趋向于无穷大）来替换*n*（我们算法的输入大小），然后去掉方程中的常数。这样做会让我们留下真正影响我们执行时间的唯一因素。
- en: 'Let''s take the same example as we did in the preceding section:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拿和前面部分相同的例子：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: When we apply the rules we just described relating to Asymptotic Notations,
    that is, *n -> Infinity*, we can quickly see that the effects of `C[4]` are rather
    insignificant and can be dropped. We can also say the same for the multiplication
    factor `C[5]`. What we are left with is that this time, `T[double]`, is directly
    proportional to the size of the input array `(n)` and thus we were able to denote
    this with the `O(n)` notation since the size n is the only variable that matters
    in this case.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们应用刚刚描述的关于渐近符号的规则时，即*n -> 无穷大*，我们很快就能看到`C[4]`的影响相当微不足道，可以忽略不计。我们也可以说相同的事情适用于乘法因子`C[5]`。我们得到的是这一次，`T[double]`与输入数组的大小`(n)`成正比，因此我们能够用`O(n)`符号表示这一点，因为在这种情况下，大小n是唯一重要的变量。
- en: 'There are three main types of Asymptotic Notations, which can be used to classify
    the running time of an algorithm:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种主要类型的渐近符号，可以用来对算法的运行时间进行分类：
- en: '**Big-O**: Represents the upper bound of the rate of growth of runtime'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Big-O**：表示运行时间增长率的上界'
- en: '**Omega**: Represents the lower bound of the rate of growth of runtime'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Omega**：表示运行时间增长率的下界'
- en: '**Theta**: Represents the tight bound of the rate of growth of runtime'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Theta**：表示运行时间增长率的紧密界限'
- en: Big-O notation
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大O符号
- en: 'Let''s assume that we have a `f(n)` method, which we want to represent with
    a time complexity function (that is, a Set) `g(n)`:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个`f(n)`方法，我们想用一个时间复杂度函数（即一个集合）`g(n)`来表示：
- en: '`f(n)` is `O(g(n))` if, and only if, there exists constants c and n[0], where
    `f(n) <= cg(n)` and where the input size `n >= n[0]`.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当且仅当存在常数c和n[0]，使得`f(n) <= cg(n)`，且输入大小`n >= n[0]`时，`f(n)`是`O(g(n))`。
- en: 'Now, let''s try to apply this to our previous example:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试将这个应用到我们之前的例子中：
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: For this example, we denoted it with the set `O(n)`, that is, `g(n) = n`.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们用集合`O(n)`表示它，也就是`g(n) = n`。
- en: 'For our time complexity assertion to hold, we will need to satisfy the following
    condition:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使我们的时间复杂度断言成立，我们需要满足以下条件：
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This equation is satisfied for values `c = 5` and `n[0] = 1`. Also, since the
    definition is met, we can safely say that the `f(n)` function is `big-O(g(n))`,
    that is, `O(g(n))` or, in this case, `O(n)`. We can also see this when plotted
    on a graph, as shown in the following diagram; after the value of `n = 1`, we
    can see that the value of `c * g(n)` is always greater than `f(n)` asymptotically.
    Take a look at the following diagram:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方程对于`c = 5`和`n[0] = 1`的值是满足的。另外，由于定义得到满足，我们可以安全地说`f(n)`函数是`big-O(g(n))`，也就是`O(g(n))`，或者在这种情况下是`O(n)`。我们也可以在图表上看到这一点，如下图所示；在`n
    = 1`之后，我们可以看到`c * g(n)`的值在渐近上始终大于`f(n)`的值。看一下下面的图表：
- en: '![](assets/bf044bdb-d2b6-4447-b244-932702ba8e11.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bf044bdb-d2b6-4447-b244-932702ba8e11.png)'
- en: Omega notation
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Omega符号
- en: 'Similar to the Big O notation discussed earlier, Omega notation denotes the
    lower bound rate of growth of the runtime of an algorithm. So, if we have a `f(n)` method, which
    we want to represent with a time complexity function (that is, a Set) `g(n)`,
    then Omega notation can be defined as the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于之前讨论的大O符号，Omega符号表示算法运行时间的增长率的下界。因此，如果我们有一个`f(n)`方法，我们想用一个时间复杂度函数（即一个集合）`g(n)`来表示，那么Omega符号可以定义如下：
- en: '`f(n)` is `O(g(n))` if and only if there exists constants c and n[0] where
    `f(n) >= cg(n)` where the input size `n >= n[0]`.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当且仅当存在常数c和n[0]，使得`f(n) >= cg(n)`，其中输入大小`n >= n[0]`时，`f(n)`是`O(g(n))`。
- en: 'Taking the same preceding example, we have `f(n) = 4n + 1` and then `g(n) =
    n`. We will need to validate the existence of c and n[0] such that the preceding
    condition holds, as shown in the following snippet:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 采用和前面部分相同的例子，我们有`f(n) = 4n + 1`，然后`g(n) = n`。我们需要验证存在c和n[0]，使得前面的条件成立，如下面的片段所示：
- en: '[PRE8]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We can see that this condition holds for `c = 4` and `n[0] = 0`. Thus, we can
    say that our function `f(n)` is `Ω(n)`. We can plot this as well on a chart and
    take a look at how it represents our function f(n) and its upper and lower bounds:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这个条件对于`c = 4`和`n[0] = 0`是成立的。因此，我们可以说我们的函数`f(n)`是`Ω(n)`。我们也可以在图表上表示这一点，看一下它如何表示我们的函数`f(n)`以及它的上界和下界：
- en: '![](assets/70c13bfd-ef7e-4149-bf2f-c75c67e23ac2.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/70c13bfd-ef7e-4149-bf2f-c75c67e23ac2.png)'
- en: From the preceding diagram, we can see that our function—`f(n)`—(in black) lies
    in between our asymptotic upper and lower bounds (in gray). The *x*-axis indicates
    the value of the size (*n*).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，我们可以看到我们的函数`f(n)`（黑色）位于渐近上限和下限（灰色）之间。*x*轴表示大小（*n*）的值。
- en: Theta Notation
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: θ符号
- en: 'Having calculated the upper and lower bound rates of growth of our function
    `f(n)`, we can now determine the tight bound or theta of our function `f(n)` as
    well. So, if we have a `f(n)` method, which we want to represent with a time complexity
    function (also known as a set) `g(n)`, then the tight bound of a function can
    be defined as follows:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 计算了函数`f(n)`的增长率的上限和下限之后，我们现在也可以确定函数`f(n)`的紧密边界或θ。因此，如果我们有一个`f(n)`方法，我们想用时间复杂度函数（也称为集合）`g(n)`来表示，那么函数的紧密边界可以定义如下：
- en: f(n) is O(g(n)) if , and only if , there exists constants c and n[0,] where
    c[1]g(n) < = f(n) <= c[2]g(n) where the input size n >= n[0]
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`f(n)`是O(g(n))，当且仅当存在常数c和n[0]，使得c[1]g(n) <= f(n) <= c[2]g(n)，其中输入大小n >= n[0]
- en: 'The preceding operation, from the previous two sections, is already calculated
    for our function, that is, `f(n) = 4n + 1`: the value of `c[1] = 4` , `c[2] =
    5`, and `n[0] = 1`.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 前两节的操作已经计算了我们的函数，即`f(n) = 4n + 1`：`c[1] = 4`，`c[2] = 5`，`n[0] = 1`。
- en: This provides us with the tight bound of our function `f(n)` and, since the
    function always lies within the tight bound after `n = 1`, we can safely say that
    our function f(n) has a tightly bound rate of growth as `θ(n)`.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这为我们提供了函数`f(n)`的紧密边界，由于函数始终在`n = 1`之后的紧密边界内，我们可以安全地说我们的函数f(n)具有紧密的增长率，即`θ(n)`。
- en: Recap
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: 'Let''s quickly take a look at what we discussed the different types of notations
    before moving on to the next topic:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续下一个主题之前，让我们快速回顾一下我们讨论的不同类型的符号：
- en: '`O` means that the growth rate of `f(n)` is asymptotically less than or equal
    to the growth rate of *g(n)*'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`O`表示`f(n)`的增长率渐近小于或等于*g(n)*的增长率'
- en: '`Ω` means that the growth rate of `f(n)` is asymptotically greater than or
    equal to the growth rate of *g(n)*'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Ω`表示`f(n)`的增长率渐近大于或等于*g(n)*的增长率'
- en: '`θ` means that the growth rate of `f(n)` is asymptotically equal to the growth
    rate of `g(n)`'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`θ`表示`f(n)`的增长率渐近等于`g(n)`的增长率'
- en: Examples of time complexity
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间复杂度的例子
- en: Let's now examine some examples of time complexity calculations, since in 99%
    of the cases we need to know the maximum time a function might take to execute;
    we will be mostly analyzing the worst case time complexity, that is, the upper
    bound of the rate of growth based on the input of a function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们检查一些时间复杂度计算的例子，因为在99%的情况下，我们需要知道函数可能执行的最长时间；我们将主要分析最坏情况时间复杂度，即基于函数输入的增长率的上限。
- en: Constant time
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常数时间
- en: 'A constant time function is one which takes the same amount of time to execute,
    irrespective of the size of the input that is passed into the function:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 常数时间函数是指执行时间不受传入函数的大小的影响：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The preceding code snippet is an example of a constant time function and is
    denoted by O(1). Constant time algorithms are the most sought out algorithms for
    obvious reasons, such as them running in a constant time, irrespective of the
    size of the input.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的代码片段是一个常数时间函数的例子，用O(1)表示。常数时间算法是最受追捧的算法，因为它们无论输入的大小如何都在恒定时间内运行。
- en: Logarithmic time
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对数时间
- en: 'A Logarithmic time function is one in which the time of execution is proportional
    to the logarithm of the input size. Consider the following example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对数时间函数是指执行时间与输入大小的对数成比例。考虑以下例子：
- en: '[PRE10]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We can see that in any given iteration, the value of *i = 2^i*, so in the *n^(th)*
    iteration, the value of *i = 2^n*. Also, we know that the value of *i* is always
    less than the size of the loop itself (*N*). From that, we can deduce the following
    result:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在任何给定的迭代中，*i = 2^i*，因此在第*n*次迭代中，*i = 2^n*。此外，我们知道*i*的值始终小于循环本身的大小(*N*)。由此，我们可以推断出以下结果：
- en: '[PRE11]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: From the preceding code, we can see that the number of iterations would always
    be less than the log on the input size. Hence, the worst-case time complexity
    of such an algorithm would be `O(log(n))`.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的代码中，我们可以看到迭代次数始终小于输入大小的对数。因此，这样的算法的最坏情况时间复杂度将是`O(log(n))`。
- en: 'Let''s consider another example, where we halve the value of `i` for the next
    iteration:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子，下一次迭代将`i`的值减半：
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here, the value of `i` in the `n^(th)` iteration will be `N/2^n`, and we know
    that the loop ends with the value of `1`. So, for our loop to stop, the value
    of `i` needs to be `<= 1`; now, by combining those two conditions, we get the
    following:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在第`n`次迭代中，`i`的值将为`N/2^n`，我们知道循环以值`1`结束。因此，为了使循环停止，`i`的值需要`<= 1`；现在，通过结合这两个条件，我们得到以下结果：
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We can again come to a similar conclusion as our first example, that the number
    of iterations will always be less than the log value of the input size or value.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以得出与第一个例子类似的结论，即迭代次数始终小于输入大小或值的对数值。
- en: One thing to notice is that this is not limited to the doubling or halving phenomenon
    only. This can be applied to any algorithm in which the number of the steps are
    being cut down by a factor, `k`. The worst case time complexity of such algorithms
    would be `O(log[k](N))`, and, in our preceding examples, `k` happens to be `2`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，这不仅限于加倍或减半现象。这可以应用于任何算法，其中步骤的数量被因子`k`减少。这类算法的最坏情况时间复杂度将是`O(log[k](N))`，在我们的前面的例子中，`k`恰好是`2`。
- en: Logarithmic Time complexity algorithms are the next favorites since they consume
    time logarithmically. Even if the size of the input doubles, the running time
    of the algorithm only increases by a small number additively (which is the definition
    of a logarithm).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对数时间复杂度算法是下一个受欢迎的，因为它们以对数方式消耗时间。即使输入的大小翻倍，算法的运行时间也只会增加一个小的数（这是对数的定义）。
- en: Linear time
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性时间
- en: 'Let''s now discuss one of the most common time complexities, the linear time.
    As one can guess, linear time complexity of a method indicates that the method
    takes linear time to execute:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们讨论最常见的时间复杂度之一，线性时间。可以猜到，方法的线性时间复杂度表示该方法执行需要线性时间：
- en: '[PRE14]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is a very basic `for` loop, within which we are performing some constant
    time operations. As the size of N increases, the number of the times the loop
    gets executed also increases.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常基本的`for`循环，我们在其中执行一些常数时间的操作。随着N的大小增加，循环执行的次数也会增加。
- en: As you can see, the value of `i` in each iteration is incremented by a constant,
    `c`, and not by `1`. This is because it does not matter what the increments are,
    as long as they are linear.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，在每次迭代中，`i`的值都会增加一个常数`c`，而不是`1`。这是因为增量是什么并不重要，只要它们是线性的。
- en: In the first iteration, the value of `i = 0`; in the second iteration, the value
    of `i = c`, then its `c + c = 2c` in the third iteration, and `3c` in the fourth
    iteration, and so on. So, in the nth iteration, we have the value of `i = c(n-1)`,
    which asymptotically is `O(n).`
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次迭代中，`i = 0`；在第二次迭代中，`i = c`，然后在第三次迭代中是`c + c = 2c`，在第四次迭代中是`3c`，依此类推。因此，在第n次迭代中，我们有`i
    = c(n-1)`的值，渐近地是`O(n)`。
- en: Depending on what your use case is, linear time complexity may, or may not,
    be good. This is kind of the gray area, which you may sometimes want to let go
    if you are unsure of whether further optimization is necessary or not.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的用例是什么，线性时间复杂度可能是好的，也可能不是。这有点是灰色地带，如果你不确定是否需要进一步优化，有时可能会放弃。
- en: Quadratic time
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 二次时间
- en: 'With quadratic time algorithms, we have now entered the dark side of the time
    complexity. As the name suggests, the size of the input quadratically affects
    the running time of the algorithm. One common example is nested loops:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随着二次时间复杂度算法，我们现在进入了时间复杂度的黑暗面。顾名思义，输入的大小会二次影响算法的运行时间。一个常见的例子是嵌套循环：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: As you can see from the preceding example, for `i = 0`, the inner loop runs
    *n* times, and the same for `i = 1`, and `i = 2`, and so on. The inner loop always
    runs n times and is not dependent on the value of n, thus making the algorithms
    time complexity `O(n²)`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面的例子所示，对于`i = 0`，内部循环运行*n*次，对于`i = 1`，`i = 2`，依此类推。内部循环总是运行n次，不依赖于n的值，因此使得算法的时间复杂度为`O(n²)`。
- en: Polynomial time
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式时间
- en: 'Polynomial time complexity is the running time complexity of algorithms, which
    runs to the order of `n^k`. Quadratic time algorithms are certain types of polynomial
    time algorithms where `k = 2`. A very simple example of such an algorithm would
    be as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式时间复杂度是算法的运行时间复杂度，其顺序为`n^k`。二次时间复杂度算法是多项式时间算法的某种类型，其中`k = 2`。这样的算法的一个非常简单的例子如下：
- en: '[PRE16]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As you can see, this example is just an extension of the example in the quadratic
    time section. The worst case complexity of this case is `O(n³)`.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，这个例子只是二次时间部分例子的延伸。这种情况的最坏时间复杂度是`O(n³)`。
- en: Polynomial time complexity classes
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多项式时间复杂度类
- en: Now that we have started this conversation, most of the time complexity types
    that we have discussed here so far are of the `O(n^k)` type, for example, it is
    a constant time complexity for `n = 1`, whereas it is quadratic complexity for `k
    = 2`.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经开始了这个对话，到目前为止我们讨论的大部分时间复杂度类型都是`O(n^k)`类型的，例如，对于`n = 1`，它是常数时间复杂度，而对于`k
    = 2`，它是二次复杂度。
- en: 'The concept of polynomial time complexity leads us into a class of problems,
    which are defined based on the complexity of their solutions. The following are
    the types of classes:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 多项式时间复杂度的概念引导我们进入了一类问题，这些问题是根据其解决方案的复杂性定义的。以下是类别的类型：
- en: '**P**: Any problem that can be solved in polynomial time `O(n^k)`.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**P**：任何可以在多项式时间`O(n^k)`内解决的问题。'
- en: '**NP**: Any problem that can be verified in polynomial time. There can exist
    problems (such as sudoku solving) that can be solved in non-deterministic polynomial
    time. If the solution to these problems can be verified in polynomial time, then
    the problem is classified as an NP-class problem. NP-class problems are a superset
    of the P-class problems.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NP**：任何可以在多项式时间内验证的问题。可以存在可以在非确定性多项式时间内解决的问题（例如数独求解）。如果这些问题的解决方案可以在多项式时间内验证，那么问题被分类为NP类问题。NP类问题是P类问题的超集。'
- en: '**NP-Complete**: Any NP problem that can be reduced as a function of another
    NP problem in polynomial time can be classified as an NP-Complete problem. This
    means that if we know the solution to a certain **NP** problem, then a solution
    to another NP problem can be derived in polynomial time.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NP-Complete**：任何可以在多项式时间内减少为另一个NP问题的NP问题可以被分类为NP-Complete问题。这意味着如果我们知道某个**NP**问题的解决方案，那么可以在多项式时间内推导出另一个NP问题的解决方案。'
- en: '**NP-Hard**: A problem can be classified as an NP-Hard problem (H) if there
    exists an **NP-Complete** problem (C) that can be reduced to H in polynomial time.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NP-Hard**：如果存在一个可以在多项式时间内减少为**NP-Complete**问题的**NP-Complete**问题，那么问题可以被分类为NP-Hard问题（H）。'
- en: In a majority of the real-world scenarios, we will encounter a lot of P and
    NP problems, a classic example of NP-class problem is Traveling Salesman, where
    a salesman wants to visit `n` number of cities to start and end his trip from
    his house. With a limited amount of gasoline and an upper limit on the total miles
    that can be driven, can the salesman visit all the cities without running out
    of gas?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数现实场景中，我们会遇到很多P和NP问题，NP类问题的一个经典例子是旅行推销员问题，其中推销员想要访问`n`个城市，从他的家出发并结束他的旅行。在汽油有限和总里程数有上限的情况下，推销员能否访问所有城市而不用完汽油？
- en: Recursion and additive complexity
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 递归和加法复杂度
- en: 'Until now, we have seen some examples that are pretty straightforward: they
    all have a single loop or nested loops. However, a lot of times, there will be
    scenarios in which we will have to handle multiple loops/function calls/branches
    originating from the same algorithm. Let us see an example of how we can calculate
    the complexity in that case?'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到一些相当简单的例子：它们都只有一个循环或嵌套循环。然而，很多时候，会有一些情况需要处理多个循环/函数调用/分支，让我们看一个这种情况下如何计算复杂度的例子？
- en: 'When we have subsequent loops/function calls, we will need to calculate the
    individual complexity of each step and then add them to get the overall complexity,
    as follows:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们有连续的循环/函数调用时，我们需要计算每个步骤的个体复杂度，然后将它们相加以获得总体复杂度，如下所示：
- en: '[PRE17]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The collective complexity of this code would be the summation of the complexity
    of both the sections. So, in this case, the overall complexity would be `O(n +
    log n)`, which asymptotically will be `O(n)`.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的综合复杂度将是两个部分复杂度的总和。因此，在这种情况下，总体复杂度将是`O(n + log n)`，渐近地将是`O(n)`。
- en: 'When we have branches in our function with varying time complexity, depending
    on what type of runtime complexity we are talking about, we will need to pick
    the correct choice:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们的函数中有不同时间复杂度的分支时，根据我们所谈论的运行时复杂度的类型，我们需要选择正确的选择：
- en: '[PRE18]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: In this case, the worst case complexity will be decided by whatever is worst
    of the two branches, which would be `O(n)`, but the best case complexity would
    be `O(log(n))`.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，最坏情况的复杂度将由两个分支中较差的那个决定，即`O(n)`，但最佳情况的复杂度将是`O(log(n))`。
- en: 'Recursive algorithms are a little tricky compared to their non-recursive counterparts,
    since not only do we need to determine what the complexity of our algorithm is,
    we also need to keep in mind how many times recursion would get triggered because
    that would contribute toward the overall complexity of the algorithm as shown
    in the following code snippet:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 递归算法与非递归算法相比有点棘手，因为我们不仅需要确定算法的复杂度，还需要记住递归会触发多少次，因为这将对算法的总体复杂度产生影响，如下面的代码片段所示：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Although our method only performs some `O(1)` operations, it constantly changes
    the input and calls itself until the size of the input array is zero. So, our
    method ends up executing n times, making the overall time complexity of `O(n)`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们的方法只执行一些`O(1)`的操作，但它不断改变输入并调用自身，直到输入数组的大小为零。因此，我们的方法最终执行了n次，使得总体时间复杂度为`O(n)`。
- en: Space complexity and Auxiliary space
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 空间复杂度和辅助空间
- en: 'Space complexity and Auxiliary space are two of the most often confused and
    interchangeably used terms when talking about the space complexity of a certain
    algorithm:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 空间复杂度和辅助空间是在谈论某个算法的空间复杂度时经常混淆和交替使用的术语之一：
- en: '**Auxiliary Space: **The extra space that is taken by an algorithm temporarily
    to finish its work'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**辅助空间：**算法暂时占用的额外空间以完成其工作'
- en: '**Space Complexity: **Space complexity is the total space taken by the algorithm
    with respect to the input size plus the auxiliary space that the algorithm uses.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**空间复杂度：**空间复杂度是算法相对于输入大小所占用的总空间加上算法使用的辅助空间。'
- en: When we try to compare two algorithms, we usually have a similar type of input,
    that is, the size of the input can be disregarded and thus what we do end up comparing
    is the auxiliary space of the algorithms. It's not a big deal to use either of
    the terms, as long as we understand the distinction between the two and use them
    correctly.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们尝试比较两个算法时，通常会有类似类型的输入，也就是说，输入的大小可以忽略不计，因此我们最终比较的是算法的辅助空间。使用这两个术语没有太大问题，只要我们理解两者之间的区别并正确使用它们。
- en: If we were using a low-level language such as C, then we can break down the
    memory required/consumed based on the data type, for example, 2 bytes to store
    an integer, 4 bytes to store floating point, and so on. However, since we are
    working with JavaScript, which is a high-level language, this is not as so straightforward,
    as we do not make a distinction between different data types explicitly.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用低级语言如C，那么我们可以根据数据类型来分解所需/消耗的内存，例如，用2个字节来存储整数，4个字节来存储浮点数等。然而，由于我们使用的是JavaScript这种高级语言，情况就不那么简单了，因为我们没有明确区分不同的数据类型。
- en: Examples of Space complexity
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 空间复杂度的例子
- en: When it comes to space complexity of an algorithm, we have types similar to
    that of the time complexity, such as constant space `S(1)` and linear space `S(N)`.
    Let's take a look at some of the examples in the following section.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在谈论算法的空间复杂度时，我们有类似于时间复杂度的类型，如常量空间`S(1)`和线性空间`S(N)`。让我们在下一节中看一些例子。
- en: Constant space
  id: totrans-121
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 常量空间
- en: A constant space algorithm is one in which the space consumed by an algorithm
    does not change by the size of the input or the algorithms input parameters in
    any way.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 常量空间算法是指算法消耗的空间不会因输入的大小或算法的输入参数而改变。
- en: 'At this point, I would like to reiterate that when we talk about the space
    complexity of an algorithm we are talking about the auxiliary space that is consumed
    by the algorithm. This implies that even if our array is of size *n*, the auxiliary
    (or the extra) space that is consumed by our algorithm will remain constant, as
    shown in the following code snippet:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我想重申一下，当我们谈论算法的空间复杂度时，我们谈论的是算法消耗的辅助空间。这意味着即使我们的数组大小为*n*，我们的算法消耗的辅助（或额外）空间将保持不变，如下面的代码片段所示：
- en: '[PRE20]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We can see here that the `firstElement` method does not take any more space,
    irrespective of what the input is. Hence, we can denote this as space complexity
    `S(1)`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到`firstElement`方法不再占用任何空间，无论输入是什么。因此，我们可以将其表示为空间复杂度`S(1)`。
- en: Linear space
  id: totrans-126
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 线性空间
- en: 'A linear space algorithm is one in which the amount of space taken by an algorithm
    is directly proportional to the size of the input, for example, algorithms that
    loop over an array and push values to a new array before returning them:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 线性空间算法是指算法占用的空间量与输入大小成正比的算法，例如，在返回值之前循环遍历数组并将值推送到新数组的算法：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'As you can see, although redundant, we are creating a new array and pushing
    all the values into that array, which will use up the same space as that of the
    input array. Consider the situation in which you have a condition before the `push`,
    as shown in the following code:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，尽管冗余，我们正在创建一个新数组，并将所有值推送到该数组中，这将占用与输入数组相同的空间。考虑在`push`之前有一个条件的情况，如下面的代码所示：
- en: '[PRE22]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the worst case, the `someCondition` flag is always true, and we end up with
    the result that is again of the same size as that of the input. Thus, we can assert
    that the space complexity of the preceding method is `S(n)`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在最坏的情况下，`someCondition` 标志始终为真，并且我们最终得到的结果与输入的大小相同。因此，我们可以断言前面方法的空间复杂度为 `S(n)`。
- en: Summary
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we scratched the surface of a beast known as computational
    complexity. There is a lot more to computational complexity than we discussed
    in this chapter. However, the topics and examples discussed in this chapter are
    the ones that most of us face in our day-to-day work. There are more advanced
    topics in space complexity, such as LSPACE, which is a class of problems that
    can be solved in logarithmic space and NLSPACE, which is the amount of space but
    using a non-deterministic Turing machine. The main goal of this chapter is to
    ensure that we understand how the complexity of our algorithms is calculated and
    how it affects the overall output. In the next chapter, we will be discussing
    what kind of micro-optimizations we can make to our applications, and understand
    the internals of how browsers (mostly Chrome) work and how we can leverage them
    to better our applications.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只是浅尝计算复杂性这个庞然大物。计算复杂性比我们在本章讨论的要多得多。然而，本章讨论的主题和示例是我们大多数人在日常工作中面对的。空间复杂性还有更高级的主题，比如
    LSPACE，它是一类可以在对数空间中解决的问题，以及 NLSPACE，它是使用非确定性图灵机的空间量。本章的主要目标是确保我们理解算法的复杂度是如何计算的，以及它如何影响整体输出。在下一章中，我们将讨论我们可以对应用程序进行哪些微观优化，并了解浏览器（主要是
    Chrome）的内部工作原理以及我们如何利用它们来改进我们的应用程序。
