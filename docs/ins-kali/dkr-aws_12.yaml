- en: ECS Auto Scaling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ECS自动扩展
- en: '**Elasticity** is one of the fundamental tenets of cloud computing, and describes
    the ability to auto scale your applications on demand to ensure the best possible
    experience and responsiveness for your customers, while optimizing cost by only
    providing additional capacity for your application when it is actually required.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '**弹性**是云计算的基本原则之一，描述了根据需求自动扩展应用程序的能力，以确保客户获得最佳体验和响应性，同时通过仅在实际需要时提供额外容量来优化成本。'
- en: 'AWS supports scaling your Docker applications that are deployed using ECS via
    two key features:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: AWS支持通过两个关键功能来扩展使用ECS部署的Docker应用程序：
- en: '**Application Auto Scaling**: This uses the AWS application auto scaling service
    and supports Auto Scaling at an ECS service level, where the number of ECS tasks
    or containers running your ECS services can be scaled up or down.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用程序自动扩展**：这使用AWS应用程序自动扩展服务，并支持在ECS服务级别进行自动扩展，您的ECS服务运行的ECS任务或容器的数量可以增加或减少。'
- en: '**EC2 Auto Scaling**: This uses the EC2 Auto Scaling service and supports Auto
    Scaling at an EC2 Auto Scaling group level, where the number of EC2 instances
    in your Auto Scaling group can be scaled up or down. In the context of ECS, your
    EC2 Auto Scaling groups typically correspond to ECS clusters, and the individual
    EC2 instances correspond to ECS container instances, so EC2 Auto Scaling is managing
    the overall capacity of your ECS cluster.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EC2自动扩展**：这使用EC2自动扩展服务，并支持在EC2自动扩展组级别进行自动扩展，您的自动扩展组中的EC2实例数量可以增加或减少。在ECS的上下文中，您的EC2自动扩展组通常对应于ECS集群，而单独的EC2实例对应于ECS容器实例，因此EC2自动扩展正在管理您的ECS集群的整体容量。'
- en: Because there are two paradigms at play here, the goal of Auto Scaling for your
    Docker applications can be a challenging technical concept to understand, let
    alone implement successfully in a predictable and reliable manner. This is further
    exacerbated by the fact that, as of the time of writing this book, application
    auto scaling and EC2 Auto Scaling are completely independent features that offer
    no integration with each other, hence, you are responsible for ensuring both features
    work together with one another.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这里涉及两种范式，为您的Docker应用程序实现自动扩展可能是一个具有挑战性的技术概念，更不用说以可预测和可靠的方式成功实现了。更糟糕的是，截至撰写本书的时间，应用程序自动扩展和EC2自动扩展是完全独立的功能，彼此之间没有集成，因此，您需要确保这两个功能能够相互配合。
- en: When it comes to analyzing each of these features, the good news is that application
    auto scaling is very straightforward to understand and implement. With application auto
    scaling, you simply need to define the key performance metrics for your applications,
    and scale up (increase) or scale down (decrease) the number of ECS tasks that
    run your application. The bad news is that EC2 auto scaling, when applied in the
    context of auto scaling ECS container instances in an ECS cluster, is definitely
    a much harder proposition to deal with. Here, you need to ensure your ECS clusters
    are providing enough compute, memory, and network resources across all ECS tasks
    running in your cluster, and you need to ensure that your cluster is able to add
    or remove capacity whenever application auto scaling scales individual ECS services
    up or down.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析这些功能时，好消息是应用程序自动扩展非常容易理解和实现。使用应用程序自动扩展，您只需定义应用程序的关键性能指标，并增加（增加）或减少（减少）运行应用程序的ECS任务的数量。坏消息是，当应用于在ECS集群中自动扩展ECS容器实例时，EC2自动扩展绝对是一个更难处理的命题。在这里，您需要确保您的ECS集群为在集群中运行的所有ECS任务提供足够的计算、内存和网络资源，并确保您的集群能够在应用程序自动扩展时增加或减少容量。
- en: Another challenge of scaling ECS clusters is ensuring you do not disrupt service
    and drain running tasks on an ECS container instance that is about to be removed
    from the cluster during a scale down/in event. The ECS life cycle hooks solution
    implemented in Chapter 11 - *Managing the ECS Infrastructure Life Cycle* takes
    care of this for you, ensuring the ECS container instances are drained of all
    running tasks before permitting the EC2 auto scaling service to take an instance
    out of service.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展ECS集群的另一个挑战是确保您不会在缩减/缩小事件期间从集群中移除的ECS容器实例上中断服务并排空正在运行的任务。第11章中实施的ECS生命周期挂钩解决方案会为您处理这一问题，确保在允许EC2自动扩展服务将实例移出服务之前，ECS容器实例会排空所有正在运行的任务。
- en: Dealing with the problem of scaling your ECS cluster resources is the primary
    focus of this chapter, as once solved, you will be able to arbitrarily scale each
    of your ECS services and be assured that your ECS cluster will dynamically add
    or remove ECS container instances to ensure there is always sufficient and optimal
    resources for your applications. In this chapter, we will first focus on solving
    the problem of ECS cluster-capacity management, and then discuss how to configure
    the AWS application auto scaling service to auto scale your ECS services and applications.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 解决扩展ECS集群资源的问题是本章的主要焦点，一旦解决了这个问题，您将能够任意扩展您的ECS服务，并确保您的ECS集群会动态地添加或移除ECS容器实例，以确保您的应用程序始终具有足够和最佳的资源。在本章中，我们将首先专注于解决ECS集群容量管理的问题，然后讨论如何配置AWS应用程序自动扩展服务以自动扩展您的ECS服务和应用程序。
- en: 'The following topics will be covered:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 将涵盖以下主题：
- en: Understanding the ECS cluster resources
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解ECS集群资源
- en: Calculating the ECS cluster capacity
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算ECS集群容量
- en: Implementing an ECS cluster-capacity management solution
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施ECS集群容量管理解决方案
- en: Configuring CloudWatch events to trigger capacity-management calculations
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置CloudWatch事件以触发容量管理计算
- en: Publishing custom CloudWatch metrics related to the ECS cluster capacity
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布与ECS集群容量相关的自定义CloudWatch指标
- en: Configuring CloudWatch alarms and EC2 auto scaling policies to scale your ECS
    clusters
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置CloudWatch警报和EC2自动扩展策略以扩展您的ECS集群
- en: Configuring ECS application auto scaling
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置ECS应用程序自动扩展
- en: Technical requirements
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following lists the technical requirements to complete this chapter:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列出了完成本章所需的技术要求：
- en: Administrator access to an AWS account
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS账户的管理员访问权限
- en: Local AWS profile configured as per the instructions in Chapter 3
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据第3章的说明配置本地AWS配置文件
- en: AWS CLI
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI
- en: This chapter continues on from Chapter 11, so it requires that you have successfully
    completed all the configuration tasks defined there.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章是从第11章继续下去的，因此需要您成功完成那里定义的所有配置任务。
- en: The following GitHub URL contains the code samples used in this chapter: [https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下GitHub URL包含本章中使用的代码示例：[https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch12)。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际操作：
- en: '[http://bit.ly/2PdgtPr](http://bit.ly/2PdgtPr)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2PdgtPr](http://bit.ly/2PdgtPr)'
- en: Understanding ECS cluster resources
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解ECS集群资源
- en: Before you can start to manage the capacity of your ECS clusters, you need to
    have a clear and solid understanding of the various resources that affect the
    capacity of your ECS clusters.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在您开始管理ECS集群的容量之前，您需要清楚而牢固地了解影响ECS集群容量的各种资源。
- en: 'In general, there are three key resources that you need to consider:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，有三个关键资源需要考虑：
- en: CPU
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU
- en: Memory
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: Network
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络
- en: CPU resources
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: CPU资源
- en: '**CPU** is a core resource that Docker supports and manages as a first-class
    citizen. ECS leverages the CPU resource management capabilities of Docker, and
    exposes the ability to manage these via your ECS task definitions. ECS defines
    CPU resources in terms of *CPU units*, where a single CPU core contains 1,024
    CPU units. When you configure your ECS task definitions, you specify a CPU reservation,
    which defines how much CPU time will be allocated to the application whenever
    there is contention for CPU time.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**CPU**是Docker支持和管理的核心资源。ECS利用Docker的CPU资源管理能力，并公开通过ECS任务定义管理这些资源的能力。ECS根据*CPU单位*定义CPU资源，其中单个CPU核心包含1,024个CPU单位。在配置ECS任务定义时，您需要指定CPU保留，这定义了每当CPU时间存在争用时将分配给应用程序的CPU时间。'
- en: Note that a CPU reservation is not a limit as to how much CPU the ECS task can
    use–each ECS task is free to burst and use all available CPU resources–the reservation
    is only applied when there is contention for CPU, and Docker attempts to allocate
    CPU time fairly based upon the configured reservation for each running ECS task.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，CPU保留并不限制ECS任务可以使用多少CPU-每个ECS任务都可以自由地突发并使用所有可用的CPU资源-当CPU存在争用时才会应用保留，并且Docker会根据每个运行的ECS任务的配置保留公平地分配CPU时间。
- en: 'It''s important to understand that each CPU reservation deducts from the available
    CPU capacity of a given ECS container instance. For example, if your ECS container
    instance has 2 CPU cores, that equates to a total of 2,048 CPU units. If you run
    3 ECS tasks that are configured with 500, 600, and 700 CPU units, this means that
    your ECS container instance has 2,048 - (500 + 600 + 700), or 248, CPU units available.
    Note that whenever the ECS scheduler needs to run a new ECS task, it will always
    ensure that a target ECS container instance has enough CPU capacity to run the
    task. Following on from the previous example, if a new ECS task needed to be started
    that reserves 400 CPU units, then the ECS container instance with 248 CPU units
    remaining would not be considered, given it does not have sufficient CPU resources
    currently available:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，每个CPU保留都会从给定的ECS容器实例的可用CPU容量中扣除。例如，如果您的ECS容器实例有2个CPU核心，那就相当于总共有2,048个CPU单位。如果您运行了配置为500、600和700
    CPU单位的3个ECS任务，这意味着您的ECS容器实例有2,048 - (500 + 600 + 700)，或248个CPU单位可用。请注意，每当ECS调度程序需要运行新的ECS任务时，它将始终确保目标ECS容器实例具有足够的CPU容量来运行任务。根据前面的例子，如果需要启动一个保留400个CPU单位的新ECS任务，那么剩余248个CPU单位的ECS容器实例将不被考虑，因为它当前没有足够的CPU资源可用：
- en: '![](assets/a5a2aea8-a27b-4ae9-baa9-7e542ad03403.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a5a2aea8-a27b-4ae9-baa9-7e542ad03403.png)'
- en: Allocating CPU resources
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 分配CPU资源
- en: In terms of configuring CPU reservations, you have already learned how to do
    this via CloudFormation–see the *Defining an ECS task definition using CloudFormation* example
    in Chapter 8 - *Deploying applications using ECS*, where you assigned a value
    of 245 to the todobackend container definition, via a property called `Cpu`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置CPU保留方面，您已经学会了如何通过CloudFormation进行此操作-请参阅第8章*使用ECS部署应用程序*中的*使用CloudFormation定义ECS任务定义*示例，在该示例中，您通过一个名为`Cpu`的属性为todobackend容器定义分配了245的值。
- en: Memory resources
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内存资源
- en: '**Memory** is another fundamental resource that is managed via Docker, and
    works in a similar fashion to CPU, although you can both reserve and limit memory
    capacity for a given ECS task, whereas you can only reserve (not limit) CPU resources
    when it comes to managing CPU capacity. This additional ability to limit memory
    results in three scenarios when it comes to configuring memory for your ECS tasks:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 内存是另一个通过Docker管理的基本资源，其工作方式类似于CPU，尽管您可以为给定的ECS任务保留和限制内存容量，但在管理CPU容量时，您只能保留（而不是限制）CPU资源。当涉及到配置ECS任务的内存时，这种额外的限制内存的能力会导致三种情况：
- en: '**Memory reservation only**: This scenario behaves identically to how CPU reservations
    work. Docker will deduct the configured reservation from the available memory
    of the ECS container instance, and attempt to allocate this amount of memory whenever
    there is contention for memory. ECS will allow the ECS task to use up to the maximum
    amount of memory supported by the ECS container instance. Memory reservations
    are configured using the `MemoryReservation` property within an ECS task container
    definition.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅内存保留**：这种情况的行为与CPU保留的工作方式相同。Docker将从ECS容器实例的可用内存中扣除配置的保留，并在内存有争用时尝试分配这些内存。ECS将允许ECS任务使用ECS容器实例支持的最大内存量。内存保留是在ECS任务容器定义中使用`MemoryReservation`属性进行配置的。'
- en: '**Memory reservation + limit**: In this scenario, the memory reservation works
    as the previous scenario, however, the maximum amount of memory that the ECS task
    can ever use is constrained by the configure memory limit. In general, configuring
    both a memory reservation and memory limit is considered the best option. Memory
    limits are configured using the `Memory` property within an ECS task container
    definition.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存保留+限制**：在这种情况下，内存保留的工作方式与前一种情况相同，但ECS任务可以使用的最大内存量受到配置内存限制的限制。一般来说，配置内存保留和内存限制被认为是最佳选择。内存限制是在ECS任务容器定义中使用`Memory`属性进行配置的。'
- en: '**Memory limit only**: Here, ECS treats the memory reservation and memory limit
    values as one and the same, meaning ECS will deduct the configured memory limit
    from the available ECS container instance memory, and also limit memory usage
    to the same limit.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仅内存限制**：在这种情况下，ECS将内存保留和内存限制值视为相同，这意味着ECS将从可用的ECS容器实例内存中扣除配置的内存限制，并且还将限制内存使用到相同的限制。'
- en: Configuring memory reservations and limits is straightforward–if you refer back
    to the *Defining an ECS task definition using CloudFormation* section of Chapter
    8 - *Deploying Applications Using ECS*, you can see that you configure the `MemoryReservation`
    property to configure a reservation of 395 MB. If you wanted to configure a memory
    limit, you would also need to configure the `Memory` property with an appropriate
    maximum limit value.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 配置内存保留和限制是直接的-如果您回顾一下第8章*使用CloudFormation定义ECS任务定义*部分，您会发现您可以配置`MemoryReservation`属性来配置395
    MB的保留。如果您想配置内存限制，您还需要使用适当的最大限制值配置`Memory`属性。
- en: Network resources
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络资源
- en: 'CPU and memory are typical and obvious resources that you would expect your
    ECS clusters to control and manage. One less obvious set of resources is *network
    resources*, which can be split into two categories:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: CPU和内存是您期望您的ECS集群控制和管理的典型和明显的资源。另一组不太明显的资源是*网络资源*，可以分为两类：
- en: '**Host network ports**: Whenever you configure static port mappings for your
    ECS services, host network ports is a resource that you will need to consider.
    The reason is that static port mappings use a common port exposed by the ECS container
    instance–for example, if you created an ECS task with a static port mapping that
    exposes port 80 for a given application, you won''t be able to deploy another
    instance of the ECS task on the same ECS container instance host, given port 80
    is still in use.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主机网络端口**：每当您为ECS服务配置静态端口映射时，主机网络端口是您需要考虑的资源。原因是静态端口映射使用ECS容器实例公开的一个常用端口 -
    例如，如果您创建了一个ECS任务，其中静态端口映射公开了给定应用程序的端口80，那么如果端口80仍在使用中，您将无法在同一ECS容器实例主机上部署ECS任务的另一个实例。'
- en: '**Host network interfaces**: If you are using ECS task networking, it is important
    to understand that this feature currently requires you to implement a single elastic
    network interface (ENI) per ECS task. Because EC2 instances have finite limits
    as to the number of ENIs each instance type can support, the number of ECS tasks
    configured with ECS task networking that can be supported will be restricted to
    the maximum number of ENIs the ECS container instance can support.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主机网络接口**：如果您正在使用ECS任务网络，重要的是要了解，该功能目前要求您为每个ECS任务实现单个弹性网络接口（ENI）。因为EC2实例对每种实例类型支持的ENI数量有限制，因此使用ECS任务网络配置的ECS任务数量将受到ECS容器实例可以支持的ENI最大数量的限制。'
- en: Calculating the ECS cluster capacity
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算ECS集群容量
- en: Before you can calculate the ECS cluster capacity, you need to have a clear
    understanding of which resources affect capacity and how you can calculate the
    current capacity for each resource. Once you have defined this for each individual
    resource, you then need to apply an aggregate calculation across all resources,
    which will result in a final calculation of the current capacity.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算ECS集群容量之前，您需要清楚地了解哪些资源会影响容量以及如何计算每种资源的当前容量。一旦为每个单独的资源定义了这一点，您就需要在所有资源上应用一个综合计算，这将导致最终计算出当前容量。
- en: 'Calculating capacity can appear to be quite a daunting task, especially when
    you consider the different types of resources and how they behave:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 计算容量可能看起来是一项相当艰巨的任务，特别是当考虑到不同类型的资源以及它们的行为时：
- en: '**CPU**: This is the simplest resource you can work with, as each CPU reservation
    simply deducts from the available CPU capacity of the cluster.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CPU**：这是您可以使用的最简单的资源，因为每个CPU预留只是从集群的可用CPU容量中扣除。'
- en: '**Memory:** Calculating the current capacity of the cluster based upon memory
    is identical to CPU in that a memory reservation deducts from the available memory
    capacity of the cluster. As per our earlier discussion in this chapter, how the
    memory reservation is configured is complicated by the various permutations of
    memory limits and memory reservations, however fundamentally once you have determined
    the memory reservation, the calculation is the same as for CPU resources.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内存**：根据内存计算集群的当前容量与CPU相同，因为内存预留会从集群的可用内存容量中扣除。根据本章早期讨论，内存预留的配置受到内存限制和内存预留的各种排列组合的影响，但基本上一旦确定了内存预留，计算方式与CPU资源相同。'
- en: '**Static network ports**: If your ECS cluster needs to support *any* containers
    that are using static port mappings, then you need to consider your ECS container
    instance network ports as a resource. For example, if a container application
    always uses port 80 on the ECS container instance, then you can only ever deploy
    one container per instance, regardless of how much CPU, memory, or other resources
    that instance might possess.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态网络端口：如果您的ECS集群需要支持使用静态端口映射的*任何*容器，那么您需要将您的ECS容器实例网络端口视为一种资源。例如，如果一个容器应用程序始终在ECS容器实例上使用端口80，那么您只能在每个实例上部署一个容器，而不管该实例可能拥有多少CPU、内存或其他资源。
- en: '**Network interfaces**: If you are have any ECS services or tasks that are
    configured for ECS task networking, it is important to understand you can currently
    only run one ECS task per network interface. For example, if you are running a
    t2.micro instance, this means you can only run one ECS task with task networking
    enabled per instance, given a t2.micro can only support a single elastic network
    interface for ECS task networking.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络接口：如果您有任何配置为ECS任务网络的ECS服务或任务，重要的是要了解，您目前只能在一个网络接口上运行一个ECS任务。例如，如果您正在运行一个t2.micro实例，这意味着您只能在一个实例上运行一个启用了任务网络的ECS任务，因为t2.micro只能支持一个弹性网络接口用于ECS任务网络。
- en: Given the sample application is not using ECS task networking and is being deployed
    using dynamic port mapping, we will only consider CPU and memory resources for
    the remainder of this chapter. If you are interested in an example solution that
    incorporates static network ports, check out the Auto Scaling ECS Applications
    module of my [Docker in Production Using Amazon Web Services](https://www.pluralsight.com/courses/docker-production-using-amazon-web-services)
    course.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于示例应用程序未使用ECS任务网络，并且正在使用动态端口映射进行部署，我们在本章的其余部分只考虑CPU和内存资源。如果您对包含静态网络端口的示例解决方案感兴趣，请查看我的《使用亚马逊网络服务进行生产中的Docker》课程的Auto
    Scaling ECS Applications模块。
- en: The challenge here is how to consider all of your ECS services and tasks in
    terms of all of the preceding considerations, and then make a decision as to when
    you should scale up or scale down the number of instances in your cluster. A common
    and somewhat naive approach I have seen is to treat each resource independently
    and scale your instances accordingly. For example, you would add a new container
    instance as soon as your cluster runs out of memory capacity, and similarly if
    your cluster is about to run out of CPU capacity. This approach works fine if
    you consider purely the ability to scale out, however it does not work when you
    want to scale in your cluster. If you scale in your cluster solely based upon
    current memory capacity, you risk scaling in too soon in terms of CPU capacity,
    as your cluster may not have sufficient CPU capacity if you remove an instance
    from the cluster.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战在于如何考虑所有ECS服务和任务，然后根据所有前述考虑做出决定，决定何时应该扩展或缩减集群中实例的数量。我见过的一种常见且有些天真的方法是独立地处理每个资源，并相应地扩展您的实例。例如，一旦您的集群的内存容量用尽，您就会添加一个新的容器实例，同样，如果您的集群即将耗尽CPU容量，也会这样做。如果您纯粹考虑扩展的能力，这种方法是有效的，但是当您想要缩减集群时，它就不起作用了。如果您仅基于当前内存容量来缩减集群，那么在CPU容量方面，您可能会过早地缩减，因为如果您从集群中移除一个实例，您的集群可能没有足够的CPU容量。
- en: This will risk your cluster getting stuck in an auto scaling loop–that is, your
    cluster keeps on scaling out and then in, and this is because individual resource
    capacities are independently driving scale-in and scale-out decisions, without
    consideration of the impact to other resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使您的集群陷入自动扩展循环中-也就是说，您的集群不断地扩展然后再缩小，这是因为各个资源容量独立地驱动着缩小和扩展的决策，而没有考虑对其他资源的影响。
- en: The key to solving this challenge is that you need to make a *single* decision
    to scale out or in, and consider *all* applicable resources for your cluster.
    This might make the overall problem seem a whole lot harder to solve, however
    it is actually quite simple. The crux of the solution is that you always consider
    the *worst-case scenario*, and make a decision based upon that. For example, if
    you have plenty of CPU and memory capacity in your cluster, however all static
    port mappings for a given port are in use on all of your cluster instances, the
    worst-case scenario says if you scale in your cluster and remove an instance,
    you will no longer be able to support the current ECS tasks that are using the
    affected static port mapping. Therefore, the decision here is simple and is purely
    based upon the worst-case scenario–all other scenarios are ignored.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这一挑战的关键在于您需要做出*单一*的扩展或缩小决策，并考虑您集群中*所有*适用的资源。这可能会使整体问题看起来更难解决，但实际上它非常简单。解决方案的关键在于您始终考虑*最坏情况*，并基于此做出决策。例如，如果您的集群中有足够的CPU和内存容量，但是所有静态端口映射都在所有集群实例上使用，最坏情况是，如果您缩小集群并删除一个实例，您将无法再支持使用受影响的静态端口映射的当前ECS任务。因此，这里的决策是简单的，纯粹基于最坏情况-所有其他情况都被忽略。
- en: Calculating the container capacity
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算容器容量
- en: One key consideration when calculating the capacity of your cluster is that
    you need to normalize your resource capacity calculations, such that the capacity
    of each resource can be expressed in a common and equivalent format, independent
    of the specific units of measurement for each individual resource. This is critical
    in making a collective decision that considers all resources, and a natural way
    to do this is to express resource capacity in terms of the number of additional
    ECS tasks that can be supported using the currently available unallocated resources.
    In addition, keeping with the theme of worst-case scenarios, you don't need to
    consider all of the different ECS tasks that you need to support–you only need
    to consider the ECS task that is the worst case (the one requiring the most resources)
    for the resource you are currently calculating the capacity for.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算集群容量时的一个关键考虑因素是，您需要对资源容量进行归一化计算，以便每个资源的容量可以以一个通用和等效的格式来表达，独立于每个单独资源的具体计量单位。这在做出考虑所有资源的集体决策时至关重要，而这样做的一种自然方式是以当前可用的未分配资源来支持多少额外的ECS任务数量来表达资源容量。此外，与最坏情况的主题保持一致，您不需要考虑所有需要支持的不同ECS任务-您只需要考虑当前正在计算容量的资源的最坏情况的ECS任务（需要最多资源的任务）。
- en: 'For example, if you have two ECS tasks that require 200 CPU units and 400 CPU
    units, respectively, you only need to calculate the CPU capacity in terms of the
    ECS task with 400 CPU units:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您有两个需要分别需要200 CPU单位和400 CPU单位的ECS任务，那么您只需要根据需要400 CPU单位的ECS任务来计算CPU容量：
- en: '![](assets/dd9bfcd2-98df-4a3e-9140-462f6575f3a0.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/dd9bfcd2-98df-4a3e-9140-462f6575f3a0.png)'
- en: The expression with the somewhat strange upside down A in the formula means
    "for each taskCpu value in a given set of taskDefinitions".
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 公式中带有有点奇怪的倒立的A的表达意思是“对于给定的taskDefinitions集合中的每个taskCpu值”。
- en: 'Once you have determined the worst-case ECS task that needs to be supported,
    you can proceed to calculate the number of additional ECS tasks that the cluster
    can currently support. Given the worst-case ECS task requires 400 CPU units, if
    we now assume that you have two instances in your cluster that each have 600 CPU
    units of free capacity, this means you can currently support an additional 2 ECS
    tasks:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦确定了需要支持的最坏情况ECS任务，就可以开始计算集群目前可以支持的额外ECS任务数量。假设最坏情况的ECS任务需要400个CPU单位，如果现在假设您的集群中有两个实例，每个实例都有600个CPU单位的空闲容量，这意味着您目前可以支持额外的2个ECS任务：
- en: '![](assets/43729108-b796-419e-9e92-32de63550246.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/43729108-b796-419e-9e92-32de63550246.png)'
- en: Calculating container capacity
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 计算容器容量
- en: It's important to note here that you need to make this calculation on a per-instance
    basis, rather than just making the calculation across the entire cluster. Using
    the previous example, if you consider the free CPU capacity across the entire
    cluster, you have 1,200 CPU units available and therefore you would calculate
    a free capacity of three ECS tasks, however the reality is that you can't *split* the
    ECS task across 2 instances, so if you consider the free capacity on a per-instance
    basis, it's obvious you can only support one additional ECS task on each instance
    for a correct total of 2 additional ECS tasks across the cluster.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的是，您需要按照每个实例的基础进行计算，而不仅仅是在整个集群上进行计算。使用先前的例子，如果您考虑整个集群的空闲CPU容量，您有1,200个CPU单位可用，因此您将计算出三个ECS任务的空闲容量，但实际情况是您不能*分割*ECS任务跨越2个实例，因此如果您按照每个实例的空闲容量进行考虑，显然您只能在每个实例上支持一个额外的ECS任务，从而得到集群中总共2个额外的ECS任务的正确总数。
- en: 'This can be formalized as a mathematical equation, as follows, where the![](assets/1a7ada8d-43a9-4c10-a5bc-be9a6ea6f917.png) annotation
    on the right-hand side of the formula means to take *floor* or the lowest nearest
    integer value of the calculation, andrepresents an instance in the cluster:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以形式化为一个数学方程，如下所示，其中公式右侧的![](assets/1a7ada8d-43a9-4c10-a5bc-be9a6ea6f917.png)注释表示取*floor*或计算的最低最近整数值，并且代表集群中的一个实例：
- en: '![](assets/f68b3eb6-74a7-4799-94d9-feaa134f7d59.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f68b3eb6-74a7-4799-94d9-feaa134f7d59.png)'
- en: 'If you repeat the previous approach for your memory resource, you will calculate
    a separate calculation that defines the current spare capacity of the cluster
    in terms of memory. If we assume the worst-case ECS task for memory requires 500
    MB of memory and both instances have 400 MB available, it''s obvious that in terms
    of memory, the cluster currently has no spare capacity:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对内存资源重复之前的方法，将计算一个单独的计算，以内存的形式定义集群的当前备用容量。如果我们假设内存的最坏情况ECS任务需要500MB内存，并且两个实例都有400MB可用，显然就内存而言，集群目前没有备用容量：
- en: '![](assets/bbf249ea-73f3-449a-b9bd-5539dcbf50d3.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bbf249ea-73f3-449a-b9bd-5539dcbf50d3.png)'
- en: 'If you now consider the two previous calculations for CPU (currently two free
    ECS tasks) and memory (currently zero ECS tasks), it''s obvious that the worst
    case scenario is the memory capacity calculation of zero free ECS tasks, which
    can be formalized as follows:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果现在考虑CPU的两个先前计算（目前有两个空闲的ECS任务）和内存（目前没有空闲的ECS任务），显然最坏情况是内存容量计算为零个空闲的ECS任务，可以形式化如下：
- en: '![](assets/adf03873-dfc3-4bee-b660-ed1316ce93a2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/adf03873-dfc3-4bee-b660-ed1316ce93a2.png)'
- en: 'Note that although we are not incorporating calculations for static network
    ports and network interfaces to help simplify our solution, the general approach
    is the same–calculate the current capacity for each instance and sum to obtain
    an overall cluster capacity value for the resource, and then incorporate the value
    into the overall cluster capacity calculation:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，虽然我们没有将静态网络端口和网络接口的计算纳入到我们的解决方案中以帮助简化，但一般的方法是相同的 - 计算每个实例的当前容量并求和以获得资源的整体集群容量值，然后将该值纳入整体集群容量的计算中：
- en: '![](assets/72628df2-87bc-4414-a63f-3588709b546c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/72628df2-87bc-4414-a63f-3588709b546c.png)'
- en: Deciding when to scale out
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 决定何时扩展
- en: At this point, we have established that you need to assess each of the current
    resource capacities in your cluster, express this in terms of the number of free
    or spare ECS tasks your cluster currently can support, and then use the worst-case
    calculation (minimum value) to determine your overall current cluster capacity.
    Once you have this calculation, you need to decide whether or not you should scale
    out the cluster, or leave the current cluster capacity unchanged. Of course, you
    also need to decide when to scale in the cluster, however we will discuss that
    topic separately soon.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们已经确定您需要评估集群中每个当前资源容量，并以当前集群可以支持的空闲或备用ECS任务数量来表达，然后使用最坏情况的计算（最小值）来确定您当前集群的整体容量。一旦您完成了这个计算，您需要决定是否应该扩展集群，或者保持当前集群容量不变。当然，您还需要决定何时缩小集群，但我们将很快单独讨论这个话题。
- en: 'For now, we will focus on whether or not we should scale *out* the cluster
    (that is, add capacity), as this is the simpler scenario to evaluate. The rule
    here is that at a minimum, you should scale out your cluster whenever your current
    cluster capacity is less than one:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将专注于是否应该扩展集群（即增加容量），因为这是更简单的情景来评估。规则是，至少在当前集群容量小于1时，您应该扩展您的集群：
- en: '![](assets/58383abe-4357-4cb0-924c-090eac36d6f7.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/58383abe-4357-4cb0-924c-090eac36d6f7.png)'
- en: In other words, if you do not currently have sufficient capacity in your cluster
    to support one more *worst-case* *scenario* ECS task, you should add a new instance
    to the ECS cluster. This makes sense, in that you are attempting to ensure that
    your cluster always has sufficient capacity for new ECS tasks as they are started.
    Of course, you can increase this threshold higher if you want more free capacity,
    which might be applicable for more dynamic environments where containers are often
    spinning up and down.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，如果您当前的集群容量不足以支持一个更糟的情况的ECS任务，您应该向ECS集群添加一个新实例。这是有道理的，因为您正在努力确保您的集群始终具有足够的容量来支持新的ECS任务的启动。当然，如果您希望获得更多的空闲容量，您可以将此阈值提高，这可能适用于更动态的环境，其中容器经常启动和关闭。
- en: Calculating the idle host capacity
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算空闲主机容量
- en: 'If we now consider the scale-in scenario, this becomes a little bit harder
    to determine. The spare ECS task capacity calculation we have discussed is related
    and required, however you need to think in these terms: if you removed an ECS
    container instance from the cluster, would there be enough capacity for all of
    the current running ECS tasks plus spare capacity for at least one additional
    ECS task? Another way to express this is to calculate the *idle host capacity*
    of the cluster–if greater than 1.0 hosts are idle in the cluster, then you can
    safely scale in the cluster, as subtracting a host would result in a remaining
    positive non-zero capacity. Note that we are referring to idle host capacity across
    the cluster–so think of this as more of a virtual host calculation, as you probably
    won''t have a completely idle host. This virtual host calculation is safe, because
    if we did remove a host from the cluster, the life cycle hooks and ECS container
    instance-draining features we introduced previously in Chapter 11 - *Managing
    the ECS Infrastructure Life Cycle* will ensure any containers that are running
    on the instance to be removed will be migrated to other instances in the cluster.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在考虑缩减规模的情况，这就变得有点难以确定了。我们讨论过的备用 ECS 任务容量计算是相关且必要的，但是你需要从这些角度思考：如果你从集群中移除一个
    ECS 容器实例，是否有足够的容量来运行所有当前正在运行的 ECS 任务，以及至少还有一个额外的 ECS 任务的备用容量？另一种表达方式是计算集群的*空闲主机容量*——如果集群中有多于
    1.0 个主机处于空闲状态，那么你可以安全地缩减集群规模，因为减少一个主机会导致剩余的正值非零容量。请注意，我们指的是整个集群中的空闲主机容量——所以把这看作更像是一个虚拟主机计算，因为你可能不会有完全空闲的主机。这个虚拟主机计算是安全的，因为如果我们从集群中移除一个主机，我们在第
    11 章*管理 ECS 基础设施生命周期*中介绍的生命周期钩子和 ECS 容器实例排空功能将确保任何运行在要移除的实例上的容器将被迁移到集群中的其他实例上。
- en: It's also important to understand that the idle host capacity must be greater
    than 1.0 and not equal to 1.0, as you must have enough spare capacity for one
    ECS task, otherwise you will trigger a scale-out action, resulting in an auto
    scaling scale-out/scale-in loop.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要了解的是，空闲主机容量必须大于 1.0，而不是等于 1.0，因为你必须有足够的备用容量来运行一个 ECS 任务，否则你将触发一个扩展规模的动作，导致自动扩展的扩展/缩减循环。
- en: 'To determine the current idle host capacity, we need to understand the following:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要确定当前的空闲主机容量，我们需要了解以下内容：
- en: The maximum number of ECS tasks that each ECS container instance can run for
    each of the different types of ECS resources (expressed as ![](assets/ded39ac8-2846-4051-8be4-ce102e7957d4.png)).
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个不同类型的 ECS 资源对应的每个 ECS 容器实例可以运行的最大 ECS 任务数量（表示为![](assets/ded39ac8-2846-4051-8be4-ce102e7957d4.png)）。
- en: The current free capacity for each type of ECS resource across the entire cluster
    (expressed as ![](assets/848fe089-3774-4825-8c43-ef5ea0ac8539.png)), which we
    already calculate when determining whether to scale out.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整个集群中每种类型的 ECS 资源的当前空闲容量（表示为![](assets/848fe089-3774-4825-8c43-ef5ea0ac8539.png)），这是我们在确定是否扩展规模时已经计算过的。
- en: 'With these pieces of information, you can calculate the idle host capacity
    for a given resource as follows:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些信息，你可以按照以下方式计算给定资源的空闲主机容量：
- en: '![](assets/d6c9883f-b371-4841-9fd4-7e37766be0fc.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/d6c9883f-b371-4841-9fd4-7e37766be0fc.png)'
- en: Idle host capacity example
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 空闲主机容量示例
- en: 'To make this more apparent, let''s work through an example, as illustrated
    in the following diagram, which starts by assuming the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更清楚地说明这一点，让我们通过以下示例来进行计算，如下图所示，假设以下情况：
- en: Worst-case ECS task CPU requirement of 400 CPU units
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最坏情况下需要 400 个 CPU 单位的 ECS 任务 CPU 要求
- en: Worst-case ECS task memory required of 200 MB
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最坏情况下需要 200 MB 的 ECS 任务内存
- en: Each ECS container instance support has a maximum of 1,000 CPU units and 1,000
    MB memory
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个 ECS 容器实例支持最多 1,000 个 CPU 单位和 1,000 MB 内存
- en: Two ECS container instances currently in the ECS cluster
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前在ECS集群中有两个ECS容器实例
- en: Each ECS container instance currently has 600 CPU units' spare capacity. Using
    the free capacity calculations discussed previously, this equates to a current
    free capacity across the cluster of two
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个ECS容器实例目前有600个CPU单位的空闲容量。使用之前讨论的空闲容量计算，这相当于集群中的当前空闲容量为2
- en: ECS tasks in terms of CPU resources, which we will refer to as ![](assets/fe5db803-ec6f-4713-9618-9e2eac790629.png).
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ECS任务的CPU资源，我们将称之为 ![](assets/fe5db803-ec6f-4713-9618-9e2eac790629.png)。
- en: 'Each ECS container instance currently has 800 MB of spare capacity. Using the
    free capacity calculations discussed previously, this equates to a current free
    capacity across the cluster of eight ECS tasks in terms of memory resources, which
    we will refer to as ![](assets/d214eb41-2e71-45da-babb-68b187099957.png):'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个ECS容器实例目前有800 MB的空闲容量。使用之前讨论的空闲容量计算，这相当于集群中的当前空闲容量为8个ECS任务的内存资源，我们将称之为 ![](assets/d214eb41-2e71-45da-babb-68b187099957.png)：
- en: '![](assets/6f13b876-6d57-4671-8b33-368c9854c33a.png)Idle host capacity'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/6f13b876-6d57-4671-8b33-368c9854c33a.png)空闲主机容量'
- en: 'We can first calculate the ![](assets/ab3ad606-7126-402a-8bc2-17b6ac2916d3.png)value
    as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以首先计算 ![](assets/ab3ad606-7126-402a-8bc2-17b6ac2916d3.png) 值如下：
- en: '![](assets/a4a2e4f2-fc90-47ca-8260-a8a8a86f925b.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/a4a2e4f2-fc90-47ca-8260-a8a8a86f925b.png)'
- en: 'For CPU, it equates to a value of 2, and for memory equates to a value of *5*:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 对于CPU，它等于2，对于内存等于*5*：
- en: '![](assets/3d4d598d-9e35-4bfb-b62d-e92855b344d6.png)![](assets/761d58d4-9b6c-46b0-82c9-7781d9f2987c.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3d4d598d-9e35-4bfb-b62d-e92855b344d6.png)![](assets/761d58d4-9b6c-46b0-82c9-7781d9f2987c.png)'
- en: 'With these values calculated and knowledge of the current free capacity of
    the cluster, we can now calculate the idle host capacity for each resource:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 通过计算这些值并了解集群当前的空闲容量，我们现在可以计算每个资源的空闲主机容量：
- en: '![](assets/e923ae69-d5f0-4d01-b2ca-1943fd040d19.png)![](assets/d9551f76-8da1-491b-bbba-816942c7297b.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/e923ae69-d5f0-4d01-b2ca-1943fd040d19.png)![](assets/d9551f76-8da1-491b-bbba-816942c7297b.png)'
- en: 'Here''s how to calculate a worst-case overall idle host capacity:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何计算最坏情况下的空闲主机容量：
- en: '![](assets/7201e489-d66f-4cae-b766-2b62ae79f69d.png)'
  id: totrans-107
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7201e489-d66f-4cae-b766-2b62ae79f69d.png)'
- en: At this point, given the idle host capacity is 1.0, we should *not* scale in
    the cluster as the capacity is not currently *greater* than 1\. This may seem
    counterintuitive given you have exactly one idle host, but if you did remove an
    instance at this point, it would result in an available CPU capacity of 0 for
    the cluster, and the cluster would scale out given there is no free CPU capacity.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，鉴于空闲主机容量为1.0，我们应该*不*缩减集群，因为容量目前*不大于*1。这可能看起来有些反直觉，因为您确实有一个空闲主机，但如果此时删除一个实例，将导致集群的可用CPU容量为0，并且集群将扩展，因为没有空闲的CPU容量。
- en: Implementing an ECS Auto Scaling solution
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实施ECS自动扩展解决方案
- en: 'Now that you have a good understanding of how to calculate the ECS cluster
    capacity for the purposes of making scale-out and scale-in decisions, we are ready
    to implement an auto scaling solution, as illustrated in the following diagram:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经很好地了解了如何计算ECS集群容量，以便进行扩展和缩减决策，我们准备实施一个自动扩展解决方案，如下图所示：
- en: '![](assets/42bafe58-768e-4b70-9a30-b8e072ea6c64.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/42bafe58-768e-4b70-9a30-b8e072ea6c64.png)'
- en: 'The following provides a walkthrough of the solution shown in the preceding
    diagram:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 以下提供了在前面的图表中显示的解决方案的步骤：
- en: Before you calculate the ECS cluster capacity, you need a mechanism that will
    trigger calculations of capacity, ideally whenever the capacity of your ECS container
    instances changes. This can be achieved by leveraging the CloudWatch Events service,
    which publishes events for various AWS services including ECS, and allows you
    to create *event rules* that subscribe to specific events and process them using
    a variety of mechanisms, including a Lambda function. CloudWatch events support
    receiving information about ECS container-instance state changes, and this represents
    the ideal mechanism for triggering cluster capacity calculations, as any change
    to the available resources of an ECS container instance will trigger a state-change
    event.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计算ECS集群容量之前，您需要一个机制来触发容量的计算，最好是在ECS容器实例的容量发生变化时触发。这可以通过利用CloudWatch Events服务来实现，该服务为包括ECS在内的各种AWS服务发布事件，并允许您创建*事件规则*，订阅特定事件并使用各种机制（包括Lambda函数）处理它们。CloudWatch事件支持接收有关ECS容器实例状态更改的信息，这代表了触发集群容量计算的理想机制，因为ECS容器实例的可用资源的任何更改都将触发状态更改事件。
- en: A Lambda function responsible for calculating ECS cluster capacity is triggered
    for each ECS container-instance state-change event.
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个负责计算ECS集群容量的Lambda函数会在每个ECS容器实例状态变化事件触发时被触发。
- en: Rather than making a decision to auto scale the cluster, the Lambda function
    simply publishes the current capacity in the form of CloudWatch custom metrics,
    which report both the current free container capacity and the idle host capacity.
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Lambda函数不会决定自动扩展集群，而是简单地以CloudWatch自定义指标的形式发布当前容量，报告当前空闲容器容量和空闲主机容量。
- en: The CloudWatch service is configured with alarms that trigger EC2 auto scaling
    actions whenever the free container capacity or idle host capacity falls below
    or exceeds the threshold for scaling out or scaling in the cluster.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CloudWatch服务配置了警报，当空闲容器容量或空闲主机容量低于或超过扩展或收缩集群的阈值时，会触发EC2自动扩展操作。
- en: The EC2 auto scaling service is configured with EC2 auto scaling policies, which
    are invoked in response to alarms raised by CloudWatch.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: EC2自动扩展服务配置了EC2自动扩展策略，这些策略会在CloudWatch引发的警报时被调用。
- en: In addition to the CloudWatch alarms configured to manage the ECS cluster capacity,
    you can configure appropriate CloudWatch alarms for each of your ECS services,
    which can then trigger the AWS application auto scaling service to scale out or
    scale in the number of ECS tasks that are running for your ECS services. For example,
    in the preceding diagram, the ECS service is configured with an application auto
    scaling policy that increases the number of ECS tasks should the CPU utilization
    for the ECS service exceed 50%.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了配置用于管理ECS集群容量的CloudWatch警报外，您还可以为每个ECS服务配置适当的CloudWatch警报，然后触发AWS应用自动扩展服务，以扩展或收缩运行您的ECS服务的ECS任务数量。例如，在前面的图表中，ECS服务配置了一个应用自动扩展策略，当ECS服务的CPU利用率超过50%时，会增加ECS任务的数量。
- en: Let's now implement the various components of the solution.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们实现解决方案的各个组件。
- en: Configuring CloudWatch events for ECS
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为ECS配置CloudWatch事件
- en: The first task we need to perform is to set up a CloudWatch event rule, which
    subscribes to ECS container-instance state-change events and is configured with
    a target of a Lambda function that will calculate the ECS cluster capacity.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要执行的第一个任务是设置一个CloudWatch事件规则，订阅ECS容器实例状态变化事件，并配置一个Lambda函数作为目标，用于计算ECS集群容量。
- en: 'The following example demonstrates adding a CloudWatch event rule to the todobackend-aws
    `stack.yml` CloudFormation template:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了如何向todobackend-aws `stack.yml` CloudFormation模板添加CloudWatch事件规则：
- en: '[PRE0]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `EcsCapacityEvents` resource defines the event rule and includes two key
    properties:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`EcsCapacityEvents` 资源定义了事件规则，并包括两个关键属性：'
- en: '`EventPattern`: Defines the pattern that matches events to this rule. All CloudWatch
    events include `source`, `detail-type`, and `detail` properties, and the event
    pattern ensures only ECS events (as defined by the `source` pattern of `aws.ecs`)
    that relate to ECS container-instance state changes (as defined by the `detail-type`
    pattern) for the `ApplicationCluster` resource (as defined by the `detail` pattern)
    that will be matched to the rule.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EventPattern`：定义了与此规则匹配事件的模式。所有 CloudWatch 事件都包括 `source`、`detail-type` 和
    `detail` 属性，事件模式确保只有与 ECS 事件相关的 ECS 事件（由 `source` 模式 `aws.ecs` 定义）与 ECS 容器实例状态更改（由
    `detail-type` 模式定义）与 `ApplicationCluster` 资源（由 `detail` 模式定义）相关的事件将被匹配到规则。'
- en: '`Targets`: Defines the target resource that the event should be routed to.
    In the preceding example, you reference the ARN of a Lambda function called `EcsCapacityFunction`,
    which you will define shortly.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Targets`：定义了事件应该路由到的目标资源。在前面的例子中，你引用了一个名为 `EcsCapacityFunction` 的 Lambda 函数的
    ARN，你很快将定义它。'
- en: The `EcsCapacityPermission` resource ensures the CloudWatch events service has
    permission to invoke the `EcsCapacityFunction` Lambda function. This is a common
    approach for any service that invokes a Lambda function, where you add a Lambda
    permission that grants a given resource (as defined by the `SourceArn` property)
    for a given AWS service (as defined by the `Principal` property) the ability to
    invoke a Lambda function ( `FunctionName` property).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`EcsCapacityPermission` 资源确保 CloudWatch 事件服务有权限调用 `EcsCapacityFunction` Lambda
    函数。这是任何调用 Lambda 函数的服务的常见方法，你可以添加一个 Lambda 权限，授予给定 AWS 服务（由 `Principal` 属性定义）对于给定资源（由
    `SourceArn` 属性定义）调用 Lambda 函数（`FunctionName` 属性）的能力。'
- en: 'Now, let''s add the referenced Lambda function, along with an IAM role and
    CloudWatch logs group:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们添加引用的 Lambda 函数，以及一个 IAM 角色和 CloudWatch 日志组：
- en: '[PRE1]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By now, you should have a good understanding of how to define Lambda functions
    using CloudFormation, so I won't describe the preceding example in depth. Note,
    however, that for now, I have implemented a basic function that simply prints
    any received events–we will use to this to gain an initial understanding of how
    the ECS container instance state change events are structured.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你应该已经对如何使用 CloudFormation 定义 Lambda 函数有了很好的理解，所以我不会深入描述前面的例子。但是请注意，目前我已经实现了一个基本的函数，它只是简单地打印出接收到的任何事件——我们将使用这个函数来初步了解
    ECS 容器实例状态更改事件的结构。
- en: 'At this point, you can now deploy your changes using the `aws cloudformation
    deploy` command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你现在可以使用 `aws cloudformation deploy` 命令部署你的更改：
- en: '[PRE2]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once deployment is complete, you can trigger an ECS container-instance state
    change by stopping an existing ECS task that is running on your ECS cluster:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，你可以通过停止运行在 ECS 集群上的现有 ECS 任务来触发 ECS 容器实例状态更改：
- en: '[PRE3]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Because this ECS task is linked to an ECS service, ECS will automatically start
    a new ECS task, and if you head over to the CloudWatch console, select Logs, and
    then open the most recent log stream for the log group for the Lambda function
    that processes ECS container instance state change events (`/aws/lambda/todobackend-ecsCapacity`),
    you should see a couple of events have been logged:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个 ECS 任务与 ECS 服务相关联，ECS 将自动启动一个新的 ECS 任务，如果你前往 CloudWatch 控制台，选择日志，然后打开用于处理
    ECS 容器实例状态更改事件的 Lambda 函数的日志组的最新日志流(`/aws/lambda/todobackend-ecsCapacity`)，你应该会看到一些事件已被记录：
- en: '![](assets/7c264632-6b24-4dd9-b464-645108398b4e.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/7c264632-6b24-4dd9-b464-645108398b4e.png)'
- en: In the preceding screenshot, you can see that two events were logged within
    a couple of seconds, which represent you stopping the ECS task and ECS then automatically
    starting a new ECS task to ensure the linked ECS service meets its configured
    desired count.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的屏幕截图中，您可以看到在几秒钟内记录了两个事件，这些事件代表您停止ECS任务，然后ECS自动启动新的ECS任务，以确保链接的ECS服务达到其配置的期望计数。
- en: 'You can see that the `source` and `detail-type` properties match the event
    pattern you configured earlier, and, if you scroll down further in the second
    event, you should find a property called `registeredResources` and `remainingResources`,
    as demonstrated in the following example:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到`source`和`detail-type`属性与您之前配置的事件模式匹配，如果您在第二个事件中继续向下滚动，您应该会找到一个名为`registeredResources`和`remainingResources`的属性，如下例所示：
- en: '[PRE5]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `registeredResources` property defines the total resources allocated to
    the instance, while `remainingResources` indicates the current remaining quantity
    of each resource. Because the event in the preceding example is raised when ECS
    starts a new ECS task for the todobackend service, the total 250 CPU units and
    400 MB of memory allocated to this task are deducted from `registeredResources`,
    which is then reflected in the `remainingResources` property. Notice also at the
    top of the output of Example 12-6 that the event includes other useful information,
    such as the ECS cluster ARN and ECS container instance ARN values (as specified
    by the `clusterArn` and `containerInstanceArn` properties).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`registeredResources`属性定义了分配给实例的总资源，而`remainingResources`指示每个资源的当前剩余数量。因为在前面的示例中，当ECS为todobackend服务启动新的ECS任务时会引发事件，因此从`registeredResources`中扣除了分配给此任务的总250个CPU单位和400
    MB内存，然后反映在`remainingResources`属性中。还要注意在示例12-6的输出顶部，事件包括其他有用的信息，例如ECS集群ARN和ECS容器实例ARN值（由`clusterArn`和`containerInstanceArn`属性指定）。'
- en: Programming the Lambda function that calculates the cluster capacity
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编写计算集群容量的Lambda函数
- en: 'Now that you have set up a CloudWatch event and Lambda function that is invoked
    whenever ECS container-instance state changes are detected, you can now implement
    the required application code in the Lambda function that will perform the appropriate
    ECS cluster-capacity calculations:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经设置了一个CloudWatch事件和Lambda函数，每当检测到ECS容器实例状态变化时就会被调用，您现在可以在Lambda函数中实现所需的应用程序代码，以执行适当的ECS集群容量计算。
- en: '[PRE6]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In the preceding example, you first define the maximum CPU and maximum memory
    of the ECS tasks that your cluster will support, which is required to make the
    various cluster-capacity calculations, and we use the current configured CPU and
    memory settings for the todobackend service, given this is the only application
    we are supporting on our cluster. Within the `handler` function, the first step
    is to collect the current resource capacity data using the received CloudWatch
    event. The event includes details about the maximum capacity of your ECS container
    instance in the `registeredResources` property, and also includes the ECS cluster
    that the instance belongs to. The function first lists all of instances in the
    cluster, and then loads detailed information about each instance using the `describe_container_instances`
    call on the ECS client.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您首先定义了ECS任务的最大CPU和最大内存，这是进行各种集群容量计算所必需的，我们使用当前配置的CPU和内存设置来支持todobackend服务，因为这是我们集群上唯一支持的应用程序。在`handler`函数中，第一步是使用接收到的CloudWatch事件收集当前的资源容量数据。该事件包括有关ECS容器实例在`registeredResources`属性中的最大容量的详细信息，还包括实例所属的ECS集群。该函数首先列出集群中的所有实例，然后使用ECS客户端上的`describe_container_instances`调用加载每个实例的详细信息。
- en: The information collected on each instance is limited to ACTIVE instances only,
    as you don't want to include resources for instances that may be in a DRAINING
    state or some other non-active state.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 对每个实例收集的信息仅限于活动实例，因为您不希望包括可能处于DRAINING状态或其他非活动状态的实例的资源。
- en: The code in the preceding example, will only work correctly in a Python 3.x
    environment, so ensure your Lambda function is configured to use Python 3.6.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 前面示例中的代码只能在Python 3.x环境中正确运行，因此请确保您的Lambda函数配置为使用Python 3.6。
- en: With the necessary information collected about each ECS container instance,
    you then iterate through each instance and calculate the CPU and memory capacity.
    This calls helper functions that query the `remainingResources` property for each
    instance, which return the current available capacity of each resource. Each calculation
    is expressed in terms of the maximum-sized containers you defined earlier, and
    is summed together to provide the CPU and memory capacity across the cluster,
    which is printed for informational purposes.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 收集有关每个ECS容器实例的必要信息后，然后迭代每个实例并计算CPU和内存容量。这调用了查询每个实例的`remainingResources`属性的辅助函数，该函数返回每个资源的当前可用容量。每个计算都以您之前定义的最大容器大小来表达，并将它们相加以提供整个集群的CPU和内存容量，以供信息目的打印。
- en: The next step is to calculate the overall container capacity, which is easily
    calculated by taking the minimum value of the previously calculated resource capacities,
    and this will be used to determine when your ECS cluster needs to scale out, at
    the very least when container capacity falls below zero. Finally, the idle host
    capacity calculation is made–this value will be used to determine when your ECS
    cluster should scale in, which should only happen if the idle host capacity is
    greater than 1.0, as discussed previously.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是计算整体容器容量，这可以通过取先前计算的资源容量的最小值来轻松计算，这将用于确定您的ECS集群何时需要扩展，至少当容器容量低于零时。最后，进行空闲主机容量计算
    - 此值将用于确定您的ECS集群何时应该缩减，只有当空闲主机容量大于1.0时才会发生，如前所述。
- en: Adding IAM permissions for calculating the cluster capacity
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为计算集群容量添加IAM权限
- en: 'One point to note about the code in the preceding example, is that it requires
    the ability to call the ECS service and execute the `ListContainerInstances` and
    `DescribeContainerInstances` API calls. This means you need to add the appropriate
    IAM permissions to the Lambda function IAM role, as demonstrated in the following
    example:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 关于前面示例中的代码需要注意的一点是，它需要能够调用ECS服务并执行`ListContainerInstances`和`DescribeContainerInstances`
    API调用的能力。这意味着您需要向Lambda函数IAM角色添加适当的IAM权限，如下例所示：
- en: '[PRE7]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Testing cluster-capacity calculations
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试集群容量计算
- en: You have added the code required to calculate the cluster capacity, and ensured
    that your Lambda function has the appropriate permissions to query ECS to determine
    the current capacity of all ECS container instances in the cluster. You can now
    deploy your changes using the `aws cloudformation deploy` command, and, once deployment
    is complete, you can test your Lambda function again by stopping any ECS task
    that is running inside the todobackend ECS cluster.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经添加了计算集群容量所需的代码，并确保您的Lambda函数有适当的权限来查询ECS以确定集群中所有ECS容器实例的当前容量。您现在可以使用`aws
    cloudformation deploy`命令部署您的更改，一旦部署完成，您可以通过停止运行在todobackend ECS集群中的任何ECS任务来再次测试您的Lambda函数。
- en: 'If you review the CloudWatch logs for your Lambda function, you should see
    events similar to those shown here:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看Lambda函数的CloudWatch日志，您应该会看到类似于这里显示的事件：
- en: '![](assets/ce9d382e-863a-4cc2-a461-e0cb3898e99e.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/ce9d382e-863a-4cc2-a461-e0cb3898e99e.png)'
- en: Notice that when you stopped the ECS task (as represented by the stop task event),
    the Lambda function reports a CPU capacity of 4, memory capacity of 2, and an
    overall capacity of 2, which is the minimum value of each of the calculated resource
    capacities.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当您停止ECS任务（如停止任务事件所表示的），Lambda函数报告CPU容量为4，内存容量为2，总体容量为2，这是计算出的每个资源容量的最小值。
- en: 'If you sanity-check this, you should find that the calculations are accurate
    and correct. For the initial event, because you stopped the ECS tasks, there are
    no tasks running, so the available CPU and memory resources are 1,024 units and
    993 MB, respectively (the capacity of a t2.micro instance). This equates to the
    following container capacities:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对此进行合理检查，您应该会发现计算是准确和正确的。对于初始事件，因为您停止了ECS任务，没有任务在运行，因此可用的CPU和内存资源分别为1,024个单位和993
    MB（即t2.micro实例的容量）。这相当于以下容器容量：
- en: CPU capacity = 1024 / 250 = 4
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU容量 = 1024 / 250 = 4
- en: Memory capacity = 993 / 400 = 2
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存容量 = 993 / 400 = 2
- en: 'When ECS automatically replaces the stopped ECS task, you can see that the
    cluster capacity drops, given a new ECS task (with 250 CPU units and 400 MB of
    memory) is now consuming resources:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当ECS自动替换停止的ECS任务时，您会看到集群容量下降，因为新的ECS任务（具有250个CPU单位和400 MB内存）现在正在消耗资源：
- en: CPU capacity = 1024 - 250 / 250 = 774 / 250 = 3
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU容量 = 1024 - 250 / 250 = 774 / 250 = 3
- en: Memory capacity = 993 - 400 / 400 = 593 / 400 = 1
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存容量 = 993 - 400 / 400 = 593 / 400 = 1
- en: Finally, you can see that the overall idle host capacity is correctly calculated
    as 1.0 when you stop the ECS task, which is correct as no ECS tasks are running
    on your cluster at that time. When ECS replaces the stopped task, the overall
    idle host capacity reduces to 0.5, given the ECS container instance is now running
    one out of the maximum two ECS tasks that can be run on a single instance in terms
    of memory resources.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以看到，当您停止ECS任务时，总体空闲主机容量正确计算为1.0，这是正确的，因为此时集群上没有运行任何ECS任务。当ECS替换停止的任务时，总体空闲主机容量减少为0.5，因为ECS容器实例现在运行的是最多可以在单个实例上运行的两个ECS任务中的一个，就内存资源而言。
- en: Publishing custom CloudWatch metrics
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布自定义CloudWatch指标
- en: 'At this point, we are calculating the appropriate metrics that determine when
    you need to both scale out or scale in the cluster, and the final task that needs
    to be performed in the function is to publish custom CloudWatch event metrics,
    which we can use to trigger auto scaling policies:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们正在计算确定何时需要扩展或缩小集群的适当指标，并且函数中需要执行的最终任务是发布自定义CloudWatch事件指标，我们可以使用这些指标来触发自动扩展策略：
- en: '[PRE8]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the preceding example, you use the CloudWatch client `put_metric_data` function
    to publish the `ContainerCapacity` and `IdleHostCapacity` custom metrics within
    the AWS/ECS namespace. These metrics are dimensioned based upon the ECS cluster,
    as specified by the ClusterName dimension name, and are limited to the todobackend
    ECS cluster.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您使用CloudWatch客户端的`put_metric_data`函数来发布AWS/ECS命名空间中的`ContainerCapacity`和`IdleHostCapacity`自定义指标。这些指标基于ECS集群进行维度化，由ClusterName维度名称指定，并且仅限于todobackend
    ECS集群。
- en: 'One final configuration task required to ensure the Lambda function operates
    correctly is to grant the function permissions to publish the CloudWatch metrics.
    This is achieved by adding the appropriate IAM permissions to the `EcsCapacityRole`
    you created earlier in the previous example:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Lambda函数正确运行的最后一个配置任务是授予函数权限以发布CloudWatch指标。这可以通过在先前示例中创建的`EcsCapacityRole`中添加适当的IAM权限来实现：
- en: '[PRE9]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'If you now deploy your changes using the `aws cloudformation deploy` command
    and then stop a running ECS task, after switching over to the CloudWatch console,
    you should be able to see new metrics being published in relation to your ECS
    cluster. If you select **Metrics** from the left-hand menu and then select **ECS
    > ClusterName** under **All metrics**, you should see your custom metrics (`ContainerCapacity`
    and `IdleHostCapacity`). The following screenshot shows these metrics graphed
    on the basis of the maximum value collected within a one-minute period. At 12:49
    on the graph, you can see both the `ContainerCapacity` and `IdleHostCapacity`
    metrics increased when you stopped the ECS task, and then once ECS started a new
    ECS task, the values for both metrics decreased as the new ECS task was allocated
    resources from your cluster:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在使用`aws cloudformation deploy`命令部署更改，然后停止运行的ECS任务，在切换到CloudWatch控制台后，您应该能够看到与您的ECS集群相关的新指标被发布。如果您从左侧菜单中选择**指标**，然后在**所有指标**下选择**ECS
    > ClusterName**，您应该能够看到您的自定义指标（`ContainerCapacity`和`IdleHostCapacity`）。以下截图显示了这些指标基于一分钟内收集的最大值进行绘制。在图表的12:49处，您可以看到当您停止ECS任务时，`ContainerCapacity`和`IdleHostCapacity`指标都增加了，然后一旦ECS启动了新的ECS任务，这两个指标的值都减少了，因为新的ECS任务从您的集群中分配了资源：
- en: '![](assets/59c87186-8313-4217-ba03-df4041c220e8.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/59c87186-8313-4217-ba03-df4041c220e8.png)'
- en: Creating CloudWatch alarms for cluster-capacity management
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为集群容量管理创建CloudWatch警报。
- en: You now have the ability to calculate and publish ECS cluster capacity metrics
    whenever an ECS container-instance state change occurs in your ECS cluster. The
    next step in the overall solution is to implement CloudWatch alarms, which will
    trigger auto scaling actions whenever a metric exceeds or drops below a specified
    threshold that relates to cluster capacity.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以在ECS集群中计算和发布ECS集群容量指标，每当ECS集群中的ECS容器实例状态发生变化时。整体解决方案的下一步是实施CloudWatch警报，这将在指标超过或低于与集群容量相关的指定阈值时触发自动扩展操作。
- en: 'The following code demonstrates adding two CloudWatch alarms to the todobackend
    stack:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了向todobackend堆栈添加两个CloudWatch警报：
- en: '[PRE10]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'In the preceding example, you add two CloudWatch alarms–a `ContainerCapacityAlarm` that
    will be used to trigger scale-out actions whenever the container capacity falls
    below 1, and an `IdleHostCapacityAlarm` that will be used to trigger scale-in
    actions whenever the idle host capacity is greater than 1\. The various properties
    for each alarm are described in further detail here:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您添加了两个CloudWatch警报-一个`ContainerCapacityAlarm`，每当容器容量低于1时将用于触发扩展操作，以及一个`IdleHostCapacityAlarm`，每当空闲主机容量大于1时将用于触发缩减操作。每个警报的各种属性在此处有进一步的描述：
- en: '`AlarmActions`: Defines the actions that should be taken should the alarm breach
    its configured criteria. Here we reference the EC2 auto scaling policy resources
    that we will define shortly, which trigger the appropriate auto scaling scale-out
    or scale-in action whenever an alarm is raised.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`AlarmActions`：定义应该采取的操作，如果警报违反其配置的条件。在这里，我们引用了我们即将定义的EC2自动扩展策略资源，这些资源在引发警报时会触发适当的自动扩展扩展或缩减操作。'
- en: '`Namespace`: Defines the namespace of the metric the alarm relates to.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Namespace`：定义警报所关联的指标的命名空间。'
- en: '`Dimensions`: Defines the context of how the metric relates to resources within
    the given namespace. In the preceding example, the context is configured as the
    ECS cluster within our stack.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Dimensions`：定义指标与给定命名空间内的资源的关系的上下文。在前面的示例中，上下文配置为我们堆栈内的ECS集群。'
- en: '`MetricName`: Defines the name of the metric. Here, we specify the name of
    each custom metric we published in the previous section.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MetricName`：定义指标的名称。在这里，我们指定了在上一节中发布的每个自定义指标的名称。'
- en: '`Statistic`: Defines the statistic of the metric that should be evaluated.
    This is actually quite an important parameter and, as an example in the case of
    the container capacity alarm, setting a value of maximum ensures transient metrics
    that fall below the configured threshold of 1 will not unnecessarily trigger the
    alarm, assuming that at least 1 value during each evaluation period exceeds the
    configured threshold. The same is applied for the idle host capacity alarm but
    in the opposite direction.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`统计`：定义应该评估的指标的统计数据。这实际上是一个非常重要的参数，在容器容量警报的情况下，设置最大值确保短暂指标不会不必要地触发警报，假设在每个评估周期内至少有1个值超过配置的阈值。对于空闲主机容量警报也是如此，但方向相反。'
- en: '`Period`, `EvaluationPeriods`, `Threshold`, and `ComparisonOperator`: These
    define the timeframe over which the metric must fall outside the bounds of the
    configured threshold and comparison operator. If these bounds are exceeded, an
    alarm will be raised.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Period`、`EvaluationPeriods`、`Threshold`和`ComparisonOperator`：这些定义了指标必须在配置的阈值和比较运算符的范围之外的时间范围。如果超出了这些范围，将会触发警报。'
- en: '`TreatMissingData`: This setting defines how you should treat missing metric
    data. In our use case, missing metric data is a common occurrence given we only
    publish metrics whenever an ECS container instance state changes, so setting a
    value of `ignore` ensures we do not treat missing data as an indication that something
    is wrong.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TreatMissingData`：此设置定义了如何处理缺少的指标数据。在我们的用例中，由于我们仅在ECS容器实例状态更改时发布指标数据，因此将值设置为`ignore`可以确保我们不会将缺失的数据视为有问题的指示。'
- en: Creating EC2 Auto Scaling policies
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建EC2自动扩展策略
- en: You now need to create the EC2 auto scaling policy resources that you referenced
    in each CloudWatch alarm resource.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您需要创建您在每个CloudWatch警报资源中引用的EC2自动扩展策略资源。
- en: 'The following example demonstrates adding a scale-out and scale-in policy to
    the todobackend stack:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例演示了向todobackend堆栈添加扩展和缩减策略：
- en: '[PRE11]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the preceding example, you define two auto scaling policies of the `SimpleScaling`
    type, which represents the simplest form of auto scaling that you can implement.
    A discussion of the various auto scaling types is outside the scope of this book,
    however if you are interested in learning more about the available options, you
    can refer to [https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html). 
    The `AdjustmentType` and `ScalingAdjustment` properties are configured to either
    increase or decrease the size of the auto scaling group by one instance, while
    the `Cooldown` property provides a mechanism to ensure further auto scaling actions
    are disabled for the specified duration, which can help avoiding auto scaling
    loops where your clusters keep on scaling out and scaling in frequently.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中，您定义了两种`SimpleScaling`类型的自动扩展策略，它代表了您可以实现的最简单的自动扩展形式。各种自动扩展类型的讨论超出了本书的范围，但如果您对了解更多可用选项感兴趣，可以参考[https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html)。`AdjustmentType`和`ScalingAdjustment`属性配置为增加或减少自动扩展组的一个实例的大小，而`Cooldown`属性提供了一种机制，以确保在指定的持续时间内禁用进一步的自动扩展操作，这可以帮助避免集群频繁地扩展和缩减。
- en: Notice that the `ApplicationAutoscaling` `UpdatePolicy` setting has been updated
    to include the `SuspendProcesses` parameter, which configures CloudFormation to
    disable certain operational processes whenever an auto scaling rolling update
    is taking place. This specifically disables auto scaling operations during a rolling
    update, which is important as you don't want auto scaling actions interfering
    with the rolling update that is orchestrated by CloudFormation. Finally, we also
    set the various count settings on the `ApplicationAutoscaling` resource to a fixed
    value of 1, as auto scaling will now manage the size of our ECS cluster.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`ApplicationAutoscaling`的`UpdatePolicy`设置已更新以包括`SuspendProcesses`参数，该参数配置CloudFormation在进行自动扩展滚动更新时禁用某些操作过程。这特别是在滚动更新期间禁用自动扩展操作很重要，因为您不希望自动扩展操作干扰由CloudFormation编排的滚动更新。最后，我们还将`ApplicationAutoscaling`资源上的各种计数设置为固定值1，因为自动扩展现在将管理我们的ECS集群的大小。
- en: Testing ECS cluster-capacity management
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试ECS集群容量管理
- en: Now, that we have all of the components to calculate the ECS cluster capacity,
    publish metrics, and trigger alarms that will invoke auto scaling actions, let's
    deploy our changes and test the solution works as expected.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经拥有了计算ECS集群容量、发布指标和触发警报的所有组件，这将调用自动扩展操作，让我们部署我们的更改并测试解决方案是否按预期工作。
- en: Testing scale out
  id: totrans-193
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试扩展
- en: 'To artificially trigger a scale-out action, we need to set the `ApplicationDesiredCount`
    input parameter to 2 in the `dev.cfg` configuration file, which will increase
    the ECS task count for our ECS service to 2 and will cause the single ECS container
    instance in the ECS cluster to no longer have enough resources to support any
    further additional containers:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 人为触发扩展操作，我们需要在`dev.cfg`配置文件中将`ApplicationDesiredCount`输入参数设置为2，这将增加我们的ECS服务的ECS任务计数为2，并导致ECS集群中的单个ECS容器实例不再具有足够的资源来支持任何进一步的附加容器：
- en: '[PRE12]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This configuration change should result in the `ContainerCapacity` metric falling
    below the configured alarm threshold of `1`, which we can test by now deploying
    our changes to CloudFormation by running the `aws cloudformation deploy` command.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 此配置更改应导致`ContainerCapacity`指标下降到配置的警报阈值`1`以下，我们可以通过运行`aws cloudformation deploy`命令将更改部署到CloudFormation来进行测试。
- en: 'Once the deployment is complete, if you browse to the CloudWatch console and
    select Alarms from the left-hand menu, you should see your container capacity alarm
    go into an ALARM state (this may take a few minutes) as demonstrated earlier:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，如果您浏览到CloudWatch控制台并从左侧菜单中选择警报，您应该会看到您的容器容量警报进入警报状态（可能需要几分钟），如前所示：
- en: '![](assets/3aedb0f1-0201-435f-b6b0-557d67d1ed07.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/3aedb0f1-0201-435f-b6b0-557d67d1ed07.png)'
- en: You can see in the Actions details that the CloudWatch alarm has triggered the
    application Auto Scaling scale-out policy, and notice in the graph on the left
    that this is because the container capacity has dropped to 0 due to the increase
    in ECS tasks running on the single ECS container instance.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在操作详细信息中看到CloudWatch警报已触发应用程序自动扩展的扩展策略，并且在左侧的图表中注意到，这是因为容器容量由于单个ECS容器实例上运行的ECS任务增加而下降到0。
- en: 'If you now navigate to the EC2 console, select **Auto Scaling Group**s from
    the left-hand menu, and then select the **Activity History** tab for the todobackend
    auto scaling group, you can see that the current instance count in the auto scaling
    group is `2`, and that a new EC2 instance was launched due to the container capacity
    alarm transitioning to an ALARM state:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在导航到EC2控制台，从左侧菜单中选择**自动扩展组**，然后选择todobackend自动扩展组的**活动历史**选项卡，您会看到自动扩展组中当前实例计数为`2`，并且由于容器容量警报转换为警报状态而启动了一个新的EC2实例：
- en: '![](assets/f9681a0f-4867-4e7c-adca-a75bc78fc5d7.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/f9681a0f-4867-4e7c-adca-a75bc78fc5d7.png)'
- en: 'Once the new ECS container instance is added to the ECS cluster, a new capacity
    calculation will take place, and if you switch back to the CloudWatch console,
    you should see the ContainerCapacity alarm eventually transition to an OK state,
    as shown in the following screenshot:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦新的ECS容器实例被添加到ECS集群中，新的容量计算将会发生，如果您切换回CloudWatch控制台，您应该看到ContainerCapacity警报最终转换为OK状态，如下面的截图所示：
- en: '![](assets/4ae43aef-c5b7-4dc5-98b3-2fe6a3b832eb.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4ae43aef-c5b7-4dc5-98b3-2fe6a3b832eb.png)'
- en: In the graph in the lower-right-hand corner, you can see the effect of adding
    a new ECS container instance, which increases the container capacity from `0`
    to `2`, placing the container capacity alarm into an OK state.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在右下角的图表中，您可以看到添加一个新的ECS容器实例的效果，这将把容器容量从`0`增加到`2`，将容器容量警报置为OK状态。
- en: Testing scale in
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试缩减规模
- en: 'Now that you have successfully tested the scale-out behavior of your ECS cluster-capacity
    management solution, let''s now artificially trigger scale-in behavior by reducing
    the `ApplicationDesiredCount` to 1 in the `dev.cfg` file and running the `aws
    cloudformation deploy` command to deploy the modified count:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经成功测试了ECS集群容量管理解决方案的扩展行为，让我们现在通过在`dev.cfg`文件中将`ApplicationDesiredCount`减少到1，并运行`aws
    cloudformation deploy`命令来部署修改后的计数，人为地触发缩减行为：
- en: '[PRE13]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Once this change has been deployed, in the CloudWatch console you should see
    the idle host capacity alarm change to an ALARM state after a few moments:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个改变被部署，您应该在CloudWatch控制台上看到空闲主机容量警报在几分钟后变为ALARM状态：
- en: '![](assets/4121b365-3f94-4ed5-ba0e-e95ceb74cc1f.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4121b365-3f94-4ed5-ba0e-e95ceb74cc1f.png)'
- en: In the preceding screenshot, the idle host capacity has increased from 1.0 to
    1.5, given we now only have one running ECS task and two ECS container instances
    in the cluster. This has triggered the configured application autoscaling scale
    in policy, which will reduce the ECS cluster capacity to a single ECS container
    instance, and eventually the idle host capacity alarm will transition to an OK
    state.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的截图中，空闲主机容量从1.0增加到1.5，因为现在我们只有一个正在运行的ECS任务和两个ECS容器实例在集群中。这触发了配置的应用程序自动缩放缩减策略，它将减少ECS集群容量到一个ECS容器实例，并最终空闲主机容量警报将转换为OK状态。
- en: Configuring the AWS application Auto Scaling service
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置AWS应用自动扩展服务
- en: We now have an ECS cluster-capacity management solution in place that will automatically
    scale out and scale in your ECS cluster, as new ECS tasks come and go in your
    ECS cluster. To date, we artificially tested this by manually increasing the task
    count of the todobackend ECS service, however in your real world applications,
    you typically would use the AWS application auto scaling service to dynamically
    scale your ECS services up and down based upon whatever metrics make the most
    sense for your application.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经有了一个ECS集群容量管理解决方案，它将自动扩展和缩减您的ECS集群，当新的ECS任务在您的ECS集群中出现和消失时。到目前为止，我们通过手动增加todobackend
    ECS服务的任务数量来人为测试这一点，然而在您的真实应用中，您通常会使用AWS应用自动扩展服务，根据应用程序最合适的指标动态地扩展和缩减您的ECS服务。
- en: Another scenario that impacts ECS cluster capacity is the deployment of new
    applications, in the form of ECS task definition changes to your ECS services.
    The rolling-update mechanism of ECS will often temporarily increase the ECS task
    count, which can result in your ECS cluster scaling out for a short period of
    time, and then scaling back in. You can tune this behavior by adjusting the period
    of time the container capacity can fall below your configured minimum threshold
    before raising an alarm, and also increasing the minimum container capacity threshold
    that must be available at all times. This approach builds more spare capacity
    in your cluster, which allows you to respond less aggressively to capacity changes
    and absorb the transient capacity fluctuations caused by rolling deployments.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ECS集群容量的另一个影响因素是部署新应用程序，以ECS任务定义更改的形式应用到ECS服务。ECS的滚动更新机制通常会暂时增加ECS任务数量，这可能会导致ECS集群在短时间内扩展，然后再缩小。您可以通过调整容器容量在降低到配置的最小阈值之前可以持续的时间来调整此行为，并且还可以增加必须始终可用的最小容器容量阈值。这种方法可以在集群中建立更多的备用容量，从而使您能够对容量变化做出较少激进的响应，并吸收滚动部署引起的瞬时容量波动。
- en: 'AWS application auto scaling is more complex to configure than EC2 auto scaling,
    and requires, at a minimum, several components:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: AWS应用自动扩展比EC2自动扩展更复杂，至少需要几个组件：
- en: '**CloudWatch alarms**: This define the metrics that you are interested in and
    trigger when you should scale out or scale in.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CloudWatch警报**：这定义了您感兴趣的指标，并在应该扩展或缩小时触发。'
- en: '**Auto Scaling target**: This defines the target component that the application
    auto scaling will be applied to. For our scenario, this will be configured as
    the todobackend ECS service.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动扩展目标**：这定义了应用程序自动扩展将应用于的目标组件。对于我们的场景，这将被配置为todobackend ECS服务。'
- en: '**Auto Scaling IAM role**: You must create an IAM role that grants the AWS
    application auto scaling service permissions to manage your CloudWatch alarms,
    read your application auto scaling policies, and modify your ECS services to increase
    or decrease the ECS service task count.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动扩展IAM角色**：您必须创建一个IAM角色，授予AWS应用自动扩展服务权限来管理您的CloudWatch警报，读取您的应用自动扩展策略，并修改您的ECS服务以增加或减少ECS服务任务数量。'
- en: '**Scale out and scale in policies**: These define the behavior associated with
    scaling your ECS services out and back in.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展和缩小策略**：这些定义了与扩展ECS服务和缩小ECS服务相关的行为。'
- en: Configuring CloudWatch alarms
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置CloudWatch警报
- en: 'Let''s get started by adding a CloudWatch alarm that will trigger application
    auto scaling in the todobackend `stack.yml` template:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先通过在`stack.yml`模板中添加一个CloudWatch警报来触发应用程序自动扩展：
- en: '[PRE14]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: In the preceding example, alarms are created for low CPU and high CPU conditions,
    and are dimensioned to the todobackend ECS service running on the todobackend
    ECS cluster. A high CPU alarm will fire when the average CPU utilization for the
    ECS service is greater than 40% for a period of 3 minutes (3 x 60 seconds), and
    a low CPU alarm will fire when the average CPU utilization falls below 20%, again
    for a period of 3 minutes. In each case, an alarm action is configured, which
    references scale-out and scale-in policy resources that we will create shortly.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，为低CPU和高CPU条件创建了警报，并将其维度设置为运行在todobackend ECS集群上的todobackend ECS服务。当ECS服务的平均CPU利用率在3分钟（3
    x 60秒）的时间内大于40%时，将触发高CPU警报，当平均CPU利用率在3分钟内低于20%时，将触发低CPU警报。在每种情况下，都配置了警报操作，引用了我们即将创建的扩展和缩小策略资源。
- en: Defining an Auto Scaling target
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义自动扩展目标
- en: 'The AWS application auto scaling requires you to define an auto scaling target,
    which is the resource that you need to scale up or scale down. For an ECS use
    case, this is defined as an ECS service, as demonstrated in the preceding example:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 应用自动缩放要求您定义自动缩放目标，这是您需要扩展或缩小的资源。对于 ECS 的用例，这被定义为 ECS 服务，如前面的示例所示：
- en: '[PRE15]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'In the preceding example, you define the following properties for the auto
    scaling target:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，您为自动缩放目标定义了以下属性：
- en: '`ServiceNamespace`: Defines the namespace of the target AWS service. Set this
    to `ecs` when targeting an ECS service.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServiceNamespace`：定义目标 AWS 服务的命名空间。当针对 ECS 服务时，将其设置为 `ecs`。'
- en: '`ResourceId`: The identifier of the resource associated with the target. For
    ECS, this is defined in the `service/<ecs-cluster-name>/<ecs-service-name>` format.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResourceId`：与目标关联的资源的标识符。对于 ECS，这是以 `service/<ecs-cluster-name>/<ecs-service-name>`
    格式定义的。'
- en: '`ScalableDimension`: Specifies the property of the target resource type that
    can be scaled. In the case of an ECS service, this is the `DesiredCount` property,
    which is defined as `ecs:service:DesiredCount`.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ScalableDimension`：指定可以扩展的目标资源类型的属性。在 ECS 服务的情况下，这是 `DesiredCount` 属性，其定义为
    `ecs:service:DesiredCount`。'
- en: '`MinCapacity` and `MaxCapacity`: The minimum and maximum bounds to which the
    desired ECS service count can be scaled.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MinCapacity` 和 `MaxCapacity`：期望的 ECS 服务计数可以扩展的最小和最大边界。'
- en: '`RoleARN`: The ARN of the IAM role that the application auto scaling service
    will use to scale out and scale in the target. In the preceding example, you references
    an IAM resource that you will create in the next section.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RoleARN`：应用自动缩放服务将用于扩展和缩小目标的 IAM 角色的 ARN。在前面的示例中，您引用了下一节中将创建的 IAM 资源。'
- en: For more details on each of the preceding properties, you can refer to the [Application
    Auto Scaling API reference](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html).
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 有关上述每个属性的更多详细信息，您可以参考 [应用自动缩放 API 参考](https://docs.aws.amazon.com/autoscaling/application/APIReference/API_RegisterScalableTarget.html)。
- en: Creating an Auto Scaling IAM role
  id: totrans-233
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建自动缩放 IAM 角色
- en: 'In the resource definition for the application auto scaling target, you referenced
    an IAM role that the application auto scaling service will assume. The following
    example defines this IAM role and the permissions required by the application
    auto scaling service:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用自动缩放目标的资源定义中，您引用了应用自动缩放服务将扮演的 IAM 角色。以下示例定义了此 IAM 角色以及应用自动缩放服务所需的权限：
- en: '[PRE16]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You can see that the application auto scaling service requires a number of read
    permissions associated with the application auto scaling service itself, an ability
    to manage CloudWatch alarms, and must be able to update the ECS services in order
    to manage the ECS service's desired count. Notice that you must specify the principal
    as `application-autoscaling.amazonaws.com` in the `AssumeRolePolicyDocument` section,
    which allows the application auto scaling service to assume the role.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到应用自动缩放服务需要与应用自动缩放服务本身关联的一些读取权限，以及管理 CloudWatch 警报的能力，并且必须能够更新 ECS 服务以管理
    ECS 服务的期望计数。请注意，您必须在 `AssumeRolePolicyDocument` 部分中将主体指定为 `application-autoscaling.amazonaws.com`，这允许应用自动缩放服务扮演该角色。
- en: Configuring scale-out and scale-in policies
  id: totrans-237
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置扩展和缩小策略
- en: 'The final task required when configuring application auto scaling is to add
    scale-out and scale-in policies:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 配置应用自动缩放时的最后一个任务是添加扩展和缩小策略：
- en: '[PRE17]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here you define scale-out and scale-in policies, ensuring the resource names
    match those you referenced earlier, when you configured the CloudWatch alarms
    used to trigger the policies. The `PolicyType` parameter specifies you are configuring
    Step-Scaling policies, which work in a similar manner to the EC2 auto scaling
    policies you defined earlier and allow you to scale up or down in incremental
    steps. The remaining properties are fairly self-explanatory, although the `StepAdjustments`
    property does warrant some further description.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您定义了扩展和缩小策略，确保资源名称与您之前引用的那些匹配，当您配置用于触发策略的CloudWatch警报时。`PolicyType`参数指定您正在配置Step-Scaling策略，它们的工作方式类似于您之前定义的EC2自动缩放策略，并允许您以增量步骤进行缩放。其余属性都相当容易理解，尽管`StepAdjustments`属性确实需要进一步描述。
- en: The `ScalingAdjustment` indicates how much you will increase or decrease the
    ECS service count by each time you scale, while the `MetricIntervalLowerBound`
    and `MetricIntervalUpperBound` properties allow you to define additional bounds
    when your alarm thresholds are exceeded to which your auto scaling actions should
    apply.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`ScalingAdjustment`指示每次缩放时您将增加或减少ECS服务计数的数量，而`MetricIntervalLowerBound`和`MetricIntervalUpperBound`属性允许您在超出警报阈值时定义额外的边界，以便您的自动缩放操作应用。'
- en: The configuration shown in the preceding example is such that whenever the CPU
    utilization exceeds or falls below the configured CloudWatch alarm thresholds,
    the application auto scaling will always be invoked. This is because the unconfigured
    upper and lower bounds default to a value of infinity or negative infinity, respectively,
    so any metric value between the alarm threshold and infinity/negative infinity
    will trigger the alarm. To help further clarify the context of the metric interval
    bounds, if you instead configured a `MetricIntervalLowerBound` value of 10 and
    `MetricIntervalUpperBound` of 30, when the CloudWatch alarm threshold (currently
    configured as 40% CPU utilization) is exceeded, the auto scaling action would
    only apply between 50% utilization (threshold + `MetricIntervalLowerBound` or
    40 + 10 = 50) and 70% utilization (`threshold` + `MetricIntervalUpperBound` or
    40 + 30 = 70%).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的示例中显示的配置是，每当CPU利用率超过或低于配置的CloudWatch警报阈值时，应用程序自动缩放将始终被调用。这是因为未配置的上限和下限默认为无穷大或负无穷大，因此在警报阈值和无穷大/负无穷大之间的任何指标值都将触发警报。为了进一步澄清指标间隔边界的上下文，如果您改为配置`MetricIntervalLowerBound`值为10和`MetricIntervalUpperBound`为30，当超过CloudWatch警报阈值（当前配置为40%的CPU利用率）时，自动缩放操作将仅在50%利用率（阈值+`MetricIntervalLowerBound`或40+10=50）和70%利用率（`阈值`+`MetricIntervalUpperBound`或40+30=70%）之间应用。
- en: Deploying application Auto Scaling
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署应用程序自动缩放
- en: 'At this point, you are now ready to deploy your ECS application auto scaling
    solution. After running the `aws cloudformation deploy` command, if you browse
    to the ECS console, select the todobackend cluster and todobackend ECS service,
    on the Auto Scaling tab, you should see your new application auto scaling configuration
    in place:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，您现在已经准备部署您的ECS应用程序自动缩放解决方案。运行`aws cloudformation deploy`命令后，如果您浏览到ECS控制台，选择todobackend集群和todobackend
    ECS服务，在自动缩放选项卡上，您应该看到您的新应用程序自动缩放配置已经就位：
- en: '![](assets/b959b6fd-e570-4d8f-99d1-2d243f9b4f1d.png)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/b959b6fd-e570-4d8f-99d1-2d243f9b4f1d.png)'
- en: Now whenever your ECS service is experiencing greater than 40% CPU utilization
    (averaged across all ECS tasks), the desired count of your ECS service will be
    increased by one. This will continue for as long as the CPU utilization exceeds
    40%, up to a maximum of 4 tasks, and as per the configuration of the preceding
    example, a cool-down period of 360 seconds will apply between each auto scaling
    action.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当您的ECS服务的CPU利用率超过40%（在所有ECS任务中平均），您的ECS服务的期望计数将增加一个。只要CPU利用率超过40%，这将持续下去，最多增加到4个任务，根据前面示例的配置，每个自动扩展操作之间将应用360秒的冷却期。
- en: At an ECS service level, you don't need to worry about the underlying ECS cluster
    resources, as your ECS cluster capacity management solution ensures there is always
    spare capacity for additional ECS tasks in the cluster. This means you now have
    the freedom to scale each ECS service independently according to its specific
    performance characteristics, and underscores the importance of understanding the
    optimal-per-ECS-task resource allocations for each of your applications.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在ECS服务级别上，您无需担心底层ECS集群资源，因为您的ECS集群容量管理解决方案确保集群中始终有足够的空闲容量来容纳额外的ECS任务。这意味着您现在可以根据每个ECS服务的特定性能特征独立扩展每个ECS服务，并强调了了解每个应用程序的最佳ECS任务资源分配的重要性。
- en: Summary
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you created a comprehensive auto scaling solution that allows
    you to auto scale your ECS services and applications in response to application
    load and customer demand, and at the same time ensures your underlying ECS cluster
    has sufficient resources to deploy new ECS tasks as required.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您创建了一个全面的自动扩展解决方案，可以让您根据应用程序负载和客户需求自动扩展您的ECS服务和应用程序，同时确保底层ECS集群有足够的资源来部署新的ECS任务。
- en: You first learned about key ECS resources including CPU, memory, network ports
    and network interfaces, and how ECS allocates these resources. When managing the
    ECS cluster capacity, these resources determine whether or not an ECS container
    instance can run a given ECS task, so it is critical that you understand how each
    resource is consumed.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您了解了关键的ECS资源，包括CPU、内存、网络端口和网络接口，以及ECS如何分配这些资源。在管理ECS集群容量时，这些资源决定了ECS容器实例是否能够运行特定的ECS任务，因此您必须了解每种资源的消耗情况至关重要。
- en: You next implemented an ECS cluster-capacity management solution that calculates
    the ECS cluster capacity whenever an ECS container instance state change occurs.
    ECS publishes theses state changes via CloudWatch events, and you created a CloudWatch
    event rule that triggers a Lambda function that calculates the current cluster
    capacity. This function calculates two key metrics–container capacity, expressed
    as the number of additional containers or ECS tasks that the cluster can currently
    support, and idle host capacity, which defines how many "virtual" hosts are currently
    idle across the entire cluster. The container capacity is used to scale out your
    ECS clusters, adding additional ECS container instances whenever the container
    capacity falls below 1, meaning the cluster no longer has enough resources to
    deploy an additional ECS task. The idle host capacity is used to scale in your
    ECS clusters, removing ECS container instances whenever idle host capacity is
    greater than 1.0, meaning you can safely remove an ECS container instance and
    still have capacity to deploy new ECS tasks.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您实现了一个ECS集群容量管理解决方案，该解决方案在ECS容器实例状态发生变化时计算ECS集群容量。ECS通过CloudWatch事件发布这些状态更改，您创建了一个CloudWatch事件规则，触发一个Lambda函数来计算当前的集群容量。该函数计算了两个关键指标——容器容量，表示集群当前可以支持的额外容器或ECS任务的数量，以及空闲主机容量，定义了整个集群中当前有多少“虚拟”主机处于空闲状态。容器容量用于扩展您的ECS集群，在容器容量低于1时添加额外的ECS容器实例，这意味着集群不再具有足够的资源来部署额外的ECS任务。空闲主机容量用于缩小您的ECS集群，在空闲主机容量大于1.0时移除ECS容器实例，这意味着您可以安全地移除一个ECS容器实例，并仍然有能力部署新的ECS任务。
- en: A key concept we discussed was the requirement to always make these calculations
    for the worst-case scenario collectively across all of your resources, which ensures
    you will never scale in when you have plenty of spare capacity of one type of
    resource, but may have low capacity for another type of resource.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的一个关键概念是始终要为所有资源的最坏情况共同进行这些计算的要求，这确保了当您拥有某种类型资源的充足空闲容量时，您永远不会进行缩小，但可能对另一种类型资源的容量较低。
- en: Finally, you learned how to configure the AWS application auto scaling service
    to scale up and down your ECS services. Here you are scaling individual ECS services
    based on appropriate metrics specific to your applications, and because you are
    scaling in the context of a single ECS service, auto scaling at this level is
    simple to define and understand. Scaling your ECS services is ultimately what
    drives changes to your overall ECS cluster capacity, with the ECS cluster-capacity
    management solution you implemented taking care of this and allowing you to auto
    scale your ECS services without needing to worry about the impact to your underlying
    ECS cluster.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您学会了如何配置AWS应用程序自动扩展服务来扩展和缩小您的ECS服务。在这里，您根据应用程序特定的适当指标来扩展单个ECS服务，因为您是在单个ECS服务的上下文中进行扩展，所以在这个级别进行自动扩展是简单定义和理解的。扩展您的ECS服务最终是驱动您整体ECS集群容量变化的原因，而您实现的ECS集群容量管理解决方案负责处理这一点，使您能够自动扩展您的ECS服务，而无需担心对底层ECS集群的影响。
- en: In the next chapter, you will learn how to continuously deliver your ECS applications
    to AWS, incorporating all of the features we have discussed in the previous chapters.
    This will allow you to deploy your latest application changes in a fully automated
    fashion, reducing operational overheads and providing fast feedback to your development
    teams.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何将您的ECS应用程序持续交付到AWS，将我们在前几章中讨论过的所有功能都纳入其中。这将使您能够以完全自动化的方式部署最新的应用程序更改，减少运营开销，并为开发团队提供快速反馈。
- en: Questions
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'True/false: When you use ECS and deploy your own ECS container instances, ECS
    automatically scales your clusters up and down for you.'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 真/假：当您使用ECS并部署自己的ECS容器实例时，ECS会自动为您扩展集群。
- en: Which AWS service do you use to scale your ECS clusters?
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您使用哪个AWS服务来扩展您的ECS集群？
- en: Which AWS service do you use to scale your ECS services?
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您使用哪个AWS服务来扩展您的ECS服务？
- en: Your application requires a minimum of 300 MB and maximum of 1 GB of memory
    to run. What parameters would you configure on your ECS task definition to support
    this configuration?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的应用程序需要最少300MB，最多1GB的内存才能运行。您会在ECS任务定义中配置哪些参数来支持这个配置？
- en: You deploy 3 different ECS tasks that each run a different application to a
    single instance ECS cluster, and configure each ECS task to reserve 10 CPU units.
    During busy periods, one of the ECS tasks hogs CPU, slowing down the other ECS
    tasks. Assuming the ECS container instance has 1,000 CPU units' capacity, what
    could you do to avoid one ECS task hogging CPU?
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将3个不同的ECS任务部署到单个实例ECS集群中，每个任务运行不同的应用程序，并配置每个ECS任务保留10个CPU单位。在繁忙时期，其中一个ECS任务占用了CPU，减慢了其他ECS任务的速度。假设ECS容器实例的容量为1,000个CPU单位，您可以采取什么措施来避免一个ECS任务占用CPU？
- en: 'True/false: If you only use dynamic port mapping for your ECS tasks, you do
    not need to worry about network port resources.'
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 真/假：如果您只为ECS任务使用动态端口映射，您就不需要担心网络端口资源。
- en: You deploy an instance to AWS that supports four network interfaces in total.
    What is the capacity in terms of number of ECS tasks for the instance, assuming
    all ECS tasks use ECS task networking?
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您在AWS部署了一个支持总共四个网络接口的实例。假设所有ECS任务都使用ECS任务网络，那么实例的容量是多少？
- en: When should you disable auto scaling in an EC2 auto scaling group?How would
    you go about this?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在EC2自动缩放组中，何时应该禁用自动缩放？你会如何做？
- en: Your ECS cluster currently has 2 ECS container instances each with 500 CPU units
    and 500 MB of memory of spare capacity. You are only deploying a single type of
    application to your cluster, and you currently have two ECS tasks running. Assuming
    the ECS task requires 500 CPU units, 500 MB of memory, and has a static port mapping
    to TCP port 80, what is the current overall spare capacity of the cluster in terms
    of number of ECS tasks?
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的ECS集群目前有2个ECS容器实例，每个实例有500个CPU单位和500MB的内存剩余容量。您只向集群部署了一种应用程序，目前有两个ECS任务正在运行。假设ECS任务需要500个CPU单位、500MB的内存，并且静态端口映射到TCP端口80，那么集群当前的整体剩余容量是多少个ECS任务？
- en: Your ECS cluster needs to support 3 different ECS tasks that require 300, 400,
    and 500MB of memory, respectively. If each of your ECS container instances has
    2 GB of memory, what would you calculate as the maximum number of containers per
    ECS container instance in terms of memory when performing ECS cluster-capacity
    calculations?
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您的ECS集群需要支持3个不同的ECS任务，分别需要300MB、400MB和500MB的内存。如果您的每个ECS容器实例都有2GB的内存，那么在进行ECS集群容量计算时，您会将每个ECS容器实例的最大容器数量计算为多少？
- en: Further reading
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can check the following links for more information about the topics we
    covered in this chapter:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看以下链接，了解本章涵盖的主题的更多信息：
- en: ECS Service Auto Scaling: [https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ECS服务自动缩放：[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html)
- en: EC2 Auto Scaling User Guide: [https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EC2自动扩展用户指南：[https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html)
- en: EC2 Auto Scaling Policy Types: [https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html)
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: EC2自动扩展策略类型：[https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scaling-simple-step.html)
- en: Recommended Best Practices for Auto Scaling Group Rolling Updates: [https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/](https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展组滚动更新的推荐最佳实践：[https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/](https://aws.amazon.com/premiumsupport/knowledge-center/auto-scaling-group-rolling-updates/)
- en: Application Auto Scaling User Guide: [https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用自动扩展用户指南：[https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html](https://docs.aws.amazon.com/autoscaling/application/userguide/what-is-application-auto-scaling.html)
- en: Task Definion Parameters Reference (See `cpu`, `memory`, and `memoryReservation`
    parameters):[ https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务定义参数参考（请参阅`cpu`、`memory`和`memoryReservation`参数）：[https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definition_parameters.html#container_definitions)
- en: CloudFormation CloudWatch Events Rule Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation CloudWatch事件规则资源参考：[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-events-rule.html)
- en: CloudFormation CloudWatch AlarmResource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation CloudWatch警报资源参考：[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-cw-alarm.html)
- en: CloudFormation EC2 Auto Scaling Policy Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation EC2自动扩展策略资源参考：[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-as-policy.html)
- en: CloudFormation Application Auto Scaling Scalable Target Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation应用自动扩展可扩展目标资源参考：[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalabletarget.html)
- en: CloudFormation Application Auto Scaling Policy Resource Reference: [https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CloudFormation 应用程序自动扩展策略资源参考：[https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-applicationautoscaling-scalingpolicy.html)
