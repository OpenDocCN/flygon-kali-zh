- en: Debugging Issues Discovered Through Metrics and Alerts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过指标和警报发现的问题调试
- en: When you eliminate the impossible, whatever remains, however improbable, must
    be the truth.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 当你排除了不可能的，无论剩下什么，无论多么不可能，都必须是真相。
- en: '- *Spock*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '- *斯波克*'
- en: So far, we explored how to gather metrics and how to create alerts that will
    notify us when there is an issue. We also learned how to query metrics and dig
    for information we might need when trying to find the cause of a problem. We'll
    expand on that and try to debug a simulated issue.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探讨了如何收集指标以及如何创建警报，以便在出现问题时通知我们。我们还学会了如何查询指标并搜索我们在尝试找到问题原因时可能需要的信息。我们将在此基础上继续，并尝试调试一个模拟的问题。
- en: Saying that an application does not work correctly should not be enough by itself.
    We should be much more precise. Our goal is to be able to pinpoint not only which
    application is malfunctioning, but also which part of it is the culprit. We should
    be able to blame a specific function, a method, a request path, and so on. The
    more precise we are in detecting which part of an application is causing a problem,
    the faster we will find the cause of an issue. As a result, it should be easier
    and faster to fix the issue through a new release (a hotfix), scaling, or any
    other means at our disposal.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅说一个应用程序工作不正常是不够的。我们应该更加精确。我们的目标是不仅能够准确定位哪个应用程序出现故障，还能够确定是其中的哪个部分出了问题。我们应该能够指责特定的功能、方法、请求路径等等。我们在检测应用程序的哪个部分导致问题时越精确，我们就越快地找到问题的原因。因此，通过新版本的发布（热修复）、扩展或其他手段修复问题应该更容易更快。
- en: Let's get going. We'll need a cluster (unless you already have one) before we
    simulate a problem that needs to be solved.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。在模拟需要解决的问题之前，我们需要一个集群（除非您已经有一个）。
- en: Creating a cluster
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个集群
- en: The `vfarcic/k8s-specs` ([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))
    repository will continue being our source of Kubernetes definitions we'll use
    for our examples. We'll make sure that it is up-to-date by pulling the latest
    version.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '`vfarcic/k8s-specs` ([https://github.com/vfarcic/k8s-specs](https://github.com/vfarcic/k8s-specs))
    仓库将继续是我们用于示例的Kubernetes定义的来源。我们将确保通过拉取最新版本使其保持最新。'
- en: All the commands from this chapter are available in the `04-instrument.sh` ([https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16](https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16))
    Gist. Just as in the previous chapter, it contains not only the commands but also
    Prometheus' expressions. They are all commented (with `#`). If you're planning
    to copy and paste the expressions from the Gist, please exclude the comments.
    Each expression has `# Prometheus expression` comment on top to help you identify
    it.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的所有命令都可以在`04-instrument.sh` ([https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16](https://gist.github.com/vfarcic/851b37be06bb7652e55529fcb28d2c16))
    Gist 中找到。就像上一章一样，它不仅包含命令，还包括Prometheus的表达式。它们都被注释了（用`#`）。如果您打算从Gist中复制和粘贴表达式，请排除注释。每个表达式顶部都有`#
    Prometheus expression`的注释，以帮助您识别它。
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Given that we learned how to install a fully operational Prometheus and the
    rest of the tools from its chart, and that we'll continue using them, I moved
    it to the Gists. Those that follow are copies of those we used in the previous
    chapter, with the addition of environment variables `PROM_ADDR` and `AM_ADDR`,
    and the steps for the installation of the **Prometheus Chart**. Please create
    a cluster that meets (or exceeds) the requirements specified in the Gists that
    follow, unless you already have a cluster that satisfies them.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们已经学会了如何安装一个完全可操作的 Prometheus 和其图表中的其他工具，并且我们将继续使用它们，我将其移至 Gists。接下来的内容是我们在上一章中使用的内容的副本，还增加了环境变量
    `PROM_ADDR` 和 `AM_ADDR`，以及安装 **Prometheus Chart** 的步骤。请创建一个符合（或超出）下面 Gists 中指定要求的集群，除非您已经有一个满足这些要求的集群。
- en: '`gke-instrument.sh`: **GKE** with 3 n1-standard-1 worker nodes, **nginx Ingress**,
    **tiller**, **Prometheus** Chart, and environment variables **LB_IP**, **PROM_ADDR**,
    and **AM_ADDR** ([https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e](https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e)).'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gke-instrument.sh`：**GKE** 配置有 3 个 n1-standard-1 工作节点，**nginx Ingress**，**tiller**，**Prometheus**
    图表，以及环境变量 **LB_IP**，**PROM_ADDR** 和 **AM_ADDR** ([https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e](https://gist.github.com/675f4b3ee2c55ee718cf132e71e04c6e))。'
- en: '`eks-instrument.sh`: **EKS** with 3 t2.small worker nodes, **nginx Ingress**,
    **tiller**, **Metrics Server**, **Prometheus** Chart, and environment variables
    **LB_IP**, **PROM_ADDR**, and **AM_ADDR** ([https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545](https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545)).'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eks-instrument.sh`：**EKS** 配置有 3 个 t2.small 工作节点，**nginx Ingress**，**tiller**，**Metrics
    Server**，**Prometheus** 图表，以及环境变量 **LB_IP**，**PROM_ADDR** 和 **AM_ADDR** ([https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545](https://gist.github.com/70a14c8f15c7ffa533ea7feb75341545))。'
- en: '`aks-instrument.sh`: **AKS** with 3 Standard_B2s worker nodes, **nginx Ingress**,
    and **tiller**, **Prometheus** Chart, and environment variables **LB_IP**, **PROM_ADDR**,
    and **AM_ADDR** ([https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339](https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339)).'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`aks-instrument.sh`：**AKS** 配置有 3 个 Standard_B2s 工作节点，**nginx Ingress**，**tiller**，**Prometheus**
    图表，以及环境变量 **LB_IP**，**PROM_ADDR** 和 **AM_ADDR** ([https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339](https://gist.github.com/65a0d5834c9e20ebf1b99225fba0d339))。'
- en: '`docker-instrument.sh`: **Docker for Desktop** with **2 CPUs**, **3 GB RAM**,
    **nginx Ingress**, **tiller**, **Metrics Server**, **Prometheus** Chart, and environment
    variables **LB_IP**, **PROM_ADDR**, and **AM_ADDR** ([https://gist.github.com/1dddcae847e97219ab75f936d93451c2](https://gist.github.com/1dddcae847e97219ab75f936d93451c2)).'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker-instrument.sh`：**Docker for Desktop** 配置有 **2 个 CPU**，**3 GB RAM**，**nginx
    Ingress**，**tiller**，**Metrics Server**，**Prometheus** 图表，以及环境变量 **LB_IP**，**PROM_ADDR**
    和 **AM_ADDR** ([https://gist.github.com/1dddcae847e97219ab75f936d93451c2](https://gist.github.com/1dddcae847e97219ab75f936d93451c2))。'
- en: '`minikube-instrument.sh`: **minikube** with **2 CPUs**, **3 GB RAM**, **ingress,
    storage-provisioner**, **default-storageclass**, and **metrics-server** addons
    enabled, **tiller**, **Prometheus** Chart, and environment variables **LB_IP**,
    **PROM_ADDR**, and **AM_ADDR** ([https://gist.github.com/779fae2ae374cf91a5929070e47bddc8](https://gist.github.com/779fae2ae374cf91a5929070e47bddc8)).'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`minikube-instrument.sh`：**minikube** 配置有 **2 个 CPU**，**3 GB RAM**，启用了 **ingress,
    storage-provisioner**，**default-storageclass** 和 **metrics-server** 插件，**tiller**，**Prometheus**
    图表，以及环境变量 **LB_IP**，**PROM_ADDR** 和 **AM_ADDR** ([https://gist.github.com/779fae2ae374cf91a5929070e47bddc8](https://gist.github.com/779fae2ae374cf91a5929070e47bddc8))。'
- en: Now we're ready to face our first simulated issue that might require debugging.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经准备好面对可能需要调试的第一个模拟问题。
- en: Facing a disaster
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面对灾难
- en: Let's explore one disaster scenario. Frankly, it's not going to be a real disaster,
    but it will require us to find a solution to an issue.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索一个灾难场景。坦率地说，这不会是一个真正的灾难，但它将需要我们找到解决问题的方法。
- en: We'll start by installing the already familiar `go-demo-5` application.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从安装已经熟悉的`go-demo-5`应用程序开始。
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We declared `GD5_ADDR` with the address through which we'll be able to access
    the application. We used it as `ingress.host` variable when we installed the `go-demo-5`
    Chart. To be on the safe side, we waited until the app rolled out, and all that's
    left, from the deployment perspective, is to confirm that it is running by sending
    an HTTP request.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`GD5_ADDR`声明了地址，通过该地址我们将能够访问应用程序。我们在安装`go-demo-5`图表时将其用作`ingress.host`变量。为了安全起见，我们等到应用程序部署完成，从部署的角度来看，唯一剩下的就是通过发送HTTP请求来确认它正在运行。
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The output is the developer's favorite message `hello, world!`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是开发人员最喜欢的消息`hello, world!`。
- en: Next, we'll simulate an issue by sending twenty slow requests with up to ten
    seconds duration. That will be our simulation of a problem that might need to
    be fixed.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过发送二十个持续时间长达十秒的慢请求来模拟问题。这将是我们模拟可能需要修复的问题。
- en: '[PRE3]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Since we already have Prometheus' alerts, we should receive a notification on
    Slack stating that the application is too slow. However, many readers might be
    using the same channel for those exercises, and it might not be clear whether
    the message comes from us. Instead, we'll open Prometheus' alerts screen to confirm
    that there is a problem. In the "real" setting, you wouldn't be checking Prometheus
    alerts, but wait for notifications on Slack, or whichever other notifications
    tool you chose.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经有了Prometheus的警报，我们应该在Slack上收到通知，说明应用程序太慢了。然而，许多读者可能会在同一个频道进行这些练习，并且可能不清楚消息是来自我们。相反，我们将打开Prometheus的警报屏幕以确认存在问题。在“真实”环境中，您不会检查Prometheus警报，而是等待在Slack上收到通知，或者您选择的其他通知工具。
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: A few moments later (don't forget to refresh the screen), the `AppTooSlow` alert
    should fire, letting us know that one of our applications is slow and that we
    should do something to remedy the problem.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后（不要忘记刷新屏幕），`AppTooSlow`警报应该触发，让我们知道我们的一个应用程序运行缓慢，我们应该采取措施解决问题。
- en: True to the promise that each chapter will feature outputs and screenshots from
    a different Kubernetes flavor, this time it's minikube's turn.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 忠于每章将展示不同Kubernetes版本的输出和截图的承诺，这次轮到minikube了。
- en: '![](assets/fb08d36b-cba3-4acb-8385-f3836d1a1f1d.png)Figure 4-1: One of Prometheus''
    alerts in the firing state'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/fb08d36b-cba3-4acb-8385-f3836d1a1f1d.png)图4-1：Prometheus中一个警报处于触发状态'
- en: We'll imagine that we did not generate slow requests intentionally, so we'll
    try to find out what the issue is. Which application is too slow? What useful
    information can we pass to the team so that they can fix the problem as soon as
    possible?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设我们没有故意生成慢请求，所以我们将尝试找出问题所在。哪个应用程序太慢了？我们可以传递什么有用的信息给团队，以便他们尽快解决问题？
- en: The first logical debugging step is to execute the same expression as the one
    used by the alert. Please expand the `AppTooSlow` alert and click the link of
    the expression. You'll be redirected to the graph screen with the expression already
    pre-populated. Click the Execute button, and switch to the *Graph* tab.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个逻辑调试步骤是执行与警报使用的相同表达式。请展开`AppTooSlow`警报，并单击表达式的链接。您将被重定向到已经预填充的图形屏幕。单击“执行”按钮，切换到*图形*选项卡。
- en: We can see, from the graph, that there was a surge in the number of slow requests.
    The alert was fired because less than ninety-five percent of responses are within
    0.25 seconds bucket. Judging from my Graph (screenshot following), zero percent
    of responses were inside the 0.25 seconds bucket or, in other words, all were
    slower than that. A moment later, that improved slightly by jumping to only six
    percent of fast requests.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 从图表中我们可以看到，慢请求数量激增。警报被触发是因为不到95%的响应在0.25秒内完成。根据我的图表（随后的截图），零百分比的响应在0.25秒内完成，换句话说，所有响应都比那慢。片刻之后，情况略有改善，只有6%的请求很快。
- en: All in all, we have a situation in which too many requests are getting slow
    responses, and we should fix that. The main question is how to find out what the
    cause of that slowness is?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们面临着太多请求得到缓慢响应的情况，我们应该解决这个问题。主要问题是如何找出缓慢的原因是什么？
- en: '![](assets/8052c5cf-a627-4785-a91b-28e759a53a1c.png)Figure 4-2: The graph with
    the percentage of requests with fast responses'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-2：百分比请求快速响应的图表
- en: How about executing different expressions. We can, for example, output the rate
    of request durations for that `ingress` (application).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试执行不同的表达式。例如，我们可以输出该`ingress`（应用程序）的请求持续时间的速率。
- en: Please type the expression that follows, and press the Execute button.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入以下表达式，然后点击执行按钮。
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: That graph shows us the history of request durations, but it does not get us
    any closer to revealing the cause of the issue or, to be more precise, to the
    part of the application that is slow. We could try using other metrics, but they
    are, more or less, equally generic and are probably not going to get us anywhere.
    We need more detailed application-specific metrics. We need data that comes from
    inside the `go-demo-5` app.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该图表显示了请求持续时间的历史记录，但它并没有让我们更接近揭示问题的原因，或者更准确地说，是应用程序的哪一部分慢。我们可以尝试使用其他指标，但它们或多或少同样泛泛，并且可能不会让我们有所收获。我们需要更详细的特定于应用程序的指标。我们需要来自`go-demo-5`应用程序内部的数据。
- en: Using instrumentation to provide more detailed metrics
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用仪器提供更详细的指标
- en: We shouldn't just say that the `go-demo-5` application is slow. That would not
    provide enough information for us to quickly inspect the code in search of the
    exact cause of that slowness. We should be able to do better and deduce which
    part of the application is misbehaving. Can we pinpoint a specific path that produces
    slow responses? Are all methods equally slow, or the issue is limited only to
    one? Do we know which function produces slowness? There are many similar questions
    we should be able to answer in situations like that. But we can't, with the current
    metrics. They are too generic, and they can usually only tell us that a specific
    Kubernetes resource is misbehaving. The metrics we're collecting are too broad
    to answer application-specific questions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应该只是说`go-demo-5`应用程序很慢。这不会为我们提供足够的信息，让我们快速检查代码以找出缓慢的确切原因。我们应该能做得更好，并推断出应用程序的哪一部分表现不佳。我们能否找出产生缓慢响应的特定路径？所有方法都一样慢吗，还是问题只限于一个？我们知道哪个函数产生缓慢吗？在这种情况下，我们应该能够回答许多类似的问题。但是，根据当前的指标，我们无法做到。它们太泛泛，通常只能告诉我们特定的Kubernetes资源表现不佳。我们收集的指标太广泛，无法回答特定于应用程序的问题。
- en: The metrics we explored so far are a combination of exporters and instrumentations.
    Exporters are in charge of taking existing metrics and converting them into the
    Prometheus-friendly format. An example would be Node Exporter ([https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter))
    that is taking "standard" Linux metrics and converting them into Prometheus' time-series
    format. Another example is kube-state-metrics ([https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics))
    that listens to Kube API server and generates metrics with the state of the resources.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们探讨的指标是出口和仪器化的组合。出口负责获取现有的指标并将其转换为Prometheus友好格式。一个例子是Node Exporter（[https://github.com/prometheus/node_exporter](https://github.com/prometheus/node_exporter)），它获取“标准”Linux指标并将其转换为Prometheus的时间序列格式。另一个例子是kube-state-metrics（[https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)），它监听Kube
    API服务器并生成资源状态的指标。
- en: Instrumented metrics are baked into applications. They are an integral part
    of the code of our apps, and they are usually exposed through the `/metrics` endpoint.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器化指标已经内置到应用程序中。它们是我们应用程序代码的一个组成部分，通常通过`/metrics`端点公开。
- en: The easiest way to add metrics to your applications is through one of the Prometheus
    client libraries. At the time of this writing, Go ([https://github.com/prometheus/client_golang](https://github.com/prometheus/client_golang)),
    Java and Scala ([https://github.com/prometheus/client_java](https://github.com/prometheus/client_java)),
    Python ([https://github.com/prometheus/client_python](https://github.com/prometheus/client_python)),
    and Ruby ([https://github.com/prometheus/client_ruby](https://github.com/prometheus/client_ruby))
    libraries are officially provided.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 将指标添加到应用程序的最简单方法是通过Prometheus客户端库之一。在撰写本文时，Go（[https://github.com/prometheus/client_golang](https://github.com/prometheus/client_golang)）、Java和Scala（[https://github.com/prometheus/client_java](https://github.com/prometheus/client_java)）、Python（[https://github.com/prometheus/client_python](https://github.com/prometheus/client_python)）和Ruby（[https://github.com/prometheus/client_ruby](https://github.com/prometheus/client_ruby)）库是官方提供的。
- en: On top of those, the community supports Bash ([https://github.com/aecolley/client_bash](https://github.com/aecolley/client_bash)),
    C++ ([https://github.com/jupp0r/prometheus-cpp](https://github.com/jupp0r/prometheus-cpp)),
    Common Lisp ([https://github.com/deadtrickster/prometheus.cl](https://github.com/deadtrickster/prometheus.cl)),
    Elixir ([https://github.com/deadtrickster/prometheus.ex](https://github.com/deadtrickster/prometheus.ex)),
    Erlang ([https://github.com/deadtrickster/prometheus.erl](https://github.com/deadtrickster/prometheus.erl)),
    Haskell ([https://github.com/fimad/prometheus-haskell](https://github.com/fimad/prometheus-haskell)),
    Lua for Nginx ([https://github.com/knyar/nginx-lua-prometheus](https://github.com/knyar/nginx-lua-prometheus)),
    Lua for Tarantool ([https://github.com/tarantool/prometheus](https://github.com/tarantool/prometheus)),
    .NET / C# ([https://github.com/andrasm/prometheus-net](https://github.com/andrasm/prometheus-net)),
    Node.js ([https://github.com/siimon/prom-client](https://github.com/siimon/prom-client)),
    Perl ([https://metacpan.org/pod/Net::Prometheus](https://metacpan.org/pod/Net::Prometheus)),
    PHP ([https://github.com/Jimdo/prometheus_client_php](https://github.com/Jimdo/prometheus_client_php)),
    and Rust ([https://github.com/pingcap/rust-prometheus](https://github.com/pingcap/rust-prometheus)).
    Even if you code in a different language, you can easily provide Prometheus-friendly
    metrics by outputting results in a text-based exposition format ([https://prometheus.io/docs/instrumenting/exposition_formats/](https://prometheus.io/docs/instrumenting/exposition_formats/)).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，社区还支持Bash ([https://github.com/aecolley/client_bash](https://github.com/aecolley/client_bash))，C++
    ([https://github.com/jupp0r/prometheus-cpp](https://github.com/jupp0r/prometheus-cpp))，Common
    Lisp ([https://github.com/deadtrickster/prometheus.cl](https://github.com/deadtrickster/prometheus.cl))，Elixir
    ([https://github.com/deadtrickster/prometheus.ex](https://github.com/deadtrickster/prometheus.ex))，Erlang
    ([https://github.com/deadtrickster/prometheus.erl](https://github.com/deadtrickster/prometheus.erl))，Haskell
    ([https://github.com/fimad/prometheus-haskell](https://github.com/fimad/prometheus-haskell))，Lua
    for Nginx ([https://github.com/knyar/nginx-lua-prometheus](https://github.com/knyar/nginx-lua-prometheus))，Lua
    for Tarantool ([https://github.com/tarantool/prometheus](https://github.com/tarantool/prometheus))，.NET
    / C# ([https://github.com/andrasm/prometheus-net](https://github.com/andrasm/prometheus-net))，Node.js
    ([https://github.com/siimon/prom-client](https://github.com/siimon/prom-client))，Perl
    ([https://metacpan.org/pod/Net::Prometheus](https://metacpan.org/pod/Net::Prometheus))，PHP
    ([https://github.com/Jimdo/prometheus_client_php](https://github.com/Jimdo/prometheus_client_php))，和Rust
    ([https://github.com/pingcap/rust-prometheus](https://github.com/pingcap/rust-prometheus))。即使您使用不同的语言编写代码，也可以通过以文本为基础的输出格式（[https://prometheus.io/docs/instrumenting/exposition_formats/](https://prometheus.io/docs/instrumenting/exposition_formats/)）轻松提供符合Prometheus的指标。
- en: Overhead of collecting metrics should be negligible and, since Prometheus' pulls
    them periodically, outputting them should have a tiny footprint as well. Even
    if you choose not to use Prometheus, or to switch to something else, the format
    is becoming the standard, and your next metrics collector tool is likely to expect
    the same data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 收集指标的开销应该可以忽略不计，而且由于Prometheus定期获取它们，输出它们的开销也应该很小。即使您选择不使用Prometheus，或者切换到其他工具，该格式也正在成为标准，您的下一个指标收集工具很可能也会期望相同的数据。
- en: All in all, there is no excuse not to bake metrics into your applications, and,
    as you'll see soon, they provide invaluable information that we cannot obtain
    from outside.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，没有理由不将指标集成到您的应用程序中，正如您很快将看到的那样，它们提供了我们无法从外部获得的宝贵信息。
- en: Let's take a look at an example of the instrumented metrics in `go-demo-5`.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个`go-demo-5`中已经标记的指标的例子。
- en: '[PRE6]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The application is written in Go. Don't worry if that's not your language of
    choice. We'll just take a quick look at a few examples as a way to understand
    the logic behind instrumentation, not the exact implementation.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 该应用程序是用Go语言编写的。如果这不是您选择的语言，不要担心。我们只是快速看一下一些例子，以了解仪表化背后的逻辑，而不是确切的实现。
- en: The first interesting part is as follows.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个有趣的部分如下。
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We defined a variable that contains a Prometheus Histogram Vector with a few
    options. The `Sybsystem` and the `Name` form the base metric `http_server_resp_time`.
    Since it is a histogram, the final metrics will be created by adding `_bucket`,
    `_sum`, and `_count` suffixes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了一个包含一些选项的Prometheus直方图向量的变量。`Sybsystem`和`Name`形成了基本指标`http_server_resp_time`。由于它是一个直方图，最终的指标将通过添加`_bucket`、`_sum`和`_count`后缀来创建。
- en: Please consult *histogram* ([https://prometheus.io/docs/concepts/metric_types/#histogram](https://prometheus.io/docs/concepts/metric_types/#histogram))
    documentation for more info about that Prometheus' metric type.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考*histogram* ([https://prometheus.io/docs/concepts/metric_types/#histogram](https://prometheus.io/docs/concepts/metric_types/#histogram))
    文档，了解有关Prometheus指标类型的更多信息。
- en: The last part is a string array (`[]string`) that defines all the labels we'd
    like to add to the metric. In our case, those labels are `service`, `code`, `method`,
    and `path`. Labels can be anything we need, just as long as they provide the sufficient
    information we might require when querying those metrics.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一部分是一个字符串数组(`[]string`)，定义了我们想要添加到指标中的所有标签。在我们的情况下，这些标签是`service`、`code`、`method`和`path`。标签可以是我们需要的任何东西，只要它们提供了我们在查询这些指标时可能需要的足够信息。
- en: The next point of interest is the `recordMetrics` function.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 兴趣点是`recordMetrics`函数。
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: I created that as a helper function that can be called from different locations
    in the code. It accepts `start` time, the `Request`, and the return `code` as
    arguments. The function itself calculates `duration` by subtracting the current
    `time` with the `start` time. That `duration` is used in the `Observe` function
    and provides the value of the metric. There are also the labels that will help
    us fine-tune our expressions later on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我创建了一个辅助函数，可以从代码的不同位置调用。它接受`start`时间、`Request`和返回的`code`作为参数。函数本身通过将当前时间与`start`时间相减来计算`duration`。`duration`在`Observe`函数中使用，并提供指标的值。还有标签，将帮助我们在以后微调我们的表达式。
- en: Finally, we'll take a look at one of the examples where the `recordMetrics`
    is invoked.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将看一个示例，其中调用了`recordMetrics`函数。
- en: '[PRE9]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The `HelloServer` function is the one that returns the `hello, world!` response
    you already saw quite a few times. The details of that function are not important.
    In this context, the only part that matters is the line `defer func() { recordMetrics(start,
    req, http.StatusOK) }()`. In Go, `defer` allows us to execute something at the
    end of the function where it resides. In our case, that something is the invocation
    of the `recordMetrics` function that will record the duration of a request. In
    other words, before the execution leaves the `HelloServer` function, it'll record
    the duration by invoking the `recordMetrics` function.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '`HelloServer`函数是返回您已经看到多次的`hello, world!`响应的函数。该函数的细节并不重要。在这种情况下，唯一重要的部分是`defer
    func() { recordMetrics(start, req, http.StatusOK) }()`这一行。在Go中，`defer`允许我们在它所在的函数结束时执行某些操作。在我们的情况下，这个操作是调用`recordMetrics`函数，记录请求的持续时间。换句话说，在执行离开`HelloServer`函数之前，它将通过调用`recordMetrics`函数记录持续时间。'
- en: I won't go further into the code that contains instrumentation since that would
    assume that you are interested in intricacies behind Go and I'm trying to keep
    this book language-agnostic. I'll let you consult the documentation and examples
    from your favorite language. Instead, we'll take a look at the `go-demo-5` instrumented
    metrics in action.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会深入探讨包含仪表的代码，因为那将意味着您对Go背后的复杂性感兴趣，而我试图让这本书与语言无关。我会让您参考您喜欢的语言的文档和示例。相反，我们将看一下`go-demo-5`中的仪表指标的实际应用。
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We created a Pod based on the `appropriate/curl` image, and we sent a request
    through the Service using the address `go-demo-5.go-demo-5:8080/metrics`. The
    first `go-demo-5` is the name of the Service, and the second is the Namespace
    where it resides. As a result, we got output with all the instrumented metrics
    available in that application. We won't go through all of them, but only those
    created by the `http_server_resp_time` histogram.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个基于`appropriate/curl`镜像的Pod，并通过使用地址`go-demo-5.go-demo-5:8080/metrics`向服务发送了一个请求。第一个`go-demo-5`是服务的名称，第二个是它所在的命名空间。结果，我们得到了该应用程序中所有可用的受监控指标的输出。我们不会逐个讨论所有这些指标，而只会讨论由`http_server_resp_time`直方图创建的指标。
- en: The relevant parts of the output are as follows.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 输出的相关部分如下。
- en: '[PRE11]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We can see that the Go library we used in the application code created quite
    a few metrics from the `http_server_resp_time` histogram. We got one for each
    of the twelve buckets (`http_server_resp_time_bucket`), one with the sum of the
    durations (`http_server_resp_time_sum`), and one with the count (`http_server_resp_time_count`).
    We would have much more if we made requests that would have different labels.
    For now, those fourteen metrics are all coming from requests that responded with
    the HTTP code `200`, that used `GET` method, that were sent to the `/demo/hello`
    path, and that are coming from the `go-demo` service (application). If we'd create
    requests with different methods (for example, `POST`) or to different paths, the
    number of metrics would increase. Similarly, if we'd implement the same instrumented
    metric in other applications (but with different `service` labels), we'd have
    metrics with the same key (`http_server_resp_time`) that would provide insights
    into multiple apps. That raises the question of whether we should unify metric
    names across all the apps, or not.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在应用程序代码中使用的Go库从`http_server_resp_time`直方图中创建了相当多的指标。我们得到了每个十二个桶的指标（`http_server_resp_time_bucket`），一个持续时间的总和指标（`http_server_resp_time_sum`），以及一个计数指标（`http_server_resp_time_count`）。如果我们发出具有不同标签的请求，我们将得到更多指标。目前，这十四个指标都来自于响应HTTP代码`200`的请求，使用`GET`方法，发送到`/demo/hello`路径，并来自`go-demo`服务（应用程序）。如果我们创建具有不同方法（例如`POST`）或不同路径的请求，指标数量将增加。同样，如果我们在其他应用程序中实现相同的受监控指标（但具有不同的`service`标签），我们将拥有具有相同键（`http_server_resp_time`）的指标，这将提供有关多个应用程序的见解。这引发了一个问题，即我们是否应该统一所有应用程序中的指标名称，还是不统一。
- en: I prefer having instrumented metrics of the same type with the same name across
    all the applications. For example, all those that collect response times can be
    called `http_server_resp_time`. That simplifies querying data in Prometheus. Instead
    of learning about instrumented metrics from each individual application, learning
    those from one provides knowledge about all. On the other hand, I am in favor
    of giving each team full control over their applications. That includes the decisions
    which metrics to implement, and how to call them.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我更喜欢在所有应用程序中具有相同名称的相同类型的受监控指标。例如，所有收集响应时间的指标都可以称为`http_server_resp_time`。这简化了在Prometheus中查询数据。与其从每个单独的应用程序中了解受监控指标，不如从一个应用程序中了解所有应用程序的知识。另一方面，我赞成让每个团队完全控制他们的应用程序。这包括决定要实现哪些指标以及如何调用它们。
- en: All in all, it depends on the structure and responsibilities of the teams. If
    a team is entirely in charge of their applications and they debug problems specific
    to their apps, there is no inherent need for standardization of the names of instrumented
    metrics. On the other hand, if monitoring is centralized and the other teams might
    expect help from experts in that area, creating naming conventions is a must.
    Otherwise, we could easily end up with thousands of metrics with different names
    and types, even though most of them are providing the same information.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这取决于团队的结构和职责。如果一个团队完全负责他们的应用程序，并且调试特定于他们应用程序的问题，那么标准化已经被仪表化指标的名称是没有必要的。另一方面，如果监控是集中的，并且其他团队可能期望从该领域的专家那里获得帮助，那么创建命名约定是必不可少的。否则，我们可能会轻易地得到成千上万个具有不同名称和类型的指标，尽管它们大多提供相同的信息。
- en: For the rest of this chapter, I will assume that we did agree to have `http_server_resp_time`
    histogram in all applications, where that's applicable.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我将假设我们同意在所有适用的应用程序中都有`http_server_resp_time`直方图。
- en: Now, let's see how we can tell Prometheus that it should pull the metrics from
    the `go-demo-5` application. It would be even better if we could tell Prometheus
    to pull data from all the apps that have instrumented metrics. Actually, now when
    I think about it, we did not yet discuss how did Prometheus find Node Exporter
    and Kube State Metrics in the previous chapter. So, let's go briefly through the
    discovery process.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何告诉Prometheus它应该从`go-demo-5`应用程序中拉取指标。如果我们能告诉Prometheus从所有有仪表化指标的应用程序中拉取数据，那将更好。实际上，现在我想起来了，我们在上一章中还没有讨论Prometheus是如何发现Node
    Exporter和Kube State Metrics的。所以，让我们简要地通过发现过程。
- en: A good starting point is the Prometheus' targets screen.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的起点是Prometheus的目标屏幕。
- en: '[PRE12]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The most interesting group of targets is the `kubernetes-service-endpoints`.
    If we take a closer look at the labels, we'll see that each has `kubernetes_name`
    and that three of the targets have it set to `go-demo-5`. Prometheus somehow found
    that we have three replicas of the application and that metrics are available
    through the port `8080`. If we look further, we'll notice that `prometheus-node-exporter`
    is there as well, one for each node in the cluster.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 最有趣的目标组是`kubernetes-service-endpoints`。如果我们仔细看标签，我们会发现每个标签都有`kubernetes_name`，其中三个目标将其设置为`go-demo-5`。Prometheus不知何故发现我们有该应用程序的三个副本，并且指标可以通过端口`8080`获得。如果我们进一步观察，我们会注意到`prometheus-node-exporter`也在其中，每个节点在集群中都有一个。
- en: The same goes for `prometheus-kube-state-metrics`. There might be others in
    that group.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`prometheus-kube-state-metrics`也是一样的。在该组中可能还有其他应用程序。
- en: '![](assets/a36dd797-57ba-4cf7-bc6c-8da9161fd59c.png)Figure 4-3: kubernetes-service-endpoints
    Prometheus'' targets'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/a36dd797-57ba-4cf7-bc6c-8da9161fd59c.png)图4-3：kubernetes-service-endpoints
    Prometheus的目标'
- en: Prometheus discovered all the targets through Kubernetes Services. It extracted
    the port from each of the Services, and it assumed that data is available through
    the `/metrics` endpoint. As a result, every application we have in the cluster,
    that is accessible through a Kubernetes Service, was automatically added to the
    `kubernetes-service-endpoints` group of Prometheus' targets. There was no need
    for us to fiddle with Prometheus' configuration to add `go-demo-5` to the mix.
    It was just discovered. Pretty neat, isn't it?
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus通过Kubernetes服务发现了所有目标。它从每个服务中提取了端口，并假定数据可以通过`/metrics`端点获得。因此，我们在集群中拥有的每个应用程序，只要可以通过Kubernetes服务访问，就会自动添加到Prometheus的目标`kubernetes-service-endpoints`组中。我们无需摆弄Prometheus的配置来将`go-demo-5`添加到其中。它只是被发现了。相当不错，不是吗？
- en: In some cases, some of the metrics will not be accessible, and that target will
    be marked as red. As an example, `kube-dns` in minikube is not reachable from
    Prometheus. That's common, and it's not a reason to be alarmed, just as long as
    that's not one of the metric sources we do need.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，一些指标将无法访问，并且该目标将标记为红色。例如，在minikube中的`kube-dns`无法从Prometheus访问。这很常见，只要这不是我们确实需要的指标来源之一，就不必惊慌。
- en: Next, we'll take a quick look at a few expressions we can write using the instrumented
    metrics coming from `go-demo-5`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将快速查看一下我们可以使用来自`go-demo-5`的仪表化指标编写的一些表达式。
- en: '[PRE13]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Please type the expression that follows, press the Execute button, and switch
    to the *Graph* tab.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入接下来的表达式，按“执行”按钮，然后切换到*图表*选项卡。
- en: '[PRE14]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: We can see three lines that correspond to three replicas of `go-demo-5`. That
    should not come as a surprise since each of those is pulled from instrumented
    metrics coming from each of the replicas of the application. Since those metrics
    are counters that can only increase, the lines of the graph are continuously going
    up.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到三条线对应于`go-demo-5`的三个副本。这应该不会让人感到惊讶，因为每个副本都是从应用程序的每个副本的仪表化指标中提取的。由于这些指标是只能增加的计数器，图表的线条不断上升。
- en: '![](assets/17add48b-f7c5-4e29-90e6-43dcf3919682.png)Figure 4-4: The graph with
    the http_server_resp_time_count counter'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/17add48b-f7c5-4e29-90e6-43dcf3919682.png)图4-4：http_server_resp_time_count计数器的图表'
- en: That wasn't very useful. If we were interested in the rate of the count of requests,
    we'd envelop the previous expression inside the `rate()` function. We'll do that
    later. For now, we'll write the simplest expression that will give us the average
    response time per request.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是很有用。如果我们对请求计数的速率感兴趣，我们会将先前的表达式包含在`rate()`函数中。我们以后会这样做。现在，我们将编写最简单的表达式，以便得到每个请求的平均响应时间。
- en: Please type the expression that follows, and press the Execute button.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入接下来的表达式，然后按“执行”按钮。
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The expression itself should be easy to understand. We are taking the sum of
    all the requests and dividing it with the count. Since we already discovered that
    the problem is somewhere inside the `go-demo-5` app, we used the `kubernetes_name`
    label to limit the results. Even though that is the only application with that
    metric currently running in our cluster, it is a good idea to get used to the
    fact that there might be others at some later date when we extend instrumentation
    to other applications.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 表达式本身应该很容易理解。我们将所有请求的总和除以计数。由于我们已经发现问题出现在`go-demo-5`应用程序中，我们使用`kubernetes_name`标签来限制结果。尽管这是我们集群中当前唯一运行该指标的应用程序，但习惯于这样做是个好主意，因为在将来我们将扩展到其他应用程序时，可能会有其他应用程序。
- en: We can see that the average request duration increased for a while, only to
    drop close to the initial values a while later. That spike coincides with the
    twenty slow requests we sent a while ago. In my case (screenshot following), the
    peak is close to the average response time of 0.1 seconds, only to drop to around
    0.02 seconds a while later.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，平均请求持续时间在一段时间内增加，只是在稍后又接近初始值。这个峰值与我们之前发送的二十个慢请求相吻合。在我的情况下（以下是屏幕截图），峰值接近平均响应时间的0.1秒，然后在稍后降至大约0.02秒。
- en: '![](assets/e4efb795-db45-4d39-87be-b5982c518722.png)Figure 4-5: The graph with
    the cumulative average response time'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/e4efb795-db45-4d39-87be-b5982c518722.png)图4-5：累积平均响应时间的图表'
- en: Please note that the expression we just executed is deeply flawed. It shows
    the cumulative average response time, instead of displaying the `rate`. But, you
    already knew that. That was only a taste of the instrumented metric, not its "real"
    usage (that comes soon).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们刚刚执行的表达式存在严重缺陷。它显示的是累积平均响应时间，而不是显示`rate`。但是，你已经知道了。那只是对仪表度量的一个预演，而不是它的“真正”用法（很快就会出现）。
- en: You might notice that even the spike is very low. It is certainly lower than
    what we'd expect from sending only twenty slow requests through `curl`. The reason
    for that lies in the fact that we were not the only ones making those requests.
    The `readinessProbe` and the `livenessProbe` are sending requests as well, and
    they are very fast. Unlike in the previous chapter when we were measuring only
    the requests coming through Ingress, this time we're capturing all the requests
    that enter the application, and that includes health-checks.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到，即使是峰值也非常低。它肯定比我们只通过`curl`发送二十个慢请求所期望的要低。原因在于我们不是唯一一个发出这些请求的人。`readinessProbe`和`livenessProbe`也在发送请求，并且非常快。与上一章不同的是，我们只测量通过Ingress进入的请求，这一次我们捕获了进入应用程序的所有请求，包括健康检查。
- en: Now that we saw a few examples of the `http_server_resp_time` metric that is
    generated inside our `go-demo-5` application, we can use that knowledge to try
    to debug the simulated issue that led us towards instrumentation.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了在我们的`go-demo-5`应用程序内部生成的`http_server_resp_time`度量标准的一些示例，我们可以利用这些知识来尝试调试导致我们走向仪表化的模拟问题。
- en: Using internal metrics to debug potential issues
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用内部度量标准来调试潜在问题
- en: We'll re-send requests with slow responses again so that we get to the same
    point where we started this chapter.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将重新发送慢响应的请求，以便我们回到开始本章的同一点。
- en: '[PRE16]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We sent twenty requests that will result in responses with random duration (up
    to ten seconds). Further on, we opened Prometheus' alerts screen.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发送了二十个请求，这些请求将产生随机持续时间的响应（最长十秒）。随后，我们打开了Prometheus的警报屏幕。
- en: A while later, the `AppTooSlow` alert should fire (remember to refresh your
    screen), and we have a (simulated) problem that needs to be solved. Before we
    start panicking and do something hasty, we'll try to find the cause of the issue.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 一段时间后，`AppTooSlow`警报应该会触发（记得刷新你的屏幕），我们有一个（模拟的）需要解决的问题。在我们开始惊慌和匆忙行事之前，我们将尝试找出问题的原因。
- en: Please click the expression of the `AppTooSlow` alert.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请点击`AppTooSlow`警报的表达式。
- en: We are redirected to the graph screen with the pre-populated expression from
    the alert. Feel free to click the Expression button, even though it will not provide
    any additional info, apart from the fact that the application was fast, and then
    it slowed down for some inexplicable reason.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们被重定向到具有警报预填表达式的图形屏幕。请随意点击表达式按钮，即使它不会提供任何额外的信息，除了应用程序一开始很快，然后因某种莫名其妙的原因变慢。
- en: You will not be able to gather more details from that expression. You will not
    know whether it's slow on all methods, whether only a specific path responds slow,
    nor much of any other application-specific details. Simply put, the `nginx_ingress_controller_request_duration_seconds`
    metric is too generic. It served us well as a way to notify us that the application's
    response time increased, but it does not provide enough information about the
    cause of the issue. For that, we'll switch to the `http_server_resp_time` metric
    Prometheus is retrieving directly from `go-demo-5` replicas.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 您将无法从该表达式中收集更多详细信息。您将不知道所有方法是否都很慢，是否只有特定路径响应缓慢，也不会知道任何其他特定于应用程序的细节。简而言之，`nginx_ingress_controller_request_duration_seconds`度量标准太泛化了。它作为通知我们应用程序响应时间增加的一种方式服务得很好，但它并不提供足够关于问题原因的信息。为此，我们将切换到Prometheus直接从`go-demo-5`副本中检索的`http_server_resp_time`度量标准。
- en: Please type the expression that follows, and press the Execute button.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入以下表达式，然后按“执行”按钮。
- en: '[PRE17]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Switch to the *Graph* tab, if you're not there already.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有切换到*图表*选项卡，请切换到那里。
- en: That expression is very similar to the queries we wrote before when we were
    using the `nginx_ingress_controller_request_duration_seconds_sum` metric. We are
    dividing the rate of requests in the 0.1 seconds bucket with the rate of all the
    requests.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 该表达式与我们以前使用`nginx_ingress_controller_request_duration_seconds_sum`指标时编写的查询非常相似。我们正在将0.1秒桶中的请求速率与所有请求的速率进行比较。
- en: In my case (screenshot following), we can see that the percentage of fast responses
    dropped twice. That coincides with the simulated slow requests we sent earlier.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的案例中（随后的屏幕截图），我们可以看到快速响应的百分比下降了两次。这与我们之前发送的模拟慢请求相吻合。
- en: '![](assets/ab8b8a7e-6ecd-45ec-a77a-3dd0ffd7cfdd.png)Figure 4-6: The graph with
    the percentage of fast requests measured with instrumented metrics'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/ab8b8a7e-6ecd-45ec-a77a-3dd0ffd7cfdd.png)图4-6：使用仪器化指标测量的快速请求百分比的图表'
- en: So far, using the instrumented metric `http_server_resp_time_count` did not
    provide any tangible benefit when compared with `nginx_ingress_controller_request_duration_seconds_sum`.
    If that would be all, we could conclude that the effort to add instrumentation
    was a waste. However, we did not yet include labels into our expressions.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，使用仪器化指标`http_server_resp_time_count`与`nginx_ingress_controller_request_duration_seconds_sum`相比，并没有提供任何实质性的好处。如果仅此而已，我们可以得出结论，添加仪器化是一种浪费。然而，我们还没有将标签包含在我们的表达式中。
- en: Let's say that we'd like to group requests by the `method` and the `path`. That
    could give us a better idea whether slowness is global, or limited only to a specific
    type of requests. If it's latter, we'll know where the problem is and, hopefully,
    would be able to find the culprit quickly.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想按`method`和`path`对请求进行分组。这可能会让我们更好地了解慢速是全局性的，还是仅限于特定类型的请求。如果是后者，我们将知道问题出在哪里，并希望能够快速找到罪魁祸首。
- en: Please type the expression that follows, and press the Execute button.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入以下表达式，然后按“执行”按钮。
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: That expression is almost the same as the one before. The only difference is
    the addition of the `by (method, path)` statements. As a result, we are getting
    a percentage of fast responses, grouped by the `method` and the `path`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 该表达式几乎与之前的表达式相同。唯一的区别是添加了`by (method, path)`语句。因此，我们得到了按`method`和`path`分组的快速响应百分比。
- en: The output does not represent a "real" world use case. Usually, we'd see many
    different lines, one for each method and path that was requested. But, since we
    only made requests to `/demo/hello` using HTTP GET, our graph is a bit boring.
    You'll have to imagine that there are many other lines.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 输出并不代表“真实”的使用情况。通常，我们会看到许多不同的线条，每条线代表被请求的每种方法和路径。但是，由于我们只对`/demo/hello`使用HTTP
    GET进行了请求，我们的图表有点无聊。你得想象还有许多其他线条。
- en: By studying the graph, we discover that all but one line (we're still imagining
    many) are close to hundred percent of fast responses. The one with the sharp drop
    would be the one with the `/demo/hello` path and the `GET` method. However, if
    that would indeed be a real-world scenario, we would probably have too many lines
    in the graph, and we might not be able to distinguish them easily. Our expression
    could benefit with an addition of a threshold.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 通过研究图表，我们发现除了一条线（我们仍在想象许多条线）之外，其他所有线都接近于百分之百的快速响应。那条急剧下降的线应该是具有`/demo/hello`路径和`GET`方法的那条线。然而，如果这确实是一个真实的情景，我们的图表可能会有太多线条，我们可能无法轻松地加以区分。我们的表达式可能会受益于添加一个阈值。
- en: Please type the expression that follows, and press the Execute button.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 请键入以下表达式，然后按“执行”按钮。
- en: '[PRE19]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The only addition is the `< 0.99` threshold. As a result, our graph excludes
    all the results (all paths and methods) but those that are below 99 percent (0.99).
    We removed all the noise and focused only on the cases when more than one percent
    of all requests are slow (or less than 99 percent are fast). The result is now
    clear. The problem is in the function that handles `GET` requests on the path
    `/demo/hello`. We know that through the labels available below the graph.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的添加是 `<0.99` 的阈值。因此，我们的图表排除了所有结果（所有路径和方法），只留下低于百分之九十九（0.99）的结果。我们去除了所有噪音，只关注超过百分之一的所有请求缓慢的情况（或者少于百分之九十九的请求快速）。结果现在很明确。问题出在处理
    `/demo/hello` 路径上的 `GET` 请求的函数中。我们通过图表下方提供的标签知道了这一点。
- en: '![](assets/f862b0b0-9ab7-4d89-93f9-4349c9692d69.png)Figure 4-7: The graph with
    the percentage of fast requests measured with instrumented metrics limited to
    results below ninety-nine percent'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图4-7：使用仪器测量的快速请求百分比的图表，限制在百分之九十九以下的结果。
- en: Now that we know (almost) the exact location of the problem, all that's left
    is to fix the issue, push the change to our Git repository, and wait until our
    continuous deployment process upgrades the software with the new release.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们几乎知道问题的确切位置，剩下的就是修复问题，将更改推送到我们的Git存储库，并等待我们的持续部署流程升级软件以使用新版本。
- en: In a relatively short period, we managed to find (debug) the issue or, to be
    more precise, to narrow it to a specific part of the code.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在相对较短的时间内，我们设法找到（调试）了问题，或者更准确地说，将问题缩小到代码的特定部分。
- en: Or, maybe we discovered that the problem is not in the code, but that our application
    needs to scale up. In either case, without instrumented metrics, we would only
    know that the application is slow and that could mean that any part of the app
    is misbehaving. Instrumentation gave us more detailed metrics that we used to
    be more precise and reduce the time we'd typically require to find the issue and
    act accordingly.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，也许我们发现问题不在代码中，而是我们的应用程序需要扩展。无论哪种情况，没有仪器测量的指标，我们只会知道应用程序运行缓慢，这可能意味着应用程序的任何部分都在表现不佳。仪器测量为我们提供了更详细的指标，我们用这些指标更准确地缩小范围，并减少我们通常需要找到问题并相应采取行动的时间。
- en: Usually, we'd have many other instrumented metrics, and our "debugging" process
    would be more complicated. We'd execute other expressions and dig through different
    metrics. Nevertheless, the point is that we should combine generic metrics with
    more detailed ones coming directly from our applications. Those in the former
    group are often used to detect that there is an issue, while the latter type is
    useful when looking for the cause of the problem. Both types of metrics have their
    place in monitoring, alerting, and debugging our clusters and applications. With
    instrumented metrics, we have more application-specific details. That allows us
    to narrow down the locations and causes of a problem. The more confident we are
    about the exact cause of an issue, the better we are equipped to react.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会有许多其他仪器测量指标，我们的“调试”过程会更加复杂。我们会执行其他表达式并查看不同的指标。然而，关键是我们应该将通用指标与直接来自我们应用程序的更详细的指标相结合。前一组通常用于检测是否存在问题，而后一种类型在寻找问题的原因时非常有用。这两种类型的指标在监控、警报和调试我们的集群和应用程序时都有其作用。有了仪器测量指标，我们可以获得更多特定于应用程序的细节。这使我们能够缩小问题的位置和原因。我们对问题的确切原因越有信心，我们就越能够做出反应。
- en: What now?
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在呢？
- en: I don't believe that we need many other examples of instrumented metrics. They
    are not any different than those we are collecting through exporters. I'll leave
    it up to you to start instrumenting your applications. Start small, see what works
    well, improve and extend.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我不认为我们需要很多其他的仪表化指标示例。它们与我们通过导出器收集的指标没有任何不同。我会让你开始为你的应用程序进行仪表化。从小处开始，看看哪些效果好，改进和扩展。
- en: Yet another chapter is finished. Destroy your cluster and start the next one
    fresh, or keep it. If you choose the latter, please execute the commands that
    follow to remove the `go-demo-5` application.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 又一个章节完成了。销毁你的集群，开始下一个新的，或者保留它。如果你选择后者，请执行接下来的命令来移除`go-demo-5`应用程序。
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Before you leave, remember the point that follows. It summarizes instrumentation.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在你离开之前，记住接下来的要点。它总结了仪表化。
- en: Instrumented metrics are baked into applications. They are an integral part
    of the code of our apps, and they are usually exposed through the `/metrics` endpoint.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仪表化指标被嵌入到应用程序中。它们是我们应用程序代码的一个组成部分，通常通过`/metrics`端点公开。
