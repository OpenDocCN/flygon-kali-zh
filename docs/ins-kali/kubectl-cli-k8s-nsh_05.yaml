- en: '*Chapter 3*: Working with Nodes'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第3章*：使用节点'
- en: Everyone familiar with Kubernetes knows that the cluster workload runs in nodes,
    where all Kubernetes pods get scheduled, deployed, redeployed, and destroyed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 熟悉Kubernetes的人都知道，集群工作负载在节点上运行，所有Kubernetes pod都会被调度、部署、重新部署和销毁。
- en: Kubernetes runs the workload by placing containers into pods and then schedules
    them to run on nodes. A node might be a virtual or physical machine, depending
    on the cluster setup. Each node has the services necessary to run pods, managed
    by the Kubernetes control plane.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes通过将容器放入pod中并将其调度到节点上来运行工作负载。节点可能是虚拟的或物理的机器，这取决于集群的设置。每个节点都有运行pod所需的服务，由Kubernetes控制平面管理。
- en: 'The main components of the node are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 节点的主要组件如下：
- en: '**kubelet**: An agent that registers/deregisters the node with the Kubernetes
    API.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kubelet**：注册/注销节点到Kubernetes API的代理。'
- en: '**Container runtime**: This runs containers.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器运行时**：这个运行容器。'
- en: '**kube-proxy**: Network proxy.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**kube-proxy**：网络代理。'
- en: 'If the Kubernetes cluster supports nodes autoscaling, then nodes can come and
    go as specified by the autoscaling rules: by setting min and max node counts.
    If there is not much load running in the cluster, unnecessary nodes will be removed
    down to the minimum nodes set by the autoscaling rules. And when the load increases,
    the required amount of nodes will be deployed to accommodate the newly scheduled
    pods.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Kubernetes集群支持节点自动扩展，那么节点可以按照自动扩展规则的指定而来去：通过设置最小和最大节点数。如果集群中运行的负载不多，不必要的节点将被移除到自动扩展规则设置的最小节点数。当负载增加时，将部署所需数量的节点以容纳新调度的pod。
- en: There are times when you need to troubleshoot, get information about the nodes
    in the cluster, find out which pods they are running, see how much CPU and memory
    they are consuming, and so on.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 有时候您需要排除故障，获取有关集群中节点的信息，找出它们正在运行哪些pod，查看它们消耗了多少CPU和内存等。
- en: There are always going to be cases when you need to stop scheduling pods on
    some nodes, or rescheduling pods to different nodes, or temporally disabling the
    scheduling of any pods to some nodes, removing nodes, or any other reasons.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 总会有一些情况，您需要停止在某些节点上调度pod，或将pod重新调度到不同的节点，或暂时禁用对某些节点的任何pod的调度，移除节点，或其他任何原因。
- en: 'In this chapter, we''re going to cover the following main topics:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要主题：
- en: Getting a list of nodes
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取节点列表
- en: Describing nodes
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述节点
- en: Displaying node resource usage
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显示节点资源使用情况
- en: Cordoning nodes
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封锁节点
- en: Draining nodes
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 排水节点
- en: Removing nodes
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除节点
- en: Introduction to node pools
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点池简介
- en: Getting a list of nodes
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取节点列表
- en: 'To start working with nodes, you need to get a list of them first. To get the
    nodes list, run the following command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用节点，您首先需要获取它们的列表。要获取节点列表，请运行以下命令：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We get the following list of nodes using the preceding command:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述命令，我们得到以下节点列表：
- en: '![Figure 3.1 – Nodes list'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.1 – 节点列表'
- en: '](image/B16411_03_001.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_001.jpg)'
- en: Figure 3.1 – Nodes list
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – 节点列表
- en: The preceding list shows we have three nodes in our Kubernetes cluster with
    a `Ready` status and Kubernetes version `1.17.5-gke.9`. However, if you have cloud-supported
    node pools with autoscaling, your nodes list could be different because nodes
    will be added/removed depending on the number of applications running in your
    cluster.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的列表显示我们的Kubernetes集群中有三个节点，状态为`Ready`，Kubernetes版本为`1.17.5-gke.9`。然而，如果您有自动扩展的云支持节点池，您的节点列表可能会有所不同，因为节点将根据集群中运行的应用程序数量而添加/删除。
- en: Describing nodes
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 描述节点
- en: The `kubectl describe` command allows us to get the state, metadata, and events
    of an object in a Kubernetes cluster. In this section, we will use it to describe
    the node.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl describe` 命令允许我们获取 Kubernetes 集群中对象的状态、元数据和事件。在本节中，我们将使用它来描述节点。'
- en: 'We have got a list of nodes, so let''s check out one of them:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得到了一个节点列表，所以让我们来看看其中的一个：
- en: 'To describe a node, run the following command:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要描述一个节点，请运行以下命令：
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: As the command's output is quite big, we are going to show only some parts of
    it. You can check out the full output yourself.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于命令的输出相当庞大，我们将只显示其中的一部分。您可以自行查看完整的输出。
- en: 'In the following screenshot, we see the assigned `Labels` (which can be used
    to organize and select subsets of objects) and `Annotations` (extra information
    about the node is stored there) for the node, and `Unschedulable: false` means
    that the node accepts pods to be scheduled on to it. For example, `Labels` can
    be used for `Node Affinity` (which allows us to constrain which nodes the pod
    is eligible to be scheduled on, based on the labels on the node) to schedule pods
    on particular nodes:![Figure 3.2 – Node describe – check labels and annotations'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '在以下截图中，我们看到了为节点分配的 `标签`（可用于组织和选择对象的子集）和 `注释`（有关节点的额外信息存储在其中），以及 `Unschedulable:
    false` 表示节点接受将 pod 调度到其上。例如，`标签` 可用于 `节点亲和性`（允许我们根据节点上的标签来限制 pod 可以被调度到哪些节点上）来调度特定节点上的
    pod：![图 3.2 – 节点描述 – 检查标签和注释'
- en: '](image/B16411_03_002.jpg)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_002.jpg)'
- en: Figure 3.2 – Node describe – check labels and annotations
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 节点描述 – 检查标签和注释
- en: In the following screenshot, we see the assigned internal and external IPs,
    the internal DNS name, and the hostname:![Figure 3.3 – Node describe – assigned
    internal and external IPs
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下截图中，我们看到了分配的内部和外部 IP、内部 DNS 名称和主机名：![图 3.3 – 节点描述 – 分配的内部和外部 IP
- en: '](image/B16411_03_003.jpg)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_003.jpg)'
- en: Figure 3.3 – Node describe – assigned internal and external IPs
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3 – 节点描述 – 分配的内部和外部 IP
- en: The following screenshot shows the running pods on the node with CPU/memory
    requests and limits per pod:![Figure 3.4 – Node describe – CPU/memory requests
    and limits per pod
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了节点上运行的 pod，以及每个 pod 的 CPU/内存请求和限制：![图 3.4 – 节点描述 – 每个 pod 的 CPU/内存请求和限制
- en: '](image/B16411_03_004.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_004.jpg)'
- en: Figure 3.4 – Node describe – CPU/memory requests and limits per pod
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.4 – 节点描述 – 每个 pod 的 CPU/内存请求和限制
- en: 'The following screenshot shows the allocated resources for the node:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了为节点分配的资源：
- en: '![Figure 3.5 – Node describe – allocated resources for the node'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.5 – 节点描述 – 为节点分配的资源'
- en: '](image/B16411_03_005.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_005.jpg)'
- en: Figure 3.5 – Node describe – allocated resources for the node
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.5 – 节点描述 – 为节点分配的资源
- en: As you can see, the `$ kubectl describe node` command allows you to get various
    information about the node.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，`$ kubectl describe node` 命令允许您获取有关节点的各种信息。
- en: Displaying node resource usage
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 显示节点资源使用情况
- en: 'It is handy to know what resources are consumed by nodes. To display the resources
    used by nodes, run the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 了解节点消耗了哪些资源是很方便的。要显示节点使用的资源，请运行以下命令：
- en: '[PRE2]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We get the following list of nodes using the preceding command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上述命令得到了以下节点列表：
- en: '![Figure 3.6 – Top nodes list with resources used'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 3.6 – 使用的资源最多的节点列表'
- en: '](image/B16411_03_006.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_006.jpg)'
- en: Figure 3.6 – Top nodes list with resources used
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.6 – 使用的资源最多的节点列表
- en: The previous command shows node metrics such as CPU cores, memory (in bytes),
    and CPU and memory percentage usage.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 上一个命令显示节点指标，如 CPU 核心、内存（以字节为单位）以及 CPU 和内存使用百分比。
- en: Also, by using `$ watch kubectl top nodes`, you can watch and monitor nodes
    in real time when, for example, load testing your application or doing other node
    operations.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过使用`$ watch kubectl top nodes`，您可以在实时监控节点，例如，在对应用进行负载测试或进行其他节点操作时。
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `watch` command might not be present in your computer, you might need to
    install it. The `watch` command will run the specified command and refresh the
    screen every few seconds.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`watch`命令可能不在您的计算机上，您可能需要安装它。`watch`命令将运行指定的命令，并每隔几秒刷新屏幕。'
- en: Cordoning nodes
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点隔离
- en: Let's suppose we are going to run an app's load test and we want to keep a node
    away from the load test. In the node list that we saw in the *Getting a list of
    nodes* section, we have three nodes, and they are all in the `Ready` state. Let's
    pick one node, `gke-kubectl-lab-default-pool-b3c7050d-8jhj`, which we do not want
    new pods to be scheduled on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们要运行一个应用的负载测试，并且希望将一个节点从负载测试中排除。在*获取节点列表*部分看到的节点列表中，我们有三个节点，它们都处于`Ready`状态。让我们选择一个节点，`gke-kubectl-lab-default-pool-b3c7050d-8jhj`，我们不希望在其上调度新的pod。
- en: '`kubectl` has a command called `cordon`, which allows us to make a node unschedulable:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`有一个名为`cordon`的命令，允许我们使节点不可调度。'
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let''s cordon the `gke-kubectl-lab-default-pool-b3c7050d-8jhj` node and then
    print a nodes list. To cordon the node, run the following:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对`gke-kubectl-lab-default-pool-b3c7050d-8jhj`节点进行隔离，然后打印节点列表。要对节点进行隔离，请运行以下命令：
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We get the following output after running the preceding command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行上述命令后，我们得到以下输出：
- en: '![Figure 3.8 – Cordoning nodes'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.8 – 节点隔离'
- en: '](image/B16411_03_007.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_007.jpg)'
- en: Figure 3.8 – Cordoning nodes
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.8 – 节点隔离
- en: We have cordoned the `gke-kubectl-lab-default-pool-b3c7050d-8jhj` node so from
    now on, no new pods will be scheduled onto that node, but whatever pods are running
    there will stay running on that node.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经对`gke-kubectl-lab-default-pool-b3c7050d-8jhj`节点进行了隔离，从现在开始，不会再有新的pod被调度到该节点，但是已经在该节点上运行的pod将继续在该节点上运行。
- en: Important note
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If the cordoned node gets rebooted then all pods that were scheduled on it will
    get rescheduled to different nodes, as even when rebooting the node its readiness
    status doesn't change.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果被隔离的节点重新启动，那么原先在其上调度的所有pod将被重新调度到不同的节点上，因为即使重新启动节点，其就绪状态也不会改变。
- en: 'If we want the node to be scheduled on again, you just use `uncordon` command.
    To uncordon the node, run the following command:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们希望再次对节点进行调度，只需使用`uncordon`命令。要对节点进行取消隔离，请运行以下命令：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We get the following output after running the preceding command:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行上述命令后，我们得到以下输出：
- en: '![Figure 3.9 – Uncordoning nodes'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.9 – 取消隔离节点'
- en: '](image/B16411_03_008.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_008.jpg)'
- en: Figure 3.9 – Uncordoning nodes
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.9 – 取消隔离节点
- en: As you can see from the preceding screenshot, the `gke-kubectl-lab-default-pool-b3c7050d-8jhj`
    node is in the `Ready` state again and new pods will be scheduled on it from now
    on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的截图中可以看出，`gke-kubectl-lab-default-pool-b3c7050d-8jhj`节点再次处于`Ready`状态，从现在开始新的pod将被调度到该节点上。
- en: Draining nodes
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点排空
- en: 'You might want to remove/evict all pods from a node that is going to be deleted,
    upgraded, or rebooted, for example. There is a command, `drain`, for that. Its
    output is quite long, so only some of the output will be shown:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望从将要被删除、升级或重新启动的节点中删除/驱逐所有的pod。有一个名为`drain`的命令可以做到这一点。它的输出非常长，所以只会显示部分输出：
- en: '[PRE6]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We get the following output from the preceding command:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从上述命令中得到以下输出：
- en: '![Figure 3.10 – Partial kubectl drain – help output'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.10 – 部分kubectl drain – 帮助输出'
- en: '](image/B16411_03_009.jpg)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_009.jpg)'
- en: Figure 3.10 – Partial kubectl drain – help output
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.10 – 部分kubectl drain – 帮助输出
- en: 'As you can see from the output, there are a few flags you need to pass to properly
    drain the node: `--ignore-daemonsets` and `–force`.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，您需要传递一些标志才能正确排干节点：`--ignore-daemonsets`和`–force`。
- en: Note
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: A DaemonSet ensures that all specified Kubernetes nodes run a copy of the same
    pod specified in the DaemonSet. A DaemonSet cannot be deleted from the Kubernetes
    node, so the `--ignore-daemonsets` flag must be used to force draining the node.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet确保所有指定的Kubernetes节点运行与DaemonSet中指定的相同的pod的副本。无法从Kubernetes节点中删除DaemonSet，因此必须使用`--ignore-daemonsets`标志来强制排干节点。
- en: 'Let''s drain the `gke-kubectl-lab-default-pool-b3c7050d-8jhj` node using the
    following command:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令排干`gke-kubectl-lab-default-pool-b3c7050d-8jhj`节点：
- en: '[PRE7]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We drain the node using the preceding command. The output of this command is
    as shown in the following screenshot:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上述命令排干节点。此命令的输出如下截图所示：
- en: '![Figure 3.11 – Drain node'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.11 - 排水节点'
- en: '](image/B16411_03_010.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_010.jpg)'
- en: Figure 3.11 – Drain node
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.11 - 排水节点
- en: Important note
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We have passed the `--ignore-daemonsets` flag so that if there are any DaemonSets
    running on the node the `drain` command will not fail.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传递了`--ignore-daemonsets`标志，以便如果节点上运行有任何DaemonSets，`drain`命令将不会失败。
- en: So, we have drained the node. What else does `drain` do? It cordons the node
    as well, so no more pods can be scheduled on to the node.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们已经排干了节点。`drain`还做了什么？它还会封锁节点，因此不会再有pod被调度到该节点上。
- en: Now we are ready to delete the node.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备删除节点。
- en: Removing nodes
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除节点
- en: The `gke-kubectl-lab-default-pool-b3c7050d-8jhj` node got drained and is not
    running any deployments, pods, or StatefulSets, so it can be easily deleted now.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`gke-kubectl-lab-default-pool-b3c7050d-8jhj`节点已经被排干，不再运行任何部署、pod或StatefulSets，因此现在可以轻松删除。'
- en: 'We do it using the `delete node` command:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`delete node`命令来执行：
- en: '[PRE8]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We delete the node using the preceding command. The output of this command
    is as shown in the following screenshot:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用上述命令删除节点。此命令的输出如下截图所示：
- en: '![Figure 3.12 – Delete node'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.12 - 删除节点'
- en: '](image/B16411_03_011.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_011.jpg)'
- en: Figure 3.12 – Delete node
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.12 - 删除节点
- en: As you can see from the `kubectl get nodes` output, the node was unregistered
    from the Kubernetes API and got deleted.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从`kubectl get nodes`的输出中可以看出，该节点已从Kubernetes API中注销并被删除。
- en: Important note
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Actual node deletion depends on your Kubernetes setup. In cloud-hosted clusters,
    the node gets unregistered and deleted, but if you are running an on-premise self-hosted
    Kubernetes cluster, the actual node will not be deleted but only deregistered
    from the Kubernetes API.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 实际节点删除取决于您的Kubernetes设置。在云托管的集群中，节点将被注销和删除，但如果您运行的是自托管的本地Kubernetes集群，则实际节点将不会被删除，而只会从Kubernetes
    API中注销。
- en: Also, when you specify the cluster size in the cloud setup, the new node will
    replace the deleted one after some time.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当您在云设置中指定集群大小时，新节点将在一段时间后替换已删除的节点。
- en: 'Let''s run `kubectl get nodes` to check the nodes:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行`kubectl get nodes`来检查节点：
- en: '![Figure 3.13 – Nodes list'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图3.13 - 节点列表'
- en: '](image/B16411_03_012.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/B16411_03_012.jpg)'
- en: Figure 3.13 – Nodes list
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.13 - 节点列表
- en: A few minutes later, we see the third node is back, even with the same name.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 几分钟后，我们看到第三个节点又回来了，甚至名称都一样。
- en: Introduction to node pools
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 节点池简介
- en: Cloud providers that have Kubernetes as a managed service support node pools.
    Let's learn what they are.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 将Kubernetes作为托管服务的云提供商支持节点池。让我们学习一下它们是什么。
- en: A node pool is just a group of Kubernetes nodes that have the same compute spec
    and the same Kubernetes node labels, nothing else too fancy.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 节点池只是具有相同计算规格和相同Kubernetes节点标签的一组Kubernetes节点，没有其他太花哨的东西。
- en: 'For example, we have two node pools:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们有两个节点池：
- en: 'The default pool with the `node-pool: default-pool` node label'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '带有 `node-pool: default-pool` 节点标签的默认池'
- en: 'The web app pool with the `node-pool: web-app` node label'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '带有 `node-pool: web-app` 节点标签的web应用程序池'
- en: Kubernetes node labels can be used in node selectors and Node Affinity to control
    how workloads are scheduled to your nodes.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes节点标签可以用于节点选择器和Node Affinity，以控制工作负载如何调度到您的节点。
- en: We are going to learn how to use Kubernetes node pools with Node Affinity in
    [*Chapter 5*](B16411_05_Final_VK_ePub.xhtml#_idTextAnchor055), *Updating and Deleting
    Applications*.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第5章*](B16411_05_Final_VK_ePub.xhtml#_idTextAnchor055)中学习如何使用Node Affinity来使用Kubernetes节点池，*更新和删除应用程序*。
- en: Summary
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we have learned how to use `kubectl` to list nodes running
    in the cluster, get information about the nodes and their resources usage; we've
    seen how to cordon, drain, and remove nodes; and we had an introduction to node
    pools.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何使用 `kubectl` 列出集群中运行的节点，获取有关节点及其资源使用情况的信息；我们看到了如何对节点进行cordon、drain和删除操作；并且我们对节点池进行了介绍。
- en: We have learned new skills that can be applied in real-world scenarios to conduct
    maintenance on Kubernetes nodes.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学到了可以应用于实际场景中的新技能，用于对Kubernetes节点进行维护。
- en: In the next chapter, we're going to learn how to create and deploy applications
    to a Kubernetes cluster using `kubectl`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习如何使用 `kubectl` 在Kubernetes集群中创建和部署应用程序。
