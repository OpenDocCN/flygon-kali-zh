- en: Chapter 1. Welcome to Docker Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章。欢迎来到Docker Swarm
- en: It's no mystery that Docker is one of the open-source technologies that have
    the most traction nowadays. The reasons are easy to understand, Docker makes the
    container technology available for all, and it comes with an included battery
    that is removable and is blessed by a vibrant community.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，Docker是当今最受欢迎的开源技术之一。原因很容易理解，Docker使容器技术对所有人都可用，并且附带一个可移除的包含电池，并得到了一个充满活力的社区的祝福。
- en: 'In the early days, users started working with Docker after being fascinated
    with this easy-to-use tool, which allowed them to sort out many challenges: pulling,
    packing, isolating, and making applications portable across systems with almost
    no burden.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，用户们开始使用Docker，因为他们被这个易于使用的工具所迷住，这个工具让他们能够解决许多挑战：拉取、打包、隔离和使应用程序在系统之间可移植几乎没有负担。
- en: '![Welcome to Docker Swarm](images/image_01_001.jpg)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![欢迎来到Docker Swarm](images/image_01_001.jpg)'
- en: '*A simplified Docker Ecosystem*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*简化的Docker生态系统*'
- en: You may notice a swarm of whales here plays nice with others. However, since
    the advent of containers, people have been looking for tools to efficiently orchestrate
    a huge number of them. The Docker team addressed this necessity with the release
    of Docker Swarm, hereinafter Swarm, one of the pieces of the Docker ecosystem,
    in 2015, alongside with Docker Machine and Docker Compose. The preceding image
    shows the simplified Docker Ecosystem, which consists of Docker Machine provisioning
    a new Docker-ready machine, then a set of machines will be formed into a Docker
    Swarm cluster. Later we will be able to use Docker Compose to deploy containers
    to the cluster, as if it were a normal Docker Engine.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会注意到这里有一群鲸鱼与其他人相处融洽。然而，自容器问世以来，人们一直在寻找有效地编排大量容器的工具。Docker团队在2015年发布了Docker
    Swarm，简称Swarm，作为Docker生态系统的一部分，与Docker Machine和Docker Compose一起发布。前面的图片显示了简化的Docker生态系统，其中Docker
    Machine提供了一个新的Docker-ready机器，然后一组机器将形成一个Docker Swarm集群。稍后，我们将能够使用Docker Compose将容器部署到集群中，就像它是一个普通的Docker
    Engine一样。
- en: The plan to make a cluster management system, natively, for Docker started in
    early 2014, as a communication protocol project called *Beam*. Later, it was implemented
    as a daemon to control heterogeneous distributed systems with the Docker API.
    The project had been renamed to `libswarm` and `Swarmd` is its daemon. Keeping
    the same concept of allowing any Docker client to connect to a pool of Docker
    Engines, the third generation of the project had been re-designed to use the same
    set of Docker Remote APIs and renamed to "Swarm" in November 2014\. Basically,
    the most important part of Swarm are its remote APIs; the maintainers work hard
    to keep them 100% compatible with every version of Docker Engine. We'll call the
    first generation of Swarm as "Swarm v1".
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在2014年初，为Docker原生地创建一个集群管理系统的计划开始，作为一个名为*Beam*的通信协议项目。后来，它被实现为一个守护进程，用于控制具有Docker
    API的异构分布式系统。该项目已更名为`libswarm`，其守护进程为`Swarmd`。保持允许任何Docker客户端连接到一组Docker引擎的相同概念，该项目的第三代已经重新设计为使用相同的一组Docker远程API，并于2014年11月更名为"Swarm"。基本上，Swarm最重要的部分是其远程API；维护者们努力保持它们与每个Docker
    Engine版本100%兼容。我们将第一代Swarm称为"Swarm v1"。
- en: In February 2016, after the core team found the scaling limitation of the centralized
    service, Swarm has been internally redesigned again as `swarm.v2`. This time,
    a decentralized cluster design has been taken into account. In June 2016, SwarmKit
    had been released as the orchestration toolkit for distributed service at any
    scale. Docker announced that SwarmKit was merged into Docker Engine at DockerCon
    2016\. We'll refer to this version of Swarm as "Swarm v2"  or "Swarm mode".
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 2016年2月，核心团队发现了集中式服务的扩展限制后，Swarm再次在内部重新设计为`swarm.v2`。这一次，采用了分散式集群设计。2016年6月，SwarmKit作为分布式服务的编排工具包发布。Docker宣布SwarmKit已合并到Docker
    Engine中，该消息是在DockerCon 2016上宣布的。我们将称这个版本的Swarm为“Swarm v2”或“Swarm模式”。
- en: As we'll see later, these three musketeers (Docker Swarm, Docker Machine, and
    Docker Compose) operate best when together and they are so seamlessly intertwined
    with each other that it is almost impossible to think of them as single pieces.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们将在后面看到的那样，这三位大侠（Docker Swarm，Docker Machine和Docker Compose）在一起运作时效果最佳，它们之间紧密地交织在一起，几乎不可能将它们视为单独的部分。
- en: However, even despite this Machine and Compose are really direct in their goals
    and easy to use and understand, Swarm is a tool that indeed deserves a book for
    itself.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使如此，Machine和Compose在其目标上确实非常直接，易于使用和理解，Swarm是一个确实值得一本书的工具。
- en: With Docker Machine, you can provision machines, both virtual and physical,
    on a number of cloud platforms as well as bare metal machines to run Docker containers.
    With Docker Compose, you can define Dockerfiles on steroids, by describing behaviors
    with the easy yet powerful syntax of YAML and launch applications by just "composing
    up" these files. Swarm is a powerful clustering tool that requires to be studied
    more in depth.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker Machine，您可以在多个云平台上以及裸机上提供虚拟和物理机器来运行Docker容器。使用Docker Compose，您可以通过使用YAML的简单而强大的语法描述行为，并通过“组合”这些文件来启动应用程序。Swarm是一个强大的集群工具，需要更深入地研究。
- en: 'In this chapter, we will be taking a look at the following topics:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看一下以下主题：
- en: What is container orchestration
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是容器编排
- en: Docker Swarm fundamentals and architecture
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm的基本原理和架构
- en: Differences with other open source orchestrators
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他开源编排器的区别
- en: The "old" Swarm, v1
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “旧”Swarm，v1
- en: The "new" Swarm, Swarm Mode
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “新”Swarm，Swarm模式
- en: Clustering tools and container managers
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群工具和容器管理器
- en: A clustering tool is software that allows an operator to talk to a single end
    point and to command and *orchestrate* a set of resources, in our case containers.
    Instead of manually distributing workloads (containers) on a cluster, a clustering
    tool is used to automate this and many other tasks. It's the clustering tool that
    will decide *where* to start jobs (containers), *how* to store them, *when* to
    eventually restart them, and so on. The operator needs to only configure some
    behaviors, decide the cluster topology and size, tune settings, and enable or
    disable advanced features. Docker Swarm is an example of clustering tool for containers.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 集群工具是一种软件，允许操作员与单个端点通信，并命令和*编排*一组资源，在我们的情况下是容器。与手动在集群上分发工作负载（容器）不同，集群工具用于自动化这一过程以及许多其他任务。集群工具将决定*何时*启动作业（容器），*如何*存储它们，*何时*最终重新启动它们等等。操作员只需配置一些行为，决定集群拓扑和大小，调整设置，并启用或禁用高级功能。Docker
    Swarm是一个用于容器的集群工具的示例。
- en: Beyond clustering tools, there is also a choice of container manager platforms.
    They do not provide container hosting, but interact with one or more existing
    systems; this kind of software usually offer good web interfaces, monitoring tools,
    and other visual or higher-level functionalities. Examples of container manager
    platforms are Rancher or Tutum (acquired in 2015 by Docker Inc.).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 除了集群工具之外，还有容器管理平台的选择。它们不提供容器托管，但与一个或多个现有系统进行交互；这种软件通常提供良好的Web界面、监控工具和其他视觉或更高级的功能。容器管理平台的示例包括Rancher或Tutum（在2015年被Docker
    Inc.收购）。
- en: Swarm goals
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm目标
- en: 'Swarm is described by Docker itself as:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm被Docker本身描述为：
- en: '*Docker Swarm is native clustering for Docker. It turns a pool of Docker hosts
    into a single, virtual Docker host.*'
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Docker Swarm是Docker的本地集群。它将一组Docker主机转换为单个虚拟Docker主机。*'
- en: Swarm is a tool that gives you the illusion to manage a single-huge Docker host
    made of many Docker hosts, as they were one and had one command-entry point. It
    allows you to orchestrate and operate a certain number of containers on these
    hosts, using the routine Docker tools, either using the Docker native or the python-docker
    client, even curl with the Docker Remote APIs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm是一个工具，它让您产生管理一个由许多Docker主机组成的单一巨大Docker主机的幻觉，就好像它们是一个，并且有一个命令入口点。它允许您使用常规的Docker工具，在这些主机上编排和操作一定数量的容器，无论是使用Docker本机还是python-docker客户端，甚至是使用Docker远程API的curl。
- en: 'This is what a minimal Swarm cluster in production looks similar to:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个在生产中看起来类似的最小的Swarm集群：
- en: '![Swarm goals](images/image_01_002.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![Swarm goals](images/image_01_002.jpg)'
- en: Why use Swarm
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么使用Swarm
- en: There are many reasons to use a clustering solution for your containers. As
    you will see your applications growing, you will face new mandatory requirements,
    such as scalability, manageability, and high availability.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 使用容器的集群解决方案有许多原因。随着您的应用程序增长，您将面临新的强制性要求，如可扩展性、可管理性和高可用性。
- en: 'There are many tools available out there; picking up Docker Swarm gives us
    some immediate advantages:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多可用的工具；选择Docker Swarm给我们带来了一些即时的优势：
- en: '**Native clustering**: Swarm is a native in Docker and made by the Docker team
    and community. Its original creators are Andrea Luzzardi and Victor Vieux, who
    are the early implementers of Docker Engine Remote API itself. Swarm integrates,
    with no additional requirements, with Machine, Compose, and the other tools from
    the ecosystem.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**本地集群**：Swarm是Docker的本地工具，由Docker团队和社区制作。其原始创作者是Andrea Luzzardi和Victor Vieux，他们是Docker
    Engine Remote API的早期实施者。Swarm与Machine、Compose和生态系统中的其他工具集成，无需额外要求。'
- en: '**Production grade**: Swarm v1 was declared mature in November 2015 and is
    ready to be used in production. The team already demonstrated that Swarm can scale-up
    to control Engines that are as large as 1,000 nodes. Swarm v2 allows forming clusters
    with multi-thousand nodes, as it uses a decentralized discovery.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产级**：Swarm v1在2015年11月被宣布成熟，并准备投入生产使用。团队已经证明Swarm可以扩展到控制多达1,000个节点的引擎。Swarm
    v2允许形成具有数千个节点的集群，因为它使用了分散式发现。'
- en: '**Work out-of-the-box**: Swarm does not require you to re-architect your app
    to adapt to another orchestration tool. You can use your Docker images and configurations
    with no changes and deploy them at a scale.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开箱即用**：Swarm不需要您重新设计您的应用程序以适应另一个编排工具。您可以使用您的Docker镜像和配置，无需更改即可进行规模部署。'
- en: '**Easy to setup and use**: Swarm is easy to operate. Effective deployments
    can be done by just adding some flags to Machine commands or using Docker commands
    since Docker 1.12\. Discovery service is integrated into Swarm Mode, making it
    quick to install: There is no need to set up external Consul, Etcd, or Zookeeper
    clusters.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**易于设置和使用**：Swarm易于操作。只需向Machine命令添加一些标志或使用Docker命令，就可以进行有效的部署，因为Docker 1.12版已经集成了发现服务到Swarm模式中，使得安装变得迅速：无需设置外部的Consul、Etcd或Zookeeper集群。'
- en: '**Active community**: Swarm is a vibrant project, with a very active community
    and is under heavy development.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**活跃的社区**：Swarm是一个充满活力的项目，拥有一个非常活跃的社区，并且正在积极开发中。'
- en: '**Available on Hub**: You don''t need to install Swarm, it comes ready as a
    Docker image (Swarm v1), and so you just pull and run it from the Hub or integrated
    into the Docker Engine. While Swarm Mode is already integrated into Docker 1.12+.
    That''s all.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在Hub上可用**：你不需要安装Swarm，它作为一个Docker镜像（Swarm v1）已经准备好了，所以你只需从Hub上拉取并运行它，或者集成到Docker
    Engine中。而Swarm Mode已经集成到Docker 1.12+中。就是这样。'
- en: Real world use case examples
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 真实世界的用例示例
- en: 'Docker Swarm is the choice of several projects, for example:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm是几个项目的选择，例如：
- en: 'Rackspace Carina is built atop Docker Swarm: Rackspace offers hosted container
    environment, which is internally based on Docker Swarm'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rackspace Carina是建立在Docker Swarm之上的：Rackspace提供托管的容器环境，内部基于Docker Swarm
- en: Zenly is using Swarm across Google Cloud Platform and bare metal servers
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zenly正在使用Swarm在Google Cloud Platform和裸金属服务器上
- en: ADP uses Docker and Swarm to give velocity to their legacy deployments
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ADP使用Docker和Swarm来加速他们的传统部署
- en: Swarms can be deployed with Amazon AWS and Microsoft Azure templates directly
    on their public clouds
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm可以直接在亚马逊AWS和微软Azure模板上部署到它们的公共云上
- en: Pet versus cattle models
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 宠物与牲畜模型
- en: 'There are two opposite approaches when creating and utilizing infrastructures:
    pet versus cattle.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建和利用基础设施时有两种相反的方法：宠物与牲畜。
- en: In the *pet* model, the administrator deploys servers or virtual machines or,
    in our case, containers and takes care of them. She or he logs in, installs software,
    configures it, and ensures that everything is working fine. As a result, this
    is her or his pet.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在*宠物*模型中，管理员部署服务器或虚拟机，或者在我们的情况下，容器，并对它们进行管理。她或他登录，安装软件，配置它，并确保一切正常运行。因此，这就是她或他的宠物。
- en: By contrast, the administrator doesn't really care about the destiny of his
    infrastructural components, when thinking of them as *cattles*. She or he doesn't
    log in to every single unit or handle it manually, rather, uses a bulk approach,
    deployment, configuration, and management are done with automation tools. If a
    server or container dies, it's automatically resurrected, or another is generated
    to substitute for the defunct. As a result, the operator is handling cattle.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，管理员并不真正关心基础设施组件的命运，当把它们看作*牲畜*时。她或他不会登录到每个单元或手动处理它，而是使用批量方法，部署、配置和管理都是通过自动化工具完成的。如果服务器或容器死掉，它会自动复活，或者生成另一个来替代已经失效的。因此，操作员正在处理牲畜。
- en: In this book, we'll use the pet model in the very first chapter to introduce
    some basic concepts to the reader. But we'll follow the cattle pattern later,
    when it will be the time to do serious things.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将在第一章中使用宠物模型来向读者介绍一些基本概念。但是在进行严肃的事情时，我们将在后面采用牲畜模式。
- en: Swarm features
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm特性
- en: 'The main purpose of Swarm was already defined, but how does it accomplish its
    goals? Here are its key features:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm的主要目的已经定义好了，但它是如何实现其目标的呢？以下是它的关键特性：
- en: Swarm v1 supports Docker Engine of version 1.6.0 or more recent. Swarm v2 has
    been in built for Docker Engine since version 1.12.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm v1支持Docker Engine 1.6.0或更高版本。Swarm v2已经内置到Docker Engine自1.12版以来。
- en: APIs of each release of Swarm will be compatible with Docker APIs on the same
    release train. API compatibility is maintained for one version backward.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个Swarm版本的API都与相同版本的Docker API兼容。API兼容性向后维护一个版本。
- en: In Swarm v1, the leader-election mechanism is implemented for multiple Swarm
    masters using the leadership library (only supported when deploying Swarm with
    a discovery service, such as Etcd, Consul, or Zookeeper).
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Swarm v1中，领导选举机制是使用领导库为多个Swarm主节点实现的（只有在部署带有发现服务的Swarm时才支持，例如Etcd、Consul或Zookeeper）。
- en: In Swarm v2, leader election has been built using the decentralized mechanism.
    Swarm v2 does not need a dedicated set of discovery services anymore because it
    integrates Etcd, an implementation of the Raft consensus algorithm (see [Chapter
    2](ch02.html "Chapter 2. Discover the Discovery Services"), *Discover the Discovery
    Services*).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Swarm v2中，领导者选举已经使用了分散机制进行构建。Swarm v2不再需要专门的一组发现服务，因为它集成了Etcd，这是Raft共识算法的实现（参见[第2章](ch02.html
    "第2章。发现发现服务")，“发现发现服务”）。
- en: In the Swarm v1 terminology, the leader Swarm master is called primary, where
    others are called replica. In Swarm v2, there is a concept of Master and Worker
    nodes. While the leader nodes are managed automatically by the cluster using Raft.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Swarm v1的术语中，领导Swarm主节点称为主节点，其他节点称为副本。在Swarm v2中，有主节点和工作节点的概念。领导节点由Raft集群自动管理。
- en: Basic and advanced scheduling options. The scheduler is an algorithm that decides
    the hosts on which the containers must be physically placed. Swarm comes with
    a set of built-in schedulers.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本和高级调度选项。调度器是一个决定容器必须物理放置在哪些主机上的算法。Swarm带有一组内置调度器。
- en: Constraints and affinities to let the operator take decisions on scheduling;
    for example, one wants to keep the database containers geographically near and
    suggest the scheduler to do that. Constraints and affinities use Docker Swarm
    labels.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 约束和亲和性让操作员对调度做出决策；例如，有人想要保持数据库容器在地理上靠近，并建议调度器这样做。约束和亲和性使用Docker Swarm标签。
- en: In Swarm v2, in-cluster load balancing is implemented with the built-in DNS
    Round-Robin, while it supports external load balancing via the routing mesh mechanism,
    which is implemented over IPVS.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Swarm v2中，集群内负载平衡是通过内置的DNS轮询实现的，同时它支持通过路由网格机制实现的外部负载平衡，该机制是基于IPVS实现的。
- en: High-availability and failover mechanism means that you can create a Swarm with
    more than one master; so if they go down, there will be other master/s ready to
    take control. Swarm v2 is available, by default, when we form a cluster of at
    least 3 nodes. All nodes can be the master nodes. Also, Swarm v2 includes health
    indicator information.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用性和故障转移机制意味着您可以创建一个具有多个主节点的Swarm；因此，如果它们宕机，将有其他主节点准备好接管。当我们形成至少3个节点的集群时，默认情况下可用Swarm
    v2。所有节点都可以是主节点。此外，Swarm v2包括健康指示器信息。
- en: Similar projects
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 类似的项目
- en: We have more than only Docker Swarm out there to clusterize containers. For
    completeness, we will briefly review the most widely known open source alternatives,
    before diving completely into Swarm.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅有Docker Swarm来对容器进行集群化。为了完整起见，我们将简要介绍最广为人知的开源替代方案，然后完全深入到Swarm中。
- en: Kubernetes
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes
- en: '**Kubernetes** ([http://kubernetes.io](http://kubernetes.io)), also known as
    **k8s**, aims at the same goal of Docker Swarm; it''s a manager for cluster of
    containers. Started originally as project Borg in Google laboratories, it was
    later open sourced and released as a stable version in 2015, supporting **Google
    Cloud Platform**, **CoreOS**, **Azure**, and **vSphere**.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes** ([http://kubernetes.io](http://kubernetes.io))，也被称为**k8s**，旨在实现与Docker
    Swarm相同的目标；它是一个容器集群的管理器。最初作为Google实验室的Borg项目开始，后来以稳定版本的形式开源并于2015年发布，支持**Google
    Cloud Platform**，**CoreOS**，**Azure**和**vSphere**。'
- en: Kubernetes so far runs containers in Docker, which is commanded via API by a
    so called Kubelet, a service that registers and manages Pods. Architecturally,
    Kubernetes divides its clusters, logically, not into bare containers but into
    Pods. A Pod is the smallest deployable unit and is physically a representation
    of an application made by a group of one or more containers, usually collocated,
    that share resources such as storage and networking (users can simulate Pods in
    Docker using Compose and starting from Docker 1.12 create Docker **DABs** (**Distributed
    Application Bundles**)).
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，Kubernetes在Docker中运行容器，通过所谓的Kubelet通过API命令，这是一个注册和管理Pods的服务。从架构上讲，Kubernetes将其集群逻辑上划分为Pods，而不是裸容器。Pod是最小的可部署单元，物理上是一个由一个或多个容器组成的应用程序的表示，通常是共同部署的，共享存储和网络等资源（用户可以使用Compose在Docker中模拟Pods，并且从Docker
    1.12开始创建Docker **DABs**（**分布式应用程序包**））。
- en: Kubernetes includes some expected basic clustering features, such as labels,
    health checkers, Pods registry, has configurable schedulers, and services such
    as ambassadors or load balancers.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes包括一些预期的基本集群功能，如标签、健康检查器、Pods注册表，具有可配置的调度程序，以及服务，如大使或负载均衡器。
- en: In practice, the Kubernetes user utilizes the kubectl client to interface to
    the Kubernetes master, the cluster controlling unit that commands the Kubernetes
    nodes doing some work, called minions. Minions run Pods and everything is glued
    by Etcd.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，Kubernetes用户利用kubectl客户端与Kubernetes主控制单元（命令Kubernetes节点执行工作的单元，称为minions）进行交互。Minions运行Pods，所有内容都由Etcd粘合在一起。
- en: On a Kubernetes node, you will find a running Docker Engine, which runs a kube-api
    container, and a system service called `kubelet.service`.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes节点上，您会发现一个正在运行的Docker引擎，它运行一个kube-api容器，以及一个名为`kubelet.service`的系统服务。
- en: There are a of kubectl commands that are pretty intuitive, such as
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多直观的kubectl命令，比如
- en: '`kubectl cluster-info`, `kubectl get pods`, and `kubectl get nodes` to retrieve
    information about the cluster and its health'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl cluster-info`，`kubectl get pods`和`kubectl get nodes`用于检索有关集群及其健康状况的信息'
- en: '`kubectl create -f cassandra.yaml` and any derivative Pod commands, to create,
    manage, and destroy Pods'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl create -f cassandra.yaml`和任何派生的Pod命令，用于创建、管理和销毁Pods'
- en: '`kubectl scale rc cassandra --replicas=2` to scale Pods and applications'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl scale rc cassandra --replicas=2`用于扩展Pods和应用程序'
- en: '`kubectl label pods cassandra env=prod` to configure Pod labels'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl label pods cassandra env=prod`用于配置Pod标签'
- en: 'This is just a high level panoramic of Kubernetes. The main differences between
    Kubernetes and Docker Swarm are:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是对Kubernetes的一个高层次全景。Kubernetes和Docker Swarm之间的主要区别是：
- en: Swarm has a more straightforward architecture to understand. Kubernetes requires
    more focus, just to grasp its fundamentals. But studying is always good!
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm的架构更直观易懂。Kubernetes需要更多的关注，只是为了掌握其基本原理。但学习总是好的！
- en: 'Again on architecture: Kubernetes is based on Pods, Swarm on containers, and
    DABs.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 再谈架构：Kubernetes基于Pods，Swarm基于容器和DABs。
- en: You need to install Kubernetes. By either deploying on GCE, using CoreOS, or
    on the top of OpenStack, you must take care of it. You must deploy and configure
    a Kubernetes cluster, and this is some little extra effort. Swarm is integrated
    into Docker, and requires no extra installations.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要安装Kubernetes。无论是在GCE上部署，使用CoreOS，还是在OpenStack上，您都必须小心处理。您必须部署和配置一个Kubernetes集群，这需要额外的努力。Swarm已集成到Docker中，无需额外安装。
- en: Kubernetes has an additional concept of Replication Controllers, a technology
    that ensure that all the Pods described by some templates are running at a given
    time.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes有一个额外的概念，叫做复制控制器，这是一种技术，确保某些模板描述的所有Pod在给定时间内都在运行。
- en: Both Kubernetes and Swarm use Etcd. But while in Kubernetes it's treated as
    an external facility service, in Swarm it's integrated and runs on manager nodes.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes和Swarm都使用Etcd。但在Kubernetes中，它被视为外部设施服务，而在Swarm中，它是集成的，并在管理节点上运行。
- en: A performance comparison between Kubernetes and Swarm might take form of holy
    wars and we want to subtract to this practice. There are benchmarks showing how
    fast is Swarm in starting containers and other benchmarks showing how fast is
    Kubernetes in running its workloads. We are of the opinion that benchmark results
    must always be taken *cum grano salis*. That said, both Kubernetes and Swarm are
    suitable for running big, fast, and scalable containers clusters.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes和Swarm之间的性能比较可能会引发争论，我们希望避免这种做法。有一些基准测试显示Swarm启动容器的速度有多快，还有一些基准测试显示Kubernetes运行其工作负载的速度有多快。我们认为基准测试结果必须始终带有一定的保留态度。也就是说，Kubernetes和Swarm都适合运行大型、快速和可扩展的容器集群。
- en: CoreOS Fleet
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CoreOS Fleet
- en: '**Fleet** ([https://github.com/coreos/fleet](https://github.com/coreos/fleet))
    is another possible choice amongst container orchestrators. It comes from the
    family of CoreOS container products (which includes CoreOS, Rocket, and Flannel)
    and is basically different from Swarm, Kubernetes, and Mesos in that it''s architected
    as an extension to system. Fleet operates through schedulers to distribute resources
    and tasks across the cluster nodes. Hence, its goal is not only to provide a pure
    containers clusterization rather to be a distributed more general elaboration
    system. It''s possible, for example, to run Kubernetes on the top of Fleet.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fleet** ([https://github.com/coreos/fleet](https://github.com/coreos/fleet))是容器编排器中的另一种可能选择。它来自CoreOS容器产品系列（包括CoreOS、Rocket和Flannel），与Swarm、Kubernetes和Mesos基本不同，因为它被设计为系统的扩展。Fleet通过调度程序在集群节点之间分配资源和任务。因此，它的目标不仅是提供纯粹的容器集群化，而是成为一个分布式的更一般的处理系统。例如，可以在Fleet上运行Kubernetes。'
- en: A Fleet cluster is made of engines responsible for scheduling jobs, other management
    operations, and agents, running on each host, that are physically executing the
    jobs they're assigned and reporting the status continuously to engines. Etcd is
    the discovery services that keeps everything glued.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Fleet集群由负责调度作业、其他管理操作和代理的引擎组成，这些代理在每个主机上运行，负责执行它们被分配的作业并持续向引擎报告状态。Etcd是保持一切连接的发现服务。
- en: You interact through a Fleet cluster with its main command `fleetctl`, with
    the list, start, and stop containers and services options.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过Fleet集群的主要命令`fleetctl`与其交互，使用列表、启动和停止容器和服务选项。
- en: 'So, summarising, Fleet is different from Docker Swarm:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结一下，Fleet与Docker Swarm不同：
- en: It's a higher-level abstraction that distributes tasks, it's not a mere container
    orchestrator.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这是一个更高级的抽象，用于分发任务，而不仅仅是一个容器编排器。
- en: Think of Fleet as more of a distributed init system for your cluster. Systemd
    is for one host, Fleet for a cluster of hosts.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Fleet视为集群的分布式初始化系统。Systemd适用于一个主机，而Fleet适用于一组主机。
- en: Fleet clusterizes specifically a bunch of CoreOS nodes
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet专门将一堆CoreOS节点集群化。
- en: You can run Kubernetes on the top of Fleet to exploit Fleet features of resiliency
    and high availability
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以在Fleet的顶部运行Kubernetes，以利用Fleet的弹性和高可用性功能。
- en: There are no known stable and robust ways to integrate Fleet and Swarm  v1 automatically.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前没有已知的稳定和强大的方法可以自动集成Fleet和Swarm v1。
- en: Currently, Fleet is not tested to run clusters with more than 100 nodes and
    1000 containers ([https://github.com/coreos/fleet/blob/master/Documentation/fleet-scaling.md](https://github.com/coreos/fleet/blob/master/Documentation/fleet-scaling.md))
    while we were able to run Swarms with 2300 and later 4500 nodes.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前，Fleet尚未经过测试，无法运行超过100个节点和1000个容器的集群（[https://github.com/coreos/fleet/blob/master/Documentation/fleet-scaling.md](https://github.com/coreos/fleet/blob/master/Documentation/fleet-scaling.md)），而我们能够运行具有2300个和后来4500个节点的Swarm。
- en: Apache Mesos
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Apache Mesos
- en: Whether you can see Fleet as a distributed init system for your cluster, you
    can think of Mesos ([https://mesos.apache.org/](https://mesos.apache.org/)) in
    terms of a *distributed kernel*. With Mesos, you can make available all your nodes
    resources as if they were one and, for the scope of this book, run containers
    clusters on them.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您将Fleet视为集群的分布式初始化系统，您都可以将Mesos（[https://mesos.apache.org/](https://mesos.apache.org/)）视为*分布式内核*。使用Mesos，您可以将所有节点的资源都作为一个节点提供，并且在本书的范围内，在它们上运行容器集群。
- en: Mesos, originally started at the University of Berkeley in 2009, is a mature
    project and has been used in production with success, for example by Twitter.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos最初于2009年在伯克利大学开始，是一个成熟的项目，并且已经成功地在生产中使用，例如Twitter。
- en: It's even more general purpose than Fleet, being multi-platform (you can run
    it on Linux, OS X or Windows nodes) and capable of running heterogeneous jobs.
    You can typically have clusters of containers running on Mesos just aside of pure
    Big Data jobs (Hadoop or Spark) and others, including continuous integration,
    real-time processing, web applications, data storage, and even more.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 它甚至比Fleet更通用，是多平台的（可以在Linux、OS X或Windows节点上运行），并且能够运行异构作业。您通常可以在Mesos上运行容器集群，旁边是纯粹的大数据作业（Hadoop或Spark）以及其他作业，包括持续集成、实时处理、Web应用程序、数据存储，甚至更多。
- en: A Mesos cluster is made of one Master, slaves, and frameworks. As you would
    expect, the master allocates resources and tasks on the slaves, it is responsible
    for the system communications and runs a discovery service (ZooKeeper). But what
    are frameworks? Frameworks are applications. A framework is made of a scheduler
    and an executor, the first one distributes tasks and the second executes them.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Mesos集群由一个Master、从属和框架组成。正如您所期望的那样，主节点在从属上分配资源和任务，负责系统通信并运行发现服务（ZooKeeper）。但是框架是什么？框架是应用程序。框架由调度程序和执行程序组成，前者分发任务，后者执行任务。
- en: For our interest, typically containers are run on Mesos through a framework
    named Marathon ([https://mesosphere.github.io/marathon/docs/native-docker.html](https://mesosphere.github.io/marathon/docs/native-docker.html)).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的兴趣，通常通过一个名为Marathon的框架在Mesos上运行容器（[https://mesosphere.github.io/marathon/docs/native-docker.html](https://mesosphere.github.io/marathon/docs/native-docker.html)）。
- en: A comparison between Mesos and Docker Swarm does not make sense here, since
    they may very well run complementarily, that is Docker Swarm v1 can run on Mesos
    and a portion of Swarm source code is just dedicated to this. Swarm Mode and SwarmKit,
    instead, are very similar to Mesos since they abstract jobs in tasks and group
    them in services, to distribute loads on the cluster. We'll discuss better of
    SwarmKit features in [Chapter 3](ch03.html "Chapter 3. Meeting Docker Swarm Mode"),
    *Meeting Docker Swarm Mode*.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里比较Mesos和Docker Swarm是没有意义的，因为它们很可能可以互补运行，即Docker Swarm v1可以在Mesos上运行，而Swarm的一部分源代码专门用于此目的。相反，Swarm
    Mode和SwarmKit与Mesos非常相似，因为它们将作业抽象为任务，并将它们分组为服务，以在集群上分配负载。我们将在[第3章](ch03.html "第3章。了解Docker
    Swarm Mode")中更好地讨论SwarmKit的功能，*了解Docker Swarm Mode*。
- en: Kubernetes versus Fleet versus Mesos
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes与Fleet与Mesos
- en: Kubernetes, Fleet and Mesos try to address a similar problem; they provide a
    layer abstraction for your resources and allow you to interface to a cluster manager.
    Then you can launch jobs and tasks and the project of your choice will sort it
    out. The difference can be seen in the features provided out-of-the-box and on
    how much you can customize the precision of allocating and scaling resources and
    jobs. Of the three, Kubernetes is more automatic, Mesos more customizable so,
    from a certain point of view, powerful (if you need all that power, of course).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes，Fleet和Mesos试图解决类似的问题；它们为您的资源提供了一个抽象层，并允许您与集群管理器进行接口。然后，您可以启动作业和任务，您选择的项目将对其进行排序。区别在于提供的开箱即用功能以及您可以自定义资源和作业分配和扩展精度的程度。在这三者中，Kubernetes更加自动化，Mesos更加可定制，因此从某种角度来看，更加强大（当然，如果您需要所有这些功能）。
- en: Kubernetes and Fleet abstract and make default many details that for Mesos are
    needed to be configured, for example a scheduler. On Mesos, you can use the Marathon
    or Chronos scheduler or even write your own. If you don't require, don't want
    or even can't dig deep into those technicalities, you can pick up Kubernetes or
    Fleet. It depends on your actual and/or forecasted workload.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes和Fleet对许多细节进行了抽象和默认设置，而这些对于Mesos来说是需要配置的，例如调度程序。在Mesos上，您可以使用Marathon或Chronos调度程序，甚至编写自己的调度程序。如果您不需要，不想或甚至无法深入研究这些技术细节，您可以选择Kubernetes或Fleet。这取决于您当前和/或预测的工作负载。
- en: Swarm versus all
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Swarm与所有
- en: So, what solution should you adopt? As always, you have a problem and open source
    is generous enough to make many technologies available that can often intersect
    on to each other, to help you successfully reach a goal. The problem is how and
    what to choose to resolve your problem. Kubernetes, Fleet, and Mesos are all powerful
    and interesting projects and so is Docker Swarm.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，您应该采用哪种解决方案？像往常一样，您有一个问题，开源技术慷慨地提供了许多可以相互交叉帮助您成功实现目标的技术。问题在于如何选择解决问题的方式和方法。Kubernetes，Fleet和Mesos都是强大且有趣的项目，Docker
    Swarm也是如此。
- en: In a hypothetic standing of how automatic and simple to understand these four
    guys are, Swarm is a winner. This is not an advantage always, but in this book
    we'll show how Docker Swarm can help you to make real things work, bearing in
    mind that in one of the DockerCon keynotes Solomon Hykes, CTO and Founder of Docker,
    suggested that *Swarm would be a tier that could provide a common interface onto
    the many orchestration and scheduling frameworks*.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在这四个项目中，如果考虑它们的自动化程度和易于理解程度，Swarm是赢家。这并不总是一个优势，但在本书中，我们将展示Docker Swarm如何帮助您使真实的事情运转，要记住，在DockerCon的一个主题演讲中，Docker的CTO和创始人Solomon
    Hykes建议*Swarm将成为一个可以为许多编排和调度框架提供共同接口的层*。
- en: The Swarm v1 architecture
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm v1架构
- en: This section discusses the overview architecture of Docker Swarm. The internal
    structure of Swarm is described in Figure 3.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本节讨论了Docker Swarm的概述架构。Swarm的内部结构在图3中描述。
- en: '![The Swarm v1 architecture](images/image_01_003.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![Swarm v1架构](images/image_01_003.jpg)'
- en: '*The internal structure of Docker Swarm v1*'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '*Docker Swarm v1的内部结构*'
- en: Starting with the **MANAGER** part, you will see a block labeled with *Docker
    Swarm API* on the left-side of the diagram. As mentioned previously, Swarm exposes
    the set of remote APIs similar to Docker, which allows you to use any Docker clients
    to connect to Swarm. However, the Swarm APIs are slightly different from the standard
    Docker Remote APIs, as Swarm APIs contains cluster-related information too. For
    example, running `docker info` against Docker Engine will give you the information
    of the single Engine, but when we call `docker info` against a Swarm cluster,
    we'll also get the number of nodes in the cluster as well as each node's information
    and health.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 从**管理器**部分开始，你会看到图表左侧标有*Docker Swarm API*的块。如前所述，Swarm暴露了一组类似于Docker的远程API，这允许您使用任何Docker客户端连接到Swarm。然而，Swarm的API与标准的Docker远程API略有不同，因为Swarm的API还包含了与集群相关的信息。例如，对Docker引擎运行`docker
    info`将给出单个引擎的信息，但当我们对Swarm集群调用`docker info`时，我们还将得到集群中节点的数量以及每个节点的信息和健康状况。
- en: The block next to Docker Swarm API is *Cluster Abstraction*. It is an abstraction
    layer to allow different kinds of cluster to be implemented as backend of Swarm
    and share the same set of Docker Remote APIs. Currently we have two cluster backend,
    the built-in Swarm cluster implementation and the Mesos cluster implementation.
    *Swarm Cluster* and *Built-in Scheduler* blocks represent the built-in Swarm cluster
    implementation, while the blocks denoted by *Mesos Cluster* is the Mesos cluster
    implementation.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 紧邻Docker Swarm API的块是*Cluster Abstraction*。它是一个抽象层，允许不同类型的集群作为Swarm的后端实现，并共享相同的Docker远程API集。目前我们有两种集群后端，内置的Swarm集群实现和Mesos集群实现。*Swarm集群*和*内置调度器*块代表内置的Swarm集群实现，而由*Mesos集群*表示的块是Mesos集群实现。
- en: The *Built-in Scheduler* of the Swarm backend comes with a number of *Scheduling
    Strategies*. Two strategies are *Spread* and *BinPack*, which will be explained
    in the later chapters. If you're familiar with Swarm, you will note that the Random
    strategy is missing here. The Random strategy is excluded from the explanation
    as it is for testing purpose only.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: Swarm后端的*内置调度器*配备了多种*调度策略*。其中两种策略是*Spread*和*BinPack*，这将在后面的章节中解释。如果您熟悉Swarm，您会注意到这里缺少了随机策略。随机策略被排除在解释之外，因为它仅用于测试目的。
- en: Along with Scheduling Strategies, Swarm employs a set of *Scheduling Filters*
    to help screening criteria-unmet nodes out. There are currently six kinds of filter
    namely, *Health*, *Port*, *Container Slots*, *Dependency*, *Affinity*, and *Constraint*.
    They are applied to filter when one is scheduling the newly created container
    in exactly this order.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 除了调度策略，Swarm还使用一组*Scheduling Filters*来帮助筛选未满足标准的节点。目前有六种过滤器，分别是*Health*、*Port*、*Container
    Slots*、*Dependency*、*Affinity*和*Constraint*。它们按照这个顺序应用于筛选，当有人在调度新创建的容器时。
- en: On the **AGENTS** part, there are Swarm agents trying to register address of
    their Engines into the discovery service.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在**代理**部分，有Swarm代理试图将其引擎的地址注册到发现服务中。
- en: Finally, the centralized piece, **DISCOVERY**, is to coordinate addresses of
    the Engines between AGENTS and MANAGER. The agent-based Discovery Service currently
    uses LibKV, which delegates the discovery function to your key-value store of
    choices, Consul, Etcd, or ZooKeeper. In contrast, we also can use only Docker
    Swarm manager without any key-value store. This mode is called agent-less discovery*,*
    which are File and Nodes (specify address on the command line).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，集中式部分**DISCOVERY**是协调代理和管理器之间的引擎地址的。基于代理的Discovery服务目前使用LibKV，它将发现功能委托给您选择的键值存储，如Consul、Etcd或ZooKeeper。相比之下，我们也可以只使用Docker
    Swarm管理器而不使用任何键值存储。这种模式称为无代理发现*，*它是文件和节点（在命令行上指定地址）。
- en: We will use the agent-less model later in this chapter to create a minimal local
    Swarm cluster. We'll meet the other discovery services starting in [Chapter 2](ch02.html
    "Chapter 2. Discover the Discovery Services"), *Discover the Discovery Services*
    and the Swarm Mode architecture in [Chapter 3](ch03.html "Chapter 3. Meeting Docker
    Swarm Mode"), *Meeting Docker Swarm Mode*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面使用无代理模型来创建一个最小的本地Swarm集群。我们将在第2章中遇到其他发现服务，*发现发现服务*，以及第3章中的Swarm Mode架构，*了解Docker
    Swarm Mode*。
- en: Terminology
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 术语
- en: Before continuing to other sections, we review some Docker-related terminologies
    to recall Docker concepts and introduce Swarm keywords.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续其他部分之前，我们回顾一些与Docker相关的术语，以回顾Docker概念并介绍Swarm关键字。
- en: A **Docker Engine** is a Docker daemon running on a host machine. Sometimes
    in the book we'll just refer to it as Engine. We usually start an Engine by calling
    `docker daemon` via systemd or other start up services.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Engine是在主机上运行的Docker守护程序。有时在本书中，我们会简称为Engine。我们通常通过调用`docker daemon`来启动Engine，通过systemd或其他启动服务。
- en: '**Docker Compose** is a tool to describe in YAML how multi-container services
    must be architected.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose是一种工具，用于以YAML描述多容器服务的架构方式。
- en: '**Docker stacks** are the binary result of creating images of multiple-containers
    app (described by Compose) instead of single containers.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker堆栈是创建多容器应用程序的镜像的二进制结果（由Compose描述），而不是单个容器。
- en: A **Docker daemon** is an interchangeable term with Docker Engine.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker守护程序是与Docker Engine可互换的术语。
- en: A **Docker client** is the client program packed in the same docker executable.
    For example, when we do `docker run`, we are using the Docker client.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker客户端是打包在同一个docker可执行文件中的客户端程序。例如，当我们运行`docker run`时，我们正在使用Docker客户端。
- en: '**Docker networking** is a Software-defined Network that links a set of containers
    in the same network together. By default, we''ll use the libnetwork ([https://github.com/docker/libnetwork](https://github.com/docker/libnetwork))
    implementation came with Docker Engine. But you can optionally deploy third-party
    network drivers of your choices using plugins.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker网络是将同一网络中的一组容器连接在一起的软件定义网络。默认情况下，我们将使用与Docker Engine一起提供的libnetwork（[https://github.com/docker/libnetwork](https://github.com/docker/libnetwork)）实现。但是，您可以选择使用插件部署您选择的第三方网络驱动程序。
- en: '**Docker Machine** is a tool used to create hosts capable of running Docker
    Engines called **machines***.*'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Machine是用于创建能够运行Docker Engine的主机的工具，称为**machines***.*
- en: A **Swarm node in Swarm v1** is a machine that is a pre-installed Docker Engine
    and has a Swarm agent program running alongside. A Swarm node will register itself
    into a Discovery service.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm v1中的Swarm节点是预先安装了Docker Engine并且在其旁边运行Swarm代理程序的机器。Swarm节点将自己注册到Discovery服务中。
- en: A **Swarm master in Swarm v1** is a machine that is running a Swarm manager
    program. A Swarm master reads addresses of Swarm nodes from its Discovery service.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm v1中的Swarm主节点是运行Swarm管理程序的机器。Swarm主节点从其Discovery服务中读取Swarm节点的地址。
- en: A **Discovery service** is a token-based service offered by Docker or a self-hosted
    one. For the self-hosted ones, you can run HashiCorp Consul, CoreOS Etcd, or Apache
    ZooKeeper as key-value stores to serve as the discovery service.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发现服务是由Docker或自托管的基于令牌的服务。对于自托管的服务，您可以运行HashiCorp Consul、CoreOS Etcd或Apache ZooKeeper作为键值存储，用作发现服务。
- en: '**Leader Election** is a mechanism done by Swarm Masters to find the primary
    node. Other master nodes will be in the replica role until the primary node goes
    down and then the leader election process will start again. As we''ll see, the
    number of Swarm masters should be an odd number.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领导者选举是由Swarm Master执行的机制，用于找到主节点。其他主节点将处于复制角色，直到主节点宕机，然后领导者选举过程将重新开始。正如我们将看到的，Swarm主节点的数量应该是奇数。
- en: '**SwarmKit** is a new Kit released by Docker to abstract orchestration. Theoretically,
    it should be able run *any* kind of service but in practice so far it orchestrates
    only containers and sets of containers.'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SwarmKit是Docker发布的一个新的Kit，用于抽象编排。理论上，它应该能够运行*任何*类型的服务，但实际上到目前为止它只编排容器和容器集。
- en: '**Swarm Mode** is the new Swarm, available since Docker 1.12, that integrates
    SwarmKit into the Docker Engine.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm Mode是自Docker 1.12以来提供的新Swarm，它将SwarmKit集成到Docker Engine中。
- en: '**Swarm Master (in Swarm Mode)** is a node that manages the cluster: It schedules
    services, keeps the cluster configuration (nodes, roles, and labels) and ensures
    that there is a cluster leader.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm Master（在Swarm Mode中）是管理集群的节点：它调度服务，保持集群配置（节点、角色和标签），并确保有一个集群领导者。
- en: '**Swarm Worker (in Swarm Mode)** is a node which runs tasks, for example, hosts
    containers.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm Worker（在Swarm Mode中）是运行任务的节点，例如，托管容器。
- en: '**Services** are abstractions of workloads. For example, we can have a service
    "nginx" replicated 10 times, meaning that you will have 10 tasks (10 nginx containers)
    distributed on the cluster and load balanced by Swarm itself'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务是工作负载的抽象。例如，我们可以有一个名为"nginx"的服务，复制10次，这意味着您将在集群上分布并由Swarm本身负载均衡的10个任务（10个nginx容器）。
- en: '**Tasks** are the unit of work of Swarms. A task is a container.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务是Swarm的工作单位。一个任务就是一个容器。
- en: Getting started with Swarm
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用Swarm
- en: We'll now proceed with the installation of two small Swarm v1 and v2 proof of
    concept clusters, the first on local and the second on Digital Ocean. In order
    to execute the recipes, check the list of ingredients, ensure that you have everything,
    and then begin.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将继续安装两个小型的Swarm v1和v2概念验证集群，第一个在本地，第二个在Digital Ocean上。为了执行这些步骤，请检查配料清单，确保您已经准备好一切，然后开始。
- en: 'To follow the example, you''ll need:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要跟随示例，您将需要：
- en: Either a Windows, Mac OS X, or Linux desktop
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Windows、Mac OS X或Linux桌面
- en: A Bash or Bash-compatible shell. On Windows you can either useCygwin or Git
    Bash.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bash或兼容Bash的shell。在Windows上，您可以使用Cygwin或Git Bash。
- en: The latest version of VirtualBox, installed for the local example
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装最新版本的VirtualBox，用于本地示例
- en: At least 4GB of memory for 4 VirtualBox instances of 1G of memory each for the
    local example
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少需要4GB内存，用于本地示例的4个VirtualBox实例，每个实例1G内存
- en: A Docker client, at least version 1.6.0 for Swarm v1 and 1.12 for Swarm v2
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少需要Docker客户端1.6.0版本用于Swarm v1和1.12版本用于Swarm v2
- en: The latest version of Docker Machine, which is currently 0.8.1
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前版本的Docker Machine，目前为0.8.1
- en: Docker for Mac
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker for Mac
- en: Docker announced the desktop version of Docker for Mac and Docker for Windows
    early in 2016\. It's better than the Docker Toolbox, since it includes the Docker
    CLI tools you expect but doesn't use boot2docker and VirtualBox anymore (it uses
    unikernels instead, which we'll introduce in [Chapter 11](ch11.html "Chapter 11. What
    is next?"), *What is Next?*) and it's fully integrated into the operating system
    (Mac OS X Sierra or Windows 10 with Hyper-V enabled).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Docker在2016年初宣布推出了Docker for Mac和Docker for Windows的桌面版本。它比Docker Toolbox更好，因为它包括您期望的Docker
    CLI工具，但不再使用boot2docker和VirtualBox（它改用unikernels，我们将在第11章中介绍，*下一步是什么？*），并且完全集成到操作系统中（Mac
    OS X Sierra或启用Hyper-V的Windows 10）。
- en: You can download the Docker desktop from [https://www.docker.com/products/overview#/install_the_platform](https://www.docker.com/products/overview#/install_the_platform)
    and install it easily.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从[https://www.docker.com/products/overview#/install_the_platform](https://www.docker.com/products/overview#/install_the_platform)下载Docker桌面版并轻松安装。
- en: '![Docker for Mac](images/image_01_004.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Mac](images/image_01_004.jpg)'
- en: Just drag and drop the Docker beta icon to your applications folder if you're
    using Mac OS X. Input your beta registration code, if any, and it's done.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是Mac OS X，只需将Docker beta图标拖放到应用程序文件夹中。输入您的beta注册码（如果有），就完成了。
- en: '![Docker for Mac](images/image_01_005.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Mac](images/image_01_005.jpg)'
- en: On OS X, you will have the Docker whale in the system tray, which you can open
    and also configure your settings. A Docker host will be running natively on your
    desktop.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在OS X上，您将在系统托盘中看到Docker鲸鱼，您可以打开它并配置您的设置。Docker主机将在您的桌面上本地运行。
- en: '![Docker for Mac](images/docker.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Mac](images/docker.jpg)'
- en: Docker for Windows
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Docker for Windows
- en: In the case of Docker for Windows, it requires Windows 10 with Hyper-V enabled.
    Basically, Hyper-V comes with Windows 10 Professional or higher versions. After
    double-clicking on the setup program, you'll see that the first screen, showing
    the License Agreement, looks similar to the following screenshot. The setup program
    will request you for a key similar to that of Docker for Mac.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Docker for Windows，它需要启用Hyper-V的Windows 10。基本上，Hyper-V随Windows 10专业版或更高版本一起提供。双击安装程序后，您将看到第一个屏幕，显示许可协议，看起来类似于以下截图。安装程序将要求您输入与Docker
    for Mac类似的密钥。
- en: '![Docker for Windows](images/image_01_007.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Windows](images/image_01_007.jpg)'
- en: 'If the installation process goes smoothly, you will see that the finish screen
    is ready for you to launch Docker for Windows, as shown:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如果安装过程顺利进行，您将看到完成屏幕已准备好启动Docker for Windows，如下所示：
- en: '![Docker for Windows](images/image_01_008.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Windows](images/image_01_008.jpg)'
- en: At the time of launch, Docker will initialize itself to the Hyper-V. Once the
    process is done, you can just open PowerShell and start using Docker.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动时，Docker将初始化为Hyper-V。一旦过程完成，您只需打开PowerShell并开始使用Docker。
- en: '![Docker for Windows](images/image_01_009.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Windows](images/image_01_009.jpg)'
- en: If something goes wrong you can open the logging Windows from the tray icon's
    menu, as well as check with Hyper-V Manager.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 如果出现问题，您可以从托盘图标的菜单中打开日志窗口，并使用Hyper-V管理器进行检查。
- en: '![Docker for Windows](images/image_01_010.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![Docker for Windows](images/image_01_010.jpg)'
- en: Getting ready with Linux
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备好使用Linux
- en: We'll extensively use Machine in this book, so ensure that you have it installed
    through Docker for Mac or Windows or Docker Toolbox. If you use Linux on your
    desktop, install the Docker client with your package system (apt or rpm). You
    will also have to download the bare machine binary, just curl it and assign it
    the execution permissions; follow the instructions at [https://docs.docker.com/machine/install-machine/](https://docs.docker.com/machine/install-machine/).
    The current stable version is 0.8.1.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书中广泛使用Machine，因此请确保您已经通过Docker for Mac或Windows或Docker Toolbox安装了它。如果您在桌面上使用Linux，请使用您的软件包系统（apt或rpm）安装Docker客户端。您还需要下载裸机二进制文件，只需使用curl并为其分配执行权限；请按照[https://docs.docker.com/machine/install-machine/](https://docs.docker.com/machine/install-machine/)上的说明进行操作。当前稳定版本为0.8.1。
- en: '[PRE0]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Check that Docker Machine is available - all systems
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查Docker Machine是否可用-所有系统
- en: 'You can check that the machine is ready to be used with the following command
    from the command line:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过命令行检查机器是否准备好使用以下命令：
- en: '[PRE1]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If you have problems, please control the system paths or download the correct
    binary for your architecture.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遇到问题，请检查系统路径或为您的架构下载正确的二进制文件。
- en: Swarm, yesterday
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 昨天的Swarm
- en: 'For the very first example, we''ll run the easiest possible configuration of
    a Swarm v1 cluster locally to get a taste of how "old" Swarms worked (and still
    works). This tiny cluster will have the following features:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一个示例，我们将在本地运行Swarm v1集群的最简单配置，以了解“旧”Swarm是如何工作的（仍然有效）。这个小集群将具有以下特点：
- en: Made of four nodes of 1CPU, 1GB of memory each, it will consist of an infrastructure
    of four CPUs and 4GB of memory available in total
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由每个1CPU，1GB内存的四个节点组成，总共将包括四个CPU和4GB内存的基础设施
- en: Each node will run on VirtualBox
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个节点将在VirtualBox上运行
- en: Each node is connected to each other on the local VirtualBox network
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个节点都连接到本地VirtualBox网络上的其他节点
- en: 'No discovery service is involved: a static `nodes://` mechanism will be used'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不涉及发现服务：将使用静态的`nodes://`机制
- en: No security is configured, in other words TLS is disabled
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有配置安全性，换句话说TLS已禁用
- en: Our cluster will look similar to the following diagram. Four Engines will be
    connected to each other through port `3376` in a mesh. Beyond the Docker engine,
    in fact, each of them will run a Docker container exposing port `3376` (Swarm)
    on host and redirecting it into itself. We, operators, will be able to connect
    to (any of) the hosts by setting the environment variable `DOCKER_HOST` to `IP:3376`.
    Everything will become clearer if you follow the example step-by-step.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的集群将类似于以下图表。四个引擎将通过端口`3376`在网格中相互连接。实际上，除了Docker引擎之外，它们每个都将运行一个在主机上暴露端口`3376`（Swarm）并将其重定向到自身的Docker容器。我们，操作员，将能够通过将环境变量`DOCKER_HOST`设置为`IP:3376`来连接到（任何一个）主机。如果您一步一步地跟随示例，一切都会变得更清晰。
- en: '![Swarm, yesterday](images/B05661_01_25.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![昨天的Swarm](images/B05661_01_25.jpg)'
- en: To begin, we must create four Docker hosts with Docker Machine. Docker Machine
    automates these steps with one command instead of manually creating a Linux VM,
    generating and uploading certificates, logging into it via SSH, and installing
    and configuring the Docker daemon.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们必须使用Docker Machine创建四个Docker主机。Docker Machine可以自动化这些步骤，而不是手动创建Linux虚拟机，生成和上传证书，通过SSH登录到它，并安装和配置Docker守护程序。
- en: 'Machine will perform the following steps:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 机器将执行以下步骤：
- en: Spin up a VirtualBox VM starting from the boot2docker image.
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从boot2docker镜像启动一个VirtualBox虚拟机。
- en: Assign the VM an IP on the VirtualBox internal network.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为虚拟机分配一个IP地址在VirtualBox内部网络上。
- en: Upload and configure certificates and keys.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传和配置证书和密钥。
- en: Install Docker daemon on this VM.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此虚拟机上安装Docker守护程序。
- en: Configure the Docker daemon and expose it so it will be remotely reachable.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置Docker守护程序并公开它，以便可以远程访问。
- en: As a result, we'll have a VM running Docker and ready to be accessed to run
    containers.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 结果，我们将有一个运行Docker并准备好被访问以运行容器的虚拟机。
- en: Boot2Docker
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Boot2Docker
- en: Built with Tiny Core Linux, **Boot2Docker** is a lightweight distribution, which
    is especially designed for running Docker containers. It's runs completely on
    RAM and the boot time is extremely fast, around five seconds from start to the
    console. When starting the Engine, Boot2Docker starts Docker Engine at the secure
    port 2376 by default.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Tiny Core Linux构建的**Boot2Docker**是一个轻量级发行版，专为运行Docker容器而设计。它完全运行在RAM上，启动时间非常快，从启动到控制台大约五秒。启动引擎时，Boot2Docker默认在安全端口2376上启动Docker引擎。
- en: Boot2Docker is by no mean for the production workload. It's designed for development
    and testing purpose only. We'll start with using boot2docker then later move on
    to the production in subsequent chapters. At the time of writing, Boot2Docker
    supports Docker 1.12.3 and uses Linux Kernel 4.4\. It comes with AUFS 4 as the
    default storage driver for Docker Engine.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Boot2Docker绝不适用于生产工作负载。它仅用于开发和测试目的。我们将从使用boot2docker开始，然后在后续章节中转向生产。在撰写本文时，Boot2Docker支持Docker
    1.12.3并使用Linux Kernel 4.4。它使用AUFS 4作为Docker引擎的默认存储驱动程序。
- en: Create 4 cluster nodes with Docker Machine
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Docker Machine创建4个集群节点
- en: 'If we execute:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们执行：
- en: '[PRE2]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: on our new installation to list the available machines, we see that we have
    no running ones.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的新安装中列出可用的机器时，我们看到没有正在运行的机器。
- en: 'So, let''s start by creating one, with this command:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们从创建一个开始，使用以下命令：
- en: '[PRE3]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This command specifically asks to use the VirtualBox driver (-d for short) and
    to name the machine node0\. Docker Machines can provision machines on dozens of
    different public and private providers, such as AWS, DigitalOcean, Azure, OpenStack,
    and has lots of options. For now, we go with the standard settings. The first
    cluster node will be ready after some time.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令明确要求使用VirtualBox驱动程序（-d简称）并将机器命名为node0。Docker Machines可以在数十个不同的公共和私人提供商上提供机器，例如AWS，DigitalOcean，Azure，OpenStack，并且有很多选项。现在，我们使用标准设置。第一个集群节点将在一段时间后准备就绪。
- en: 'At this point, issue the following command to get a control of this host (so
    to remotely gain access):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，发出以下命令以控制此主机（以便远程访问）：
- en: '[PRE4]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This will print some shell variables. Just copy the last row, the one with eval,
    paste it and issue enter. With those variables configured, you are not operating
    the local daemon anymore (if any), but the Docker daemon of `node0`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印一些shell变量。只需复制最后一行，即带有eval的那一行，粘贴并按Enter。配置了这些变量后，您将不再操作本地守护程序（如果有的话），而是操作`node0`的Docker守护程序。
- en: '![Create 4 cluster nodes with Docker Machine](images/image_01_012.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker Machine创建4个集群节点](images/image_01_012.jpg)'
- en: 'If you check the list of machines again, you will see a `*` next to the image
    name, to indicate that it''s the machine currently in use. Alternatively, you
    can type the following command to print the currently active machine:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果再次检查机器列表，您将看到图像名称旁边有一个`*`，表示它是当前正在使用的机器。或者，您可以输入以下命令以打印当前活动的机器：
- en: '[PRE5]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![Create 4 cluster nodes with Docker Machine](images/image_01_013.jpg)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker Machine创建4个集群节点](images/image_01_013.jpg)'
- en: 'The daemon is running on this machine, with some standard settings (such as
    on port `tcp/2376` enabled TLS). You can ensure that by SSHing to the node and
    verify the running processes:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 守护程序正在此机器上运行，并具有一些标准设置（例如在端口`tcp/2376`上启用了TLS）。您可以通过SSH到节点并验证运行的进程来确保这一点：
- en: '[PRE6]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'So, you can immediately this Docker daemon by, for example, starting containers
    and checking the Docker status:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，您可以通过立即启动容器并检查Docker状态来启动Docker守护程序：
- en: '![Create 4 cluster nodes with Docker Machine](images/image_01_014.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker Machine创建4个集群节点](images/image_01_014.jpg)'
- en: 'Perfect! Now we provision the other three hosts, in the same exact way, by
    naming them `node1`, `node2`, and `node3`:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 完美！现在我们以完全相同的方式为其他三个主机进行配置，将它们命名为`node1`、`node2`和`node3`：
- en: '[PRE7]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: When they finish, you will have four Docker hosts available. Check with Docker
    machine.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当它们完成时，您将有四个可用的Docker主机。使用Docker Machine检查。
- en: '![Create 4 cluster nodes with Docker Machine](images/image_01_015.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![使用Docker Machine创建4个集群节点](images/image_01_015.jpg)'
- en: 'We''re now ready to start a Swarm cluster. But, before, for this very first
    example in order to keep it as simple as possible, we''ll go with disabling TLS
    for running engines. Our plan is: Run the Docker daemon on port `2375`, without
    TLS.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备启动一个Swarm集群。但是，在此之前，为了使这个非常简单的第一个示例尽可能简单，我们将禁用运行引擎的TLS。我们的计划是：在端口`2375`上运行Docker守护程序，没有TLS。
- en: Let's make a bit of order and explain all ports combinations in detail.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们稍微整理一下，并详细解释所有端口组合。
- en: '| **Insecure** | **Secure** |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| **不安全** | **安全** |'
- en: '| Engine: 2375 | Engine: 2376 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 引擎：2375 | 引擎：2376 |'
- en: '| Swarm: 3375 | Swarm: 3376 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| Swarm: 3375 | Swarm: 3376 |'
- en: '|  | Swarm v2 uses 2377 for node discovery among nodes |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | Swarm v2使用2377进行节点之间的发现 |'
- en: Port `2377` is for Swarm v2 node to discover each other nodes in the cluster.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 端口`2377`用于Swarm v2节点在集群中发现彼此的节点。
- en: Configuring the Docker hosts
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置Docker主机
- en: To understand where the TLS configuration is, we'll do some exercises by turning
    off the TLS of all our Docker hosts. Also turning it off here is intended to motivate
    the readers to learn how the `swarm manage` command works by invoking it ourselves.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解TLS配置在哪里，我们将通过关闭所有Docker主机的TLS来进行一些练习。在这里关闭它也是为了激励读者学习如何通过自己调用`swarm manage`命令来工作。
- en: 'We have four hosts running Docker on port `tcp/2376` and with TLS, as Docker
    Machine creates them by default. We must reconfigure them to change the daemon
    port to `tls/2375` and remove TLS. So, we log in into each of them, with this
    command:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有四个主机在端口`tcp/2376`上运行Docker，并且使用TLS，因为Docker Machine默认创建它们。我们必须重新配置它们以将守护程序端口更改为`tls/2375`并删除TLS。因此，我们登录到每个主机，使用以下命令：
- en: '[PRE8]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Then, we gain root privileges:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们获得了root权限：
- en: '[PRE9]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And configure `boot2docker`, by modifying the file `/var/lib/boot2docker/profile`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 并通过修改文件`/var/lib/boot2docker/profile`来配置`boot2docker`：
- en: '[PRE10]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'We delete the rows with CACERT, SERVERKEY, and SERVERCERT and configure the
    daemon port to `tcp/2375` and `DOCKER_TLS` to `no`. In practice this will be our
    configuration:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们删除了具有CACERT、SERVERKEY和SERVERCERT的行，并将守护程序端口配置为`tcp/2375`，将`DOCKER_TLS`配置为`no`。实际上，这将是我们的配置：
- en: '![Configuring the Docker hosts](images/image_01_016.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![配置Docker主机](images/image_01_016.jpg)'
- en: 'After this log out from the SSH session and restart the machine:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后退出SSH会话并重新启动机器：
- en: '[PRE11]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Docker is now running on port `tcp/2375` with no security. You can check this
    with the following command:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: Docker现在在端口`tcp/2375`上运行，没有安全性。您可以使用以下命令检查：
- en: '[PRE12]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Finally, on your local desktop computer, unset `DOCKER_TLS_VERIFY` and re-export
    `DOCKER_HOST` in order to use the daemon listening on `tcp/2375` with no TLS:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在您的本地桌面计算机上，取消设置`DOCKER_TLS_VERIFY`并重新导出`DOCKER_HOST`，以便使用在`tcp/2375`上监听且没有TLS的守护程序：
- en: '[PRE13]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We must repeat these steps for each of our four nodes that will be part of our
    first Swarm.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须为我们的第一个Swarm中的每个四个节点重复这些步骤。
- en: Starting Docker Swarm
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动Docker Swarm
- en: 'To get started with Swarm v1 (no surprise), one must pull the `swarm` image
    from the Docker hub. Open the four terminals, source the environment variables
    for each of your machines in each one in the first one, source node0 (`docker-machine
    env node0`, and copy and paste the `env` variable to the shell), in second `node1`,
    and so on -, and after completing the steps for changing the standard port and
    disabling TLS described some lines above, on each of them do:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用Swarm v1（毫不意外），必须从Docker hub拉取`swarm`镜像。打开四个终端，在第一个终端中为每台机器的环境变量设置环境变量，在第一个终端中设置node0（`docker-machine
    env node0`，并将`env`变量复制并粘贴到shell中），在第二个终端中设置`node1`，依此类推 - ，并在完成更改标准端口和禁用TLS的步骤后，对每个终端执行以下操作：
- en: '[PRE14]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '![Starting Docker Swarm](images/image_01_017.jpg)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![启动Docker Swarm](images/image_01_017.jpg)'
- en: 'We''ll use no discovery service for the first example, but the simplest of
    the mechanisms, such as the `nodes://`. With `nodes://`, the Swarm cluster nodes
    are connected manually, to form a grid of peers. What the operator has to do is
    simply define a list of nodes IPs and the daemon port, separated by commas, as
    shown:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在第一个示例中不使用发现服务，而是使用最简单的机制，例如`nodes://`。使用`nodes://`，Swarm集群节点是手动连接的，以形成对等网格。操作员所需做的就是简单地定义一个节点IP和守护进程端口的列表，用逗号分隔，如下所示：
- en: '[PRE15]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To use Swarm, you simply run the swarm container with some arguments. To show
    the help online, you type:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Swarm，您只需使用一些参数运行swarm容器。要在线显示帮助，您可以输入：
- en: '[PRE16]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![Starting Docker Swarm](images/image_01_018.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![启动Docker Swarm](images/image_01_018.jpg)'
- en: 'As you see, Swarm has basically four commands:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Swarm基本上有四个命令：
- en: '**Create** is used to create clusters with a discovery service, for example
    `token://`'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Create**用于使用发现服务创建集群，例如`token://`'
- en: '**List** shows the list of the cluster nodes'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**List**显示集群节点的列表'
- en: '**Manage** allows you to operate a Swarm cluster'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Manage**允许您操作Swarm集群'
- en: '**Join**, in combination with a discovery service, is used for joining new
    nodes to an existing cluster'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Join**与发现服务结合使用，用于将新节点加入现有集群'
- en: 'For now, we''ll use the `manage` command. This is the command with most of
    the options (which you can investigate by issuing `docker run swarm manage --help`).
    We limit now to connect nodes. The following is the strategy on each node:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`manage`命令。这是具有大多数选项的命令（您可以通过发出`docker run swarm manage --help`来进行调查）。我们现在限制连接节点。以下是每个节点的策略：
- en: Expose the Swarm service through the swarm container.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过swarm容器公开Swarm服务。
- en: Run this container in `daemon` (`-d`) mode.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以`daemon`（`-d`）模式运行此容器。
- en: Forward the standard Swarm port `tcp/3376` to the internal (on container) port
    `tcp/2375`.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将标准Swarm端口`tcp/3376`转发到内部（容器上）端口`tcp/2375`。
- en: Specify the list of hosts part of the cluster, with `nodes://` - each host has
    to be a pair `IP:port` where the port is the Docker engine port (`tcp/2375`).
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`nodes://`指定集群中的主机列表 - 每个主机都必须是`IP:port`对，其中端口是Docker引擎端口（`tcp/2375`）。
- en: 'So, in each terminal you''re connected to every machine, execute this:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在每个终端上，您连接到每台机器，执行以下操作：
- en: '[PRE17]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Tip
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: When using the `nodes://` mechanism, you can use Ansible-like host range patterns,
    so compact the syntax of three contiguous IPs like nodes:`//192.168.99.101:2375,192.168.99.102:2375,192.168.99.103:2375`
    In nodes:`//192.168.99.[101:103]:2375`
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用`nodes://`机制时，您可以使用类似Ansible的主机范围模式，因此可以使用三个连续IP的紧凑语法，例如nodes:`//192.168.99.101:2375,192.168.99.102:2375,192.168.99.103:2375`
    在nodes:`//192.168.99.[101:103]:2375`
- en: 'Now, as the next step, we''ll connect to it and inspect its information before
    starting using for running containers. For convenience, open a new terminal. We
    connect now not anymore to the Docker engine on one of our nodes, but to the Docker
    Swarm. So we will connect to `tcp/3376` and not to `tcp/2375` anymore. For the
    purpose of showing in detail what we''re doing, let''s start by sourcing `node0`
    variables:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，作为下一步，我们将连接到它并在开始运行容器之前检查其信息。为了方便起见，打开一个新的终端。我们现在连接的不再是我们的一个节点上的Docker引擎，而是Docker
    Swarm。因此，我们将连接到`tcp/3376`而不再是`tcp/2375`。为了详细展示我们正在做什么，让我们从`node0`变量开始：
- en: '[PRE18]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Copy and paste the eval line, as you already know, and check what shell variables
    are exported with the following command:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 复制并粘贴eval行，正如您已经知道的那样，并使用以下命令检查导出的shell变量：
- en: '[PRE19]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'We now need to do the following:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要做以下事情：
- en: Change the `DOCKER_HOST` to connect to Swarm port `tcp/3376` instead of Engine
    `tcp/2375`
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`DOCKER_HOST`更改为连接到Swarm端口`tcp/3376`，而不是引擎`tcp/2375`
- en: Disable `DOCKER_TLS_VERIFY`.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 禁用`DOCKER_TLS_VERIFY`。
- en: Disable `DOCKER_CERT_PATH`.![Starting Docker Swarm](images/image_01_019.jpg)
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 禁用`DOCKER_CERT_PATH`。![启动Docker Swarm](images/image_01_019.jpg)
- en: 'You should have a configuration similar to this:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该有类似于这样的配置：
- en: '![Starting Docker Swarm](images/image_01_020.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![启动Docker Swarm](images/image_01_020.jpg)'
- en: 'If we now connect to the Docker swarm at `3376`, and show some info, we see
    that we''re running Swarm:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在连接到`3376`的Docker Swarm，并显示一些信息，我们会看到我们正在运行Swarm：
- en: '![Starting Docker Swarm](images/image_01_021.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![启动Docker Swarm](images/image_01_021.jpg)'
- en: Congratulations! You just started your first Docker cluster with Swarm. We can
    see that we still have no containers running on our cluster apart from the four
    swarms, but the Server Version is swarm/1.2.3, the scheduling strategy is spread,
    and, most importantly, we have four healthy nodes in our swarm (details of each
    Swarm node follow).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您刚刚启动了您的第一个带有Swarm的Docker集群。我们可以看到除了四个Swarm之外，我们的集群上还没有运行任何容器，但服务器版本是swarm/1.2.3，调度策略是spread，最重要的是，我们的Swarm中有四个健康节点（每个Swarm节点的详细信息如下）。
- en: 'Also, you can get some extra information regarding the scheduler behavior of
    this Swarm cluster:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您可以获取有关此Swarm集群调度程序行为的一些额外信息：
- en: '[PRE20]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: A spread scheduling strategy means that Swarm will attempt to place containers
    on the less utilized host and the listed filters are available when you create
    containers, thus allowing you to decide to manually suggest some options. For
    example, you might want to make your Galera cluster containers geographically
    near but on different hosts.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: spread调度策略意味着Swarm将尝试将容器放置在使用较少的主机上，并且在创建容器时提供了列出的过滤器，因此允许您决定手动建议一些选项。例如，您可能希望使您的Galera集群容器在地理上靠近但位于不同的主机上。
- en: 'But, what''s the size of this Swarm? You can see it at the very end of this
    output:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，这个Swarm的大小是多少？您可以在输出的最后看到它：
- en: '![Starting Docker Swarm](images/image_01_022.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![启动Docker Swarm](images/image_01_022.jpg)'
- en: 'It means that on this tiny Swarm you have the total availability of these resources:
    four CPUs and 4GB of memory. That''s just what we expected, by merging the computational
    resources of 4 VirtualBox hosts with a CPU and 1GB of memory each.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在这个小小的Swarm上，您拥有这些资源的总可用性：四个CPU和4GB的内存。这正是我们预期的，通过合并每个具有1GB内存的CPU的4个VirtualBox主机的计算资源。
- en: Test your Swarm cluster
  id: totrans-272
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试您的Swarm集群
- en: Now that we have a Swarm cluster, it's time to start using it. We'll show that
    the spread strategy algorithm will decide to place containers to the less loaded
    hosts. In this example, it's really easy, as we start with four empty nodes. So,
    we're connected to Swarm and Swarm will put containers on hosts. We start one
    nginx container, mapping its port tcp/80 to the host (machine) port `tcp/80`.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个Swarm集群，是时候开始使用它了。我们将展示扩展策略算法将决定将容器放置在负载较轻的主机上。在这个例子中，这很容易，因为我们从四个空节点开始。所以，我们连接到Swarm，Swarm将在主机上放置容器。我们启动一个nginx容器，将其端口tcp/80映射到主机（机器）端口`tcp/80`。
- en: '[PRE21]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this example, we see that the Swarm scheduler decided to place this container
    onto `node1`:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们看到Swarm调度程序决定将这个容器放到`node1`上：
- en: '![Test your Swarm cluster](images/image_01_023.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
  zh: '![测试您的Swarm集群](images/image_01_023.jpg)'
- en: 'Since we have to bind a port `tcp/80` to any host, we will have only four chances,
    four containers on four different hosts. Let''s create new nginx containers and
    see what happens:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们必须将端口`tcp/80`绑定到任何主机，我们只有四次机会，四个不同主机上的四个容器。让我们创建新的nginx容器，看看会发生什么：
- en: '[PRE22]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now we have 4 nginx containers placed on our 4 Swarm hosts:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有4个nginx容器放置在我们的4个Swarm主机上：
- en: '![Test your Swarm cluster](images/image_01_024.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![测试您的Swarm集群](images/image_01_024.jpg)'
- en: 'Now we try to create a new nginx:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们尝试创建一个新的nginx：
- en: '[PRE23]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'What happened is just that Swarm wasn''t able to find a suitable host to place
    a new container on, because on all hosts, port `tcp/80` are all occupied. After
    running these 4 nginx containers, plus the four swarm containers (for the infrastructure
    management), as we expected, we have eight running containers on this Swarm cluster:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 发生的事情只是Swarm无法找到一个合适的主机来放置一个新的容器，因为在所有主机上，端口`tcp/80`都被占用。在运行了这4个nginx容器之后，再加上四个Swarm容器（用于基础设施管理），正如我们所预期的那样，我们在这个Swarm集群上有八个正在运行的容器：
- en: '![Test your Swarm cluster](images/image_01_025.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![测试您的Swarm集群](images/image_01_025.jpg)'
- en: This is how Swarm v1 was intended to work (and still does its job).
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Swarm v1的预期工作方式（它仍然在工作）。
- en: Swarm, today
  id: totrans-286
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm，今天
- en: In this section, we'll set up a small cluster with the new Swarm mode built
    in Docker Engine 1.12 or later.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用内置在Docker Engine 1.12或更高版本中的新Swarm模式设置一个小集群。
- en: 'At the DockerCon16, among the big announcements, two drew big attention regarding
    containers orchestration:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在DockerCon16上，大量的公告中，有两个关于容器编排引起了很大的关注：
- en: The integration between the Engine and Swarm, called the Docker Swarm mode.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引擎和Swarm之间的集成，称为Docker Swarm模式。
- en: SwarmKit
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SwarmKit
- en: In practice, the Docker daemon, starting from version 1.12, adds the possibility
    to run a so-called Swarm Mode. New CLI commands were added to the docker client,
    such as `node`, `service`, `stack`, `deploy`, alongside with, of course, `swarm`.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，Docker守护程序从1.12版本开始增加了运行所谓的Swarm Mode的可能性。docker客户端添加了新的CLI命令，如`node`、`service`、`stack`、`deploy`，当然还有`swarm`。
- en: We'll cover Swarm Mode and SwarmKit in more detail starting from[Chapter 3](ch03.html
    "Chapter 3. Meeting Docker Swarm Mode"), *Meeting Docker Swarm Mode*, but now
    that we finished the example with Swarm v1, we're going to give the reader a taste
    on how Swarm v2 has a much simpler user experience than v1\. The only requirement
    to use Swarm v2 is to have a daemon version of at least version 1.12-rc1\. But
    with Docker Machine 0.8.0-rc1+, you can provision Docker hosts fulfilling this
    requirement with the usual procedure.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从[第3章](ch03.html "第3章。了解Docker Swarm模式")开始更详细地介绍Swarm Mode和SwarmKit，但现在我们完成了Swarm
    v1的示例，我们将让读者体验一下Swarm v2比v1具有更简单的用户体验。使用Swarm v2的唯一要求是至少有1.12-rc1版本的守护程序版本。但是，使用Docker
    Machine 0.8.0-rc1+，您可以使用通常的程序满足这一要求来提供Docker主机。
- en: 'Docker also announced Docker for AWS and Docker for Azure at DockerCon 2016\.
    Not only AWS and Azure, but actually we''re also fans of DigitalOcean, so we created
    a new tool that wraps around `doctl` the DigitalOcean command line interface,
    to help provision Docker cluster in the new massively way. The tool is called
    `belt` and now available from [http://github.com/chanwit/belt](http://github.com/chanwit/belt).
    You can pull belt with this command:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Docker还在DockerCon 2016上宣布了Docker for AWS和Docker for Azure。不仅仅是AWS和Azure，实际上我们也是DigitalOcean的粉丝，所以我们创建了一个新工具，它包装了DigitalOcean命令行界面的`doctl`，以帮助以新的大规模方式提供Docker集群。该工具称为`belt`，现在可以从[http://github.com/chanwit/belt](http://github.com/chanwit/belt)获取。您可以使用以下命令拉取belt：
- en: '`go get github.com/chanwit/belt`'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '`go get github.com/chanwit/belt`'
- en: or download the binary from the **Release** tab of the project.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 或者从项目的**Release**标签中下载二进制文件。
- en: 'First, we''ll prepare a template file for provisioning on DigitalOcean. Your
    `.belt.yaml` will look like this:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将为在DigitalOcean上进行配置准备一个模板文件。您的`.belt.yaml`将如下所示：
- en: '[PRE24]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Please note that my image number `18153887` is the snapshot containing Docker
    1.12\. DigitalOcean usually makes the latest Docker image available after every
    release. To make you able to control your cluster, SSH key needs to be there.
    For the field `ssh_key_fingerprint`, you can either put the finger print as well
    as the key ID.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我的镜像编号`18153887`是包含Docker 1.12的快照。DigitalOcean通常会在每次发布后提供最新的Docker镜像。为了让您能够控制您的集群，需要有SSH密钥。对于字段`ssh_key_fingerprint`，您可以放置指纹以及密钥ID。
- en: 'Do not forget to set your `DIGITALOCEAN_ACCESS_TOKEN` environment variable.
    Also, Belt recognizes the same set of Docker Machine shell variables. If you are
    familiar with Docker Machine you''ll know how to set them. To refresh, these are
    the shell variables we introduced in the previous section:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记设置您的`DIGITALOCEAN_ACCESS_TOKEN`环境变量。此外，Belt也识别相同的一组Docker Machine shell变量。如果您熟悉Docker
    Machine，您将知道如何设置它们。刷新一下，这些是我们在上一节介绍的shell变量：
- en: '`export DOCKER_TLS_VERIFY="1"`'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`export DOCKER_TLS_VERIFY="1"`'
- en: '`export DOCKER_HOST="tcp://<IP ADDRESS>:2376"`'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`export DOCKER_HOST="tcp://<IP ADDRESS>:2376"`'
- en: '`export DOCKER_CERT_PATH="/Users/user/.docker/machine/machines/machine"`'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`export DOCKER_CERT_PATH="/Users/user/.docker/machine/machines/machine"`'
- en: '`export DOCKER_MACHINE_NAME="machine"`'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`export DOCKER_MACHINE_NAME="machine"`'
- en: 'So, now let''s see how to use Belt:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在让我们看看如何使用Belt：
- en: '[PRE25]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Now we create a Swarm of four nodes each with 512M of memory:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们创建一个包含512M内存的四个节点的Swarm：
- en: '[PRE26]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You can see that we can specify a set of nodes with similar syntax node[1:4].
    This command created four nodes on DigitalOcean. Please wait for about 55 seconds
    for all nodes to be provisioned. Then you can list them:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到，我们可以使用类似的语法node[1:4]指定一组节点。此命令在DigitalOcean上创建了四个节点。请等待大约55秒，直到所有节点都被配置。然后您可以列出它们：
- en: '[PRE27]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Their status now has changed from "new" to "active". All IP addresses are assigned.
    Everything is good to go for now.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的状态现在已从“新”更改为“活动”。所有IP地址都已分配。目前一切都进行得很顺利。
- en: We now can start Swarm.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以启动Swarm。
- en: Before that make sure we are running Docker 1.12\. We check this on `node1`.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 在此之前，请确保我们正在运行Docker 1.12。我们在`node1`上检查这一点。
- en: '[PRE28]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The `belt docker` command is just a thin wrapper command that sends the whole
    command line going through SSH to your Docker host. So this tool will not get
    in the way and your Docker Engines is always in-control.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '`belt docker`命令只是一个薄包装命令，它将整个命令行通过SSH发送到您的Docker主机。因此，这个工具不会妨碍您的Docker引擎始终处于控制状态。'
- en: Now we will initialize the first node with Swarm Mode.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用Swarm Mode初始化第一个节点。
- en: '[PRE29]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Then we''ll join other three nodes to this newly formed cluster. Joining a
    large cluster is a tedious task. Instead of going through every node and do docker
    swarm join manually, we''ll let `belt` do this for us:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将其他三个节点加入到这个新形成的集群中。加入一个大集群是一项繁琐的任务。我们将让`belt`代替我们手动执行此操作，而不是逐个节点进行docker
    swarm join：
- en: '[PRE30]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Tip
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示
- en: You can of course be able to run: `belt --host node2 docker swarm join <node1's
    IP>:2377` to manually join node2 to your cluster.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您可以运行：`belt --host node2 docker swarm join <node1's IP>:2377`，手动将node2加入到您的集群中。
- en: 'And you''ll get this view of cluster:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 然后您将看到集群的这个视图：
- en: '[PRE31]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Congratulations! You just installed a Swarm cluster on DigitalOcean.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您刚在DigitalOcean上安装了一个Swarm集群。
- en: We now create a service for `nginx`. This command creates an Nginx service with
    2 instances of containers published at port 80.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在为`nginx`创建一个服务。这个命令将创建一个Nginx服务，其中包含2个容器实例，发布在80端口。
- en: '[PRE32]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Here we go:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开始吧：
- en: '[PRE33]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Now let's scale it to 4 nodes.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们将其扩展到4个节点。
- en: '[PRE34]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Similar to Docker Swarm, you can now use `belt ip` to see where the node runs.
    You can use any IP address to browse the NGINX service. It's available on every
    node.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于Docker Swarm，您现在可以使用`belt ip`来查看节点的运行位置。您可以使用任何IP地址来浏览NGINX服务。它在每个节点上都可用。
- en: '[PRE35]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This is how Swarm Mode looks like starting from Docker 1.12.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是Docker 1.12开始的Swarm模式的样子。
- en: Summary
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we met Docker Swarm, defined its aims, features, and architecture.
    We also reviewed some of the other possible open source alternatives to Swarm,
    and their relationships with it. Finally, we installed and started using Swarm
    by creating a simple local cluster made of four hosts on Virtualbox and on Digital
    Ocean.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们了解了Docker Swarm，定义了其目标、特性和架构。我们还回顾了一些其他可能的开源替代方案，并介绍了它们与Swarm的关系。最后，我们通过在Virtualbox和Digital
    Ocean上创建一个由四个主机组成的简单本地集群来安装和开始使用Swarm。
- en: Clusterize containers with Swarm will be the main topic for the whole book,
    but before we start using Swarm in production, we'll understand some theory before,
    beginning with the discovery services, the topic of [Chapter 2](ch02.html "Chapter 2. Discover
    the Discovery Services"), *Discover the Discovery Services*.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Swarm对容器进行集群化将是整本书的主题，但在我们开始在生产环境中使用Swarm之前，我们将先了解一些理论知识，首先是发现服务的主题，即[第2章](ch02.html
    "第2章。发现发现服务")*发现发现服务*。
