- en: Docker Swarm
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm
- en: In this chapter, we will learn what Docker swarm is, and how to set up a Docker
    swarm cluster. We'll learn about all of the swarm management commands, and then
    we will find out more about swarm managers and swarm workers. Next, we will discover
    swarm services. And finally, we will find out how easy it is to access a container
    application running on any node in a swarm cluster.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习什么是Docker swarm，以及如何设置Docker swarm集群。我们将了解所有的集群管理命令，然后我们将更多地了解集群管理者和集群工作者。接下来，我们将发现集群服务。最后，我们将发现在集群中任何节点上运行的容器应用程序是多么容易访问。
- en: There are currently over 17,000,000 shipping containers in the world, and 5
    or 6,000,000 of them are currently shipping around the world on vessels, trucks,
    and trains. In total, they make around 200,000,000 trips a year.      – [https://www.billiebox.co.uk/facts-about-shipping-containers](https://www.billiebox.co.uk/facts-about-shipping-containers)
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 目前全球有超过17,000,000个集装箱，其中5或6,000,000个正在船舶、卡车和火车上运输。总共，它们每年大约进行200,000,000次旅行。-
    [https://www.billiebox.co.uk/facts-about-shipping-containers](https://www.billiebox.co.uk/facts-about-shipping-containers)
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: What is Docker swarm?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是Docker swarm？
- en: Setting up a Docker swarm cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立Docker swarm集群
- en: Managers and workers
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理者和工作者
- en: Swarm services
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群服务
- en: Accessing container applications in a swarm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问集群中的容器应用程序
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will be pulling Docker images from Docker's public repo, so basic internet
    access is required to execute the examples within this chapter. You will be setting
    up a multi-node swarm cluster, so you will need multiple nodes to complete the
    examples in this chapter. You can use physical servers, EC2 instances, Virtual
    Machines on vSphere or Workstation or even on Virtual Box. I utilized 6 VMs on
    Vmware Workstation for my nodes. Each VM is configured with 1 GB ram, 1 CPU, and
    20 GB HDD. The guest OS utilized is Xubuntu 18.04 for its small size and full
    Ubuntu feature set. Xubuntu can be downloaded from [https://xubuntu.org/download/](https://xubuntu.org/download/). Virtually
    any modern Linux operating system choice would be acceptable for the nodes.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 您将从Docker的公共存储库中拉取Docker镜像，因此需要基本的互联网访问权限来执行本章中的示例。您将设置一个多节点的集群，因此需要多个节点来完成本章的示例。您可以使用物理服务器、EC2实例、vSphere或Workstation上的虚拟机，甚至是Virtual
    Box上的虚拟机。我在Vmware Workstation上使用了6个虚拟机作为我的节点。每个虚拟机配置为1GB内存、1个CPU和20GB硬盘。所使用的客户操作系统是Xubuntu
    18.04，因为它体积小且具有完整的Ubuntu功能集。Xubuntu可以从[https://xubuntu.org/download/](https://xubuntu.org/download/)下载。任何现代的Linux操作系统都可以作为节点的选择。
- en: 'The code files of this chapter can be found on GitHub:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码文件可以在GitHub上找到：
- en: '[https://github.com/PacktPublishing/Docker-Quick-Start-Guide/tree/master/Chapter05](https://github.com/PacktPublishing/Docker-Quick-Start-Guide/tree/master/Chapter05)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Docker-Quick-Start-Guide/tree/master/Chapter05](https://github.com/PacktPublishing/Docker-Quick-Start-Guide/tree/master/Chapter05)'
- en: 'Check out the following video to see the code in action: [http://bit.ly/2KENJOD](http://bit.ly/2KENJOD)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的运行情况：[http://bit.ly/2KENJOD](http://bit.ly/2KENJOD)
- en: What is Docker swarm?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是Docker swarm？
- en: 'You probably have not noticed this, but so far, all of the Docker workstation
    deployments, or nodes that we have used in our examples have been run in single-engine
    mode. What does that mean? Well, it tells us that the Docker installation is managed
    directly and as a standalone Docker environment. While this is effective, it is
    not very efficient and it does not scale well. Of course, Docker understands the
    limitations and has provided a powerful solution to this problem. It is called
    Docker swarm. Docker swarm is a way to link Docker nodes together, and manage
    those nodes and the dockerized applications that run on them efficiently and at
    scale. Simply stated, a Docker swarm is a group of Docker nodes connected and
    managed as a cluster or swarm. Docker swarm is built into the Docker engine, so
    no additional installation is required to use it. When a Docker node is part of
    a swarm, it is running in swarm mode. If there is any doubt, you can easily check
    whether a system running Docker is part of a swarm or is running in single-engine
    mode using the `docker system info` command:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能没有注意到，但到目前为止，我们在示例中使用的所有Docker工作站部署或节点都是以单引擎模式运行的。这是什么意思？这告诉我们，Docker安装是直接管理的，作为一个独立的Docker环境。虽然这是有效的，但它不太高效，也不具有良好的扩展性。当然，Docker了解到这些限制，并为这个问题提供了一个强大的解决方案。它被称为Docker蜂群。Docker蜂群是将Docker节点连接在一起，并有效地管理这些节点和在其上运行的docker化应用程序的一种方式。简而言之，Docker蜂群是一组Docker节点连接并作为集群或蜂群进行管理。Docker蜂群内置在Docker引擎中，因此无需额外安装即可使用。当Docker节点是蜂群的一部分时，它运行在蜂群模式下。如果有任何疑问，您可以使用`docker
    system info`命令轻松检查运行Docker的系统是否是蜂群的一部分或者是以单引擎模式运行：
- en: '![](Images/9e0e8cfa-39dd-47f7-a668-80354184afee.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/9e0e8cfa-39dd-47f7-a668-80354184afee.png)'
- en: 'The features that provide swarm mode are part of the Docker SwarmKit, which
    is a tool for orchestrating distributed systems at scale, that is, Docker swarm
    clusters. Once a Docker node joins a swarm, it becomes a swarm node, becoming
    either a Manager node or a Worker node. We will talk about the difference between
    managers and workers shortly. For now, know that the very first Docker node to
    join a new swarm becomes the first Manager, also known as the Leader. There is
    a *lot* of technical magic that happens when that first node joins a swarm (actually,
    it creates and initializes the swarm, and then joins it) and becomes the leader.
    Here is some of the wizardry that happens (in no particular order):'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 提供蜂群模式的功能是Docker SwarmKit的一部分，这是一个用于在规模上编排分布式系统的工具，即Docker蜂群集群。一旦Docker节点加入蜂群，它就成为蜂群节点，成为管理节点或工作节点。我们很快会谈到管理节点和工作节点之间的区别。现在，知道加入新蜂群的第一个Docker节点成为第一个管理节点，也被称为领导者。当第一个节点加入蜂群并成为领导者时，会发生很多技术上的魔法（实际上，它创建并初始化了蜂群，然后加入了蜂群）。以下是发生的一些巫术（没有特定顺序）：
- en: A Swarm-ETCD-based configuration database or cluster store is created and encrypted
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了基于Swarm-ETCD的配置数据库或集群存储，并进行了加密
- en: Mutual TLS (mTLS) authentication and encryption is set up for all inter-node
    communication
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为所有节点间通信设置了双向TLS（mTLS）认证和加密
- en: Container orchestration is enabled, which takes responsibility for managing
    which containers run on which nodes
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用了容器编排，负责管理容器在哪些节点上运行
- en: The cluster store is configured to automatically replicate to all manager nodes
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群存储被配置为自动复制到所有管理节点
- en: The node gets assigned a cryptographic ID
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该节点被分配了一个加密ID
- en: A Raft-based distributed consensus-management system is enabled
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启用了基于Raft的分布式共识管理系统
- en: The node becomes a Manager and is elected to the status of swarm leader
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点成为管理节点并被选举为蜂群领导者
- en: The swarm managers are configured for HA
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蜂群管理器被配置为高可用
- en: A public-key infrastructure system is created
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建了一个公钥基础设施系统
- en: The node becomes the certificate authority, allowing it to issue client certificates
    to any nodes that join the swarm
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点成为证书颁发机构，允许其向加入集群的任何节点颁发客户端证书
- en: A default 90-day certificate-rotation policy is configured on the certificate
    authority
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 证书颁发机构上配置了默认的90天证书轮换策略
- en: The node gets issued its client certificate, which includes its name, ID, the
    swarm ID, and the node's role in the swarm
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点获得其客户端证书，其中包括其名称、ID、集群ID和节点在集群中的角色
- en: Creating a new cryptographic join token for adding new swarm managers occurs
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为添加新的swarm管理者创建一个新的加密加入令牌
- en: Creating a new cryptographic join token for adding new swarm workers occurs
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为添加新的swarm工作节点创建一个新的加密加入令牌
- en: That list represents a lot of powerful features that you get by joining the
    first node to a swarm. And, with great power comes great responsibility, meaning
    that you really need to be prepared to do a lot of work to create your Docker
    swarm, as you might well imagine. So, let's move on to the next section, where
    we will discuss how to enable all of these features when you set up a swarm cluster.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该列表代表了通过将第一个节点加入到swarm中获得的许多强大功能。伴随着强大的功能而来的是巨大的责任，这意味着您确实需要准备好做大量工作来创建您的Docker
    swarm，正如您可能想象的那样。因此，让我们继续下一节，我们将讨论在设置swarm集群时如何启用所有这些功能。
- en: References
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Check out the following links for more information:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接获取更多信息：
- en: The repository for SwarmKit: [https://github.com/docker/swarmkit](https://github.com/docker/swarmkit)
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SwarmKit的存储库：[https://github.com/docker/swarmkit](https://github.com/docker/swarmkit)
- en: 'The Raft consensus algorithm: [https://raft.github.io/](https://raft.github.io/)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Raft一致性算法：[https://raft.github.io/](https://raft.github.io/)
- en: How to set up a Docker swarm cluster
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何设置Docker swarm集群
- en: 'You have just learned about all of the incredible features that get enabled
    and set up when you create a Docker swarm cluster. So, now I am going to show
    you all of the steps needed to set up a Docker swarm cluster. Are you ready? Here
    they are:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 您刚刚了解了创建Docker swarm集群时启用和设置的所有令人难以置信的功能。现在我将向您展示设置Docker swarm集群所需的所有步骤。准备好了吗？以下是它们：
- en: '[PRE0]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: What? Wait? Where is the rest of it? Nope. There is nothing missing. All of
    the setup and functionality that is described in the preceding section is achieved
    with one simple command. With that single `swarm init` command, the swarm cluster
    is created, the node is transformed from a single-instance node into a swarm-mode
    node, the role of manager is assigned to the node and it is elected as the leader
    of the swarm, the cluster store is created, the node becomes the certificate authority
    of the cluster and assigns itself a new certificate that includes a cryptographic
    ID, a new cryptographic join token is created for managers, and another is created
    for workers, and on and on. This is complexity made simple.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 什么？等等？剩下的在哪里？没有。没有遗漏任何内容。在上一节描述的所有设置和功能都可以通过一个简单的命令实现。通过单个的`swarm init`命令，集群被创建，节点从单实例节点转变为swarm模式节点，节点被分配为管理者角色并被选举为集群的领导者，集群存储被创建，节点成为集群的证书颁发机构并为自己分配一个包含加密ID的新证书，为管理者创建一个新的加密加入令牌，为工作节点创建另一个令牌，依此类推。这就是简化的复杂性。
- en: 'The swarm commands make up another Docker management group. Here are the swarm-management
    commands:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: swarm命令组成了另一个Docker管理组。以下是swarm管理命令：
- en: '![](Images/bd6dff1c-08fb-4b1b-9361-ad8741316fff.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/bd6dff1c-08fb-4b1b-9361-ad8741316fff.png)'
- en: 'We''ll review the purpose for each these commands in just a moment, but before
    we do, I want to make you aware of some important networking configurations. We
    will talk more about Docker networking in [Chapter 6](873454a4-2f8e-42df-93ab-7648545167bb.xhtml),
    *Docker Networking*, but for now be aware that you may need to open access to
    some protocols and ports on your Docker nodes to allow Docker swarm to function
    properly. Here is the information straight from Docker''s *Getting started with
    swarm mode* wiki:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在片刻后审查每个命令的目的，但在此之前，我想让您了解一些重要的网络配置。我们将在[第6章](873454a4-2f8e-42df-93ab-7648545167bb.xhtml)
    *Docker Networking*中更多地讨论Docker网络，但现在请注意，您可能需要在Docker节点上打开一些协议和端口的访问权限，以使Docker
    swarm正常运行。以下是来自Docker的*Getting started with swarm mode*维基的信息：
- en: '![](Images/4a75151b-36db-43db-b9e7-ab46c7288927.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/4a75151b-36db-43db-b9e7-ab46c7288927.png)'
- en: 'Two other ports that you may need to open for the REST API are as follows:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能需要为REST API打开的另外两个端口如下：
- en: TCP 2375 for Docker REST API (plain text)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP 2375用于Docker REST API（纯文本）
- en: TCP 2376 for Docker REST API (ssl)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCP 2376用于Docker REST API（ssl）
- en: Alright, let's move on to reviewing the swarm commands.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，让我们继续审查swarm命令。
- en: docker swarm init
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm init
- en: 'You have already seen what the init command is for, that being to create the
    swarm cluster, add (this) the first Docker node to it, and then set up and enable
    all of the swarm features we just covered. The init command can be as simple as
    using it with no parameters, but there are many optional parameters available to
    fine-tune the initialization process. You can get a full list of the optional
    parameters, as usual, by using `--help`, but let''s consider a few of the available
    parameters now:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经看到了init命令的用途，即创建swarm集群，将第一个Docker节点添加到其中，然后设置和启用我们刚刚介绍的所有swarm功能。init命令可以简单地使用它而不带任何参数，但有许多可用的可选参数可用于微调初始化过程。您可以通过使用`--help`获得所有可选参数的完整列表，但现在让我们考虑一些可用的参数：
- en: '`--autolock`: Use this parameter to enable manager autolocking.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--autolock`：使用此参数启用管理器自动锁定。'
- en: '`--cert-expiry duration`: Use this parameter to change the default validity
    period (of 90 days) for node certificates.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--cert-expiry duration`：使用此参数更改节点证书的默认有效期（90天）。'
- en: '`--external-ca external-ca`: Use this parameter to specify one or more certificate-signing
    endpoints, that is, external CAs.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--external-ca external-ca`：使用此参数指定一个或多个证书签名端点，即外部CA。'
- en: docker swarm join-token
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm join-token
- en: 'When you initialize the swarm by running the `swarm init` command on the first
    node, one of the functions that is executed creates unique cryptographic join
    tokens, one joins additional manager nodes, and one joins worker nodes. Using
    the `join-token` command, you can obtain these two join tokens. In fact, using
    the `join-token` command will deliver the full join command for whichever role
    you specify. The role parameter is required. Here are examples of the command:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在第一个节点上运行`swarm init`命令初始化swarm时，执行的功能之一是创建唯一的加密加入令牌，一个加入额外的管理节点，一个加入工作节点。使用`join-token`命令，您可以获取这两个加入令牌。实际上，使用`join-token`命令将为您提供指定角色的完整加入命令。角色参数是必需的。以下是命令的示例：
- en: '[PRE1]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is what that looks like:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是它的样子：
- en: '![](Images/2f9b447e-3447-40f2-8449-5f4d754a4182.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2f9b447e-3447-40f2-8449-5f4d754a4182.png)'
- en: '[PRE2]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that this does not invalidate existing workers that have used the old,
    now invalid, join token. They are still a part of the swarm and are unaffected
    by the change in the join token. Only new nodes that you wish to join to the swarm
    need to use the new token.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这不会使已使用旧的、现在无效的加入令牌的现有工作节点失效。它们仍然是swarm的一部分，并且不受加入令牌更改的影响。只有您希望加入swarm的新节点需要使用新令牌。
- en: docker swarm join
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm join
- en: 'You have already seen the join command used in the preceding *docker swarm
    join-token* section. The join command is used, in conjunction with a cryptographic
    join token, to add a Docker node to the swarm. All nodes except the very first
    node will use the join command to become part of the swarm (the first node uses
    the "init" command, of course). The join command has a few parameters, the most
    important of them being the `--token` parameter. This is the required join token,
    obtainable with the `join-token` command. Here is an example:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经在前面的 *docker swarm join-token* 部分看到了 join 命令的使用。join 命令与加密的 join token 结合使用，用于将
    Docker 节点添加到 swarm 中。除了第一个节点之外，所有节点都将使用 join 命令加入到 swarm 中（第一个节点当然使用 "init" 命令）。join
    命令有一些参数，其中最重要的是 `--token` 参数。这是必需的 join token，可通过 `join-token` 命令获取。以下是一个示例：
- en: '[PRE3]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: You will notice that the role is not needed for this command. This is because
    the token itself is associated with the role it has been created for. When you
    execute the join, the output provides an informational message telling you what
    role the node has joined as manager or worker. If you have inadvertently use a
    manager token to join a worker or vice versa, you can use the `leave` command
    to remove a node from the swarm, and then using the token for the actual desired
    role, rejoin the node to the swarm.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到，此命令不需要角色。这是因为 token 本身与其创建的角色相关联。当您执行 join 时，输出会提供一个信息消息，告诉您节点加入的角色是管理节点还是工作节点。如果您无意中使用了管理节点
    token 加入工作节点，或反之，您可以使用 `leave` 命令将节点从 swarm 中移除，然后使用实际所需角色的 token，重新将节点加入到 swarm。
- en: docker swarm ca
  id: totrans-65
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm ca
- en: 'The `swarm ca` command is used when you want to view the current certificate
    for the swarm, or you need to rotate the current swarm certificate. To rotate
    the certificate, you would include the `--rotate` parameter:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要查看 swarm 的当前证书或需要旋转当前的 swarm 证书时，可以使用 `swarm ca` 命令。要旋转证书，您需要包括 `--rotate`
    参数：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The `swarm ca` command can only be executed successfully on a swarm manager
    node. One reason you might use the rotate swarm certificate feature is if you
    are moving from the internal root CA to an external CA, or vice versa. Another
    reason you might need to rotate the swarm certificate is in the event of one or
    more manager nodes getting compromised. In that case, rotating the swarm certificate
    will block all other managers from being able to communicate with the manager
    that rotated the certificate or each other using the old certificate. When you
    rotate the certificate, the command will remain active, blocking until all swarm
    nodes, both managers and workers, have been updated. Here is an example of rotating
    the certificate on a very small cluster:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`swarm ca` 命令只能在 swarm 管理节点上成功执行。您可能使用旋转 swarm 证书功能的一个原因是，如果您正在从内部根 CA 切换到外部
    CA，或者反之。另一个可能需要旋转 swarm 证书的原因是，如果一个或多个管理节点受到了威胁。在这种情况下，旋转 swarm 证书将阻止所有其他管理节点能够使用旧证书与旋转证书的管理节点或彼此进行通信。旋转证书时，命令将保持活动状态，直到所有
    swarm 节点（管理节点和工作节点）都已更新。以下是在一个非常小的集群上旋转证书的示例：'
- en: '![](Images/2a03929d-d015-43f8-a233-3a03370983b6.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/2a03929d-d015-43f8-a233-3a03370983b6.png)'
- en: 'Since the command will remain active until all nodes have updated both the
    TLS certificate and the CA certificate, it can present an issue if there are nodes
    in the swarm that are offline. When that is a potential problem, you can include
    the `--detach` parameter, and the command will initiate the certificate rotation
    and return control immediately to the session. Be aware that you will not get
    any status as to the progress, success, or failure of the certificate rotation
    when you use the `--detach` optional parameter. You can use the node ls command
    to query the state of the certificates within the cluster to check the progress.
    Here is the full command you can use:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 由于命令将保持活动状态，直到所有节点都更新了TLS证书和CA证书，如果集群中有离线的节点，可能会出现问题。当这是一个潜在的问题时，您可以包括`--detach`参数，命令将启动证书旋转并立即返回会话控制。请注意，当您使用`--detach`可选参数时，您将不会得到有关证书旋转进度、成功或失败的任何状态。您可以使用node
    ls命令查询集群中证书的状态以检查进度。以下是您可以使用的完整命令：
- en: '[PRE5]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `ca rotate` command will continue trying to complete, either in the foreground,
    or in the background if detached. If a node was offline when the rotate is initiated,
    and it comes back online, the certificate rotation will complete. Here is an example
    of `node04` being offline when the rotate command was executed, and then a while
    later, after it came back on; check the status found it successfully rotated:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`ca rotate`命令将继续尝试完成，无论是在前台还是在后台（如果分离）。如果在旋转启动时节点离线，然后重新上线，证书旋转将完成。这里有一个示例，`node04`在执行旋转命令时处于离线状态，然后过了一会儿，它重新上线；检查状态发现它成功旋转了：'
- en: '![](Images/5889e8b1-e526-4871-9c48-c0a45664a4c2.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/5889e8b1-e526-4871-9c48-c0a45664a4c2.png)'
- en: Another important point to remember is that rotating the certificate will immediately
    invalidate both of the current join tokens.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的要点要记住的是，旋转证书将立即使当前的加入令牌无效。
- en: docker swarm unlock
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm unlock
- en: 'You may recall from the discussion regarding the `docker swarm init` command
    that one of the optional parameters that you can include with the `init` command
    is `--autolock`. Using this parameter will enable the autolock feature on the
    swarm cluster. What does that mean? Well, when a swarm cluster is configured to
    use auto-locking, any time the docker daemon of a manager node goes offline, and
    then comes back online (that is, is restarted) it is necessary to enter an unlock
    key to allow the node to rejoin the swarm. Why would you use the auto-lock feature
    to lock your swarm? The auto-lock feature helps to protect the mutual TLS encryption
    key of the swarm, along with the encrypt and decrypt keys used with the swarm''s
    raft logs. It is an additional security feature intended to supplement Docker
    Secrets. When the docker daemon restarts on the manager node of a locked swarm,
    you must enter the unlock key. Here is what using the unlock key looks like:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还记得关于`docker swarm init`命令的讨论，其中一个可选参数是`--autolock`。使用此参数将在集群中启用自动锁定功能。这是什么意思？嗯，当一个集群配置为使用自动锁定时，任何时候管理节点的docker守护程序离线，然后重新上线（即重新启动），都需要输入解锁密钥才能允许节点重新加入集群。为什么要使用自动锁定功能来锁定您的集群？自动锁定功能有助于保护集群的相互TLS加密密钥，以及用于集群的raft日志的加密和解密密钥。这是一个旨在补充Docker
    Secrets的额外安全功能。当锁定的集群的管理节点上的docker守护程序重新启动时，您必须输入解锁密钥。以下是使用解锁密钥的样子：
- en: '![](Images/cb49b249-6ef8-4013-a8f4-a1aa987b8927.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/cb49b249-6ef8-4013-a8f4-a1aa987b8927.png)'
- en: By the way, to the rest of the swarm, a manager node that has not been unlocked
    will report as down, even though the docker daemon is running. The swarm auto-lock
    feature can be enabled or disabled on an existing swarm cluster using the `swarm
    update` command, which we will take a look at shortly. The unlock key is generated
    during the swarm initialization and will be presented on the command line at that
    time. If you have lost the unlock key, you can retrieve it on an unlocked manager
    node using the `swarm unlock-key` command.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，对于其余的群集，尚未解锁的管理节点将报告为已关闭，即使Docker守护程序正在运行。Swarm自动锁定功能可以使用`swarm update`命令在现有的Swarm集群上启用或禁用，我们很快将看一下。解锁密钥是在Swarm初始化期间生成的，并将在那时在命令行上呈现。如果您丢失了解锁密钥，可以使用`swarm
    unlock-key`命令在未锁定的管理节点上检索它。
- en: docker swarm unlock-key
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm unlock-key
- en: 'The `swarm unlock-key` command is much like the `swarm ca` command. The unlock-key
    command can be used to retrieve the current swarm unlock key, or it can be used
    to rotate the unlock key to a new one:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`swarm unlock-key`命令很像`swarm ca`命令。解锁密钥命令可用于检索当前的Swarm解锁密钥，或者可以用于将解锁密钥更改为新的：'
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Depending on the size of the swarm cluster, the unlock key rotation can take
    a while for all of the manager nodes to get updated.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Swarm集群的大小，解锁密钥轮换可能需要一段时间才能更新所有管理节点。
- en: It is a good idea to keep the current (old) key handy for a while when you rotate
    the unlock key, on the off-chance that a manager node goes offline before getting
    the updated key. That way, you can still unlock the node using the old key. Once
    the node is unlocked and receives the rotated (new) unlock key, the old key can
    be discarded.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 当您轮换解锁密钥时，最好在更新密钥之前将当前（旧）密钥随手放在一边，以防万一管理节点在获取更新的密钥之前离线。这样，您仍然可以使用旧密钥解锁节点。一旦节点解锁并接收到轮换（新）解锁密钥，旧密钥就可以丢弃了。
- en: As you might expect, the `swarm unlock-key` command is only useful when issued
    on a manager node of a cluster with the auto-lock feature enabled. If you have
    a cluster that does not have the auto-lock feature enabled, you can enable it
    with the `swarm update` command.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能期望的那样，`swarm unlock-key`命令只在启用了自动锁定功能的集群的管理节点上使用时才有用。如果您的集群未启用自动锁定功能，可以使用`swarm
    update`命令启用它。
- en: docker swarm update
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm update
- en: 'There are several swarm cluster features that are enabled or configured when
    you initialize the cluster on the first manager node via the `docker swarm init`
    command. There may be times that you want to change which features are enabled,
    disabled, or configured after the cluster has been initialized. To accomplish
    this, you will need to use the `swarm update` command. For example, you may want
    to enable the auto-lock feature for your swarm cluster. Or, you might want to
    change the length of time that certificates are valid for. These are the types
    of changes you can execute using the `swarm update` command. Doing so might look
    like this:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个管理节点上通过`docker swarm init`命令初始化集群时，将启用或配置几个Swarm集群功能。在集群初始化后，可能会有时候您想要更改哪些功能已启用、已禁用或已配置。要实现这一点，您需要使用`swarm
    update`命令。例如，您可能想要为Swarm集群启用自动锁定功能。或者，您可能想要更改证书有效期。这些都是您可以使用`swarm update`命令执行的更改类型。这样做可能看起来像这样：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Here is the list of settings that can be affected by the `swarm update` command:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是`swarm update`命令可能影响的设置列表：
- en: '![](Images/4137a701-e2f1-4dd9-886a-7f344bcc1e65.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/4137a701-e2f1-4dd9-886a-7f344bcc1e65.png)'
- en: docker swarm leave
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: docker swarm leave
- en: 'This one is pretty much what you would expect. You can remove a docker node
    from a swarm with the `leave` command. Here is an example of needing to use the
    `leave` command to correct a user error:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这基本上是你所期望的。您可以使用`leave`命令从swarm中移除docker节点。以下是需要使用`leave`命令来纠正用户错误的示例：
- en: '![](Images/4e74723e-4d0d-4f2a-8d68-ca2e556fe0a0.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/4e74723e-4d0d-4f2a-8d68-ca2e556fe0a0.png)'
- en: Node03 was intended to be a manager node. I accidentally added the node as a
    worker. Realizing my error, I used the `swarm leave` command to remove the node
    from the swarm, putting it back into single instance mode. Then, using the *manager*
    join token, I re-added the node to the swarm as a manager. Phew! Crisis averted.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Node03原本是一个管理节点。我不小心将该节点添加为工作者。意识到我的错误后，我使用`swarm leave`命令将节点从swarm中移除，将其放回单实例模式。然后，使用*manager*加入令牌，我将节点重新添加到swarm作为管理者。哦！危机已解除。
- en: References
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Check out these links for more information:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接获取更多信息：
- en: Getting started with swarm mode tutorial: [https://docs.docker.com/engine/swarm/swarm-tutorial/](https://docs.docker.com/engine/swarm/swarm-tutorial/)
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用swarm模式教程入门：[https://docs.docker.com/engine/swarm/swarm-tutorial/](https://docs.docker.com/engine/swarm/swarm-tutorial/)
- en: The `docker swarm init` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_init/](https://docs.docker.com/engine/reference/commandline/swarm_init/)
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm init`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_init/](https://docs.docker.com/engine/reference/commandline/swarm_init/)'
- en: The `docker swarm ca` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_ca/](https://docs.docker.com/engine/reference/commandline/swarm_ca/)
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm ca`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_ca/](https://docs.docker.com/engine/reference/commandline/swarm_ca/)'
- en: The `docker swarm join-token` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_join-token/](https://docs.docker.com/engine/reference/commandline/swarm_join-token/)
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm join-token`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_join-token/](https://docs.docker.com/engine/reference/commandline/swarm_join-token/)'
- en: The `docker swarm join` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_join/](https://docs.docker.com/engine/reference/commandline/swarm_join/)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm join`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_join/](https://docs.docker.com/engine/reference/commandline/swarm_join/)'
- en: The `docker swarm unlock` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_unlock/](https://docs.docker.com/engine/reference/commandline/swarm_unlock/)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm unlock`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_unlock/](https://docs.docker.com/engine/reference/commandline/swarm_unlock/)'
- en: The `docker swarm unlock-key` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/](https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm unlock-key`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/](https://docs.docker.com/engine/reference/commandline/swarm_unlock-key/)'
- en: The `docker swarm update` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_update/](https://docs.docker.com/engine/reference/commandline/swarm_update/)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm update`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_update/](https://docs.docker.com/engine/reference/commandline/swarm_update/)'
- en: The `docker swarm leave` command wiki doc: [https://docs.docker.com/engine/reference/commandline/swarm_leave/](https://docs.docker.com/engine/reference/commandline/swarm_leave/)
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker swarm leave`命令的wiki文档：[https://docs.docker.com/engine/reference/commandline/swarm_leave/](https://docs.docker.com/engine/reference/commandline/swarm_leave/)'
- en: Learn more about Docker Secrets: [https://docs.docker.com/engine/swarm/secrets/](https://docs.docker.com/engine/swarm/secrets/)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解更多关于Docker Secrets的信息：[https://docs.docker.com/engine/swarm/secrets/](https://docs.docker.com/engine/swarm/secrets/)
- en: Managers and workers
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理者和工作者
- en: We have discussed swarm managers a little in the previous sections, but let's
    take a closer look at what swarm managers do. The swarm managers do exactly what
    you would expect. They manage and maintain the state of the swarm cluster. They
    schedule swarm services, which we will talk about in *Swarm services* section
    of this chapter, but for now, think of swarm services as running containers. Manager
    nodes also serve up the API endpoints of the cluster, allowing for programmatic
    access via REST. Managers also direct traffic to the running services so that
    any container can be reached through any manager node without having to know which
    node is actually running the containers. As part of maintaining the state of the
    cluster, the managers will deal with the loss of nodes in the system, electing
    a new leader node in the event that the manager lost was the leader, and they
    will keep the desired number of service containers running if containers or nodes
    go down.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的章节中已经讨论了集群管理节点，但让我们更仔细地看看管理节点的工作。管理节点确切地做了你所期望的事情。它们管理和维护集群的状态。它们调度集群服务，我们将在本章的*集群服务*部分中讨论，但现在，把集群服务想象成运行的容器。管理节点还提供集群的API端点，允许通过REST进行编程访问。管理节点还将流量引导到正在运行的服务，以便任何容器都可以通过任何管理节点访问，而无需知道实际运行容器的节点。作为维护集群状态的一部分，管理节点将处理系统中节点的丢失，在管理节点丢失时选举新的领导节点，并在容器或节点宕机时保持所需数量的服务容器运行。
- en: The best practices for the number of manager in a swarm are three, five, or
    seven. You'll note that all of these options represent an odd number of manager
    nodes. This is so that if the leader node is lost, the raft consensus algorithm
    can more easily select a new leader for the swarm. You can run a swarm cluster
    with one manager node, and that is actually a better option than having two manager
    nodes. But, for a much more highly available swarm cluster, it is recommended
    that you have at least three manager nodes. For larger clusters, having five or
    seven managers is good, but it is not recommended to have more than seven. Once
    you have more than seven managers in the same cluster, you actually experience
    degraded performance.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中管理节点的最佳实践是三个、五个或七个。你会注意到所有这些选项都代表管理节点的奇数数量。这是为了在领导节点丢失时，raft一致性算法可以更容易地为集群选择新的领导者。你可以运行一个只有一个管理节点的集群，这实际上比有两个管理节点更好。但是，对于一个更高可用的集群，建议至少有三个管理节点。对于更大的集群，有五个或七个管理节点是不错的选择，但不建议超过七个。一旦在同一集群中有超过七个管理节点，你实际上会遇到性能下降的问题。
- en: Another important consideration for the manager nodes is the network performance
    between them. Managers need a low-latency network connection for optimal performance.
    If you are running your swarm in AWS, for example, you probably don't want the
    managers within a swarm spread across regions. You would likely encounter issues
    with the swarm if you were to do so. If you put the managers within a swarm in
    different availability zones within a single region, you shouldn't have any network-performance-related
    issues.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于管理节点来说，另一个重要考虑因素是它们之间的网络性能。管理节点需要低延迟的网络连接以实现最佳性能。例如，如果你在AWS上运行你的集群，你可能不希望管理节点分布在不同的地区。如果这样做，你可能会遇到集群的问题。如果你将管理节点放在同一地区的不同可用区内，你不应该遇到任何与网络性能相关的问题。
- en: Worker nodes don't do anything except run containers. They don't have a say
    in electing new leaders when the leader node goes down. They don't handle API
    calls. They don't direct traffic. They do nothing but run containers. In fact,
    you can't have a swarm with just a worker node. On the other hand, you can have
    a swarm with just a manager node, in which case the manager will also act as a
    worker and run containers in addition to its manager duties.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点除了运行容器之外什么也不做。当领导节点宕机时，它们没有发言权。它们不处理API调用。它们不指挥流量。它们除了运行容器之外什么也不做。事实上，你不能只有一个工作节点的swarm。另一方面，你可以只有一个管理节点的swarm，在这种情况下，管理节点也将充当工作节点，并在其管理职责之外运行容器。
- en: 'All manager nodes are actually worker nodes as well by default. This means
    that they can and will run containers. If you want to keep your managers from
    running workloads, you need to change the node''s availability setting. Changing
    it to draining will carefully stop any running containers on the manager node
    marked as draining, and will start up those containers on other (non-draining)
    nodes. No new container workloads will be started on a node in drain mode, for
    example as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，所有管理节点实际上也是工作节点。这意味着它们可以并且将运行容器。如果您希望您的管理节点不运行工作负载，您需要更改节点的可用性设置。将其更改为排水将小心地停止标记为排水的管理节点上的任何运行容器，并在其他（非排水）节点上启动这些容器。在排水模式下，不会在节点上启动新的容器工作负载，例如如下所示：
- en: '[PRE8]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'There may be times when you want or need to change the role of a docker node
    in the swarm. You can promote a worker node to manager status, or you can demote
    a manager node to worker status. Here are some examples of these activities:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 也许有时候您想要或需要改变swarm中docker节点的角色。您可以将工作节点提升为管理节点，或者将管理节点降级为工作节点。以下是这些活动的一些示例：
- en: '[PRE9]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: References
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: Check out the official documentation on how nodes work at [https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看有关节点如何工作的官方文档[https://docs.docker.com/engine/swarm/how-swarm-mode-works/nodes/]。
- en: Swarm services
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Swarm服务
- en: 'Alright. Now you know a lot about setting up a Docker swarm cluster, and how
    its nodes go from single-engine mode into swarm mode. You also know that the significance
    of that is to free you from directly managing individual running containers. So,
    you may be starting to wonder, if I don''t manage my containers directly and individually
    now, how do I manage them? You''ve come to the right place! This is where swarm
    services come into play. swarm services allow you to define the desired state
    for your container application in terms of how many concurrent running copies
    of the container there should be. Let''s take a quick look at what commands are
    available to us in the management group for swarm services, and then we''ll talk
    about those commands:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 好了。现在你已经了解了如何设置Docker swarm集群，以及它的节点如何从单引擎模式转换为swarm模式。你也知道这样做的意义是为了让你摆脱直接管理单个运行的容器。因此，你可能开始想知道，如果我现在不直接管理我的容器，我该如何管理它们？你来对地方了！这就是swarm服务发挥作用的地方。swarm服务允许您根据容器应用程序的并发运行副本数量来定义所需的状态。让我们快速看一下在swarm服务的管理组中有哪些可用的命令，然后我们将讨论这些命令：
- en: '![](Images/430b9977-6481-4879-916d-7a80e747488a.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/430b9977-6481-4879-916d-7a80e747488a.png)'
- en: 'The first thing that you''ll probably want to do is create a new service, so
    we will begin our swarm services discussion with the `service create` command.
    Here is the syntax and a basic sample of the `service create` command:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想要做的第一件事情是创建一个新的服务，因此我们将从`service create`命令开始讨论我们的swarm服务。以下是`service create`命令的语法和基本示例：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'OK. Let''s break down the sample `service create` command shown here. First,
    you have the management group service followed by the `create` command. Then,
    we start getting into the parameters; the first one is `--replicas`. This defines
    the number of copies of the container that should be run concurrently. Next, we
    have the `--name` parameter. This one is pretty obvious and is the name of the
    service we are creating, in this case, `submarine`. We will be able to use the
    stated name in other service commands. After the name parameter, we have the fully-qualified
    Docker image name. In this case, it is just `alpine`. It could have been something
    such as `alpine:3.8`, or `alpine:latest`, or something more qualified such as
    `tenstartups/alpine:latest`. Following the image name to use for the service is
    the command to use when running the container and the parameters to pass to that
    command—`ping` and `google.com`, respectively. So, the preceding sample `service
    create` command will launch a single container from the `alpine` image, which
    will run the `ping` command with the google.com parameter, and then name the service
    `submarine`. Here is what that looks like:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。让我们分解一下这里显示的`service create`命令示例。首先，你有管理组服务，然后是`create`命令。然后，我们开始进入参数；第一个是`--replicas`。这定义了应同时运行的容器副本数量。接下来是`--name`参数。这个很明显，是我们要创建的服务的名称，在这种情况下是`submarine`。我们将能够在其他服务命令中使用所述名称。在名称参数之后，我们有完全合格的Docker镜像名称。在这种情况下，它只是`alpine`。它可以是诸如`alpine:3.8`或`alpine:latest`之类的东西，或者更合格的东西，比如`tenstartups/alpine:latest`。在用于服务的图像名称之后是运行容器时要使用的命令和传递给该命令的参数——分别是`ping`和`google.com`。因此，前面的`service
    create`命令示例将从`alpine`镜像启动一个单独的容器，该容器将使用`ping`命令和google.com参数运行，并将服务命名为`submarine`。看起来是这样的：
- en: '![](Images/3701eca6-03c6-412d-8dfd-49676e2fb619.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/3701eca6-03c6-412d-8dfd-49676e2fb619.png)'
- en: 'You now know the basics of creating docker services. But, before you get too
    excited, there''s still a lot of ground to cover for the `service create` command.
    In fact, this command has so many options that listing them all out would take
    two pages in this book. So, rather than do that, I want you to use the `--help`
    feature and enter the following command now:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在知道了创建docker服务的基础知识。但在你过于兴奋之前，`service create`命令还有很多内容要涵盖。事实上，这个命令有很多选项，列出它们将占据本书两页的篇幅。所以，我希望你现在使用`--help`功能并输入以下命令：
- en: '[PRE11]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I know, right? There are a *lot* of optional parameters you can use. Don't worry.
    I'm not going to leave you out to dry here. I'll give you some guidance to help
    you get a firm foundation for creating services, and then you can branch out and
    try some of the other parameters you see in `--help`.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道，对吧？有很多可选参数可以使用。别担心。我不会丢下你不管的。我会给你一些指导，帮助你建立创建服务的坚实基础，然后你可以扩展并尝试一些你在`--help`中看到的其他参数。
- en: Just so you know, the two parameters we used so far, `--replicas` and `--name`,
    are both optional. If you don't provide a number of replicas to use, the service
    will be created with a default of 1\. Also, if you don't provide a name for the
    service, a fanciful name will be made up and given to the service. This is the
    same type of default naming we saw when using the `docker container run` command
    in [Chapter 2](e66034ed-dcc0-48a8-a2ec-9466669e6649.xhtml), *Learning Docker Commands*.
    It is generally better to provide both of these options for each `service create`
    command issued.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 只是让你知道，到目前为止我们使用的两个参数，`--replicas`和`--name`，都是可选的。如果你不提供要使用的副本数量，服务将以默认值1创建。此外，如果你不为服务提供名称，将会编造一个奇特的名称并赋予服务。这与我们在[第2章](e66034ed-dcc0-48a8-a2ec-9466669e6649.xhtml)中使用`docker
    container run`命令时看到的默认命名类型相同，*学习Docker命令*。通常最好为每个发出的`service create`命令提供这两个选项。
- en: Also, know that generally speaking, the command and command parameters for the
    image that were supplied in the preceding sample are optional as well. In this
    specific case, they are necessary because, by itself, a container run from the
    alpine image with no other command or parameters supplied will just exit. In the
    sample, that would show up as a failure to converge the service and Docker would
    perpetually try to restart the service. Stated another way, you can leave off
    the command and its parameters if the image being used has them built in (such
    as in the `CMD` or `ENTRYPOINT` instruction of the Dockerfile).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，要知道，一般来说，在前面的示例中提供的镜像的命令和命令参数也是可选的。在这种特定情况下，它们是必需的，因为单独从alpine镜像运行的容器，如果没有提供其他命令或参数，将会立即退出。在示例中，这将显示为无法收敛服务，Docker将永远尝试重新启动服务。换句话说，如果使用的镜像内置了命令和参数（比如在Dockerfile的`CMD`或`ENTRYPOINT`指令中），则可以省略命令及其参数。
- en: 'Let''s move on to some more create parameters now. You should recall from [Chapter
    2](e66034ed-dcc0-48a8-a2ec-9466669e6649.xhtml), *Learning Docker Commands* that
    there is a `--publish` parameter you can use on a `docker container run` command
    that defines the port exposed on the docker host and the port in the container
    that the host port is mapped to. It looked something like this:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们继续讨论一些创建参数。你应该还记得[第2章](e66034ed-dcc0-48a8-a2ec-9466669e6649.xhtml)中提到的`--publish`参数，你可以在`docker
    container run`命令上使用，它定义了在docker主机上暴露的端口以及主机端口映射到的容器中的端口。它看起来像这样：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Well, you need the same functionality for a swarm service, and in their wisdom,
    Docker made the parameter used for both the `container run` command and the `service
    create` command the same: `--publish`. You can use the same abbreviated format
    we saw before, `--publish 8080:80`, or you can use a more verbose format: `--publish
    published=8080`, `target=80`. This still translates to redirect host traffic from
    port `8080` to port 80 in the container. Let''s try out another example, this
    time one that uses the `--publish` parameter. We''ll give the `nginx` image another
    run:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你需要为一个集群服务使用相同的功能，在他们的智慧中，Docker使`container run`命令和`service create`命令使用相同的参数：`--publish`。你可以使用我们之前看到的相同的缩写格式，`--publish
    8080:80`，或者你可以使用更详细的格式：`--publish published=8080`，`target=80`。这仍然意味着将主机流量从端口`8080`重定向到容器中的端口80。让我们尝试另一个例子，这次使用`--publish`参数。我们将再次运行`nginx`镜像：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This example will create a new service that runs three container replicas,
    using the `nginx` image and exposing port `80` on the containers and port `8080`
    on the hosts. Have a look:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子将创建一个新的服务，运行三个容器副本，使用`nginx`镜像，在容器上暴露端口`80`，在主机上暴露端口`8080`。看一下：
- en: '![](Images/d43881b1-4d53-443c-916e-bb51f16581d8.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/d43881b1-4d53-443c-916e-bb51f16581d8.png)'
- en: Now, you're getting there. Let's quickly cover three more parameters and you
    will be ready to take on the world (of swarm services, at least). First up, `--restart-window`.
    This parameter is used to tell the Docker daemon how long to wait for the container
    to start up its application before testing to see whether it is healthy. The default
    is five seconds. If you create an app in your container that will take more than
    five seconds to start up and report as healthy, you will want to include a `--restart-window`
    parameter with your `service create`. Next up, `--restart-max-attempts`. This
    parameter tells the Docker daemon how many times to keep trying to start a container
    replica that is not reporting as healthy before giving up. The default is *Never
    give up*. *Never surrender*! Finally, let's talk about the `--mode` parameter.
    The default mode for a swarm service is *replicated*. That means the Docker daemon
    will continue to stand up containers for your service until the number of concurrently
    running containers is equal to the value you provided in the `--replicas` parameter
    (or 1 if you don't provide the parameter). For example, with a `--replicas 3` parameter,
    you will get three containers running in the swarm for your service. There is
    another mode, called **global**. If you provide the `--mode global` parameter
    when you create your service, the Docker daemon will stand up exactly one container
    on every node in the cluster. If you have a six-node cluster, you will end up
    with six containers running, one per node. With a 12-node cluster, you get 12
    containers, and so on. This is a very handy option when you have services that
    provide functionality for each host, such as a monitoring app or log forwarder.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经接近成功了。让我们快速介绍另外三个参数，然后您就可以准备好应对世界（至少是集群服务的世界）。首先是 `--restart-window`。此参数用于告诉Docker守护程序在测试容器是否健康之前等待多长时间启动其应用程序。默认值为五秒。如果您在容器中创建了一个需要超过五秒才能启动并报告为健康的应用程序，您将需要在
    `service create` 中包含 `--restart-window` 参数。接下来是 `--restart-max-attempts`。此参数告诉Docker守护程序在放弃之前尝试启动未报告为健康的容器副本的次数。默认值是*永不放弃*。*永不投降*！最后，让我们谈谈
    `--mode` 参数。集群服务的默认模式是*replicated*。这意味着Docker守护程序将继续为您的服务创建容器，直到同时运行的容器数量等于您在
    `--replicas` 参数中提供的值（如果您没有提供该参数，则为1）。例如，使用 `--replicas 3` 参数，您将在集群中获得三个运行中的容器。还有另一种模式，称为**global**。如果您在创建服务时提供
    `--mode global` 参数，Docker守护程序将在集群中的每个节点上精确地创建一个容器。如果您有一个六节点的集群，您将得到六个运行中的容器，每个节点一个。对于一个12节点的集群，您将得到12个容器，依此类推。当您有为每个主机提供功能的服务时，例如监控应用程序或日志转发器，这是一个非常方便的选项。
- en: 'Let''s review some of the other service commands you will want to know and
    use. Once you''ve created some services, you might want a list of those services.
    This can be achieved with the `service list` command. It looks like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一些其他您需要了解和使用的服务命令。一旦您创建了一些服务，您可能想要列出这些服务。这可以通过 `service list` 命令来实现。如下所示：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Once you have reviewed the list of running services, you might want more details
    about one or more of those services. To achieve this, you would use the `service
    ps` command. Have a look:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您查看了运行中服务的列表，您可能想要了解一个或多个服务的更多详细信息。为了实现这一点，您将使用 `service ps` 命令。看一下：
- en: '[PRE15]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Once a service has outlived its usefulness, you might want to terminate it.
    The command to do that is the `service remove` command. Here is what that looks
    like:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦一个服务已经没有用处，您可能想要终止它。执行此操作的命令是 `service remove` 命令。如下所示：
- en: '[PRE16]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'If you want to remove all of the services running in the swarm, you can combine
    some of these commands and execute something such as this:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想要删除在集群中运行的所有服务，您可以组合其中一些命令并执行类似以下的命令：
- en: '[PRE17]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Finally, if you realize that the number of replicas currently configured is
    not set to the desired number, you can use the `service scale` command to adjust
    it. Here is how you do that:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果您意识到当前配置的副本数量未设置为所需数量，您可以使用`service scale`命令进行调整。以下是您可以这样做的方法：
- en: '[PRE18]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![](Images/354cacd5-2139-4ad7-acb7-abb6cc0f00fa.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/354cacd5-2139-4ad7-acb7-abb6cc0f00fa.png)'
- en: 'That should be enough to keep you busy for a while. Before we move on [Chapter
    6](873454a4-2f8e-42df-93ab-7648545167bb.xhtml), *Docker Networking*, let''s cover
    one more topic in this chapter: accessing your container applications running
    in a swarm.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该足够让您忙一段时间了。在我们继续[第6章](873454a4-2f8e-42df-93ab-7648545167bb.xhtml)之前，*Docker网络*，让我们在本章中再涵盖一个主题：访问在集群中运行的容器应用程序。
- en: References
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考
- en: Read more about the Docker service create reference at [https://docs.docker.com/engine/reference/commandline/service_create/](https://docs.docker.com/engine/reference/commandline/service_create/).
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读有关Docker服务创建参考的更多信息[https://docs.docker.com/engine/reference/commandline/service_create/](https://docs.docker.com/engine/reference/commandline/service_create/)。
- en: Accessing container applications in a swarm
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在集群中访问容器应用程序
- en: So, now you have a swarm running with an odd number of manager nodes, and a
    number of worker nodes. You have deployed some swarm services to run your favorite
    containerized applications. What's next? Well, you just might want to access one
    or more of the applications running in your swarm. Perhaps you have deployed a
    web server application. It would be nice to be able to visit the web pages shared
    by that web server, right? Let's take a quick look and see how easy it is to do
    so.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，现在您有一个运行着奇数个管理节点和若干个工作节点的集群。您已经部署了一些集群服务来运行您喜爱的容器化应用程序。接下来呢？嗯，您可能想要访问在您的集群中运行的一个或多个应用程序。也许您已经部署了一个web服务器应用程序。能够访问该web服务器共享的网页将是很好的，对吧？让我们快速看一下，看看这是多么容易。
- en: 'One of the features that the swarm managers handle for us is to direct traffic
    to our services. In an earlier example, we set up a web service that was running
    three replicas in the swarm. The swarm I am currently using happens to have three
    manager nodes and three worker nodes. All six nodes are eligible to run workloads
    so when the service is started, three of the six nodes will end up running a container.
    If we take a look at the details of the tasks of the service using the `service
    ps` command, you can see which of the six nodes are running the web-service containers:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理器为我们处理的功能之一是将流量引导到我们的服务。在之前的示例中，我们设置了一个在集群中运行三个副本的web服务。我目前使用的集群恰好有三个管理节点和三个工作节点。所有六个节点都有资格运行工作负载，因此当服务启动时，六个节点中的三个将最终运行一个容器。如果我们使用`service
    ps`命令查看服务的任务的详细信息，您可以看到六个节点中哪些正在运行web服务容器：
- en: '![](Images/f42332f8-0d66-4aab-a195-d99bd73fc86a.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/f42332f8-0d66-4aab-a195-d99bd73fc86a.png)'
- en: 'In this example, you can see that the web service containers are running on
    node 01, 02, and 04\. The wonderful thing is that you don''t need to know which
    nodes are running your service containers. You can access the service via any
    node in the swarm. Of course, you would expect to be able to access the container
    on node 01, 02, or 04, but have a look at this:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，您可以看到web服务容器正在节点01、02和04上运行。美妙的是，您不需要知道哪些节点正在运行您的服务容器。您可以通过集群中的任何节点访问该服务。当然，您期望能够访问节点01、02或04上的容器，但是看看这个：
- en: '![](Images/63e01e66-7ca6-4121-9a4c-b653f2b773cb.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/63e01e66-7ca6-4121-9a4c-b653f2b773cb.png)'
- en: 'There is an unfortunate side-effect of having the ability to access a service
    from any node in the swarm. Can you think of what it might be? I won''t keep you
    in suspense for long. The side effect is that you can only assign a (host) port
    to one service in the swarm. In our example, we are using port `8080` for our
    web service. That means that we cannot use port `8080` for the host port of any
    other service we want to run in this swarm:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有在集群中的任何节点上访问服务的能力会带来一个不幸的副作用。你能想到可能是什么吗？我不会让你悬念太久。副作用是你只能将（主机）端口分配给集群中的一个服务。在我们的例子中，我们正在为我们的web服务使用端口`8080`。这意味着我们不能将端口`8080`用于我们想要在这个集群中运行的任何其他服务的主机端口：
- en: '![](Images/71ca5156-7db9-4eb0-ad77-00a558c82bdc.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/71ca5156-7db9-4eb0-ad77-00a558c82bdc.png)'
- en: References
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Check out the following links for more information:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接以获取更多信息：
- en: Wiki doc with a very detailed overview of deploying services on a swarm: [https://docs.docker.com/v17.09/engine/swarm/services/](https://docs.docker.com/v17.09/engine/swarm/services/)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 维基文档中有关在集群上部署服务的非常详细的概述：[https://docs.docker.com/v17.09/engine/swarm/services/](https://docs.docker.com/v17.09/engine/swarm/services/)
- en: How services work: [https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/)
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务的工作原理：[https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/](https://docs.docker.com/engine/swarm/how-swarm-mode-works/services/)
- en: Docker's getting started with swarm mode training: [https://docs.docker.com/v17.09/engine/swarm/swarm-tutorial/](https://docs.docker.com/v17.09/engine/swarm/swarm-tutorial/)
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker的入门培训：[https://docs.docker.com/v17.09/engine/swarm/swarm-tutorial/](https://docs.docker.com/v17.09/engine/swarm/swarm-tutorial/)
- en: Summary
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we finally started to pull some of the pieces together and
    make some fun stuff happen. We learned how much functionality we get by enabling
    swarm mode, and creating a swarm cluster. And, we found out just how easy it is
    to set everything up, using one single `swarm init` command. Then, we learned
    how to grow and manage our swarm cluster, and finally, we learned how to run our
    containers as services within our new swarm cluster. It's been fun, right?!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们最终开始整合一些要点，并实现一些有趣的事情。我们了解了通过启用集群模式和创建集群集群可以获得多少功能。而且，我们发现了使用一个`swarm
    init`命令设置一切有多么容易。然后，我们学会了如何扩展和管理我们的集群集群，最后，我们学会了如何在我们的新集群集群中将我们的容器作为服务运行。很有趣，对吧？！
- en: Now, let's take things to the next level. In [Chapter 6](873454a4-2f8e-42df-93ab-7648545167bb.xhtml),
    *Docker Networking*, we'll learn about Docker Networking. If you're ready for
    more good stuff, turn the page.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们把事情提升到下一个级别。在[第6章](873454a4-2f8e-42df-93ab-7648545167bb.xhtml)中，*Docker网络*，我们将学习关于Docker网络的知识。如果你准备好了解更多好东西，就翻页吧。
