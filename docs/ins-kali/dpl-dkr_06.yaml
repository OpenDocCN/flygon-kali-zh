- en: Advanced Deployment Topics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级部署主题
- en: 'We have spent a decent amount of time talking about container communication
    and security, but in this chapter, we will take a look at taking deployments even
    further by covering the following:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花了相当多的时间讨论容器通信和安全性，但在本章中，我们将进一步探讨以下内容：
- en: Advanced debugging techniques.
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级调试技术。
- en: Implementing queue messaging.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现队列消息传递。
- en: Running security checks.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行安全检查。
- en: Container security in depth.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入容器安全。
- en: We will also look at a few other tools and techiniques that will help you manage
    your deployments better.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将介绍一些其他工具和技术，帮助您更好地管理部署。
- en: Advanced debugging
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级调试
- en: The ability to debug containers in the wild is a very important topic and we
    previously covered some of the more basic techniques that can be of use here.
    But there are cases where `docker ps` and `docker exec` just aren't enough, so
    in this section, we will examine a few more tools you can add to your toolbox
    that can help resolve those tricky issues.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在野外调试容器的能力是一个非常重要的话题，我们之前介绍了一些基本的技术，可以在这里派上用场。但也有一些情况下，`docker ps`和`docker exec`并不够用，因此在本节中，我们将探讨一些可以添加到您的工具箱中的其他工具，可以帮助解决那些棘手的问题。
- en: Attaching to a container's process space
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附加到容器的进程空间
- en: There may be times when a container is running with a minimalist distribution
    such as Alpine Linux ([https://www.alpinelinux.org/](https://www.alpinelinux.org/))
    and the container in question has an issue with a process that you would like
    to debug but also lacks the most basic tooling you need for debugging included.
    By default, Docker isolates all containers in their individual process namespace
    so our current debugging workflow, which we used before by attaching to that container
    directly and trying to figure out what was wrong with very limited tooling is
    not going to help us much here.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 有时容器正在运行的是极简的发行版，比如Alpine Linux（[https://www.alpinelinux.org/](https://www.alpinelinux.org/)），而且容器本身存在一个你想要调试的进程问题，但缺乏基本的调试工具。默认情况下，Docker会将所有容器隔离在它们各自的进程命名空间中，因此我们之前直接附加到容器并尝试使用非常有限的工具来找出问题的调试工作流在这里不会有太大帮助。
- en: 'Luckily for us though, Docker is fully capable of joining the process namespaces
    of two containers with the `docker run --pid "container:<name_or_id>"` flag, so
    that we can attach a debug tooling container directly onto the affected one:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Docker完全能够使用`docker run --pid "container:<name_or_id>"`标志加入两个容器的进程命名空间，这样我们就可以直接将调试工具容器附加到受影响的容器上：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, we can just attach a debugging container into the same PID namespace
    and debug any oddly behaving process this way and can keep the original container
    pristine from the installation of debug tooling! Using this technique, the original
    container can be kept small since the tooling can be shipped separately and the
    container remains running throughout the debugging process so your task will not
    be rescheduled. That said, whenever you are debugging different containers using
    this method, be careful not to kill the processes or the threads within it as
    they have a likely chance of cascading and killing the whole container, halting
    your investigation.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们可以将一个调试容器附加到相同的PID命名空间中，以这种方式调试任何行为异常的进程，并且可以保持原始容器不受调试工具的安装！使用这种技术，原始容器可以保持较小，因为工具可以单独安装，而且容器在整个调试过程中保持运行，因此您的任务不会被重新安排。也就是说，当您使用这种方法调试不同的容器时，要小心不要杀死其中的进程或线程，因为它们有可能会级联并杀死整个容器，从而停止您的调查。
- en: 'Interestingly enough, this `pid` flag can also be invoked with `--pid host`
    to share the host''s process namespace if you have a tool that does not run on
    your distribution and there is a Docker container for it (or, alternatively, if
    you want to use a container for the management of the host''s processes):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，这个`pid`标志也可以通过`--pid host`来调用，以共享主机的进程命名空间，如果你有一个在你的发行版上无法运行的工具，并且有一个Docker容器可以运行它（或者，如果你想要使用一个容器来管理主机的进程）：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It should be apparent as to how much capability this flag's functionality can
    provide for both running and debugging applications, so do not hesitate to use
    it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，这个标志的功能对于运行和调试应用程序提供了多少能力，所以不要犹豫使用它。
- en: Warning! Sharing the host's process namespace with the container is a big security
    hole as a malicious container can easily commandeer or DoS the host by manipulating
    processes, especially if the container's user is running as a root. Due to this,
    exercise extreme caution when utilizing `--pid host` and ensure that you use this
    flag only on containers you trust completely.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 警告！与容器共享主机的进程命名空间是一个很大的安全漏洞，因为恶意容器可以轻易地通过操纵进程来控制或者DoS主机，特别是如果容器的用户是以root身份运行的。因此，在使用`--pid
    host`时要格外小心，并确保只在你完全信任的容器上使用这个标志。
- en: Debugging the Docker daemon
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试Docker守护程序
- en: If none of these techniques have helped you so far, you can try to run the Docker
    container and check what the daemon API is doing with `docker system events`,
    which tracks almost all actions that are triggered on its API endpoint. You can
    use this for both auditing and debugging, but generally, the latter is its primary
    purpose as you can see in the following example.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果到目前为止这些技术都没有帮助到你，你可以尝试运行Docker容器，并使用`docker system events`来检查守护程序API正在执行的操作，该命令可以跟踪几乎所有在其API端点上触发的操作。你可以用它来进行审计和调试，但一般来说，后者是它的主要目的，就像你在下面的例子中所看到的那样。
- en: 'On the first terminal, run the following command and leave it running so that
    we can see what information we can collect:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一个终端上运行以下命令，并让它保持运行，这样我们就可以看到我们可以收集到什么信息：
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'On another Terminal, we will run a new container:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个终端上，我们将运行一个新的容器：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'After you have done this start and stop of the container, the `events` command
    in the first terminal should have output something similar to this:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在你完成了对容器的启动和停止之后，第一个终端中的`events`命令应该输出类似于这样的内容：
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Its use is fairly niche but this type of tracing, along with the other tips
    and tricks we have discussed so far, should provide you with the tools to tackle
    almost any type of problem on a Docker-based cluster. Everything already mentioned
    aside, in my personal experience, there have also been a couple of times where
    `gdb` was required as well as a couple of times when a problem turned out to be
    an upstream bug. Because of that, be prepared to get your hands dirty when scaling
    up as the chance of novel problems increases too.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 它的使用范围相当有限，但是这种跟踪方式，以及我们到目前为止讨论过的其他技巧，应该为你提供在基于Docker的集群上解决几乎任何类型的问题的工具。除了已经提到的一切之外，在我的个人经验中，也有几次需要使用`gdb`，还有几次问题最终被证明是上游bug。因此，在扩展规模时，要做好准备，因为出现新问题的可能性也会增加。
- en: Advanced networking
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级网络
- en: Networking is one of the most important things for Docker clusters and it needs
    to be kept operational and running smoothly on clusters for the whole system to
    operate in any capacity. With that in mind, it stands to reason that it behooves
    us to cover a few of the topics that we have not talked about yet but that are
    important in most real-world deployments, big and small. There is a big chance
    you will encounter at least one of these use cases in your own deployments so
    I would recommend a full read-through, but your mileage may vary.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 网络是Docker集群中最重要的事情之一，它需要在整个系统的集群上保持运行顺畅，以便系统能够以任何能力运行。考虑到这一点，我们有理由涵盖一些我们尚未讨论但在大多数实际部署中都很重要的主题。您很有可能会在自己的部署中遇到至少其中一个用例，因此我建议您全文阅读，但您的情况可能有所不同。
- en: Static host configuration
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 静态主机配置
- en: In some specific configurations, you may have a host on your network that needs
    to be mapped or re-mapped to a specific IP address for the container that is trying
    to reach it. This allows a flexible configuration of named servers and can be
    a real life-saver for static hosts on the network without a good network DNS server.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些特定的配置中，您可能有一个需要映射或重新映射到容器尝试到达的特定IP地址的网络主机。这允许对命名服务器进行灵活配置，并且对于网络上没有良好的网络DNS服务器的静态主机来说，这可能是一个真正的救命稻草。
- en: 'To add such a host mapping to a container, you can run the container with `docker
    run --add-host` and using this flag, an entry in `/etc/hosts` is added that matches
    your input so that you can properly route your requests to it:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要将这样的主机映射添加到容器中，您可以使用`docker run --add-host`命令运行容器，并使用此标志，将在`/etc/hosts`中添加一个与您的输入匹配的条目，以便您可以正确地将请求路由到它：
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As mentioned, this can be very useful when you have a non-containerized service
    for which you do not want to hardcode the IP into the container that also is not
    resolvable from the Internet DNS servers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，当您有一个非容器化服务时，您可能不希望将IP硬编码到容器中，该服务也无法从互联网DNS服务器解析时，这可能非常有用。
- en: DNS configuration
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DNS配置
- en: 'Speaking of DNS, we should probably talk a bit about Docker DNS handling. By
    default, Docker Engine uses the DNS settings from the host, but in some advanced
    deployment settings where the network that the cluster is being deployed in is
    within an already built-out network, there may be times when the engine or the
    container needs to be configured with a custom DNS setting or the DNS search prefix
    (also know as the domain name). In such cases, you are able to override the default
    DNS settings of the Docker Engine easily by adding the `dns` and/or `dns-search`
    parameters to `/etc/docker/daemon.json` and restarting the daemon. Both parameters
    allow multiple values and are pretty self-explanatory:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 说到DNS，我们可能应该稍微谈谈Docker DNS处理。默认情况下，Docker引擎使用主机的DNS设置，但在一些高级部署设置中，集群所在的网络可能已经构建好，此时可能需要配置引擎或容器的自定义DNS设置或DNS搜索前缀（也称为域名）。在这种情况下，您可以通过向`/etc/docker/daemon.json`添加`dns`和/或`dns-search`参数并重新启动守护程序来轻松覆盖Docker引擎的默认DNS设置。这两个参数都允许多个值，并且相当容易理解。
- en: '[PRE6]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In all networking setups that I have ever worked on, I have not seen a situation
    where overriding DNS server IPs or DNS search prefixes is a better option to deploying
    your own DHCP server within the network and setting the appropriate options for
    the DNS server(s) (`option 6`) and domain name (`option 15`), which the machine
    will pick up when initializing the network interface. If you would like to find
    out more about these DHCP flags, I would highly recommend that you visit [https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol#DHCP_options](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol#DHCP_options)
    and read up on them before using the parameters we mentioned previously.Caution!
    In some cases where the engine host's DNS servers are pointed to `localhost` ranges,
    as they are in most `systemd-resolve` and `dnsmasq` setups, the container cannot
    access the host's `localhost` address and is thus replaced with Google's DNS servers
    (`8.8.8.8` and `8.8.4.4`) by default for all containers running on that instance.
    If you would like to retain the host's DNS setting within the container, you must
    ensure that the DNS resolver in the configuration is not one on the `localhost`
    IP range and is accessible by container networks. You can find more information
    about this at [https://docs.docker.com/engine/userguide/networking/default_network/configure-dns/](https://docs.docker.com/engine/userguide/networking/default_network/configure-dns/).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在我曾经工作过的所有网络设置中，我从未见过覆盖DNS服务器IP或DNS搜索前缀是部署自己的DHCP服务器并设置适当的选项来设置DNS服务器（`选项6`）和域名（`选项15`）更好的选择，当初始化网络接口时，机器将会选择这些选项。如果您想了解更多关于这些DHCP标志的信息，我强烈建议您访问[https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol#DHCP_options](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol#DHCP_options)并在使用我们之前阅读相关内容。注意！在某些情况下，引擎主机的DNS服务器指向`localhost`范围，就像大多数`systemd-resolve`和`dnsmasq`设置一样，容器无法访问主机的`localhost`地址，因此默认情况下，所有在该实例上运行的容器都会被替换为Google的DNS服务器（`8.8.8.8`和`8.8.4.4`）。如果您想在容器中保留主机的DNS设置，您必须确保配置中的DNS解析器不是`localhost`
    IP范围之一，并且可以被容器网络访问。您可以在[https://docs.docker.com/engine/userguide/networking/default_network/configure-dns/](https://docs.docker.com/engine/userguide/networking/default_network/configure-dns/)找到更多信息。
- en: 'If you are not interested in engine-wide configuration and are only trying
    to override a single container''s DNS settings, you can do the equivalent action
    by adding `--dns` and `--dns-search` options to the `docker run` command, which
    ends up replacing the default `/etc/resolv.conf` settings in the relevant container:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对引擎范围的配置不感兴趣，只想覆盖单个容器的DNS设置，您可以通过向`docker run`命令添加`--dns`和`--dns-search`选项来执行等效操作，这将替换相关容器中的默认`/etc/resolv.conf`设置。
- en: '[PRE7]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see, the settings in the container have been changed to match our
    parameters. In our case, any DNS resolution will flow to the `4.4.4.2` server
    and any unqualified hostname will first be attempted to get resolved as `<host>.domain.com`.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，容器中的设置已经更改以匹配我们的参数。在我们的情况下，任何DNS解析都将流向`4.4.4.2`服务器，并且任何未经验证的主机名将首先尝试解析为`<host>.domain.com`。
- en: Overlay networks
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 叠加网络
- en: We only briefly touched on this in [Chapter 4](80265a90-781c-4bcf-80a8-945d30d22720.xhtml),
    *Scaling the Containers,* but in order to get our containers to work with the
    Swarm service discovery, we had to create this type of network though we didn't
    really spend much time explaining what it is. In the context of Docker Swarm,
    containers on one machine cannot reach containers on a different machine as their
    networks are routed directly to the next hop as they traverse the network and
    a bridge network prevents each container from reaching its neighbor on the same
    node. To hook all of the containers together in this multi-host setup seamlessly,
    you can create an overlay network that spans any Swarm nodes that are part of
    the cluster. Sadly, this type of network is only available in Docker Swarm clusters,
    so in general, it has limited portability across the orchestration tooling but
    you can create one with `docker network create -d overlay network_name`. Since
    we have already covered an example of a deployment using this type of a network
    in [Chapter 4](80265a90-781c-4bcf-80a8-945d30d22720.xhtml), *Scaling the Containers,*
    you can look it up there to see it in action.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在《第4章》*扩展容器*中只是简单提及了这一点，但为了使我们的容器能够与Swarm服务发现一起工作，我们不得不创建这种类型的网络，尽管我们并没有花太多时间解释它是什么。在Docker
    Swarm的上下文中，一台机器上的容器无法访问另一台机器上的容器，因为它们的网络直接路由到下一个跳点，而桥接网络阻止了每个容器在同一节点上访问其邻居。为了在这种多主机设置中无缝地连接所有容器，您可以创建一个覆盖整个集群的overlay网络。遗憾的是，这种类型的网络只在Docker
    Swarm集群中可用，因此在编排工具中的可移植性有限，但您可以使用`docker network create -d overlay network_name`来创建一个。由于我们已经在《第4章》*扩展容器*中涵盖了使用这种类型网络的部署示例，您可以在那里查看它的运行情况。
- en: Caution! Overlay networks do not communicate data securely by default with other
    nodes, so using the `--opt encrypted` flag when creating one is highly encouraged
    where network transport cannot be trusted fully. Using this option will incur
    some processing cost and will require you to allow port `50` communication within
    your cluster, but in most cases, it should be worth it turning it on.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！默认情况下，覆盖网络不会与其他节点安全地通信，因此在创建时使用`--opt encrypted`标志是非常鼓励的，特别是在网络传输不能完全信任的情况下。使用此选项将产生一些处理成本，并要求您在集群内允许端口`50`的通信，但在大多数情况下，打开它应该是值得的。
- en: Docker built-in network mappings
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker内置网络映射
- en: 'In previous chapters, we were mostly working with containers with the default
    network settings, which were utilizing the `bridge` network in most cases since
    that is the default, but this is not the only type of networking that can be used
    for a container. The following is a list of the available network connections,
    and almost all of them can be set through the `docker run --network` parameter:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们大多数情况下都是使用默认网络设置的容器，大多数情况下都是使用`bridge`网络，因为这是默认设置，但这并不是容器可以使用的唯一类型的网络。以下是可用网络连接的列表，几乎所有这些连接都可以通过`docker
    run --network`参数进行设置：
- en: '`bridge`: As mentioned in earlier chapters, this type of network creates an
    independent virtual interface on the host for communicating with the container,
    and the container can communicate with the host and the Internet. Generally, inter-container
    communication is prevented in this type of a network.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bridge`：如前几章所述，这种类型的网络在主机上创建了一个独立的虚拟接口，用于与容器通信，容器可以与主机和互联网通信。通常情况下，这种类型的网络会阻止容器之间的通信。'
- en: '`none`: Disables all networking communication for the container. This is useful
    with containers that only contain tooling and have no need for network communication.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`none`：禁用容器的所有网络通信。这对于只包含工具的容器并且不需要网络通信的情况非常有用。'
- en: '`host`: Uses the host''s networking stack and does not create any virtual interfaces.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`host`：使用主机的网络堆栈，不创建任何虚拟接口。'
- en: '`<network_name_or_id>`: Connects to a named network. This flag is useful when
    you create a network and want to put multiple containers in the same networking
    grouping. For example, this would be useful for hooking up multiple chatty containers
    such as Elasticsearch into their own isolated network.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<network_name_or_id>`：连接到命名网络。当您创建一个网络并希望将多个容器放入相同的网络组时，此标志非常有用。例如，这对于连接多个喋喋不休的容器（如Elasticsearch）到它们自己的隔离网络中将非常有用。'
- en: '`<container_name_or_id>`: This allows you to connect to a networking stack
    of the specified container. Just like the `--pid` flag, this is very useful for
    debugging running containers without directly attaching to them, though the network
    may need to be created with the `--attachable` flag depending on the network driver
    used.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`<container_name_or_id>`：这允许您连接到指定容器的网络堆栈。就像`--pid`标志一样，这对于调试运行中的容器非常有用，而无需直接附加到它们，尽管根据使用的网络驱动程序，网络可能需要使用`--attachable`标志进行创建。'
- en: Warning! Using the `host` networking switch gives the container full access
    to local system services and as such is a liability when used in any context other
    than testing. Use extreme caution when this flag is used, but luckily, there are
    only very few cases (if any) where there will be a legitimate use for this mode.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 警告！使用`host`网络开关会使容器完全访问本地系统服务，因此在除测试之外的任何情况下使用都是一种风险。在使用此标志时要非常小心，但幸运的是，只有极少数情况（如果有的话）会有正当使用这种模式的情况。
- en: Docker communication ports
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker通信端口
- en: 'Unless you are running Docker Swarm, you will probably never need to worry
    about what ports Docker uses to communicate, but this is something that is relatively
    good to know as a point of reference should you ever encounter such configurations
    in the field or you want to have such deployments within your clusters. The list
    is pretty short, but each port is very important for the operation of most Swarm
    clusters:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 除非您正在运行Docker Swarm，否则您可能永远不需要担心Docker用于通信的端口，但这是一个相对重要的参考点，如果您在现场遇到这样的配置或者您想在集群中部署这样的部署。列表非常简短，但每个端口对于大多数Swarm集群的操作非常重要：
- en: '[PRE8]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: High availability pipelines
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高可用性管道
- en: Previously, we spent the majority of our time working with socket-based communication
    between nodes on a cluster, which is generally something that makes sense to most
    people and has tooling built around it in almost every programming language. So,
    it is the first tool that people transitioning their classic infrastructure to
    containers usually go for, but for large-and-beyond scales where you are dealing
    with pure data processing, it simply does not work well due to the back-pressure
    caused by exceeding the capacity of a particular stage on the rest of the processing
    pipeline.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，我们大部分时间都在集群中的节点之间进行基于套接字的通信，这通常是大多数人可以理解的事情，并且几乎每种编程语言都有围绕它构建的工具。因此，这是人们将经典基础架构转换为容器时通常会选择的第一个工具，但对于大规模及以上规模的纯数据处理，由于超出了处理管道其余阶段的容量而导致的背压，它根本不起作用。
- en: 'If you imagine each cluster service as a consecutive set of transformation
    steps, the socket-based system would go through a loop of steps similar to these:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您将每个集群服务想象为一系列连续的转换步骤，那么基于套接字的系统将经历类似于这些步骤的循环：
- en: Opening a listening socket.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 打开一个监听套接字。
- en: 'Looping forever doing the following:'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 永远循环执行以下操作：
- en: Waiting for data on a socket from the previous stage.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在套接字上等待来自上一阶段的数据。
- en: Processing that data.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理这些数据。
- en: Sending the processed data to the next stage's socket.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将处理后的数据发送到下一阶段的套接字。
- en: But what happens in that last step if the next stage is already at the maximum
    capacity? What most socket-based systems will do is either throw an exception
    and completely fail the processing pipeline for this particular piece of data
    or prevent the execution from continuing and keep retrying to send the data to
    the next stage until it succeeds. Since we don't want to fail the processing pipeline
    as the result was not an error and we do not want to keep our worker waiting around
    for the next stage to unblock, we need something that can hold inputs to stages
    in an ordered structure so that the previous stage can continue working on its
    own new set of inputs.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果下一个阶段已经达到最大容量，最后一步会发生什么呢？大多数基于套接字的系统要么会抛出异常并完全失败处理管道的这一特定数据，要么阻止执行继续并不断重试将数据发送到下一个阶段直到成功。由于我们不希望处理管道失败，因为结果并非错误，也不希望让我们的工作人员等待下一个阶段解除阻塞，我们需要一些可以按顺序保存阶段输入的东西，以便前一个阶段可以继续处理自己的新输入。
- en: Container messaging
  id: totrans-64
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器消息
- en: For the scenario that we just talked about, where back-pressure on individual
    processing stages causes cascade backflow stoppages, message queues (often alternatively
    referred to as pub/sub messaging systems) are here to provide us with the exact
    solution we need. Message queues generally store data as messages in a **First-In**,
    **First-Out** (**FIFO**) queue structure and work by allowing the sender to add 
    the desired inputs to a particular stage's queue ("enqueue") and the worker (listener)
    to trigger on new messages within that queue. When the worker is processing a
    message, the queue hides it from the rest of the workers and when the worker is
    complete and successful, the message is removed from the queue permanently. By
    operating on results in an asynchronous manner, we can allow the senders to keep
    working on their own tasks and completely modularize the data processing pipeline.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们刚刚讨论的情景，即个别处理阶段的背压导致级联回流停止的情况，消息队列（通常也称为发布/订阅消息系统）在这里为我们提供了我们需要的确切解决方案。消息队列通常将数据存储为**先进先出**（FIFO）队列结构中的消息，并通过允许发送方将所需的输入添加到特定阶段的队列（"入队"），并允许工作人员（监听器）在该队列中触发新消息来工作。当工作人员处理消息时，队列会将其隐藏在其他工作人员之外，当工作人员完成并成功时，消息将永久从队列中删除。通过以异步方式处理结果，我们可以允许发送方继续处理自己的任务，并完全模块化数据处理管道。
- en: 'To see queues in action, let''s say we have two running containers and within
    a very short period of time, messages **A**, **B**, **C**, and **D** arrive one
    after another as inputs from some imaginary processing step (red indicating the
    top of the queue):'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了看到队列的运作，假设我们有两个正在运行的容器，并且在很短的时间内，消息**A**、**B**、**C**和**D**一个接一个地作为来自某个想象的处理步骤的输入到达（红色表示队列顶部）：
- en: '![](assets/4ca21d49-acf4-4270-9a8b-5ebe5a31716f.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4ca21d49-acf4-4270-9a8b-5ebe5a31716f.png)'
- en: 'Internally, the queue tracks their ordering, and initially, neither of the
    container queue listeners have noticed the messages, but very quickly, they get
    a notification that there is new work to be done, so they get the messages in
    the order in which they were received. The messaging queue (depending on the exact
    implementation) marks those messages as unavailable for other listeners and sets
    a timeout for the worker to complete. In this example **Message A** and **Message
    B** have been marked for processing by the available workers:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部，队列跟踪它们的顺序，最初，容器队列监听器都没有注意到这些消息，但很快，它们收到通知，有新的工作要做，所以它们按接收顺序获取消息。消息队列（取决于确切的实现）将这些消息标记为不可用于其他监听器，并为工作人员设置一个完成的超时。在这个例子中，**消息A**和**消息B**已被标记为可供可用工作人员处理：
- en: '![](assets/8c7c07c9-7469-4ebd-9884-94731f6384d2.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/8c7c07c9-7469-4ebd-9884-94731f6384d2.png)'
- en: 'During this process, let''s assume that **Container** 1 had a catastrophic
    failure and it just died. **Message A** timeout on the queue expires without it
    being finished so the queue puts it back on top and makes it available again for
    listeners while our other container keeps on working:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，假设**容器**1发生了灾难性故障并且它就这样死了。**消息A**在队列中的超时时间到期，而它还没有完成，所以队列将其放回顶部，并使其再次可用于侦听器，而我们的另一个容器继续工作：
- en: '![](assets/23561640-e0a7-44ad-8f4a-b5076d565155.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/23561640-e0a7-44ad-8f4a-b5076d565155.png)'
- en: 'With **Message B** successfully completed, **Container 2** notifies the queue
    that the task is done and the queue removes it completely from its lists. With
    that out of the way, the container now takes the topmost message, which turns
    out to be the unfinished **Message A** and the process continues just like before:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 成功完成**消息B**后，**容器2**通知队列任务已完成，并且队列将其从列表中完全移除。完成这一步后，容器现在取出最顶部的消息，结果是未完成的**消息A**，整个过程就像以前一样进行：
- en: '![](assets/97d75585-51a9-4eef-bdf8-9bb82855def0.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/97d75585-51a9-4eef-bdf8-9bb82855def0.png)'
- en: While this cluster stage has been dealing with failures and overloading, the
    previous stage that put all of these messages in the queue kept working on its
    dedicated workload. Our current stage also has not lost any data even though half
    of our processing capability got forcefully removed at a random point in time.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个集群阶段处理故障和过载的同时，将所有这些消息放入队列的上一个阶段继续处理其专用工作负载。即使在某个随机时间点，我们的处理能力的一半被强制移除，我们当前的阶段也没有丢失任何数据。
- en: 'The new pseudocode loop for a worker would be a bit more like this now:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，工作人员的新伪代码循环会更像这样：
- en: Register as a listener on a queue.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在队列上注册为侦听器。
- en: 'Loop forever doing the following:'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 永远循环执行以下操作：
- en: Wait for a message from the queue.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等待队列中的消息。
- en: Process the data from the queue.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理队列中的数据。
- en: Send the processed data to the next queue.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将处理后的数据发送到下一个队列。
- en: With this new system, if there is any kind of processing slowdown in the pipeline,
    the queues for those overloaded stages will start to grow in size, but if the
    earlier stages slow down, the queues will shrink until they are empty. As long
    as the maximum queue size can handle the volume of messages and the overloaded
    stages can handle the average demands, you can ascertain that all the data that
    is in the pipeline will be eventually processed and your triggers for scaling
    up stages are pretty much as simple as noticing larger queues that are not caused
    by bugs. This not only helps mitigate differences in pipeline stage scaling, but
    it also helps preserve data if pieces of your cluster go down since the queues
    will grow during failure time and then empty as you bring your infrastructure
    back to fully working - and all of this will happen without data loss.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个新系统，如果管道中的某个阶段出现任何处理减速，那么这些过载阶段的队列将开始增长，但如果较早的阶段减速，队列将缩小直到为空。只要最大队列大小能够处理消息的数量，过载阶段能够处理平均需求，你就可以确定管道中的所有数据最终都会被处理，而且扩展阶段的触发器几乎就像是注意到不是由错误引起的更大的队列一样简单。这不仅有助于缓解管道阶段扩展的差异，而且还有助于在集群的某些部分出现故障时保留数据，因为队列在故障时会增长，然后在将基础设施恢复到正常工作时会清空
    - 所有这些都将在不丢失数据的情况下发生。
- en: If this bundle of benefits was not enough of a positive, consider that you can
    now have a guarantee that the data was processed since the queue keeps the data
    around so if a worker dies, the queue will (as we've seen earlier) put the message
    back in the queue to possibly get processed by another worker, unlike socket-based
    processing which would just silently die in that case. The increase in processing
    density, increase in failure tolerance, and better handling of burst data makes
    queues extremely attractive to container developers. If all your communication
    is also done with queues, service discovery might not even be needed for these
    workers except to tell them where the queue manager is since the queue is doing
    that discovery work for you.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这些好处的组合还不够积极，那么请考虑现在可以保证数据已经被处理，因为队列会保留数据，所以如果一个工作进程死掉，队列会（正如我们之前看到的）将消息放回队列，可能由另一个工作进程处理，而不像基于套接字的处理那样在这种情况下会悄然死去。处理密度的增加、故障容忍度的增加以及对突发数据的更好处理使队列对容器开发者非常有吸引力。如果你所有的通信也都是通过队列完成的，那么服务发现甚至可能不需要对这些工作进程进行除了告诉它们队列管理器在哪里之外的工作，因为队列正在为你做这项发现工作。
- en: Unsurprisingly, most queues come at a development cost, which is why they are
    not as widely in use as one might expect. In most cases, you will not only need
    to add custom queue client libraries to your worker code, but in many types of
    deployments, you will also need a process or a daemon somewhere that will be the
    main queue arbitrator that handles the messages. In fact, I would probably go
    as far as to say that choosing the messaging system alone is a research task onto
    itself, but if you're looking for quick answers, generally Apache Kafka ([https://kafka.apache.org/](https://kafka.apache.org/)),
    RabbitMQ ([https://www.rabbitmq.com/](https://www.rabbitmq.com/)), and Redis-backed
    custom implementations ([https://redis.io/](https://redis.io/)) seem to be more
    popular in clustering contexts for in-house messaging queues going from the biggest
    deployments to the smallest, respectively.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，大多数队列都需要开发成本，这就是为什么它们没有像人们预期的那样被广泛使用的原因。在大多数情况下，你不仅需要将自定义队列客户端库添加到你的工作代码中，而且在许多类型的部署中，你还需要一个处理消息的主要队列仲裁者的进程或守护进程。事实上，我可能会说选择消息系统本身就是一个研究任务，但如果你正在寻找快速答案，一般来说，Apache
    Kafka（[https://kafka.apache.org/](https://kafka.apache.org/)）、RabbitMQ（[https://www.rabbitmq.com/](https://www.rabbitmq.com/)）和基于Redis的自定义实现（[https://redis.io/](https://redis.io/)）似乎在集群环境中更受欢迎，从最大的部署到最小的部署。
- en: As with all things we have been covering so far, most cloud providers offer
    some type of service for this (AWS SQS, Google Cloud Pub/Sub, Azure Queue Storage,
    and so on) so that you don't have to build it yourself. If you are OK with spending
    a little bit more money, you can utilize these and not worry about hosting the
    daemon process yourself. Historically, messaging queues have been hard to maintain
    and manage properly in house, so I would venture to say that many, if not most,
    cloud systems use these services instead of deploying their own.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们迄今为止一直在讨论的所有事物一样，大多数云提供商都提供了某种类型的服务（如AWS SQS，Google Cloud Pub/Sub，Azure
    Queue Storage等），这样你就不必自己构建它。如果你愿意多花一点钱，你可以利用这些服务，而不必担心自己托管守护进程。从历史上看，消息队列在内部维护和管理方面一直很难，所以我敢说，许多云系统使用这些服务，而不是部署自己的服务。
- en: Implementing our own messaging queue
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现我们自己的消息队列
- en: With the theory out of the way, let's see how we can build our own little queue
    publisher and listener. For our example here, we will use one of the simpler messaging
    systems based on Redis called `bull` ([https://www.npmjs.com/package/bull](https://www.npmjs.com/package/bull)).
    First we will write the code that will run this whole system, and to make things
    easy for us, we will use the same image for both the consumer and the producer.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 理论讲解完毕，让我们看看如何构建我们自己的小型队列发布者和监听者。在这个例子中，我们将使用基于Redis的较简单的消息系统之一，名为`bull`（[https://www.npmjs.com/package/bull](https://www.npmjs.com/package/bull)）。首先，我们将编写将运行整个系统的代码，并且为了简化操作，我们将同时使用相同的镜像作为消费者和生产者。
- en: 'In a new directory, create the following:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个新的目录中，创建以下内容：
- en: As a reminder, this code is also in the GitHub repository and you can view it
    or clone it from [https://github.com/sgnn7/deploying_with_docker/tree/master/chapter_6/redis_queue](https://github.com/sgnn7/deploying_with_docker/tree/master/chapter_6/redis_queue)
    if you do not want to type the full text.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，这段代码也在GitHub存储库中，如果你不想输入完整的文本，可以在[https://github.com/sgnn7/deploying_with_docker/tree/master/chapter_6/redis_queue](https://github.com/sgnn7/deploying_with_docker/tree/master/chapter_6/redis_queue)查看或克隆它。
- en: package.json
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: package.json
- en: 'This file is pretty much just a copy of our older example with the addition
    of the `bull` package and a name change:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件基本上只是我们旧的示例的副本，增加了`bull`包和名称更改：
- en: '[PRE9]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: index.js
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: index.js
- en: '`index.js` is a single-file app that either sends a timestamp every 1.5 seconds
    to the queue or reads from the queue depending on the invocation argument. The
    queue location is defined by the `QUEUE_HOST` environment variable:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`index.js`是一个单文件应用程序，根据调用参数，每1.5秒要么向队列发送一个时间戳，要么从队列中读取。队列位置由`QUEUE_HOST`环境变量定义：'
- en: '[PRE10]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Dockerfile
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Dockerfile
- en: 'Nothing special here: the file is pretty much a trimmed-down version of our
    older Node.js app:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有什么特别的：这个文件基本上是我们旧的Node.js应用程序的精简版本：
- en: '[PRE11]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will build the image now:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将构建镜像：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'With the image building out of the way, we can now write out our stack definition
    file: `swarm_application.yml`. We are pretty much creating the queue server, the
    queue listener, and the queue sender on a single network and making sure that
    they can find each other here:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建镜像，我们现在可以编写我们的堆栈定义文件：`swarm_application.yml`。我们基本上是在单个网络上创建队列服务器、队列监听器和队列发送器，并确保它们可以在这里找到彼此：
- en: '[PRE13]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Having both image built and the stack definition, we can launch our queue cluster
    to see whether it works:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在镜像构建和堆栈定义都完成后，我们可以启动我们的队列集群，看看它是否正常工作：
- en: '[PRE14]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: At this point, we could add any number of senders and listeners (within reason)
    and our system will work just fine in a very asynchronous style, increasing throughput
    at both ends. As a reminder, though, if you decide to go this route, another queue
    type is highly advised (Kafka, SQS, and so on) but the underlying principles are
    pretty much the same.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们可以添加任意数量的发送者和监听者（在合理范围内），我们的系统将以非常异步的方式正常工作，从而增加两端的吞吐量。不过，作为提醒，如果你决定走这条路，强烈建议使用另一种队列类型（如Kafka、SQS等），但基本原则基本上是相同的。
- en: Advanced security
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级安全
- en: We have covered some security issues in previous chapters, but for some issues
    that seem to be frequently ignored, we need to cover them with a little bit more
    depth than the small info box in the middle of the text and see why they are such
    large issues when used improperly. While it might seem like a lot of work to implement
    all the things we pointed out in various warnings and info boxes, the smaller
    the attack surface you provide to your potential intruders, the better you will
    be in the long run. That said, unless you are working on deploying this system
    for a government agency, I expect that there will be some compromises but I urge
    you to strongly weigh the pros and cons for each otherwise you risk getting that
    dreaded midnight call about an intrusion.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在之前的章节中已经涵盖了一些安全问题，但对于一些似乎经常被忽视的问题，我们需要更深入地讨论它们，而不仅仅是在文本中间的小信息框中看到它们，并了解为什么当不正确使用时它们会成为如此严重的问题。虽然在实施我们在各种警告和信息框中指出的所有事情可能会显得很费力，但是你提供给潜在入侵者的攻击面越小，从长远来看你就会越好。也就是说，除非你正在为政府机构部署这个系统，我预计会有一些妥协，但我敦促你强烈权衡每个方面的利弊，否则你就有可能会收到那个可怕的午夜电话，通知你发生了入侵。
- en: Ironically, hardened systems usually take so much time to develop and deploy
    that they are often obsolete or provide marginal business value by the time they
    are in production environments, and due to their carefully assembled pieces, they
    are rarely (if ever) updated with a newer functionality, have patches applied
    to them quickly, or code improvements done on the source so it is a truly a double-edged
    sword. There is *never* a perfect solution, only a range of things you are comfortable
    with to some degree of dealing with. Historically, I have mostly seen horrible
    execution on either extremes of the fence so my advice here is that you look for
    a blend of the two if possible.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 具有讽刺意味的是，加固系统通常需要花费大量时间来开发和部署，以至于它们往往在投入生产环境时已经过时或提供的业务价值较小，并且由于它们精心组装的部件，它们很少（如果有的话）会更新为新功能，迅速应用补丁，或对源代码进行改进，因此它真的是一把双刃剑。没有*完美的解决方案，只有一系列你在某种程度上感到舒适的事情。从历史上看，我大多数情况下看到的是在两个极端之间的可怕执行，所以我在这里的建议是，如果可能的话，你应该寻求两者的结合。
- en: Mounting the Docker socket into the container
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Docker套接字挂载到容器中
- en: This is by far the most egregious security hole that developers completely disregard
    when deploying containerized solutions. For various things related to container
    management, often advice on the Internet is generally leaning toward bind-mounting
    the Docker socket (`/var/run/docker.sock`) into the container, but the thing rarely
    mentioned is effectively giving the host's root-level access to such a container
    when you do this. Since the Docker's socket is actually just an API endpoint and
    the Docker daemon runs as the root, the container can simply escape its containment
    by launching other containers with the host's system folders being mounted on
    them and then executing arbitrary commands on them.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对是开发人员在部署容器化解决方案时完全忽视的最严重的安全漏洞。对于与容器管理相关的各种事情，通常在互联网上的建议都倾向于将Docker套接字（`/var/run/docker.sock`）绑定到容器中，但很少提到的是这样做实际上会有效地将主机的根级访问权限赋予这样的容器。由于Docker的套接字实际上只是一个API端点，而Docker守护程序以root身份运行，容器可以通过在其上挂载主机系统文件夹并在其上执行任意命令来简单地逃离其封闭环境。
- en: 'For more information on using the Docker socket as a RESTful endpoint, you
    can take a look at the source code or explore a bit through the documentation
    for Docker Engine API at [https://docs.docker.com/engine/api/v1.31/](https://docs.docker.com/engine/api/v1.31/).
    The only thing you will generally need to do to use it through a tool such as
    `curl` is to add `--unix-socket <socket_path>` and, optionally `-H "Content-Type:
    application/json"` for `POST` requests.Docker has been making strides at turning
    its service into a userspace one from a root-level one, but so far, this feature
    has not materialized in any practical manner. While personally I have reservations
    about this happening anytime soon, keep an eye out for this feature as at some
    point it may actually get released and become a usable feature which would be
    a huge step forward for container security.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '有关使用Docker套接字作为RESTful端点的更多信息，您可以查看源代码，或者通过Docker Engine API的文档进行探索[https://docs.docker.com/engine/api/v1.31/](https://docs.docker.com/engine/api/v1.31/)。通常，您只需要通过诸如`curl`之类的工具添加`--unix-socket
    <socket_path>`，并且对于`POST`请求，可以选择添加`-H "Content-Type: application/json"`。'
- en: 'With the theory of how to misuse the Docker socket, now we will break out of
    our container though we will stop short of actually doing anything damaging to
    the system:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Docker一直在努力将其服务从根级别转变为用户空间级别，但到目前为止，这个功能还没有以任何实际的方式实现。尽管我个人对这种情况很怀疑，但请留意这个功能，因为在某个时候它可能会真正发布并成为一个可用的功能，这将是容器安全性的重大进步。
- en: '[PRE15]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: It should be apparent now how the benign container was able to root the host
    with just a few CLI commands. While some of it is predicated on the container
    process running as the root, the same could possibly be done if the Docker group
    ID clashes with a non-privileged group within the container, but with nitpicks
    aside, suffice it to say that mounting the Docker socket without fully understanding
    the implications can lead to a very painful breach. With that in mind, there are
    (albeit rare) legitimate uses of this technique so use your best judgment here.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在应该很明显了，良性容器是如何能够仅通过几个CLI命令就在主机上获得root权限的。虽然其中一些是基于容器进程以root身份运行，但如果Docker组ID与容器中的非特权组冲突，可能也会出现相同的情况，但是除了这些细微之处，可以说，挂载Docker套接字而不完全理解其影响可能导致非常痛苦的违规行为。考虑到这一点，这种技术也有（虽然很少）合法的用途，所以在这里要慎重使用。
- en: Host security scans
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在我们已经了解了如何滥用Docker套接字的理论，接下来我们将跳出容器，尽管我们不会真的对系统造成任何破坏：主机安全扫描。
- en: 'As part of a drive to increase the security of deployments, a tool was released
    by Docker that can help easily identify the most common security issues with a
    host running a Docker Engine called **Docker Bench for Security**. This tool will
    scan and verify a large number of possible weaknesses in your configuration and
    will present them in a very easy-to-read listing. You can download and run this
    image just like you would one of the other regular containers available on Docker
    Hub:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 作为增加部署安全性的一部分，Docker发布了一个工具，可以帮助轻松识别运行Docker Engine的主机上最常见的安全问题，称为**Docker Bench
    for Security**。这个工具将扫描和验证配置中的大量可能的弱点，并以非常易于阅读的列表形式呈现出来。您可以像在Docker Hub上使用其他常规容器一样下载和运行这个镜像。
- en: Warning! This security scan requires many permissions (`--net host`, `--pid
    host`, Docker socket mounting, and so on) that we have covered as generally really
    bad ideas to run on a host since they present a pretty large attack vector for
    malicious actors but on the other hand, the scan needs those permissions to check
    the settings you have. As such, I would highly recommend running this type of
    security scan on a clone of the host machine that you are trying to test in a
    network-isolated environment in order to prevent compromises of your infrastructure
    if the scanning image is maliciously modified.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 警告！此安全扫描需要许多权限（`--net host`、`--pid host`、Docker 套接字挂载等），我们已经讨论过这些权限通常是在主机上运行的一个非常糟糕的主意，因为它们为恶意行为者提供了一个相当大的攻击向量，但另一方面，扫描需要这些权限来检查您的设置。因此，我强烈建议在网络隔离的环境中克隆要测试的主机机器上运行这种类型的安全扫描，以防止扫描镜像被恶意修改而危及您的基础设施。
- en: '[PRE16]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The list is pretty long, so most of the output lines were removed, but you should
    have a pretty good idea about what this tool does and how to use it. Note that
    this is not the only product in this space (e.g. Clair from CoreOS at [https://github.com/coreos/clair](https://github.com/coreos/clair))
    so try to use as many of them as you can in order to see where your weaknesses
    in the infrastructure lie.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 列表相当长，因此大部分输出行都被删除了，但你应该对这个工具的功能和如何使用有一个相当好的了解。请注意，这不是这个领域唯一的产品（例如，CoreOS 的
    Clair 在 [https://github.com/coreos/clair](https://github.com/coreos/clair)），因此尽量使用尽可能多的产品，以便了解基础设施的弱点所在。
- en: Read-only containers
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 只读容器
- en: 'In the development of our previous examples spanning most of the chapters,
    we did not really pay much attention to whether containers changed the state of
    the filesystem while running. This is not such a problem for test and development
    systems, but in production, it is very important to lock things down even further
    in order to prevent malicious runtime exploitation from both internal and external
    sources. For this purpose, there is a `docker run --read-only` flag, which (unsurprisingly)
    mounts the container''s root filesystem as read-only. By doing this, we ensure
    that all data that is not mounted with volumes is as pristine as when we built
    the image, ensuring consistency and protecting your cluster. The only thing that
    you might need to be careful of if you run the containers in this manner is that
    locations for temporary storage of files in places such as `/run`, `/tmp`, and
    `/var/tmp` are extremely likely to be required by the container during execution,
    so these mounts should be additionally mounted as `tmpfs` volumes:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们之前的示例开发中，跨越了大部分章节，我们并没有真正关注容器在运行时是否改变了文件系统的状态。这对于测试和开发系统来说并不是问题，但在生产环境中，进一步加强锁定非常重要，以防止来自内部和外部来源的恶意运行时利用。为此，有一个
    `docker run --read-only` 标志，它（不出所料地）将容器的根文件系统挂载为只读。通过这样做，我们确保除了使用卷挂载的数据外，所有数据都与构建镜像时一样纯净，确保一致性并保护您的集群。如果以这种方式运行容器，您唯一需要注意的是，容器在执行过程中极有可能需要临时存储文件的位置，例如
    `/run`、`/tmp` 和 `/var/tmp`，因此这些挂载应该额外作为 `tmpfs` 卷挂载：
- en: '[PRE17]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If you do not expect your container to change anything on the filesystem and
    since containers should generally not need to write to paths such as `/usr`, using
    this flag in production is highly recommended, so apply it liberally to all your
    static services if possible.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不希望容器在文件系统上做出任何更改，并且由于容器通常不需要写入 `/usr` 等路径，强烈建议在生产中使用此标志，因此如果可能的话，请在所有静态服务上广泛应用它。
- en: Base system (package) updates
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础系统（软件包）更新
- en: We talked a little about this previously, but it seems that in most online documentation
    and blogs, package updates have been sorely neglected in coverage within the context
    of Docker containers. While there are supporters of both camps, it is important
    to remember that there is no guarantee that the tagged images available from places
    such as Docker Hub have been built with the latest updates, and even in cases
    where they are, the tagged image might have been built a while ago and, as such,
    won't contain the latest security patches.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前已经谈到了这个问题，但似乎在大多数在线文档和博客中，Docker容器环境中软件包更新的覆盖范围被严重忽视。虽然支持者有两种观点，但重要的是要记住，无法保证来自Docker
    Hub等地方可用的标记图像是否已经使用最新的更新构建，即使在这些情况下，标记图像可能已经建立了一段时间，因此不包含最新的安全补丁。
- en: While it is true that within Docker containers, the host's kernel is used to
    run the context of the container, a security hole in any of the supporting libraries
    within the container can (and usually does) result in a breach that can often
    cascade onto the host and into your whole network. Due to this fact, my personal
    recommendation for containers that will be deployed to production is that you
    should always make sure that the container is built with the latest libraries
    if possible. There are definite risks, albeit small, in manually upgrading packages
    on some base images that are caused by library incompatibilities that occur when
    you do the upgrade, but as a general rule, it is a risk worth taking.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在Docker容器中使用主机的内核来运行容器的上下文是真实的，但容器中任何支持库的安全漏洞通常会导致漏洞，这些漏洞经常会级联到主机和整个网络中。因此，我个人建议部署到生产环境的容器应该尽可能确保使用最新的库构建容器。手动升级一些基本镜像上的软件包存在明显的风险，这是由于升级时可能会出现库不兼容性，但总的来说，这是一个值得冒的风险。
- en: 'In most cases, in order to do this kind of upgrade, just like we covered earlier
    in most of our Docker examples, you pretty much need to invoke the system upgrade
    lines specific to the base OS distribution of the image in `Dockerfile`. For our
    default deployment OS (Ubuntu LTS), this operation is done with `apt-get update`
    and `apt-get dist-upgrade`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，为了进行这种升级，就像我们在大多数Docker示例中所介绍的那样，你基本上需要在`Dockerfile`中调用特定于镜像基本操作系统发行版的系统升级命令。对于我们默认的部署操作系统（Ubuntu
    LTS），可以使用`apt-get update`和`apt-get dist-upgrade`来完成此操作。
- en: '[PRE18]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Caution! Do not forget that by default, `docker build` will cache all individual
    layers that have unchanged `Dockerfile` directives, so this command will work
    as expected the first time, but its layer will be pulled from the cache any subsequent
    time it is used if none of the lines preceding it have changed due to the fact
    that this line will stay the same regardless of packages changing upstream. If
    you want to ensure that you get the latest updates, you will have to break the
    cache either by changing a line above `apt-get` in your `Dockerfile` or by adding
    `--no-cache` to your `docker build` command. Also, note that using `--no-cache`,
    all layers will be regenerated, possibly causing a prolonged build cycle and/or
    registry disk use.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！不要忘记，默认情况下，`docker build`将缓存所有未更改的`Dockerfile`指令的各个层，因此该命令在第一次使用时会按预期工作，但如果它之前的任何行都没有更改，那么在后续使用时将从缓存中提取其层，因为这行将保持不变，而不管上游包是否更改。如果要确保获取最新更新，必须通过更改`Dockerfile`中`apt-get`上面的行或在`docker
    build`命令中添加`--no-cache`来打破缓存。此外，请注意，使用`--no-cache`将重新生成所有层，可能会导致较长的构建周期和/或注册表磁盘使用。
- en: Privileged mode versus --cap-add and --cap-drop
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特权模式与--cap-add和--cap-drop
- en: 'Some advanced things that you might want to do within a container, such as
    **Docker-in-Docker (DinD)**, NTP, mounting loopback devices, and many others,
    will require higher privileges than the ones given to the root user of the container
    by default. As such, additional privileges need to be allowed for the container
    to run without issues, so for that use case, Docker has a very simple but extremely
    broad privileged mode that adds the complete host''s capabilities to the container.
    To use this mode, just append `--privileged` to the `docker run` command:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器内可能需要执行的一些高级操作，例如**Docker-in-Docker（DinD）**、NTP、挂载回环设备等，都需要比默认情况下容器的根用户所拥有的更高权限。因此，需要为容器允许额外的权限，以便它能够无问题地运行，因此，对于这种情况，Docker有一个非常简单但非常广泛的特权模式，它将主机的完整功能添加到容器中。要使用此模式，只需在`docker
    run`命令后附加`--privileged`：
- en: '**Docker-in-Docker** (commonly known as **DinD**) is a special configuration
    of a container that allows you to run the Docker Engine within the container that
    is already running on a Docker Engine but without sharing the Docker socket, which
    allows (if precautions are taken) a more secure and robust way to build containers
    within your infrastructure that is already containerized. The prevalence of this
    configuration is somewhat rare but is very powerful when used as part of a **Continuous
    Integration** (**CI**) and **Continuous Delivery** (**CD**) setup.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker-in-Docker**（通常称为**DinD**）是容器的特殊配置，允许您在已在Docker引擎上运行的容器内运行Docker引擎，但不共享Docker套接字，这允许（如果采取预防措施）更安全和更可靠地在已容器化的基础架构中构建容器。这种配置的普及程度有些罕见，但在**持续集成**（**CI**）和**持续交付**（**CD**）设置的一部分时非常强大。'
- en: '[PRE19]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, adding this flag removes all errors from the output as we can
    now change the system time.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，添加此标志将从输出中删除所有错误，因为我们现在可以更改系统时间。
- en: 'With the functionality of this mode explained, we can now talk about why ideally,
    if possible, you should never use the privileged mode. By default, the privileged
    mode allows practically full access to most of the host''s systems and is not
    granular enough to make sense in most circumstances, so after you figure out that
    your container needs additional privileges, you should selectively add them with
    `--cap-add` instead. These flags are standard Linux capability identifiers that
    you can find in places such as [http://man7.org/linux/man-pages/man7/capabilities.7.html](http://man7.org/linux/man-pages/man7/capabilities.7.html)
    and allow fine-tuning to the level of access you desire. If we now convert our
    previous NTP daemon example into this new style, it should look a bit more like
    this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 解释了此模式的功能后，我们现在可以谈论为什么在理想情况下，如果可能的话，您永远不应该使用特权模式。默认情况下，特权模式几乎允许访问主机系统的所有内容，并且在大多数情况下不够细粒度，因此在确定容器需要额外权限后，应该使用`--cap-add`有选择地添加它们。这些标志是标准的Linux功能标识符，您可以在[http://man7.org/linux/man-pages/man7/capabilities.7.html](http://man7.org/linux/man-pages/man7/capabilities.7.html)等地方找到，并允许对所需的访问级别进行微调。如果我们现在将先前的NTP守护程序示例转换为这种新样式，它应该看起来更像这样：
- en: '[PRE20]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: If you noticed, we still have an error visible due to another missing capability,
    but the `settimeofday` error is gone, which is the most important problem that
    we needed to fix for this container to run.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您注意到，由于另一个缺失的功能，我们仍然有一个可见的错误，但`settimeofday`错误已经消失了，这是我们需要解决的最重要的问题，以便该容器能够运行。
- en: 'Interestingly enough, we can also drop capabilities from our container that
    are not being used with `--cap-drop` if we want to increase security. For this
    flag, there is also a special keyword, `ALL`, that can be used to drop all available
    privileges. If we use this to fully lock down our NTP container but have everything
    working, let us see what that will look like:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，我们还可以使用`--cap-drop`从容器中删除未被使用的功能，以增加安全性。对于这个标志，还有一个特殊的关键字`ALL`，可以用来删除所有可用的权限。如果我们使用这个来完全锁定我们的NTP容器，但一切正常运行，让我们看看会是什么样子：
- en: '[PRE21]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here, we have removed all capabilities first and then added back the few that
    are really needed to run the container, and as you can see, things are working
    just fine. In your own deployments, I would strongly suggest that if you have
    spare development capacity or are security-oriented, take some time to lock your
    running containers in this manner as they will be much more secure and you will
    be much more sure that the container is running with the principle of least privilege.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们首先删除了所有的功能，然后再添加回运行容器所需的少数功能，正如您所看到的，一切都运行正常。在您自己的部署中，我强烈建议，如果您有多余的开发能力或者注重安全性，花一些时间以这种方式锁定正在运行的容器，这样它们将更加安全，您也将更加确信容器是在最小权限原则下运行的。
- en: The **Principle of Least Privilege** is a concept in computer security where
    you allow only the minimal privileges needed to run a component to the user or
    a service. This principle is very much a staple of high-security implementations
    but is often not found elsewhere due to the assumed overhead of managing the access
    even though it is a great way to increase the security and stability of your systems.
    If you would like to find out more about this concept, you should definitely make
    your way to [https://en.wikipedia.org/wiki/Principle_of_least_privilege](https://en.wikipedia.org/wiki/Principle_of_least_privilege)
    and check it out.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: “最小权限原则”是计算机安全中的一个概念，它只允许用户或服务运行组件所需的最低权限。这个原则在高安全性实现中非常重要，但通常在其他地方很少见，因为管理访问的开销被认为很大，尽管这是增加系统安全性和稳定性的好方法。如果您想了解更多关于这个概念的信息，您应该去[https://en.wikipedia.org/wiki/Principle_of_least_privilege](https://en.wikipedia.org/wiki/Principle_of_least_privilege)查看一下。
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we have learned many advanced tools and techniques needed
    to deploy robust clusters, such as the following:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了许多部署强大集群所需的高级工具和技术，例如以下内容：
- en: Additional debugging options to manage container issues.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理容器问题的额外调试选项。
- en: Deep dives into Docker's advanced networking topics.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入研究Docker的高级网络主题。
- en: Implementing our own queue messaging.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施我们自己的队列消息传递。
- en: Various security hardening tips and tricks.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 各种安全加固技巧和窍门。
- en: All of these topics combined with previous material should cover the gamut of
    deployment needs for most clusters. But in the next chapter, we will see what
    issues we need to worry about when the number of hosts, services, and tasks reaches
    levels that aren't generally expected and we start seeing the clusters fall apart
    and what we can do to mitigate such problems.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些主题加上之前的材料应该涵盖了大多数集群的部署需求。但在下一章中，我们将看到当主机、服务和任务的数量达到通常不被期望的水平时，我们需要担心什么问题，以及我们可以采取什么措施来减轻这些问题。
