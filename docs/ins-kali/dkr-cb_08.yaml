- en: Chapter 8. Docker Orchestration and Hosting Platforms
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第8章 Docker编排和托管平台
- en: 'In this chapter, we will cover the following recipes:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下配方：
- en: Running applications with Docker Compose
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose运行应用程序
- en: Setting up Cluster with Docker Swarm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Swarm设置集群
- en: Setting up CoreOS for Docker orchestration
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Docker编排设置CoreOS
- en: Setting up a Project Atomic host
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Project Atomic主机
- en: Doing atomic update/rollback with Project Atomic
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Project Atomic进行原子更新/回滚
- en: Adding more storage for Docker in Project Atomic
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Project Atomic中的Docker添加更多存储
- en: Setting up Cockpit for Project Atomic
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为Project Atomic设置Cockpit
- en: Setting up a Kubernetes cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置Kubernetes集群
- en: Scaling up and down in a Kubernetes cluster
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中进行扩展和缩减
- en: Setting up WordPress with a Kubernetes cluster
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kubernetes集群设置WordPress
- en: Introduction
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍
- en: Running Docker on a single host may be good for the development environment,
    but the real value comes when we span multiple hosts. However, this is not an
    easy task. You have to orchestrate these containers. So, in this chapter, we'll
    cover some of the orchestration tools and hosting platforms.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在单个主机上运行Docker可能对开发环境有好处，但当我们跨多个主机时才能发挥真正的价值。然而，这并不是一件容易的事情。您必须编排这些容器。因此，在本章中，我们将介绍一些编排工具和托管平台。
- en: 'Docker Inc. announced two such tools:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Inc.宣布了两种工具：
- en: Docker Compose ([https://docs.docker.com/compose](https://docs.docker.com/compose))
    to create apps consisting of multiple containers and Docker Swarm ([https://docs.docker.com/swarm/](https://docs.docker.com/swarm/))
    to cluster multiple Docker hosts. Docker Compose was previously called Fig ([http://www.fig.sh/](http://www.fig.sh/)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Docker Compose（[https://docs.docker.com/compose](https://docs.docker.com/compose)）创建由多个容器组成的应用程序，使用Docker
    Swarm（[https://docs.docker.com/swarm/](https://docs.docker.com/swarm/)）来集群多个Docker主机。Docker
    Compose以前被称为Fig（[http://www.fig.sh/](http://www.fig.sh/)）。
- en: CoreOS ([https://coreos.com/](https://coreos.com/)) created etcd ([https://github.com/coreos/etcd](https://github.com/coreos/etcd))
    for consensus and service discovery, fleet ([https://coreos.com/using-coreos/clustering](https://coreos.com/using-coreos/clustering))
    to deploy containers in a cluster, and flannel ([https://github.com/coreos/flannel](https://github.com/coreos/flannel))
    for overlay networking.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS（[https://coreos.com/](https://coreos.com/)）创建了etcd（[https://github.com/coreos/etcd](https://github.com/coreos/etcd)）用于一致性和服务发现，fleet（[https://coreos.com/using-coreos/clustering](https://coreos.com/using-coreos/clustering)）用于在集群中部署容器，flannel（[https://github.com/coreos/flannel](https://github.com/coreos/flannel)）用于覆盖网络。
- en: Google started Kubernetes ([http://kubernetes.io/](http://kubernetes.io/)) for
    Docker orchestration. Kubernetes provides mechanisms for application deployment,
    scheduling, updating, maintenance, and scaling.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌启动了Kubernetes（[http://kubernetes.io/](http://kubernetes.io/)）用于Docker编排。Kubernetes提供了应用部署、调度、更新、维护和扩展的机制。
- en: Red Hat launched a container-specific operating system called Project Atomic
    ([http://www.projectatomic.io/](http://www.projectatomic.io/)), which can leverage
    the orchestration capabilities of Kubernetes.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 红帽推出了一个专门针对容器的操作系统，名为Project Atomic（[http://www.projectatomic.io/](http://www.projectatomic.io/)），可以利用Kubernetes的编排能力。
- en: Even Microsoft announced a specialized operating system for Docker ([http://azure.microsoft.com/blog/2015/04/08/microsoft-unveils-new-container-technologies-for-the-next-generation-cloud/](http://azure.microsoft.com/blog/2015/04/08/microsoft-unveils-new-container-technologies-for-the-next-generation-cloud/)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 甚至微软也宣布了专门为Docker设计的操作系统（[http://azure.microsoft.com/blog/2015/04/08/microsoft-unveils-new-container-technologies-for-the-next-generation-cloud/](http://azure.microsoft.com/blog/2015/04/08/microsoft-unveils-new-container-technologies-for-the-next-generation-cloud/)）。
- en: Apache Mesos ([http://mesos.apache.org/](http://mesos.apache.org/)), which provides
    resource management and scheduling across entire datacenter and cloud environments,
    also added support for Docker ([http://mesos.apache.org/documentation/latest/docker-containerizer/](http://mesos.apache.org/documentation/latest/docker-containerizer/)).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Apache Mesos（[http://mesos.apache.org/](http://mesos.apache.org/)）提供了整个数据中心和云环境的资源管理和调度，还增加了对Docker（[http://mesos.apache.org/documentation/latest/docker-containerizer/](http://mesos.apache.org/documentation/latest/docker-containerizer/)）的支持。
- en: VMware also launched the container-specific host VMware Photon ([http://vmware.github.io/photon/](http://vmware.github.io/photon/)).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: VMware还推出了专门针对容器的宿主机VMware Photon（[http://vmware.github.io/photon/](http://vmware.github.io/photon/)）。
- en: 'This is definitely a very interesting space, but the policy management tools
    of many orchestration engines do not make the lives of developers and operators
    easy. They have to learn different tools and formats when they move from one platform
    to another. It would be great if we could have a standard way to build and launch
    composite, multicontainer apps. The Project Atomic community seems to be working
    on one such platform-neutral specification called Nulecule ([https://github.com/projectatomic/nulecule/](https://github.com/projectatomic/nulecule/)).
    A good description about Nulecule is available at [http://www.projectatomic.io/blog/2015/05/announcing-the-nulecule-specification-for-composite-applications/](http://www.projectatomic.io/blog/2015/05/announcing-the-nulecule-specification-for-composite-applications/):'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对是一个非常有趣的领域，但许多编排引擎的策略管理工具并没有让开发人员和运维人员的生活变得轻松。当他们从一个平台转移到另一个平台时，他们必须学习不同的工具和格式。如果我们能够有一种标准的方式来构建和启动复合的多容器应用程序，那将是很棒的。Project
    Atomic社区似乎正在致力于一种名为Nulecule的平台中立规范（[https://github.com/projectatomic/nulecule/](https://github.com/projectatomic/nulecule/)）。关于Nulecule的一个很好的描述可以在[http://www.projectatomic.io/blog/2015/05/announcing-the-nulecule-specification-for-composite-applications/](http://www.projectatomic.io/blog/2015/05/announcing-the-nulecule-specification-for-composite-applications/)找到。
- en: '*"Nulecule defines a pattern and model for packaging complex multi-container
    applications, referencing all their dependencies, including orchestration metadata,
    in a single container image for building, deploying, monitoring, and active management.
    Just create a container with a Nulecule file and the app will ''just work''. In
    the Nulecule spec, you define orchestration providers, container locations and
    configuration parameters in a graph, and the Atomic App implementation will piece
    them together for you with the help of Providers. The Nulecule specification supports
    aggregation of multiple composite applications, and it''s also container and orchestration
    agnostic, enabling the use of any container and orchestration engine."*'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “Nulecule定义了打包复杂的多容器应用程序的模式和模型，引用了它们的所有依赖关系，包括单个容器映像中的编排元数据，用于构建、部署、监视和主动管理。只需创建一个带有Nulecule文件的容器，应用程序就会‘自动运行’。在Nulecule规范中，您可以在图形中定义编排提供者、容器位置和配置参数，Atomic
    App实现将在提供者的帮助下将它们组合在一起。Nulecule规范支持多个复合应用程序的聚合，它也是容器和编排引擎不可知的，可以使用任何容器和编排引擎。”
- en: AtomicApp is a reference implementation ([https://github.com/projectatomic/atomicapp/](https://github.com/projectatomic/atomicapp/))
    of the Nulecule specification. It can be used to bootstrap container applications
    and to install and run them. AtomicApp currently has a limited number of providers
    (Docker, Kubernetes, OpenShift), but support for others will be added soon.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: AtomicApp是Nulecule规范的一个参考实现（[https://github.com/projectatomic/atomicapp/](https://github.com/projectatomic/atomicapp/)）。它可以用来引导容器应用程序的安装和运行。AtomicApp目前支持有限数量的提供者（Docker、Kubernetes、OpenShift），但很快将添加对其他提供者的支持。
- en: On a related note, the CentOS community is building a CI environment, which
    will take advantage of Nulecule and AtomicApp. For further information, visit
    [http://wiki.centos.org/ContainerPipeline](http://wiki.centos.org/ContainerPipeline).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相关的是，CentOS社区正在构建一个CI环境，将利用Nulecule和AtomicApp。欲了解更多信息，请访问[http://wiki.centos.org/ContainerPipeline](http://wiki.centos.org/ContainerPipeline)。
- en: All of the preceding tools and platforms need separate chapters for themselves.
    In this chapter, we'll explore Compose, Swarm, CoreOS, Project Atomic, and Kubernetes
    briefly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所有前述的工具和平台都需要单独的章节来介绍。在本章中，我们将简要探讨Compose、Swarm、CoreOS、Project Atomic和Kubernetes。
- en: Running applications with Docker Compose
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose运行应用程序
- en: Docker Compose ([http://docs.docker.com/compose/](http://docs.docker.com/compose/))
    is the native Docker tool to run the interdependent containers that make up an
    application. We define a multicontainer application in a single file and feed
    it to Docker Compose, which sets up the application. At the time of writing, Compose
    is still not production-ready. In this recipe, we'll once again use WordPress
    as a sample application to run.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose（[http://docs.docker.com/compose/](http://docs.docker.com/compose/)）是运行组成应用程序的相互依赖容器的本地Docker工具。我们在一个文件中定义一个多容器应用程序，并将其提供给Docker
    Compose，它会设置应用程序。在撰写本文时，Compose仍未达到生产就绪状态。在本教程中，我们将再次使用WordPress作为示例应用程序来运行。
- en: Getting ready
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: 'Make sure you have Docker Version 1.3 or later installed on the system. To
    install Docker Compose, run the following command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 确保系统上安装了Docker版本1.3或更高版本。要安装Docker Compose，请运行以下命令：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: How to do it…
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: Create a directory for the application, and within it create `docker-compose.yml`
    to define the app:![How to do it…](../Images/image00378.jpeg)
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为应用程序创建一个目录，并在其中创建`docker-compose.yml`来定义应用程序：![如何做…](../Images/image00378.jpeg)
- en: We have taken the preceding example from the official WordPress Docker repo
    on Docker Hub ([https://registry.hub.docker.com/_/wordpress/](https://registry.hub.docker.com/_/wordpress/)).
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们从Docker Hub的官方WordPress Docker存储库（[https://registry.hub.docker.com/_/wordpress/](https://registry.hub.docker.com/_/wordpress/)）中获取了上述示例。
- en: 'Within the app directory, run the following command to build the app:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在应用程序目录中，运行以下命令构建应用程序：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once the build is complete, access the WordPress installation page from `http://localhost:8080`
    or `http://<host-ip>:8080`.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建完成后，从`http://localhost:8080`或`http://<host-ip>:8080`访问WordPress安装页面。
- en: How it works…
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的…
- en: Docker Compose downloads both the `mariadb` `wordpress` images, if not available
    locally from the official Docker registry. First, it starts the `db` container
    from the `mariadb` image; then it starts the `wordpress` container. Next, it links
    with the `db` container and exports the port to the host machine.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose会从官方Docker注册表下载`mariadb`和`wordpress`镜像（如果本地不存在）。首先，它会从`mariadb`镜像启动`db`容器；然后启动`wordpress`容器。接下来，它会与`db`容器进行链接，并将端口导出到主机。
- en: There's more…
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容…
- en: 'We can even build images from the Dockerfile during the compose and then use
    it for the app. For example, to build the `wordpress` image, we can get the corresponding
    Dockerfile and other supporting file from within the application''s Compose directory
    and update the `docker-compose.yml` file in a similar manner as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以在Compose期间从Dockerfile构建镜像，然后将其用于应用程序。例如，要构建`wordpress`镜像，我们可以从应用程序的Compose目录中获取相应的Dockerfile和其他支持文件，并以类似的方式更新`docker-compose.yml`文件：
- en: '![There''s more…](../Images/image00379.jpeg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![更多内容…](../Images/image00379.jpeg)'
- en: We can start, stop, rebuild, and get the status of the app. Visit its documentation
    on the Docker website.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以启动、停止、重建和获取应用程序的状态。请访问Docker网站上的文档。
- en: See also
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The Docker Compose YAML file reference at [http://docs.docker.com/compose/yml/](http://docs.docker.com/compose/yml/)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose YAML文件参考位于[http://docs.docker.com/compose/yml/](http://docs.docker.com/compose/yml/)
- en: The Docker Compose command-line reference at [http://docs.docker.com/compose/cli/](http://docs.docker.com/compose/cli/)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose命令行参考位于[http://docs.docker.com/compose/cli/](http://docs.docker.com/compose/cli/)
- en: The Docker Compose GitHub repository at [https://github.com/docker/compose](https://github.com/docker/compose)
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose GitHub存储库位于[https://github.com/docker/compose](https://github.com/docker/compose)
- en: Setting up cluster with Docker Swarm
  id: totrans-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Swarm设置集群
- en: Docker Swarm ([http://docs.docker.com/swarm/](http://docs.docker.com/swarm/))
    is native clustering to Docker. It groups multiple Docker hosts into a single
    pool in which one can launch containers. In this recipe, we'll use Docker Machine
    ([http://docs.docker.com/machine/](http://docs.docker.com/machine/)) to set up
    a Swarm cluster. At the time of writing, Swarm is still not production-ready.
    If you recall, we used Docker Machine to set up a Docker host on Google Compute
    Engine in [Chapter 1](part0015.xhtml#aid-E9OE2 "Chapter 1. Introduction and Installation"),
    *Introduction and Installation*. To keep things simple, here we'll use VirtualBox
    as the backend for Docker Machine to configure hosts.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm ([http://docs.docker.com/swarm/](http://docs.docker.com/swarm/))是Docker的本机集群。它将多个Docker主机分组到一个池中，可以在其中启动容器。在本教程中，我们将使用Docker
    Machine ([http://docs.docker.com/machine/](http://docs.docker.com/machine/))来设置Swarm集群。在撰写本文时，Swarm仍未达到生产就绪状态。如果您还记得，我们在[第1章](part0015.xhtml#aid-E9OE2
    "第1章。介绍和安装")中使用Docker Machine在Google Compute Engine上设置了Docker主机，*介绍和安装*。为了保持简单，我们将在这里使用VirtualBox作为Docker
    Machine的后端来配置主机。
- en: Getting ready
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Install VirtualBox on your system ([https://www.virtualbox.org/](https://www.virtualbox.org/)).
    Instructions to configure VirtualBox are outside the scope of this book.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您的系统上安装VirtualBox ([https://www.virtualbox.org/](https://www.virtualbox.org/))。配置VirtualBox的说明不在本书的范围之内。
- en: 'Download and set up Docker Machine. In Fedora x86_64, run the following commands:'
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并设置Docker Machine。在Fedora x86_64上，运行以下命令：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: How to do it…
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作方法…
- en: 'Using the Swarm discovery service, we first need to create a Swarm token to
    identify our cluster uniquely. Other than the default hosted discovery service,
    Swarm supports different types of discovery services such as etcd, consul, and
    zookeeper. For more details, please visit [https://docs.docker.com/swarm/discovery/](https://docs.docker.com/swarm/discovery/).
    To create a token using the default hosted discovery service, we''ll first set
    up the Docker host using Docker Machine on a VM and then get the token:'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Swarm发现服务，我们首先需要创建一个Swarm令牌来唯一标识我们的集群。除了默认的托管发现服务外，Swarm还支持不同类型的发现服务，如etcd、consul和zookeeper。有关更多详细信息，请访问[https://docs.docker.com/swarm/discovery/](https://docs.docker.com/swarm/discovery/)。要使用默认的托管发现服务创建令牌，我们将首先在VM上使用Docker
    Machine设置Docker主机，然后获取令牌：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To access the Docker we just created from your local Docker client, run the
    following command:'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要从本地Docker客户端访问我们刚创建的Docker，请运行以下命令：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'To get the token, run the following command:'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取令牌，请运行以下命令：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using the token created in the preceding step, set up Swarm master:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前一步骤中创建的令牌，设置Swarm主节点：
- en: '[PRE6]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Similarly, let''s create two Swarm nodes:'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，让我们创建两个Swarm节点：
- en: '[PRE7]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, connect to Docker Swarm from your local Docker client:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，从本地Docker客户端连接到Docker Swarm：
- en: '[PRE8]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Swarm APIs are compatible with Docker client APIs. Let''s run the `docker info`
    command to see Swarm''s current configuration/setup:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Swarm API与Docker客户端API兼容。让我们运行`docker info`命令来查看Swarm的当前配置/设置：
- en: '[PRE9]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![How to do it…](../Images/image00380.jpeg)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![操作方法…](../Images/image00380.jpeg)'
- en: 'As you can see, we have three nodes in the cluster: one master and two nodes.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们的集群中有三个节点：一个主节点和两个节点。
- en: How it works…
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: Using the unique token we got from the hosted discovery service, we registered
    the master and nodes in a cluster.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们从托管发现服务获得的唯一令牌，我们在集群中注册了主节点和节点。
- en: There's more…
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In the preceding `docker info` output, we also scheduled policy (strategy) and
    filters. More information on these can be found at [https://docs.docker.com/swarm/scheduler/strategy/](https://docs.docker.com/swarm/scheduler/strategy/)
    and [https://docs.docker.com/swarm/scheduler/filter/](https://docs.docker.com/swarm/scheduler/filter/).
    These define where the container will run.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在前面的`docker info`输出中，我们还安排了策略和过滤器。有关这些的更多信息可以在[https://docs.docker.com/swarm/scheduler/strategy/](https://docs.docker.com/swarm/scheduler/strategy/)和[https://docs.docker.com/swarm/scheduler/filter/](https://docs.docker.com/swarm/scheduler/filter/)找到。这些定义了容器将在哪里运行。
- en: There is active development happening to integrate Docker Swarm and Docker Compose
    so that we point and compose the app to the Swarm cluster. The app will then start
    on the cluster. Visit [https://github.com/docker/compose/blob/master/SWARM.md](https://github.com/docker/compose/blob/master/SWARM.md)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正在积极开发以集成Docker Swarm和Docker Compose，以便我们将应用指向Swarm集群并进行组合。然后应用将在集群上启动。访问[https://github.com/docker/compose/blob/master/SWARM.md](https://github.com/docker/compose/blob/master/SWARM.md)
- en: See also
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The Swarm documentation on the Docker website at [https://docs.docker.com/swarm/](https://docs.docker.com/swarm/)
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker网站上的Swarm文档位于[https://docs.docker.com/swarm/](https://docs.docker.com/swarm/)
- en: Swarm's GitHub repository at [https://github.com/docker/swarm](https://github.com/docker/swarm)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Swarm的GitHub存储库位于[https://github.com/docker/swarm](https://github.com/docker/swarm)
- en: Setting up CoreOS for Docker orchestration
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Docker编排设置CoreOS
- en: CoreOS ([https://coreos.com/](https://coreos.com/)) is a Linux distribution
    that has been rearchitected to provide the features needed to run modern infrastructure
    stacks. It is Apache 2.0 Licensed. It has a product called CoreOS Managed Linux
    ([https://coreos.com/products/managed-linux/](https://coreos.com/products/managed-linux/))
    for which the CoreOS team provides commercial support.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: CoreOS（[https://coreos.com/](https://coreos.com/)）是一种经过重新架构以提供运行现代基础架构堆栈所需功能的Linux发行版。它是Apache
    2.0许可的。它有一个名为CoreOS Managed Linux（[https://coreos.com/products/managed-linux/](https://coreos.com/products/managed-linux/)）的产品，CoreOS团队为其提供商业支持。
- en: 'Essentially, CoreOS provides platforms to host a complete applications stack.
    We can set up CoreOS on different cloud providers, bare metal, and in the VM environment.
    Let''s look at the building blocks of CoreOS:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，CoreOS提供了托管完整应用程序堆栈的平台。我们可以在不同的云提供商、裸机和虚拟机环境上设置CoreOS。让我们来看看CoreOS的构建模块：
- en: etcd
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: etcd
- en: Container runtime
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时
- en: Systemd
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Systemd
- en: Fleet
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fleet
- en: 'Let''s discuss each in detail:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细讨论每个：
- en: '**etcd**: From the GitHub page of etcd ([https://github.com/coreos/etcd/#etcd](https://github.com/coreos/etcd/#etcd)).
    `etcd` is a highly available key-value store for shared configuration and service
    discovery. It is inspired by Apache ZooKeeper and doozer with a focus on being:'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**etcd**：来自etcd的GitHub页面（[https://github.com/coreos/etcd/#etcd](https://github.com/coreos/etcd/#etcd)）。`etcd`是一个用于共享配置和服务发现的高可用性键值存储。它受到Apache
    ZooKeeper和doozer的启发，专注于以下方面：'
- en: '**Simple**: Curl-able user-facing API (HTTP plus JSON)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简单**：可通过Curl访问的用户界面API（HTTP加JSON）'
- en: '**Secure**: Optional SSL client certificate authentication'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全**：可选的SSL客户端证书认证'
- en: '**Fast**: Benchmark of 1,000s of writes per instance'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**快速**：每个实例的数千次写入的基准测试'
- en: '**Reliable**: Proper distribution using Raft'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可靠**：使用Raft进行适当的分发'
- en: 'It is written in Go and uses the Raft consensus algorithm ([https://raftconsensus.github.io/](https://raftconsensus.github.io/))
    to manage a highly available replicated log. etcd can be used independent of CoreOS.
    We can:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 它是用Go编写的，并使用Raft一致性算法（[https://raftconsensus.github.io/](https://raftconsensus.github.io/)）来管理高可用性的复制日志。etcd可以独立于CoreOS使用。我们可以：
- en: Set up a single or multinode cluster. More information on this can be found
    at [https://github.com/coreos/etcd/blob/master/Documentation/clustering.md](https://github.com/coreos/etcd/blob/master/Documentation/clustering.md).
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立单节点或多节点集群。有关此信息，请访问[https://github.com/coreos/etcd/blob/master/Documentation/clustering.md](https://github.com/coreos/etcd/blob/master/Documentation/clustering.md)。
- en: Access using CURL and different libraries, found at [https://github.com/coreos/etcd/blob/master/Documentation/libraries-and-tools.md](https://github.com/coreos/etcd/blob/master/Documentation/libraries-and-tools.md).
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CURL和不同的库进行访问，可在[https://github.com/coreos/etcd/blob/master/Documentation/libraries-and-tools.md](https://github.com/coreos/etcd/blob/master/Documentation/libraries-and-tools.md)找到。
- en: In CoreOS, `etcd` is meant for the coordination of clusters. It provides a mechanism
    to store configurations and information about services in a consistent way.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在CoreOS中，`etcd`用于协调集群。它提供了一种以一致的方式存储配置和关于服务的信息的机制。
- en: '**Container runtime**: CoreOS supports Docker as a container runtime environment.
    In December 2014, CoreOS announced a new container runtime Rocket ([https://coreos.com/blog/rocket/](https://coreos.com/blog/rocket/)).
    Let''s restrict our discussion to Docker, which is currently installed on all
    CoreOS machines.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器运行时**：CoreOS支持Docker作为容器运行时环境。在2014年12月，CoreOS宣布推出了一个新的容器运行时Rocket ([https://coreos.com/blog/rocket/](https://coreos.com/blog/rocket/))。让我们将讨论限制在目前安装在所有CoreOS机器上的Docker上。'
- en: '**systemd**: `systemd` is an init system used to start, stop, and manage processes.
    In CoreOS, it is used to:'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**systemd**：`systemd`是用于启动、停止和管理进程的初始化系统。在CoreOS中，它用于：'
- en: Launch Docker containers
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动Docker容器
- en: Register services launched by containers to etcd
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将由容器启动的服务注册到etcd
- en: 'Systemd manages unit files. A sample unit file looks like the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: Systemd管理单元文件。示例单元文件如下：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This unit file starts the Docker daemon with the command mentioned in `ExecStart`
    on Fedora 21\. The Docker daemon will start after the `network target` and `docker
    socket` services. `docker socket` is a prerequisite for the Docker daemon to start.
    Systemd targets are ways to group processes so that they can start at the same
    time. `multi-user` is one of the targets with which the preceding unit file is
    registered. For more details, you can look at the upstream documentation of Systemd
    at [http://www.freedesktop.org/wiki/Software/systemd/](http://www.freedesktop.org/wiki/Software/systemd/).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 此单元文件在Fedora 21上使用`ExecStart`中提到的命令启动Docker守护程序。Docker守护程序将在`network target`和`docker
    socket`服务之后启动。`docker socket`是Docker守护程序启动的先决条件。Systemd目标是将进程分组以便它们可以同时启动的方式。`multi-user`是前面单元文件注册的目标之一。有关更多详细信息，您可以查看Systemd的上游文档[http://www.freedesktop.org/wiki/Software/systemd/](http://www.freedesktop.org/wiki/Software/systemd/)。
- en: '**Fleet**: Fleet ([https://coreos.com/using-coreos/clustering/](https://coreos.com/using-coreos/clustering/))
    is the cluster manager that controls `systemd` at the cluster level. systemd unit
    files are combined with some Fleet-specific properties to achieve the goal. From
    the Fleet documentation ([https://github.com/coreos/fleet/blob/master/Documentation/architecture.md](https://github.com/coreos/fleet/blob/master/Documentation/architecture.md)):'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fleet**：Fleet ([https://coreos.com/using-coreos/clustering/](https://coreos.com/using-coreos/clustering/))是控制集群级别的`systemd`的集群管理器。systemd单元文件与一些特定于Fleet的属性结合起来实现目标。来自Fleet文档([https://github.com/coreos/fleet/blob/master/Documentation/architecture.md](https://github.com/coreos/fleet/blob/master/Documentation/architecture.md))：'
- en: '*"Every system in the fleet cluster runs a single `fleetd` daemon. Each daemon
    encapsulates two roles: the *engine* and the *agent*. An engine primarily makes
    scheduling decisions while an agent executes units. Both the engine and agent
    use the *reconciliation model*, periodically generating a snapshot of ''current
    state'' and ''desired state'' and doing the necessary work to mutate the former
    towards the latter."*'
  id: totrans-104
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“Fleet集群中的每个系统都运行一个`fleetd`守护程序。每个守护程序封装了两个角色：*引擎*和*代理*。引擎主要做出调度决策，而代理执行单元。引擎和代理都使用*协调模型*，定期生成''当前状态''和''期望状态''的快照，并进行必要的工作将前者变异为后者。”*'
- en: '`etcd` is the sole datastore in a `fleet` cluster. All persistent and ephemeral
    data is stored in `etcd`; unit files, cluster presence, unit state, and so on.
    `etcd` is also used for all internal communication between fleet engines and agents.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`是`fleet`集群中唯一的数据存储。所有持久和临时数据都存储在`etcd`中；单元文件、集群存在、单元状态等。`etcd`也用于fleet引擎和代理之间的所有内部通信。'
- en: Now we know of all the building blocks of CoreOS. Let's try out CoreOS on our
    local system/laptop. To keep things simple, we will use Vagrant to set up the
    environment.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了CoreOS的所有构建模块。让我们在本地系统/笔记本上尝试CoreOS。为了保持简单，我们将使用Vagrant来设置环境。
- en: Getting ready
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Install VirtualBox on the system ([https://www.virtualbox.org/](https://www.virtualbox.org/))
    and Vagrant ([https://www.vagrantup.com/](https://www.vagrantup.com/)). The instructions
    to configure both of these things are outside the scope of this book.
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在系统上安装VirtualBox（[https://www.virtualbox.org/](https://www.virtualbox.org/)）和Vagrant（[https://www.vagrantup.com/](https://www.vagrantup.com/)）。配置这两个东西的说明超出了本书的范围。
- en: 'Clone the `coreos-vagrant` repository:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆`coreos-vagrant`存储库：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Copy the sample file `user-data.sample` to `user-data` and set up the token
    to bootstrap the cluster:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将示例文件`user-data.sample`复制到`user-data`并设置引导集群的令牌：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: When we configure the CoreOS cluster with more than one node, we need a token
    to bootstrap the cluster to select the initial etcd leader. This service is provided
    free by the CoreOS team. We just need to open `https://discovery.etcd.io/new`
    in the browser to get the token and update it within the `user-data` file as follows:![Getting
    ready](../Images/image00381.jpeg)
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们使用多个节点配置CoreOS集群时，我们需要一个令牌来引导集群以选择初始的etcd领导者。这项服务由CoreOS团队免费提供。我们只需要在浏览器中打开`https://discovery.etcd.io/new`来获取令牌，并在`user-data`文件中更新如下：![准备就绪](../Images/image00381.jpeg)
- en: 'Copy `config.rb.sample` to `config.rb` and make changes to the following line:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将`config.rb.sample`复制到`config.rb`并更改以下行：
- en: '[PRE13]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'It should now look like this:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在应该是这样的：
- en: '[PRE14]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will ask Vagrant to set up three node clusters. By default, Vagrant is
    configured to get the VM images from the alpha release. We can change it to beta
    or stable by updating the `$update_channel` parameter in Vagrantfile. For this
    recipe, I chose stable.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这将要求Vagrant设置三个节点集群。默认情况下，Vagrant配置为从alpha版本获取VM映像。我们可以通过在Vagrantfile中更新`$update_channel`参数将其更改为beta或stable。对于这个示例，我选择了stable。
- en: How to do it…
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤如下…
- en: 'Run the following command to set up the cluster:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令设置集群：
- en: '[PRE15]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, check the status, using the command shown in the following screenshot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用以下截图中显示的命令检查状态：
- en: '![How to do it…](../Images/image00382.jpeg)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤如下…](../Images/image00382.jpeg)'
- en: 'Log in to one of the VMs using SSH, look at the status of services, and list
    the machines in the cluster:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SSH登录到其中一个VM，查看服务状态，并列出集群中的机器：
- en: '[PRE16]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![How to do it…](../Images/image00383.jpeg)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤如下…](../Images/image00383.jpeg)'
- en: 'Create a service unit file called `myapp.service` with the following content:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`myapp.service`的服务单元文件，内容如下：
- en: '[PRE17]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let''s now submit the service for scheduling and start the service:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们提交服务进行调度并启动服务：
- en: '[PRE18]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '![How to do it…](../Images/image00384.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤如下…](../Images/image00384.jpeg)'
- en: As we can see, our service has started on one of the nodes in the cluster.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，我们的服务已经在集群中的一个节点上启动。
- en: How it works…
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: Vagrant uses the cloud configuration file (`user-data`) to boot the VMs. As
    they have the same token to bootstrap the cluster, they select the leader and
    start operating. Then, with `fleetctl`, which is the fleet cluster management
    tool, we submit the unit file for scheduling, which starts on one of the nodes.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Vagrant使用云配置文件（`user-data`）来引导VM。由于它们具有相同的令牌来引导集群，它们选择领导者并开始操作。然后，使用`fleetctl`，这是fleet集群管理工具，我们提交单元文件进行调度，该文件在一个节点上启动。
- en: There's more…
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: Using the cloud configuration file in this recipe, we can start `etcd` and `fleet`
    on all the VMs. We can choose to run `etcd` just on selected nodes and then configure
    worker nodes running `fleet` to connect to etcd servers. This can be done by setting
    the cloud configuration file accordingly. For more information, please visit [https://coreos.com/docs/cluster-management/setup/cluster-architectures/](https://coreos.com/docs/cluster-management/setup/cluster-architectures/).
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用此配方中的云配置文件，我们可以在所有VM上启动`etcd`和`fleet`。我们可以选择仅在选定的节点上运行`etcd`，然后配置运行`fleet`的工作节点以连接到etcd服务器。可以通过相应地设置云配置文件来完成此操作。有关更多信息，请访问[https://coreos.com/docs/cluster-management/setup/cluster-architectures/](https://coreos.com/docs/cluster-management/setup/cluster-architectures/)。
- en: With `fleet`, we can configure services for high availability. For more information,
    take a look at [https://coreos.com/docs/launching-containers/launching/fleet-unit-files/](https://coreos.com/docs/launching-containers/launching/fleet-unit-files/).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`fleet`，我们可以为高可用性配置服务。有关更多信息，请查看[https://coreos.com/docs/launching-containers/launching/fleet-unit-files/](https://coreos.com/docs/launching-containers/launching/fleet-unit-files/)。
- en: Though your service is running on the host, you will not be able to reach it
    from the outside world. You will need to add some kind of router and wildcard
    DNS configuration to reach your service from the outside world.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽管您的服务正在主机上运行，但您将无法从外部访问它。您需要添加某种路由器和通配符DNS配置，以便从外部世界访问您的服务。
- en: See also
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The CoreOS documentation for more details at [https://coreos.com/docs/](https://coreos.com/docs/)
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更多详细信息，请参阅CoreOS文档[https://coreos.com/docs/](https://coreos.com/docs/)
- en: The visualization of RAFT consensus algorithm at [http://thesecretlivesofdata.com/raft](http://thesecretlivesofdata.com/raft)
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[http://thesecretlivesofdata.com/raft](http://thesecretlivesofdata.com/raft)上可视化RAFT一致性算法
- en: How to configure the cloud config file at [https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/](https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/)
    and [https://coreos.com/validate/](https://coreos.com/validate/)
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何配置云配置文件，请访问[https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/](https://coreos.com/docs/cluster-management/setup/cloudinit-cloud-config/)和[https://coreos.com/validate/](https://coreos.com/validate/)
- en: Documentation on systemd at [https://coreos.com/docs/launching-containers/launching/getting-started-with-systemd/](https://coreos.com/docs/launching-containers/launching/getting-started-with-systemd/)
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关systemd的文档，请访问[https://coreos.com/docs/launching-containers/launching/getting-started-with-systemd/](https://coreos.com/docs/launching-containers/launching/getting-started-with-systemd/)
- en: How to launch containers with fleet at [https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/](https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/)
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用fleet启动容器，请访问[https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/](https://coreos.com/docs/launching-containers/launching/launching-containers-fleet/)
- en: Setting up a Project Atomic host
  id: totrans-145
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Project Atomic主机
- en: Project Atomic facilitates application-centric IT architecture by providing
    an end-to-end solution to deploy containerized applications quickly and reliably,
    with atomic update and rollback for the application and host alike.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: Project Atomic通过提供端到端的解决方案来促进以应用为中心的IT架构，快速可靠地部署容器化应用程序，并为应用程序和主机提供原子更新和回滚。
- en: This is achieved by running applications in containers on a Project Atomic host,
    which is a lightweight operating system specially designed to run containers.
    The hosts can be based on Fedora, CentOS, or Red Hat Enterprise Linux.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通过在Project Atomic主机上在容器中运行应用程序来实现的，这是一种专门设计用于运行容器的轻量级操作系统。主机可以基于Fedora、CentOS或Red
    Hat Enterprise Linux。
- en: Next, we will elaborate on the building blocks of the Project Atomic host.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将详细介绍Project Atomic主机的构建模块。
- en: '**OSTree and rpm-OSTree**: OSTree ([https://wiki.gnome.org/action/show/Projects/OSTree](https://wiki.gnome.org/action/show/Projects/OSTree))
    is a tool to manage bootable, immutable, and versioned filesystem trees. Using
    this, we can build client-server architecture in which the server hosts an OSTree
    repository and the client subscribed to it can incrementally replicate the content.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OSTree和rpm-OSTree**：OSTree ([https://wiki.gnome.org/action/show/Projects/OSTree](https://wiki.gnome.org/action/show/Projects/OSTree))是一种管理可引导、不可变和版本化文件系统树的工具。使用这个工具，我们可以构建客户端-服务器架构，其中服务器托管一个OSTree存储库，订阅它的客户端可以逐步复制内容。'
- en: rpm-OSTree is a system to decompose RPMs on the server side into the OSTree
    repository to which the client can subscribe and perform updates. With each update,
    a new root is created, which is used for the next reboot. During updates, `/etc`
    is rebased and `/var` is untouched.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: rpm-OSTree是一种在服务器端将RPM解压缩为客户端可以订阅并执行更新的OSTree存储库的系统。每次更新都会创建一个新的根，用于下一次重启。在更新期间，`/etc`被重新设置，`/var`则不变。
- en: '**Container runtime**: As of now Project Atomic only supports Docker as container
    runtime.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器运行时**：截至目前，Project Atomic只支持Docker作为容器运行时。'
- en: '**systemd**: As we saw in earlier recipes, systemd is a new init system. It
    also helps to set up SELinux policies to containers for complete multitenant security
    and to control Cgroups policies, which we looked in at [Chapter 1](part0015.xhtml#aid-E9OE2
    "Chapter 1. Introduction and Installation"), *Introduction and Installation*.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**systemd**：正如我们在之前的配方中看到的，systemd是一个新的init系统。它还帮助为完整的多租户安全性设置SELinux策略，并控制Cgroups策略，我们在[第1章](part0015.xhtml#aid-E9OE2
    "第1章。介绍和安装")中看到了*介绍和安装*。'
- en: Project Atomic uses Kubernetes ([http://kubernetes.io/](http://kubernetes.io/))
    for application deployment over clusters of container hosts. Project Atomic can
    be installed on bare metal, cloud providers, VMs, and so on. In this recipe, let's
    see how we can install it on a VM using virt-manager on Fedora.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Project Atomic使用Kubernetes ([http://kubernetes.io/](http://kubernetes.io/))在容器主机集群上部署应用程序。Project
    Atomic可以安装在裸机、云提供商、虚拟机等上。在这个配方中，让我们看看如何在Fedora上使用virt-manager在虚拟机上安装它。
- en: Getting ready
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: 'Download the image:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载图像：
- en: '[PRE19]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: I have downloaded the beta image for Fedora 22 Cloud image *For Containers*.
    You should look for the latest cloud image *For Containers* at [https://getfedora.org/en/cloud/download/](https://getfedora.org/en/cloud/download/).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经下载了Fedora 22云图像*用于容器*的测试版图像。您应该在[https://getfedora.org/en/cloud/download/](https://getfedora.org/en/cloud/download/)上寻找最新的云图像*用于容器*。
- en: 'Uncompress this image by using the following command:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令解压此图像：
- en: '[PRE20]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: How to do it…
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做到这一点…
- en: 'We downloaded the cloud image that does not have any password set for the default
    user `fedora`. While booting the VM, we have to provide a cloud configuration
    file through which we can customize the VM. To do this, we need to create two
    files, `meta-data` and `user-data`, as follows:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们下载了一个没有为默认用户`fedora`设置任何密码的云镜像。在启动虚拟机时，我们必须通过一个云配置文件来自定义虚拟机。为此，我们需要创建两个文件，`meta-data`和`user-data`，如下所示：
- en: '[PRE21]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In the preceding code, we need to provide the complete SSH public key. We then
    need to create an ISO image consisting of these files, which we will use to boot
    to the VM. As we are using a cloud image, our setting will be applied to the VM
    during the boot process. This means the hostname will be set to `atomichost`,
    the password will be set to `atomic`, and so on. To create the ISO, run the following
    command:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我们需要提供完整的SSH公钥。然后，我们需要创建一个包含这些文件的ISO镜像，我们将使用它来引导虚拟机。由于我们使用的是云镜像，我们的设置将在引导过程中应用于虚拟机。这意味着主机名将设置为`atomichost`，密码将设置为`atomic`，依此类推。要创建ISO，请运行以下命令：
- en: '[PRE22]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Start virt-manager.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动virt-manager。
- en: Select **New Virtual Machine** and then import the existing disk image. Enter
    the image path of the Project Atomic image we downloaded earlier. Select **OS
    type** as **Linux** and **Version** as **Fedora 20/Fedora 21 (or later)**, and
    click on **Forward**. Next, assign CPU and Memory and click on **Forward**. Then,
    give a name to the VM and select **Customize configuration** before install. Finally,
    click on **Finish** and review the details.
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**新建虚拟机**，然后导入现有的磁盘映像。输入我们之前下载的Project Atomic映像的路径。选择**操作系统类型**为**Linux**，**版本**为**Fedora
    20/Fedora 21（或更高版本）**，然后点击**下一步**。接下来，分配CPU和内存，然后点击**下一步**。然后，在安装之前为虚拟机命名并选择**自定义配置**。最后，点击**完成**并查看详细信息。
- en: Next, click on **Add Hardware**, and after selecting **Storage**, attach the
    ISO (`init.iso`) file we created to the VM and select **Begin Installation**:![How
    to do it…](../Images/image00385.jpeg)
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，点击**添加硬件**，在选择**存储**后，将我们创建的ISO（`init.iso`）文件附加到虚拟机，并选择**开始安装**：![如何操作…](../Images/image00385.jpeg)
- en: Once booted, you can see that its hostname is correctly set and you will be
    able to log in through the password given in the cloud init file. The default
    user is `fedora` and password is `atomic` as set in the `user-data` file.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 启动后，您可以看到其主机名已正确设置，并且您将能够使用云初始化文件中给定的密码登录。默认用户是`fedora`，密码是`atomic`，如在`user-data`文件中设置的那样。
- en: How it works…
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: In this recipe, we took a Project Atomic Fedora cloud image and booted it using
    `virt-manager` after supplying the cloud init file.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们使用`virt-manager`提供云初始化文件，使用Project Atomic Fedora云镜像引导了虚拟机。
- en: There's more…
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更多内容…
- en: After logging in, if you do file listing at `/`, you will see that most of the
    traditional directories are linked to `/var` because it is preserved across upgrades.![There's
    more…](../Images/image00386.jpeg)
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 登录后，如果在`/`目录下列出文件，你会看到大多数传统目录都链接到`/var`，因为它在升级过程中会被保留。![更多内容…](../Images/image00386.jpeg)
- en: 'After logging in, you can run the Docker command as usual:'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 登录后，您可以像往常一样运行Docker命令：
- en: '[PRE23]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: See also
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The virtual manager documentation at [https://virt-manager.org/documentation/](https://virt-manager.org/documentation/)
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关虚拟管理器的文档，请访问[https://virt-manager.org/documentation/](https://virt-manager.org/documentation/)
- en: More information on package systems, image systems, and RPM-OSTree at [https://github.com/projectatomic/rpm-ostree/blob/master/doc/background.md](https://github.com/projectatomic/rpm-ostree/blob/master/doc/background.md)
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关软件包系统、镜像系统和RPM-OSTree的更多信息，请访问[https://github.com/projectatomic/rpm-ostree/blob/master/doc/background.md](https://github.com/projectatomic/rpm-ostree/blob/master/doc/background.md)
- en: The quick-start guide on the Project Atomic website at [http://www.projectatomic.io/docs/quickstart/](http://www.projectatomic.io/docs/quickstart/)
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Project Atomic网站上的快速入门指南，请访问[http://www.projectatomic.io/docs/quickstart/](http://www.projectatomic.io/docs/quickstart/)
- en: The resources on cloud images at [https://www.technovelty.org//linux/running-cloud-images-locally.html](https://www.technovelty.org//linux/running-cloud-images-locally.html)
    and [http://cloudinit.readthedocs.org/en/latest/](http://cloudinit.readthedocs.org/en/latest/)
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有关云镜像的资源，请访问[https://www.technovelty.org//linux/running-cloud-images-locally.html](https://www.technovelty.org//linux/running-cloud-images-locally.html)和[http://cloudinit.readthedocs.org/en/latest/](http://cloudinit.readthedocs.org/en/latest/)
- en: How to set up Kubernetes with an Atomic host at [http://www.projectatomic.io/blog/2014/11/testing-kubernetes-with-an-atomic-host/](http://www.projectatomic.io/blog/2014/11/testing-kubernetes-with-an-atomic-host/)
    and [https://github.com/cgwalters/vagrant-atomic-cluster](https://github.com/cgwalters/vagrant-atomic-cluster)
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在Atomic主机上设置Kubernetes，网址为[http://www.projectatomic.io/blog/2014/11/testing-kubernetes-with-an-atomic-host/](http://www.projectatomic.io/blog/2014/11/testing-kubernetes-with-an-atomic-host/)和[https://github.com/cgwalters/vagrant-atomic-cluster](https://github.com/cgwalters/vagrant-atomic-cluster)
- en: Doing atomic update/rollback with Project Atomic
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Project Atomic进行原子更新/回滚
- en: To get to the latest version or to roll back to the older version of Project
    Atomic, we use the `atomic host` command, which internally calls rpm-ostree.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要升级到最新版本或回滚到Project Atomic的旧版本，我们使用`atomic host`命令，该命令内部调用rpm-ostree。
- en: Getting ready
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Boot and log in to the Atomic host.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 启动并登录到Atomic主机。
- en: How to do it…
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Just after the boot, run the following command:'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动后，运行以下命令：
- en: '[PRE24]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: You will see details about one deployment that is in use now.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到有关当前正在使用的部署的详细信息。
- en: '![How to do it…](../Images/image00387.jpeg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00387.jpeg)'
- en: 'To upgrade, run the following command:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 升级，请运行以下命令：
- en: '![How to do it…](../Images/image00388.jpeg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00388.jpeg)'
- en: This changes and/or adds new packages. After the upgrade, we will need to reboot
    the system to use the new update. Let's reboot and see the outcome:![How to do
    it…](../Images/image00389.jpeg)
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这将更改和/或添加新的软件包。升级后，我们需要重新启动系统以使用新的更新。让我们重新启动并查看结果：![如何做…](../Images/image00389.jpeg)
- en: As we can see, the system is now booted with the new update. The `*`, which
    is at the beginning of the first line, specifies the active build.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，系统现在已经使用新的更新启动。位于第一行开头的`*`表示活动构建。
- en: 'To roll back, run the following command:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要回滚，请运行以下命令：
- en: '[PRE25]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: We will have to reboot again if we want to use older bits.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想使用旧的位，我们将不得不再次重启。
- en: How it works…
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: For updates, the Atomic host connects to the remote repository hosting the newer
    build, which is downloaded and used from the next reboot onwards until the user
    upgrades or rolls back. In the case rollback older build available on the system
    used after the reboot.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更新，Atomic主机连接到托管较新构建的远程存储库，该构建将在下一次重启后下载并使用，直到用户升级或回滚。在回滚的情况下，系统上可用的旧构建将在重启后使用。
- en: See also
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The documentation Project Atomic website, which can be found at [http://www.projectatomic.io/docs/os-updates/](http://www.projectatomic.io/docs/os-updates/)
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以在Project Atomic网站的文档中找到，网址为[http://www.projectatomic.io/docs/os-updates/](http://www.projectatomic.io/docs/os-updates/)
- en: Adding more storage for Docker in Project Atomic
  id: totrans-201
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Project Atomic中为Docker添加更多存储
- en: The Atomic host is a minimal distribution and, as such, is distributed on a
    6 GB image to keep the footprint small. This is very less amount of storage to
    build and store lots of Docker images, so it is recommended to attach external
    storage for those operations.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Atomic主机是一个最小的发行版，因此以6GB的镜像分发，以保持占用空间小。这是非常少的存储空间来构建和存储大量的Docker镜像，因此建议为这些操作附加外部存储。
- en: By default, Docker uses `/var/lib/docker` as the default directory where all
    Docker-related files, including images, are stored. In Project Atomic, we use
    direct LVM volumes via the devicemapper backend to store Docker images and metadata
    in `/dev/atomicos/docker-data` and `/dev/atomicos/docker-meta` respectively.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Docker使用`/var/lib/docker`作为存储所有与Docker相关的文件（包括镜像）的默认目录。在Project Atomic中，我们使用直接的LVM卷通过devicemapper后端将Docker镜像和元数据存储在`/dev/atomicos/docker-data`和`/dev/atomicos/docker-meta`中。
- en: 'So, to add more storage, Project Atomic provides a helper script called `docker-storage-helper`
    to add an external disk into the existing LVM thin pool. Let''s look at the current
    available storage to Docker with the `docker info` command:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了添加更多存储空间，Project Atomic提供了一个名为`docker-storage-helper`的辅助脚本，将外部磁盘添加到现有的LVM
    thin pool中。让我们使用`docker info`命令查看当前可用于Docker的存储空间：
- en: '![Adding more storage for Docker in Project Atomic](../Images/image00390.jpeg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![在Project Atomic中为Docker添加更多存储空间](../Images/image00390.jpeg)'
- en: As we can see, the total data space is 2.96 GB and the total metadata space
    is 8.38 MB.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，总数据空间为2.96 GB，总元数据空间为8.38 MB。
- en: Getting ready
  id: totrans-207
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 做好准备
- en: Stop the VM, if it is running.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 停止VM，如果它正在运行。
- en: Add an additional disk of the size you want to the Project Atomic VM. I have
    added 8 GB.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向Project Atomic VM添加所需大小的额外磁盘。我已经添加了8 GB。
- en: Boot the VM.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动VM。
- en: Check whether the newly attached disk is visible to the VM or not.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查新添加的磁盘是否对VM可见。
- en: How to do it…
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作...
- en: Check if the additional disk is available to the Atomic host VM:![How to do
    it…](../Images/image00391.jpeg)
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查附加磁盘是否可用于Atomic主机VM：![如何操作...](../Images/image00391.jpeg)
- en: As we can see, the newly created 8 GB disk is available to the VM.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，新创建的8 GB磁盘对VM可用。
- en: 'As the newly attached disk is `/dev/sdb`, create a file called `/etc/sysconfig/docker-storage-setup`
    with the following content:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于新添加的磁盘是`/dev/sdb`，因此创建一个名为`/etc/sysconfig/docker-storage-setup`的文件，并包含以下内容：
- en: '[PRE26]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Run the `docker-storage-setup` command to add `/dev/sdb` to the existing volume:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行`docker-storage-setup`命令将`/dev/sdb`添加到现有卷中：
- en: '[PRE27]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![How to do it…](../Images/image00392.jpeg)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](../Images/image00392.jpeg)'
- en: Now, let's look at the current available storage to Docker once again with the
    `docker info` command:![How to do it…](../Images/image00393.jpeg)
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们再次使用`docker info`命令查看当前可用于Docker的存储空间：![如何操作...](../Images/image00393.jpeg)
- en: As we can see, both the total data space and metadata space have increased.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，总数据空间和元数据空间都增加了。
- en: How it works…
  id: totrans-222
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The procedure is the same as extending any other LVM volume. We create a physical
    volume on the added disk, add that physical volume to the volume group, and then
    extend the LVM volumes. Since we are directly accessing the thin pool within Docker,
    we won't need to create or extend a filesystem or mount the LVM volumes.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程与扩展任何其他LVM卷的过程相同。我们在添加的磁盘上创建一个物理卷，将该物理卷添加到卷组中，然后扩展LVM卷。由于我们直接访问Docker中的thin
    pool，因此我们不需要创建或扩展文件系统或挂载LVM卷。
- en: There's more…
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: In addition to the `DEVS` option, you can also add the `VG` option to the `/etc/sysconfig/docker-storage-setup`
    file to use a different volume group.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 除了`DEVS`选项之外，您还可以在`/etc/sysconfig/docker-storage-setup`文件中添加`VG`选项以使用不同的卷组。
- en: You can add more than one disk with the `DEVS` option.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以使用`DEVS`选项添加多个磁盘。
- en: If a disk that is already part of the Volume Group has been mentioned with the
    `DEVS` option, then the `docker-storage-setup` script will exit, as the existing
    device has a partition and physical volume already created.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果已经在卷组中的磁盘已经在`DEVS`选项中被提及，那么`docker-storage-setup`脚本将退出，因为现有设备已经创建了分区和物理卷。
- en: The `docker-storage-setup` script reserves 0.1 percent of the size for `meta-data`.
    This is why we saw an increase in the Metadata Space as well.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker-storage-setup`脚本为`meta-data`保留了0.1％的大小。这就是为什么我们也看到了Metadata Space的增加。'
- en: See also
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The documentation on the Project Atomic website at [http://www.projectatomic.io/docs/docker-storage-recommendation/](http://www.projectatomic.io/docs/docker-storage-recommendation/)
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Project Atomic网站上的文档[http://www.projectatomic.io/docs/docker-storage-recommendation/](http://www.projectatomic.io/docs/docker-storage-recommendation/)
- en: Supported filesystems with Project Atomic at [http://www.projectatomic.io/docs/filesystems/](http://www.projectatomic.io/docs/filesystems/)
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Project Atomic上支持的文件系统[http://www.projectatomic.io/docs/filesystems/](http://www.projectatomic.io/docs/filesystems/)
- en: Setting up Cockpit for Project Atomic
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为Project Atomic设置Cockpit
- en: Cockpit ([http://cockpit-project.org/](http://cockpit-project.org/)) is a server
    manager that makes it easy to administer your GNU/Linux servers via a web browser.
    It can be used to manage the Project Atomic host as well. More than one host can
    be managed through one Cockpit instance. Cockpit does not come by default with
    the latest Project Atomic, and you will need to start it as a **Super Privileged
    Container** (**SPC**). SPCs are specially built containers that run with security
    turned off (`--privileged`); they turn off one or more of the namespaces or "volume
    mounts in" parts of the host OS into the container. For more details on SPC, refer
    to [https://developerblog.redhat.com/2014/11/06/introducing-a-super-privileged-container-concept/](https://developerblog.redhat.com/2014/11/06/introducing-a-super-privileged-container-concept/)
    and [https://www.youtube.com/watch?v=eJIeGnHtIYg](https://www.youtube.com/watch?v=eJIeGnHtIYg).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Cockpit ([http://cockpit-project.org/](http://cockpit-project.org/))是一个服务器管理器，可以通过Web浏览器轻松管理GNU/Linux服务器。它也可以用来管理Project
    Atomic主机。一个Cockpit实例可以管理多个主机。Cockpit不会默认随最新的Project Atomic一起提供，您需要将其作为**超级特权容器**（**SPC**）启动。SPC是专门构建的容器，以关闭安全性运行（`--privileged`）；它关闭一个或多个命名空间或将主机OS的“卷挂载到”容器中的部分。有关SPC的更多详细信息，请参阅[https://developerblog.redhat.com/2014/11/06/introducing-a-super-privileged-container-concept/](https://developerblog.redhat.com/2014/11/06/introducing-a-super-privileged-container-concept/)和[https://www.youtube.com/watch?v=eJIeGnHtIYg](https://www.youtube.com/watch?v=eJIeGnHtIYg)。
- en: Because Cockpit runs as an SPC, it can access the resources needed to manage
    the Atomic host within the container.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Cockpit作为SPC运行，所以可以访问容器内管理原子主机所需的资源。
- en: Getting ready
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Set up the Project Atomic host and log in to it.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 设置Project Atomic主机并登录。
- en: How to do it…
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何操作…
- en: 'Run the following command to start the Cockpit container:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令启动Cockpit容器：
- en: '[PRE28]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![How to do it…](../Images/image00394.jpeg)'
  id: totrans-240
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作…](../Images/image00394.jpeg)'
- en: Open the browser (`http://<VM IP>:9090`) and log in with the default user/password
    `fedora/atomic`. Once logged in, you can select the current host to manage. You
    will see a screen as shown here:![How to do it…](../Images/image00395.jpeg)
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开浏览器（`http://<VM IP>:9090`）并使用默认用户/密码`fedora/atomic`登录。登录后，您可以选择当前主机进行管理。您将看到如下所示的屏幕：![如何操作…](../Images/image00395.jpeg)
- en: How it works…
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: 'Here, we used the `atomic` command instead of the `docker` command to start
    the container. Let''s look at the Cockpit Dockerfile ([https://github.com/fedora-cloud/Fedora-Dockerfiles/blob/master/cockpit-ws/Dockerfile](https://github.com/fedora-cloud/Fedora-Dockerfiles/blob/master/cockpit-ws/Dockerfile))
    to see why we did that. In the Dockerfile you will see some instructions:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用`atomic`命令而不是`docker`命令来启动容器。让我们看看Cockpit Dockerfile([https://github.com/fedora-cloud/Fedora-Dockerfiles/blob/master/cockpit-ws/Dockerfile](https://github.com/fedora-cloud/Fedora-Dockerfiles/blob/master/cockpit-ws/Dockerfile))，看看为什么我们这样做。在Dockerfile中，您将看到一些指令：
- en: '[PRE29]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: If you recall from [Chapter 2](part0022.xhtml#aid-KVCC1 "Chapter 2. Working
    with Docker Containers"), *Working with Docker Containers* and [Chapter 3](part0038.xhtml#aid-147LC1
    "Chapter 3. Working with Docker Images"), *Working with Docker Images*, we could
    assign metadata to images and containers using labels. `INSTALL`, `UNINSTALL`,
    and `RUN` are labels here. The `atomic` command is a command specific to Project
    Atomic, which reads those labels and performs operations. As the container is
    running as an SPC, it does not need port forwarding from host to container. For
    more details on the `atomic` command, please visit [https://developerblog.redhat.com/2015/04/21/introducing-the-atomic-command/](https://developerblog.redhat.com/2015/04/21/introducing-the-atomic-command/).
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您回忆起[第2章](part0022.xhtml#aid-KVCC1 "Chapter 2. Working with Docker Containers")中的*使用Docker容器*和[第3章](part0038.xhtml#aid-147LC1
    "Chapter 3. Working with Docker Images")中的*使用Docker镜像*，我们可以使用标签为镜像和容器分配元数据。这里的标签是`INSTALL`、`UNINSTALL`和`RUN`。`atomic`命令是Project
    Atomic特有的命令，它读取这些标签并执行操作。由于容器作为SPC运行，因此不需要从主机到容器的端口转发。有关`atomic`命令的更多详细信息，请访问[https://developerblog.redhat.com/2015/04/21/introducing-the-atomic-command/](https://developerblog.redhat.com/2015/04/21/introducing-the-atomic-command/)。
- en: There's more…
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'You can perform almost all administrator tasks from the GUI for the given system.
    You can manage Docker images/containers through this. You can perform operations
    such as:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过GUI执行几乎所有管理员任务。您可以通过这个管理Docker镜像/容器。您可以执行以下操作：
- en: Pulling an image
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉取镜像
- en: Starting/stopping the containers
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动/停止容器
- en: You can also add other machines to the same Cockpit instance so that you manage
    them from one central location.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将其他机器添加到同一个Cockpit实例中，以便从一个中央位置管理它们。
- en: See also
  id: totrans-251
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: The Cockpit documentation at [http://files.cockpit-project.org/guide/](http://files.cockpit-project.org/guide/)
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cockpit文档位于[http://files.cockpit-project.org/guide/](http://files.cockpit-project.org/guide/)
- en: Setting up a Kubernetes cluster
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置Kubernetes集群
- en: 'Kubernetes is an open source container orchestration tool across multiple nodes
    in the cluster. Currently, it only supports Docker. It was started by Google,
    and now developers from other companies are contributing to it. It provides mechanisms
    for application deployment, scheduling, updating, maintenance, and scaling. Kubernetes''
    auto-placement, auto-restart, auto-replication features make sure that the desired
    state of the application is maintained, which is defined by the user. Users define
    applications through YAML or JSON files, which we''ll see later in the recipe.
    These YAML and JSON files also contain the API Version (the `apiVersion` field)
    to identify the schema. The following is the architectural diagram of Kubernetes:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个开源的容器编排工具，可以跨集群的多个节点进行操作。目前，它只支持Docker。它是由Google发起的，现在其他公司的开发人员也在为其做出贡献。它提供了应用部署、调度、更新、维护和扩展的机制。Kubernetes的自动放置、自动重启、自动复制功能确保了应用程序的期望状态得以维持，这是由用户定义的。用户通过YAML或JSON文件定义应用程序，我们稍后会看到。这些YAML和JSON文件还包含API版本（`apiVersion`字段）来识别模式。以下是Kubernetes的架构图：
- en: '![Setting up a Kubernetes cluster](../Images/image00396.jpeg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![设置Kubernetes集群](../Images/image00396.jpeg)'
- en: '[https://raw.githubusercontent.com/GoogleCloudPlatform/kubernetes/master/docs/architecture.png](https://raw.githubusercontent.com/GoogleCloudPlatform/kubernetes/master/docs/architecture.png)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://raw.githubusercontent.com/GoogleCloudPlatform/kubernetes/master/docs/architecture.png](https://raw.githubusercontent.com/GoogleCloudPlatform/kubernetes/master/docs/architecture.png)'
- en: Let's look at some of the key components and concepts of Kubernetes.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Kubernetes的一些关键组件和概念。
- en: '**Pods**: A pod, which consists of one or more containers, is the deployment
    unit of Kubernetes. Each container in a pod shares different namespaces with other
    containers in the same pod. For example, each container in a pod shares the same
    network namespace, which means they can all communicate through localhost.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pods**：Pod由一个或多个容器组成，是Kubernetes的部署单元。Pod中的每个容器与同一Pod中的其他容器共享不同的命名空间。例如，Pod中的每个容器共享相同的网络命名空间，这意味着它们可以通过localhost进行通信。'
- en: '**Node/Minion**: A node, which was previously known as a minion, is a worker
    node in the Kubernetes cluster and is managed through master. Pods are deployed
    on a node, which has the necessary services to run them:'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点/从属节点**：节点，以前被称为从属节点，是Kubernetes集群中的工作节点，并通过主节点进行管理。Pod被部署在具有运行它们所需服务的节点上。'
- en: docker, to run containers
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: docker，用于运行容器
- en: kubelet, to interact with master
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubelet，用于与主节点交互
- en: proxy (kube-proxy), which connects the service to the corresponding pod
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理（kube-proxy），将服务连接到相应的Pod
- en: '**Master**: Master hosts cluster-level control services such as the following:'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主节点**：主节点托管集群级别的控制服务，例如以下内容：'
- en: '**API server**: This has RESTful APIs to interact with master and nodes. This
    is the only component that talks to the etcd instance.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API服务器**：具有用于与主节点和节点交互的RESTful API。这是唯一与etcd实例通信的组件。'
- en: '**Scheduler**: This schedules jobs in clusters, such as creating pods on nodes.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度器**：在集群中调度作业，例如在节点上创建Pod。'
- en: '**Replication controller**: This ensures that the user-specified number of
    pod replicas is running at any given time. To manage replicas with replication
    controller, we have to define a configuration file with the replica count for
    a pod.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复制控制器**：确保用户指定数量的Pod副本在任何给定时间都在运行。要使用复制控制器管理副本，我们必须定义一个配置文件，其中包含Pod的副本计数。'
- en: Master also communicates with etcd, which is a distributed key-value pair. etcd
    is used to store the configuration information, which is used by both master and
    nodes. The watch functionality of etcd is used to notify the changes in the cluster.
    etcd can be hosted on master or on a different set of systems.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 主节点还与etcd通信，etcd是一个分布式键值对。etcd用于存储配置信息，主节点和节点都使用这些信息。etcd的watch功能用于通知集群中的更改。etcd可以托管在主节点上或不同的一组系统上。
- en: '**Services**: In Kubernetes, each pod gets its own IP address, and pods are
    created and destroyed every now and then based on the replication controller configuration.
    So, we cannot rely on a pod''s IP address to cater an app. To overcome this problem,
    Kubernetes defines an abstraction, which defines a logical set of pods and policies
    to access them. This abstraction is called a service. Labels are used to define
    the logical set, which a service manages.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务**：在Kubernetes中，每个Pod都有自己的IP地址，并且根据复制控制器的配置，Pod会不时地被创建和销毁。因此，我们不能依赖于Pod的IP地址来为应用程序提供服务。为了解决这个问题，Kubernetes定义了一个抽象，定义了一组逻辑Pod和访问它们的策略。这个抽象被称为服务。标签用于定义服务管理的逻辑集合。'
- en: '**Labels**: Labels are key-value pairs that can be attached to objects like,
    using which we select a subset of objects. For example, a service can select all
    pods with the label `mysql`.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：标签是可以附加到对象的键值对，使用它们可以选择对象的子集。例如，服务可以选择具有标签`mysql`的所有Pod。'
- en: '**Volumes**: A volume is a directory that is accessible to the containers in
    a pod. It is similar to Docker volumes but not the same. Different types of volumes
    are supported in Kubernetes, some of which are EmptyDir (ephemeral), HostDir,
    GCEPersistentDisk, and NFS. Active development is happening to support more types
    of volumes. More details can be found at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md).'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**卷**: 卷是一个对pod中的容器可访问的目录。它类似于Docker卷，但不完全相同。Kubernetes支持不同类型的卷，其中一些是EmptyDir（临时）、HostDir、GCEPersistentDisk和NFS。正在积极开发以支持更多类型的卷。更多细节可以在[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md)找到。'
- en: Kubernetes can be installed on VMs, physical machines, and the cloud. For the
    complete matrix, take a look at [https://github.com/GoogleCloudPlatform/kubernetes/tree/master/docs/getting-started-guides](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/docs/getting-started-guides).
    In this recipe, we'll see how to install it on VMs, using Vagrant with VirtualBox
    provider. This recipe and the following recipes on Kubernetes, were tried on v0.17.0
    of Kubernetes.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes可以安装在虚拟机、物理机和云上。要查看完整的矩阵，请查看[https://github.com/GoogleCloudPlatform/kubernetes/tree/master/docs/getting-started-guides](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/docs/getting-started-guides)。在这个示例中，我们将看到如何在虚拟机上使用VirtualBox提供程序安装它。这个示例和接下来关于Kubernetes的示例是在Kubernetes的v0.17.0上尝试的。
- en: Getting ready
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Install latest Vagrant >= 1.6.2 from [http://www.vagrantup.com/downloads.html](http://www.vagrantup.com/downloads.html).
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[http://www.vagrantup.com/downloads.html](http://www.vagrantup.com/downloads.html)安装最新的Vagrant
    >= 1.6.2。
- en: Install the latest VirtualBox from [https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads).
    Detailed instructions on how to set this up are outside the scope of this book.
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从[https://www.virtualbox.org/wiki/Downloads](https://www.virtualbox.org/wiki/Downloads)安装最新的VirtualBox。如何设置这个的详细说明超出了本书的范围。
- en: How to do it…
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做...
- en: 'Run the following command to set up Kubernetes on Vagrant VMs:'
  id: totrans-276
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令在Vagrant虚拟机上设置Kubernetes：
- en: '[PRE30]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: How it works…
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它是如何工作的...
- en: The bash script downloaded from the `curl` command, first downloads the latest
    Kubernetes release and then runs the `./kubernetes/cluster/kube-up.sh` bash script
    to set up the Kubernetes environment. As we have specified Vagrant as `KUBERNETES_PROVIDER`,
    the script first downloads the Vagrant images and then, using Salt ([http://saltstack.com/](http://saltstack.com/)),
    configures one master and one node (minion) VM. Initial setup takes a few minutes
    to run.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 从`curl`命令下载的bash脚本首先下载最新的Kubernetes版本，然后运行`./kubernetes/cluster/kube-up.sh`
    bash脚本来设置Kubernetes环境。由于我们已经指定Vagrant为`KUBERNETES_PROVIDER`，脚本首先下载Vagrant镜像，然后使用Salt
    ([http://saltstack.com/](http://saltstack.com/)) 配置一个主节点和一个节点（minion）虚拟机。初始设置需要几分钟来运行。
- en: Vagrant creates a credential file in `~/.kubernetes_vagrant_auth` for authentication.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Vagrant在`~/.kubernetes_vagrant_auth`中创建一个凭据文件进行身份验证。
- en: There's more…
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'Similar to `./cluster/kube-up.sh`, there are other helper scripts to perform
    different operations from the host machine itself. Make sure you are in the `kubernetes`
    directory, which was created with the preceding installation, while running the
    following commands:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`./cluster/kube-up.sh`，还有其他辅助脚本可以在主机上执行不同的操作。确保你在`kubernetes`目录中，在运行以下命令时已经安装了之前的安装：
- en: 'Get the list of nodes:'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取节点列表：
- en: '[PRE31]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Get the list of pods:'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取pod的列表：
- en: '[PRE32]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Get the list of services:'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取服务列表：
- en: '[PRE33]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Get the list of replication controllers:'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取复制控制器的列表：
- en: '[PRE34]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Destroy the vagrant cluster:'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 销毁vagrant集群：
- en: '[PRE35]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Then bring back the vagrant cluster:'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后恢复vagrant集群：
- en: '[PRE36]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You will see some `pods`, `services`, and `replicationControllers` listed, as
    Kubernetes creates them for internal use.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到一些列出的`pods`，`services`和`replicationControllers`，因为Kubernetes为内部使用创建它们。
- en: See also
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Setting up the Vagrant environment at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)设置Vagrant环境
- en: The Kubernetes user guide at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)的Kubernetes用户指南'
- en: Kubernetes API conventions at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/api-conventions.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/api-conventions.md)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/api-conventions.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/api-conventions.md)了解Kubernetes
    API约定
- en: Scaling up and down in a Kubernetes cluster
  id: totrans-300
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中进行扩展和缩减
- en: In the previous section, we mentioned that the replication controller ensures
    that the user-specified number of pod replicas is running at any given time. To
    manage replicas with the replication controller, we have to define a configuration
    file with the replica count for a pod. This configuration can be changed at runtime.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们提到复制控制器确保用户指定数量的pod副本在任何给定时间都在运行。要使用复制控制器管理副本，我们必须定义一个具有pod副本计数的配置文件。此配置可以在运行时更改。
- en: Getting ready
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备就绪
- en: Make sure the Kubernetes setup is running as described in the preceding recipe
    and that you are in the `kubernetes` directory, which was created with the preceding
    installation.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 确保Kubernetes设置正在按照前面的配方运行，并且您在`kubernetes`目录中，该目录是使用前面的安装创建的。
- en: How to do it…
  id: totrans-304
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何做…
- en: 'Start the `nginx` container with a replica count of 3:'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动带有3个副本计数的`nginx`容器：
- en: '[PRE37]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '![How to do it…](../Images/image00397.jpeg)'
  id: totrans-307
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00397.jpeg)'
- en: 'This will start three replicas of the `nginx` container. List the pods to get
    the status:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动`nginx`容器的三个副本。列出pod以获取状态：
- en: '[PRE38]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Get the replication controller configuration:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取复制控制器配置：
- en: '[PRE39]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '![How to do it…](../Images/image00398.jpeg)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00398.jpeg)'
- en: As you can see, we have a `my-nginx` controller, which has a replica count of
    3\. There is a replication controller for `kube-dns`, which we will explore in
    next recipe.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，我们有一个`my-nginx`控制器，其副本计数为3。还有一个`kube-dns`的复制控制器，我们将在下一个配方中探索。
- en: 'Request the replication controller service to scale down to replica of 1 and
    update the replication controller:'
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请求复制控制器服务将副本缩减为1并更新复制控制器：
- en: '[PRE40]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '![How to do it…](../Images/image00399.jpeg)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00399.jpeg)'
- en: 'Get the list of pods to verify; you should see only one pod for `nginx`:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取pod列表以进行验证；您应该只看到一个`nginx`的pod：
- en: '[PRE41]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: How it works…
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理…
- en: We request the replication controller service running on master to update the
    replicas for a pod, which updates the configuration and requests nodes/minions
    to act accordingly to honor the resizing.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 我们请求在主节点上运行的复制控制器服务更新pod的副本，这将更新配置并要求节点/从节点相应地进行调整以遵守调整大小。
- en: There's more…
  id: totrans-321
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多…
- en: 'Get the services:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 获取服务：
- en: '[PRE42]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![There''s more…](../Images/image00400.jpeg)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
  zh: '![还有更多…](../Images/image00400.jpeg)'
- en: As you can see, we don't have any service defined for our `nginx` containers
    started earlier. This means that though we have a container running, we cannot
    access them from outside because the corresponding service is not defined.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们之前启动的`nginx`容器没有定义任何服务。这意味着虽然我们有一个正在运行的容器，但我们无法从外部访问它们，因为相应的服务没有定义。
- en: See also
  id: totrans-326
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Setting up the Vagrant environment at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)设置Vagrant环境
- en: The Kubernetes user guide at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)中的Kubernetes用户指南'
- en: Setting up WordPress with a Kubernetes cluster
  id: totrans-329
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中设置WordPress
- en: In this recipe, we will use the WordPress example given in the Kubernetes GitHub
    ([https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples/mysql-wordpress-pd](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples/mysql-wordpress-pd)).
    The given example requires some changes, as we'll be running it on the Vagrant
    environment instead of the default Google Compute engine. Also, instead of using
    the helper functions (for example, `<kubernetes>/cluster/kubectl.sh`), we'll log
    in to master and use the `kubectl` binary.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程中，我们将使用Kubernetes GitHub中提供的WordPress示例([https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples/mysql-wordpress-pd](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples/mysql-wordpress-pd))。给定的示例需要一些更改，因为我们将在Vagrant环境中运行它，而不是默认的Google
    Compute引擎。此外，我们将登录到master并使用`kubectl`二进制文件，而不是使用辅助函数（例如，`<kubernetes>/cluster/kubectl.sh`）。
- en: Getting ready
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备工作
- en: Make sure the Kubernetes cluster has been set up as described in the previous
    recipe.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保Kubernetes集群已按照上一个教程中描述的那样设置。
- en: 'In the `kubernetes` directory that was downloaded during the setup, you will
    find an examples directory that contains many examples. Let''s go to the `mysql-wordpress-pd`
    directory:'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在安装过程中下载的`kubernetes`目录中，您将找到一个包含许多示例的examples目录。让我们转到`mysql-wordpress-pd`目录：
- en: '[PRE43]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: These `.yaml` files describe pods and services for `mysql` and `wordpress` respectively.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些`.yaml`文件分别描述了`mysql`和`wordpress`的pod和服务。
- en: In the pods files (`mysql.yaml` and `wordpress.yaml`), you will find the section
    on volumes and the corresponding `volumeMount` file. The original example assumes
    that you have access to Google Compute Engine and that you have the corresponding
    storage setup. For simplicity, we will not set up that and instead use ephemeral
    storage with the `EmptyDir` volume option. For reference, our `mysql.yaml` will
    look like the following:![Getting ready](../Images/image00401.jpeg)
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在pod文件（`mysql.yaml`和`wordpress.yaml`）中，您将找到关于卷和相应`volumeMount`文件的部分。原始示例假定您可以访问Google
    Compute Engine并且已经设置了相应的存储。为简单起见，我们将不设置它，而是使用`EmptyDir`卷选项的临时存储。供参考，我们的`mysql.yaml`将如下所示：![准备工作](../Images/image00401.jpeg)
- en: Make the similar change to `wordpress.yaml`.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对`wordpress.yaml`进行类似的更改。
- en: How to do it…
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操作步骤…
- en: 'With SSH, log in to the master node and look at the running pods:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过SSH登录到master节点并查看正在运行的pod：
- en: '[PRE44]'
  id: totrans-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![How to do it…](../Images/image00402.jpeg)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
  zh: '![操作步骤…](../Images/image00402.jpeg)'
- en: 'The `kube-dns-7eqp5` pod consists of three containers: `etcd`, `kube2sky`,
    and `skydns`, which are used to configure an internal DNS server for service name
    to IP resolution. We''ll see it in action later in this recipe.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-dns-7eqp5` pod包含三个容器：`etcd`、`kube2sky`和`skydns`，用于配置内部DNS服务器以进行服务名到IP的解析。我们稍后会在这个示例中看到它的运行。'
- en: The Vagrantfile used in this example is created so that the `kubernetes` directory
    that we created earlier is shared under `/vagrant` on VM, which means that the
    changes we made to the host system will be visible here as well.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中使用的Vagrantfile是这样创建的，我们之前创建的`kubernetes`目录在VM下被共享为`/vagrant`，这意味着我们对主机系统所做的更改也会在这里可见。
- en: 'From the master node, create the `mysql` pod and check the running pods:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从主节点创建`mysql` pod并检查运行中的pod：
- en: '[PRE45]'
  id: totrans-345
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![How to do it…](../Images/image00403.jpeg)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00403.jpeg)'
- en: As we can see, a new pod with the `mysql` name has been created and it is running
    on host `10.245.1.3`, which is our node (minion).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，一个名为`mysql`的新pod已经被创建，并且正在运行在主机`10.245.1.3`上，这是我们的节点（minion）。
- en: 'Now let''s create the service for `mysql` and look at all the services:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在让我们为`mysql`创建服务并查看所有服务：
- en: '[PRE46]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![How to do it…](../Images/image00404.jpeg)'
  id: totrans-350
  prefs: []
  type: TYPE_IMG
  zh: '![如何做…](../Images/image00404.jpeg)'
- en: As we can see, a service named `mysql` has been created. Each service has a
    Virtual IP. Other than the `kubernetes` services, we see a service named `kube-dns`,
    which is used as the service name for the `kube-dns` pod we saw earlier.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，一个名为`mysql`的服务已经被创建。每个服务都有一个虚拟IP。除了`kubernetes`服务，我们还看到一个名为`kube-dns`的服务，它被用作我们之前看到的`kube-dns`
    pod的服务名。
- en: 'Similar to `mysql`, let''s create a pod for `wordpress`:'
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似于`mysql`，让我们为`wordpress`创建一个pod：
- en: '[PRE47]'
  id: totrans-353
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'With this command, there are a few things happening in the background:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个命令，后台会发生一些事情：
- en: The `wordpress` image gets downloaded from the official Docker registry and
    the container runs.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wordpress`镜像从官方Docker注册表中下载并运行容器。'
- en: By default, whenever a pod starts, information about all the existing services
    is exported as environment variables. For example, if we log in to the `wordpress`
    pod and look for `MYSQL`-specific environment variables, we will see something
    like the following:![How to do it…](../Images/image00405.jpeg)
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 默认情况下，每当一个pod启动时，所有现有服务的信息都会导出为环境变量。例如，如果我们登录到`wordpress` pod并查找`MYSQL`特定的环境变量，我们会看到类似以下的内容：![如何做…](../Images/image00405.jpeg)
- en: When the WordPress container starts, it runs the `/entrypoint.sh` script, which
    looks for the environment variables mentioned earlier to start the service. [https://github.com/docker-library/wordpress/blob/master/docker-entrypoint.sh](https://github.com/docker-library/wordpress/blob/master/docker-entrypoint.sh).
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当WordPress容器启动时，它运行`/entrypoint.sh`脚本，该脚本查找之前提到的环境变量来启动服务。[https://github.com/docker-library/wordpress/blob/master/docker-entrypoint.sh](https://github.com/docker-library/wordpress/blob/master/docker-entrypoint.sh)。
- en: With the `kube-dns` service, PHP scripts of `wordpress` are able to the reserve
    lookup to proceed forward.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`kube-dns`服务，`wordpress`的PHP脚本能够进行反向查找以继续向前进行。
- en: 'After starting the pod, the last step here is to set up the `wordpress` service.
    In the default example, you will see an entry like the following in the service
    file `(/vagrant/examples/mysql-wordpress-pd/mysql-service.yaml`):'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动pod后，这里的最后一步是设置`wordpress`服务。在默认示例中，你会在服务文件`(/vagrant/examples/mysql-wordpress-pd/mysql-service.yaml)`中看到类似以下的条目：
- en: '[PRE48]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This has been written to keep in mind that this example will run on the Google
    Compute Engine. So it is not valid here. In place of that, we will need to make
    an entry like the following:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章是为了记住这个示例将在Google Compute Engine上运行。所以这里不适用。我们需要做的是像下面这样做一个条目：
- en: '[PRE49]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We have replaced the load-balancer entry with the public IP of the node, which
    in our case is the IP address of the node (minion). So, the `wordpress` file would
    look like the following:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 我们用节点的公共IP替换了负载均衡器的条目，这在我们的情况下就是节点（minion）的IP地址。因此，`wordpress`文件看起来会像下面这样：
- en: '![How to do it…](../Images/image00406.jpeg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](../Images/image00406.jpeg)'
- en: 'To start the `wordpress` service, run the following command from the master
    node:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要启动`wordpress`服务，请从主节点上运行以下命令：
- en: '[PRE50]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '![How to do it…](../Images/image00407.jpeg)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![如何操作...](../Images/image00407.jpeg)'
- en: We can see here that our service is also available through the node (minion)
    IP.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到我们的service也可以通过节点（minion）IP访问。
- en: 'To verify if everything works fine, we can install the links package on master
    by which we can browse a URL through the command line and connect to the public
    IP we mentioned:'
  id: totrans-369
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要验证一切是否正常工作，我们可以在主节点上安装links软件包，通过它我们可以通过命令行浏览URL并连接到我们提到的公共IP：
- en: '[PRE51]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: With this, you should see the `wordpress` installation page.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，你应该能看到`wordpress`安装页面。
- en: How it works…
  id: totrans-372
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作原理...
- en: In this recipe, we first created a `mysql` pod and service. Later, we connected
    it to a `wordpress` pod, and to access it, we created a `wordpress` service. Each
    YAML file has a `kind` key that defines the type of object it is. For example,
    in pod files, the `kind` is set to pod and in service files, it is set to service.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们首先创建了一个`mysql`的pod和service。之后，我们将它连接到了一个`wordpress`的pod，并且为了访问它，我们创建了一个`wordpress`的service。每个YAML文件都有一个`kind`键，用来定义它是什么类型的对象。例如，在pod文件中，`kind`被设置为pod，在service文件中，被设置为service。
- en: There's more…
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 还有更多...
- en: 'In this example setup, we have only one Node (minion). If you log in to it,
    you will see all the running containers:'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个示例设置中，我们只有一个节点（minion）。如果你登录进去，你会看到所有正在运行的容器：
- en: '[PRE52]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: In this example, we have not configured replication controllers. We can extend
    this example by creating them.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个示例中，我们没有配置复制控制器。我们可以通过创建它们来扩展这个示例。
- en: See also
  id: totrans-378
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另请参阅
- en: Setting up the Vagrant environment at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[设置Vagrant环境](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/getting-started-guides/vagrant.md)上
- en: The Kubernetes User Guide at [https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Kubernetes用户指南](https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/user-guide.md)'
- en: The documentation on kube-dns at [https://github.com/GoogleCloudPlatform/kubernetes/tree/master/cluster/addons/dns](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/cluster/addons/dns)
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[kube-dns](https://github.com/GoogleCloudPlatform/kubernetes/tree/master/cluster/addons/dns)上的文档
