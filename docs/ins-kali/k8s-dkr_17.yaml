- en: '*Chapter 14*: Provisioning a Platform'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第14章*：提供平台'
- en: Every chapter in this book, up until this point, has focused on the infrastructure
    of your cluster. We have explored how to deploy Kubernetes, how to secure it,
    and how to monitor it. What we haven't talked about is how to deploy applications.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 直到目前为止，这本书的每一章都集中在集群的基础设施上。我们已经探讨了如何部署Kubernetes，如何保护它以及如何监视它。我们还没有讨论如何部署应用程序。
- en: In this, our final chapter, we're going to work on building an application deployment
    platform using what we've learned about Kubernetes. We're going to build our platform
    based on some common enterprise requirements. Where we can't directly implement
    a requirement, because building a platform on Kubernetes can fill its own book,
    we'll call it out and provide some insights.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的最后一章中，我们将致力于利用我们对Kubernetes的了解来构建一个应用部署平台。我们将根据一些常见的企业需求来构建我们的平台。在我们无法直接实现某项需求时，因为在Kubernetes上构建平台可以填满一本书，我们会指出并提供一些见解。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Designing a pipeline
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计管道
- en: Preparing our cluster
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备我们的集群
- en: Deploying GitLab
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署GitLab
- en: Deploying Tekton
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Tekton
- en: Deploying ArgoCD
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署ArgoCD
- en: Automating project onboarding using OpenUnison
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用OpenUnison自动化项目入职
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: To perform the exercises in this chapter, you will need a clean KinD cluster
    with a minimum of 8 GB of memory, 75 GB storage, and 4 CPUs. The system we will
    build is minimalist but still requires considerable horsepower to run.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行本章的练习，您需要一个干净的KinD集群，至少有8GB内存，75GB存储空间和4个CPU。我们将构建的系统是最简化的，但仍需要相当大的计算能力来运行。
- en: 'You can access the code for this chapter at the following GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下GitHub存储库中访问本章的代码：[https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide)。
- en: Designing a pipeline
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计管道
- en: 'The term "pipeline" is used extensively in the Kubernetes and DevOps world.
    Very simply, a pipeline is a process, usually automated, that takes code and gets
    it running. This usually involves the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “管道”这个术语在Kubernetes和DevOps世界中被广泛使用。非常简单地说，管道是一个过程，通常是自动化的，它接受代码并使其运行。这通常涉及以下内容：
- en: '![Figure 14.1 – A simple pipeline'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.1 - 一个简单的管道'
- en: '](image/Fig_14.1_B15514.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.1_B15514.jpg)'
- en: Figure 14.1 – A simple pipeline
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.1 - 一个简单的管道
- en: 'Let''s quickly run through the steps involved in this process:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下这个过程中涉及的步骤：
- en: Storing the source code in a central repository, usually Git
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将源代码存储在一个中央仓库中，通常是Git
- en: When code is committed, building it and generating artifacts, usually a container
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当代码提交时，构建它并生成构件，通常是一个容器
- en: Telling the platform – in this case, Kubernetes – to roll out the new containers
    and shut down the old ones
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 告诉平台 - 在这种情况下是Kubernetes - 推出新的容器并关闭旧的容器。
- en: 'This is about as basic as a pipeline can get and isn''t of much use in most
    deployments. In addition to building our code and deploying it, we want to make
    sure we scan containers for known vulnerabilities. We may also want to run our
    containers through some automated testing before going into production. In enterprise
    deployments, there''s often a compliance requirement where someone takes responsibility
    for the move to production as well. Taking this into account, the pipeline starts
    to get more complex:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个管道可以变得多么基本，并且在大多数部署中并不太有用。除了构建我们的代码并部署它之外，我们还希望确保扫描容器中已知的漏洞。在进入生产之前，我们可能还希望对我们的容器进行一些自动化测试。在企业部署中，通常存在一个合规性要求，即有人对进入生产负责。考虑到这一点，管道开始变得更加复杂：
- en: '![Figure 14.2 – Pipeline with common enterprise requirements'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.2 - 具有常见企业要求的管道'
- en: '](image/Fig_14.2_B15514.jpg)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.2_B15514.jpg)'
- en: Figure 14.2 – Pipeline with common enterprise requirements
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.2 - 具有常见企业要求的管道
- en: 'The pipeline has added some extra steps, but it''s still linear with one starting
    point, a commit. This is also very simplistic and unrealistic. The base containers
    and libraries your applications are built on are constantly being updated as new
    **Common Vulnerabilities and Exposures** (**CVEs**), a common way to catalog and
    identify security vulnerabilities, are discovered and patched. In addition to
    having developers that are updating application code for new requirements, you
    will want to have a system in place that scans both the code and the base containers
    for available updates. These scanners watch your base containers and can do something
    to trigger a build once a new base container is ready. While the scanners could
    call an API to trigger a pipeline, your pipeline is already waiting on your Git
    repository to do something, so it would be better to simply add a commit or a
    pull request to your Git repository to trigger the pipeline:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 管道已经添加了一些额外的步骤，但它仍然是线性的，有一个起点，一个提交。这也非常简单和不切实际。您的应用程序构建在其上的基本容器和库不断更新，因为发现和修补了新的**通用漏洞和暴露**（**CVEs**）（一种常见的目录和识别安全漏洞的方式）。除了有开发人员更新应用程序代码以满足新需求之外，您还希望建立一个系统，用于扫描代码和基本容器是否有可用的更新。这些扫描程序监视您的基本容器，并且可以在新的基本容器就绪时触发构建。虽然扫描程序可以调用API来触发管道，但您的管道已经在等待Git存储库执行某些操作，因此最好只需向Git存储库添加提交或拉取请求以触发管道：
- en: '![Figure 14.3 – Pipeline with scanners integrated'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.3 - 集成了扫描程序的管道'
- en: '](image/Fig_14.3_B15514.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.3_B15514.jpg)'
- en: Figure 14.3 – Pipeline with scanners integrated
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.3 - 集成了扫描程序的管道
- en: This means your application code is tracked and your operational updates are
    tracked in Git. Git is now the source of truth for not only what your application
    code is but also operations updates. When it's time to go through your audits,
    you have a ready-made change log! If your policies require you to enter changes
    into a change management system, simply export the changes from Git.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着您的应用程序代码和操作更新都在Git中进行跟踪。Git现在不仅是您的应用程序代码的真相，还是操作更新的真相。当需要进行审计时，您就有了一个现成的变更日志！如果您的政策要求您将更改输入到变更管理系统中，只需从Git中导出更改即可。
- en: So far, we have focused on our application code and just put **Rollout** at
    the end of our pipeline. The final rollout step usually means patching a **Deployment**
    or **StatefulSet** with our newly built container, letting Kubernetes do the work
    of spinning up new **Pods** and scaling down the old ones. This could be done
    with a simple API call, but how are we tracking and auditing that change? What's
    the source of truth?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经专注于我们的应用程序代码，并且在管道的最后放置了**Rollout**。最终的部署步骤通常意味着使用我们新构建的容器来修补**Deployment**或**StatefulSet**，让Kubernetes来完成启动新的**Pods**和缩减旧的Pods的工作。这可以通过简单的API调用来完成，但我们如何跟踪和审计这个变化？真相是什么？
- en: 'Our application in Kubernetes is defined as a series of objects stored in **etcd**
    that are generally represented as code using YAML files. Why not store those files
    in a Git repository too? This gives us the same benefits as storing our application
    code in Git. We have a single source of truth for both the application source
    and the operations of our application! Now, our pipeline involves some more steps:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在Kubernetes中的应用程序被定义为存储在**etcd**中的一系列对象，通常使用YAML文件表示为代码。为什么不也将这些文件存储在Git存储库中呢？这给我们带来了与将应用程序代码存储在Git中相同的好处。我们对应用程序源代码和应用程序操作都有一个统一的真相！现在，我们的管道涉及一些更多的步骤：
- en: '![Figure 14.4 – GitOps pipeline'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.4 - GitOps管道'
- en: '](image/Fig_14.4_B15514.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.4_B15514.jpg)'
- en: Figure 14.4 – GitOps pipeline
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.4 - GitOps流水线
- en: In this diagram, our rollout updates a Git repository with our application's
    Kubernetes YAML. A controller inside our cluster watches for updates to Git and
    when it sees them, gets the cluster in sync with what's in Git. It can also detect
    drift in our cluster and bring it back to alignment with our source of truth.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，我们的部署更新了一个包含我们应用的Kubernetes YAML的Git仓库。我们集群内的控制器会监视Git的更新，当它发现更新时，将集群与Git中的内容同步。它还可以检测集群中的漂移，并将其重新调整到与我们的真相源一致。
- en: This focus on Git is called **GitOps**. The idea is that all of the work of
    an application is done via code, not directly via APIs. How strict you are with
    this idea can dictate what your platform looks like. Next, we'll explore how opinions
    can shape your platform.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种对Git的关注被称为GitOps。其理念是所有应用的工作都是通过代码完成，而不是直接通过API。你对这个理念的严格程度可以决定你的平台是什么样子的。接下来，我们将探讨观点如何塑造你的平台。
- en: Opinionated platforms
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主张性平台
- en: 'Kelsey Hightower, a developer advocate for Google and leader in the Kubernetes
    world, once said: "Kubernetes is a platform for building platforms. It''s a better
    place to start; not the endgame." When you look at the landscape of vendors and
    projects building Kubernetes-based products, they all have their own opinions
    of how systems should be built. As an example, Red Hat''s **OpenShift Container
    Platform** (**OCP**) wants to be a one-stop-shop for multi-tenant enterprise deployment.
    It builds in a great deal of the pipeline we discussed. You define a pipeline
    that is triggered by a commit, which builds a container and pushes it into its
    own internal registry that then triggers a rollout of the new container. Namespaces
    are the boundaries of tenants. Canonical is a minimalist distribution that doesn''t
    include any pipeline components. Managed vendors such as Amazon, Azure, and Google
    provide the building blocks of a cluster and the hosted build tools of a pipeline
    but leave it to you to build out your platform.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kelsey Hightower，谷歌的开发者倡导者和Kubernetes世界的领导者，曾经说过：“Kubernetes是一个构建平台的平台。这是一个更好的开始，而不是终点。”当你看看构建基于Kubernetes的产品的供应商和项目的格局时，它们都对系统应该如何构建有自己的看法。举个例子，红帽的OpenShift容器平台（OCP）希望成为多租户企业部署的一站式服务。它内置了我们讨论过的大量流水线。你定义一个由提交触发的流水线，它构建一个容器并将其推送到自己的内部注册表，然后触发新容器的部署。命名空间是租户的边界。Canonical是一个不包括任何流水线组件的极简主义发行版。亚马逊、Azure和谷歌等托管供应商提供了集群的构建模块和托管构建工具，但让你自己构建平台。
- en: There is no correct answer as to which platform to use. Each is opinionated
    and the right one for your deployment will depend on your own requirements. Depending
    on the size of your enterprise, it wouldn't be surprising to see more than one
    platform deployed!
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 没有正确的答案来确定使用哪个平台。每个平台都有自己的观点，对于你的部署来说，选择合适的平台将取决于你自己的需求。根据你的企业规模，部署多个平台也不足为奇！
- en: Having looked at the idea of opinionated platforms, let's explore the security
    impacts of building a pipeline.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在看了主张性平台的概念之后，让我们探讨构建流水线的安全影响。
- en: Securing your pipeline
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保护你的流水线
- en: Depending on your starting point, this can get complex quickly. How much of
    your pipeline is one integrated system, or could it be described using a colorful
    American colloquialism involving duct tape? Even in platforms where all the components
    are there, tying them together can often mean building a complex system. Most
    of the systems that are part of your pipeline will have a visual component. Usually,
    the visual component is a dashboard. Users and developers may need access to that
    dashboard. You don't want to maintain separate accounts for all those systems,
    do you? You'll want to have one login point and portal for all the components
    of your pipeline.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的起点，这可能会很快变得复杂起来。您的管道有多少是一个集成系统，或者可以用涉及胶带的美国俚语来描述？即使在所有组件都在的平台上，将它们联系在一起通常意味着构建一个复杂的系统。您的管道中的大多数系统都将具有视觉组件。通常，视觉组件是一个仪表板。用户和开发人员可能需要访问该仪表板。您不想为所有这些系统维护单独的帐户，对吧？您会希望为管道的所有组件设置一个登录点和门户。
- en: After determining how to authenticate the users who use these systems, the next
    question is how to automate the rollout. Each component of your pipeline requires
    configuration. It can be as simple as an object that gets created via an API call
    or as complex as tying together a Git repo and build process with SSH keys to
    automate security. In such a complex environment, manually creating pipeline infrastructure
    will lead to security gaps. It will also lead to impossible-to-manage systems.
    Automating the process and providing consistency will help you both secure your
    infrastructure and keep it maintainable.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 确定如何对使用这些系统的用户进行身份验证后，下一个问题是如何自动化推出。您的管道的每个组件都需要配置。它可以是通过API调用创建的对象，也可以是将Git存储库和构建过程与SSH密钥联系在一起以自动化安全的复杂过程。在这样一个复杂的环境中，手动创建管道基础设施将导致安全漏洞。这也将导致无法管理的系统。自动化流程并提供一致性将帮助您确保基础设施的安全性并使其易于维护。
- en: Finally, it's important to understand the implications of GitOps on our cluster
    from a security standpoint. We discussed authenticating administrators and developers
    to use the Kubernetes API and authorizing access to different APIs in [*Chapter
    7*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203), *Integrating Authentication
    into Your Cluster*, and [*Chapter 8*](B15514_08_Final_ASB_ePub.xhtml#_idTextAnchor228)*,
    RBAC Policies Using Active Directory Users*. What is the impact if someone can
    check in a **RoleBinding** that assigns them the **admin** **ClusterRole** for
    a namespace and a GitOps controller automatically pushes it through to the cluster?
    As you design your platform, consider how developers and administrators will want
    to interact with it. It's tempting to say "Let everyone interact with their application's
    Git registry," but that means putting the burden on you as the cluster owner for
    many requests. As we discussed in [*Chapter 8*](B15514_08_Final_ASB_ePub.xhtml#_idTextAnchor228),
    *RBAC Policies Using Active Directory*, this could make your team the bottleneck
    in an enterprise. Understanding your customers, in this case, is important in
    knowing how they want to interact with their operations even if it's not how you
    intended.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，从安全的角度来看，了解GitOps对我们的集群的影响是很重要的。我们在《第7章》，*将认证集成到您的集群*和《第8章》，*使用Active Directory用户的RBAC策略*中讨论了对管理员和开发人员进行身份验证以使用Kubernetes
    API，并授权访问不同API的访问。如果有人可以提交一个分配给他们命名空间的**admin ClusterRole**的**RoleBinding**，并且GitOps控制器自动将其推送到集群，那会有什么影响？在设计平台时，考虑开发人员和管理员将如何与其互动。诱人的做法是说“让每个人与他们的应用程序的Git注册表互动”，但这意味着您作为集群所有者需要处理许多请求的负担。正如我们在《第8章》，*使用Active
    Directory的RBAC策略*中讨论的那样，这可能使您的团队成为企业的瓶颈。了解您的客户在这种情况下是重要的，因为这样可以知道他们希望如何与他们的操作进行交互，即使这不是您的本意。
- en: Having touched on some of the security aspects of GitOps and a pipeline, let's
    explore the requirements for a typical pipeline and how we will build it.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在涉及GitOps和流水线的一些安全方面后，让我们探讨一下典型流水线的要求以及我们将如何构建它。
- en: Building our platform's requirements
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 满足我们平台的要求。
- en: 'Kubernetes deployments, especially in enterprise settings, will often have
    the following basic requirements:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes部署，特别是在企业环境中，通常会有以下基本要求：
- en: '**Development and test environments**: At least two clusters to test the impacts
    of changes on the cluster level to applications'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发和测试环境：至少有两个集群，以测试对应用程序的集群级别的更改的影响
- en: '**Developer sandbox**: A place where developers can build containers and test
    them without worrying about impacts on shared namespaces'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发人员沙盒：开发人员可以构建容器并测试它们，而不必担心对共享命名空间的影响
- en: '**Source control and issue tracking**: A place to store code and track open
    tasks'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 源代码控制和问题跟踪：存储代码并跟踪未完成的任务的地方
- en: In addition to these basic requirements, enterprises will often have additional
    requirements, such as regular access reviews, limiting access based on policy,
    and workflows that assign responsibility for actions that could impact a shared
    environment.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些基本要求之外，企业通常还会有额外的要求，例如定期访问审查、基于策略限制访问以及分配对可能影响共享环境的操作负责的工作流程。
- en: 'For our platform, we want to encompass as many of these requirements as possible.
    To better automate deployments onto our platform, we''re going to define each
    application as having the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的平台，我们希望尽可能包含这些要求。为了更好地自动化部署到我们的平台，我们将定义每个应用程序具有以下内容：
- en: '**A development namespace**: Developers are administrators.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发命名空间：开发人员是管理员。
- en: '**A production namespace**: Developers are viewers.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生产命名空间：开发人员是查看者。
- en: '**A source control project**: Developers can fork.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源代码控制项目**：开发人员可以fork。'
- en: '**A build process**: Triggered by updates to Git.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**构建流程**：由对Git的更新触发。'
- en: '**A deploy process**: Triggered by updates to Git.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署流程**：由对Git的更新触发。'
- en: In addition, we want our developers to have their own sandbox so that each user
    will get their own namespace for development.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们希望我们的开发人员有他们自己的沙盒，这样每个用户都将获得自己的开发命名空间。
- en: Important Note
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In a real deployment, you will want to separate your development and production
    environments into separate clusters. This makes it much easier to test cluster-wide
    operations, such as upgrades, without impacting running applications. We're doing
    everything in one cluster to make it easier for you to set up on your own.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际部署中，您会希望将开发和生产环境分开到不同的集群中。这样可以更容易地测试集群范围的操作，例如升级，而不会影响正在运行的应用程序。我们在一个集群中做所有操作是为了让您更容易自行设置。
- en: 'To provide access to each application, we will define three roles:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供对每个应用程序的访问权限，我们将定义三个角色：
- en: '**Owners**: Users that are application owners can approve access for other
    roles inside their application. This role is assigned to the application requestor
    and can be assigned by application owners. Owners are also responsible for pushing
    changes into development and production.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**所有者**：应用程序所有者可以批准其他角色在其应用程序内的访问权限。这个角色由应用程序请求者分配，并可以由应用程序所有者分配。所有者还负责推送更改到开发和生产环境中。'
- en: '**Developers**: These are users that will have access to an application''s
    source control and can administer the application''s development namespace. They
    can view objects in the production namespace but can''t edit anything. This role
    can be requested by any users and is approved by an application owner.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发人员**：这些用户将可以访问应用程序的源代码控制，并可以管理应用程序的开发命名空间。他们可以查看生产命名空间中的对象，但不能编辑任何内容。任何用户都可以请求此角色，并由应用程序所有者批准。'
- en: '**Operations**: These users have the capabilities as developers, but can also
    make changes to the production namespace as needed. This role can be requested
    by any user and is approved by the application owner.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运维人员**：这些用户具有开发人员的能力，但也可以根据需要对生产命名空间进行更改。任何用户都可以请求此角色，并由应用程序所有者批准。'
- en: 'We will also create some environment-wide roles:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一些环境范围的角色：
- en: '**System approvers**: Users with this role can approve access to any system-wide
    roles.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统审批者**：拥有此角色的用户可以批准对任何系统范围角色的访问权限。'
- en: '**Cluster administrators**: This role is specifically for managing our cluster
    and the applications that comprise our pipeline. It can be requested by anyone
    and must be approved by a member of the system approvers role.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群管理员**：这个角色专门用于管理我们的集群和构成我们流水线的应用程序。任何人都可以请求此角色，并必须得到系统审批者角色的批准。'
- en: '**Developers**: Anyone who logs in gets their own namespace for development.
    These namespaces cannot be requested for access by other users. These namespaces
    are not directly connected to any CI/CD infrastructure or Git repositories.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发人员**：任何登录的用户都会获得自己的开发命名空间。这些命名空间不能被其他用户请求访问。这些命名空间与任何CI/CD基础设施或Git存储库没有直接连接。'
- en: Even with our very simple platform, we have six roles that need to be mapped
    to the applications that make up our pipeline. Each application has its own authentication
    and authorization processes that these roles will need to be mapped to. This is
    just one example of why automation is so important to the security of your clusters.
    Provisioning this access manually based on email requests can become unmanageable
    quickly.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们的平台非常简单，我们有六个角色需要映射到构成我们流水线的应用程序上。每个应用程序都有自己的身份验证和授权流程，这些角色需要映射到这些流程上。这就是为什么自动化对于集群安全如此重要的一个例子。根据电子邮件请求手动提供访问权限可能会迅速变得难以管理。
- en: 'The workflow that developers are expected to go through with an application
    will line up with the GitOps flow we designed previously:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员预期通过应用程序进行的工作流程将与我们之前设计的GitOps流程一致：
- en: Application owners will request an application be created. Once approved, a
    Git repository will be created for application code, pipeline build manifests,
    and Kubernetes manifests. Development and production namespaces will be created
    as well with appropriate **RoleBinding** objects. Groups will be created that
    reflect the roles for each application, with approval for access to those groups
    delegated to the application owner.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序所有者将请求创建一个应用程序。一旦获得批准，将为应用程序代码、流水线构建清单和Kubernetes清单创建一个Git存储库。还将创建开发和生产命名空间，并创建适当的**RoleBinding**对象。将创建反映每个应用程序角色的组，并将访问这些组的批准委托给应用程序所有者。
- en: Developers and operations staff are granted access to the application by either
    requesting it or having it provided directly by an application owner. Once granted
    access, updates are expected in both the developer's sandbox and the development
    namespace. Updates are made in a user's fork for the Git repository, with pull
    requests used to merge code into the main repositories that drive automation.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发人员和运维人员可以通过请求或直接由应用程序所有者提供来获得对应用程序的访问权限。一旦获得访问权限，预期在开发人员的沙盒和开发命名空间中进行更新。更新是在用户的Git存储库分支中进行的，使用拉取请求将代码合并到驱动自动化的主存储库中。
- en: All builds are controlled via "scripts" in the application's source control.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有构建都通过应用程序的源代码中的“脚本”进行控制。
- en: All artifacts are published to a centralized container registry.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有工件都发布到集中式容器注册表中。
- en: All production updates must be approved by application owners.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有生产更新必须得到应用程序所有者的批准。
- en: This basic workflow doesn't include typical components of a workflow, such as
    code and container scans, periodic access recertifications, or requirements for
    privileged access. The topic of this chapter can easily be a complete book on
    its own. The goal isn't to build a complete enterprise platform but to give you
    a starting point for building and designing your own system.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基本的工作流程不包括工作流的典型组件，比如代码和容器扫描，定期访问重新认证，或者特权访问的要求。本章的主题很容易成为一本完整的书。目标不是构建一个完整的企业平台，而是为您构建和设计自己的系统提供一个起点。
- en: Choosing our technology stack
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择我们的技术栈
- en: In the previous parts of this section, we talked about pipelines in a generic
    way. Now, let's get into the specifics of what technology is needed in our pipeline.
    We identified earlier that every application has application source code and Kubernetes
    manifest definitions. It also has to build containers. There needs to be a way
    to watch for changes to Git and update our cluster. Finally, we need an automation
    platform so that all these components work together.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的前几部分中，我们以一种通用的方式讨论了流水线。现在，让我们进入我们的流水线所需的技术的具体细节。我们之前确定，每个应用程序都有应用程序源代码和Kubernetes清单定义。它还必须构建容器。需要一种方式来监视Git的更改并更新我们的集群。最后，我们需要一个自动化平台，使所有这些组件能够协同工作。
- en: 'Based on our requirements for our platform, we want technology that has the
    following features:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们对平台的要求，我们希望拥有以下功能的技术：
- en: '**Open source**: We don''t want you to buy anything just for this book!'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源**：我们不希望您为了这本书而购买任何东西！'
- en: '**API-driven**: We need to be able to provision components and access in an
    automated way.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于API的：我们需要能够以自动化的方式配置组件并访问。
- en: '**Has a visual component that supports external authentication**: This book
    focuses on enterprise, and everyone in the enterprise loves their GUIs. Just not
    having different credentials for each application.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**具有支持外部身份验证的视觉组件**：这本书侧重于企业，企业中的每个人都喜欢他们的图形用户界面。只是不想为每个应用程序使用不同的凭据。'
- en: '**Supported on Kubernetes**: This is a book on Kubernetes.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在Kubernetes上支持**：这是一本关于Kubernetes的书。'
- en: 'To meet these requirements, we''re going to deploy the following components
    to our cluster:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了满足这些要求，我们将在我们的集群中部署以下组件：
- en: '**Git Registry – GitLab**: GitLab is a powerful system that provides a great
    UI and experience for working with Git that supports external authentication (that
    is, **Single Sign-On (SSO)**. It has integrated issue management and an extensive
    API. It also has a Helm chart that we have tailored for the book to run a minimal
    install.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Git注册表 - GitLab**：GitLab是一个强大的系统，提供了一个很好的UI和体验，用于与支持外部身份验证的Git一起工作（即**单点登录（SSO）**）。它集成了问题管理和广泛的API。它还有一个Helm图表，我们已经为本书定制了一个最小的安装。'
- en: '**Automated Builds – Tekton**: Originally the build portion of the Knative
    project for Kubernetes function-as-a-service deployments, Tekton was spun off
    into its own project to provide build services for generic applications. It runs
    in Kubernetes with all interactions being via the Kubernetes API. There''s an
    early stage dashboard too!'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动化构建 - Tekton**：最初是Kubernetes函数即服务部署的Knative项目的构建部分，Tekton被分离出来成为自己的项目，为通用应用程序提供构建服务。它在Kubernetes中运行，所有交互都通过Kubernetes
    API进行。它也有一个早期阶段的仪表板！'
- en: '**Container Registry – simple Docker registry**: There are many very capable
    open source registries. Since this deployment will get complex quickly, we decided
    just to use the registry provided by Docker. There won''t be any security on it,
    so don''t use it in production!'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容器注册表 - 简单的Docker注册表**：有许多功能强大的开源注册表。由于这个部署很快就会变得复杂，我们决定只使用Docker提供的注册表。它不会有任何安全性，所以不要在生产中使用！'
- en: '**GitOps – ArgoCD**: ArgoCD is a collaboration between Intuit and Weaveworks
    to build a feature-rich GitOps platform. It''s Kubernetes native, has its own
    API, and stores its objects as Kubernetes custom resources, making it easier to
    automate. Its UI and CLI tools both integrate with SSO using OpenID Connect.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GitOps - ArgoCD**：ArgoCD是Intuit和Weaveworks之间合作构建功能丰富的GitOps平台。它是Kubernetes本地的，有自己的API，并将其对象存储为Kubernetes自定义资源，使自动化变得更容易。它的UI和CLI工具都使用OpenID
    Connect与SSO集成。'
- en: '**Access, authentication, and automation – OpenUnison**: We''ll continue to
    use OpenUnison for authentication into our cluster. We''re also going to integrate
    the UI components of our technology stack as well to provide a single portal for
    our platform. Finally, we''ll use OpenUnison''s workflows to manage access to
    each system based on our role structure and provision the objects needed for everything
    to work together. Access will be provided via OpenUnison''s self-service portal.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问、身份验证和自动化 - OpenUnison**：我们将继续使用OpenUnison进行对集群的身份验证。我们还将整合我们技术堆栈的UI组件，以提供一个平台的单一门户。最后，我们将使用OpenUnison的工作流根据我们的角色结构管理对每个系统的访问，并提供一切工作所需的对象。访问将通过OpenUnison的自助门户提供。'
- en: Reading through this technology stack, you might ask "Why didn't you choose
    *XYZ*?" The Kubernetes ecosystem is diverse with no shortage of great projects
    and products for your cluster. This is by no means a definitive stack, nor is
    it even a "recommended" stack. It's a collection of applications that meets our
    requirements and lets us focus on the processes being implemented, rather than
    learning a specific technology.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读这个技术栈时，你可能会问：“为什么你没有选择*XYZ*？”Kubernetes生态系统多样且拥有众多出色的项目和产品供您的集群使用。这绝不是一个确定的技术栈，甚至不是一个“推荐”的技术栈。这是一个满足我们需求并让我们专注于正在实施的流程的应用程序集合，而不是学习特定技术。
- en: You might also find that there's quite a bit of overlap between even the tools
    in this stack. For instance, GitLab has GitOps capabilities and its own build
    system, but we chose not to use them for this chapter. We did that so that you
    can see how to tie different systems together to build a platform. Your platform
    may use GitHub's SaaS solution for source control but run builds internally and
    combine with Amazon's container registry. We wanted you to see how these systems
    can be connected to build a platform instead of focusing on specific tools.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还会发现，即使在这个技术栈中，工具之间也存在相当大的重叠。例如，GitLab具有GitOps功能和自己的构建系统，但我们选择不在本章中使用它们。我们这样做是为了让您看到如何将不同的系统连接在一起构建平台。您的平台可能会使用GitHub的SaaS解决方案进行源代码控制，但在内部运行构建，并与亚马逊的容器注册表结合。我们希望您看到这些系统如何连接在一起构建平台，而不是专注于特定工具。
- en: This section was a very deep exploration of the theory behind pipeline design
    and looking at common requirements for building a Kubernetes-based platform. We
    identified technology components that can implement those requirements and why
    we chose them. With this knowledge in hand, it's time to build!
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这一部分是对管道设计理论的深入探讨，以及对构建基于Kubernetes的平台的常见要求的审视。我们确定了可以实现这些要求的技术组件以及我们为什么选择它们。有了这些知识，现在是时候开始构建了！
- en: Preparing our cluster
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 准备我们的集群
- en: Before we begin deploying our technology stack, we need to do a couple of things.
    I recommend starting with a fresh cluster. If you're using the KinD cluster from
    this book, start with a new cluster. We're deploying several components that need
    to be integrated and it will be simpler and easier to start fresh rather than
    potential struggling with previous configurations. Before we start deploying the
    applications that will make up our stack, we're going to deploy JetStack's cert-manager
    to automate certificate issuing, a simple container registry, and OpenUnison for
    authentication and automation.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始部署技术栈之前，我们需要做一些事情。我建议从一个新的集群开始。如果您正在使用本书中的KinD集群，请从一个新的集群开始。我们正在部署几个需要集成的组件，最好从头开始，而不是可能与先前的配置斗争。在我们开始部署构成我们技术栈的应用程序之前，我们将部署JetStack的cert-manager来自动化证书签发，一个简单的容器注册表，以及用于身份验证和自动化的OpenUnison。
- en: Deploying cert-manager
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署cert-manager
- en: JetStack, a Kubernetes-focused consulting company, created a project called
    **cert-manager** to make it easier to automate the creation and renewal of certificates.
    This project works by letting you define issuers using Kubernetes custom resources
    and then using annotations on **Ingress** objects to generate certificates using
    those issuers. The end result is a cluster running with properly managed and rotated
    certificates without generating a single **certificate signing request** (**CSR**)
    or worrying about expiration!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: JetStack是一家专注于Kubernetes的咨询公司，他们创建了一个名为**cert-manager**的项目，以便更容易地自动创建和更新证书。该项目通过让您使用Kubernetes自定义资源定义发行者，然后在**Ingress**对象上使用注释来使用这些发行者生成证书来工作。最终结果是集群运行正常管理和轮换证书，而不需要生成一个**证书签名请求**（**CSR**）或担心过期！
- en: The **cert-manager** project is most often mentioned with *Let's Encrypt* (https://letsencrypt.org/)
    to automate the publishing of certificates that have been signed by a commercially
    recognized certificate authority for free (as in beer). This is possible because
    *Let's Encrypt* automates the process. The certificates are only good for 90 days
    and the entire process is API-driven. In order to drive this automation, you must
    have some way of letting *Let's Encrypt* verify ownership of the domain you are
    trying to get a certificate for. Throughout this book, we have used **nip.io**
    to simulate DNS. If you have a DNS service that you can use and is supported by
    **cert-manager**, such as Amazon's Route 53, then this is a great solution.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**cert-manager**项目通常与*Let''s Encrypt*（https://letsencrypt.org/）一起提到，以自动发布由商业认可的证书颁发机构免费签名的证书（就像啤酒一样）。这是可能的，因为*Let''s
    Encrypt*自动化了这个过程。证书只有90天的有效期，整个过程都是API驱动的。为了驱动这种自动化，您必须有一种让*Let''s Encrypt*验证您正在尝试获取证书的域的所有权的方法。在本书中，我们使用**nip.io**来模拟DNS。如果您有一个可以使用并且受**cert-manager**支持的DNS服务，比如亚马逊的Route
    53，那么这是一个很好的解决方案。'
- en: Since we're using **nip.io**, we will deploy **cert-manager** with a self-signed
    certificate authority. This gives us the benefit of having a certificate authority
    that can quickly generate certificates without having to worry about domain validation.
    We will then instruct our workstation to trust this certificate as well as the
    applications we deploy so that everything is secured using properly built certificates.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用**nip.io**，我们将部署**cert-manager**与自签名证书颁发机构。这使我们能够拥有一个证书颁发机构，可以快速生成证书，而不必担心域验证的问题。然后，我们将指示我们的工作站信任此证书以及我们部署的应用程序，以便一切都使用正确构建的证书进行保护。
- en: Important Note
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Using a self-signed certificate authority is a common practice for most enterprises
    for internal deployments. This avoids having to deal with potential validation
    issues where a commercially signed certificate won't provide much value. Most
    enterprises are able to distribute an internal certificate authority's certificates
    via their Active Directory infrastructure. Chances are your enterprise has a way
    to request either an internal certificate or a wildcard that could be used too.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数企业来说，使用自签名证书颁发机构是内部部署的常见做法。这避免了处理商业签名证书无法提供太多价值的潜在验证问题。大多数企业能够通过其Active
    Directory基础架构分发内部证书颁发机构的证书。很可能您的企业也有一种方式可以请求内部证书或可用的通配符。
- en: 'The steps to deploy **cert-manager** are as follows:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 部署**cert-manager**的步骤如下：
- en: 'From your cluster, deploy the **cert-manager** manifests:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从您的集群中，部署**cert-manager**清单：
- en: '**$ kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.16.1/cert-manager.yaml**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v0.16.1/cert-manager.yaml**'
- en: 'Once the Pods are running in the **cert-manager** namespace, create a self-signed
    certificate that we''ll use as our certificate authority. In the **chapter14/shell**
    directory of the Git repository for this book is a script called **makeca.sh**
    that will generate this certificate for you:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦Pod在**cert-manager**命名空间中运行，创建一个自签名证书，我们将用作我们的证书颁发机构。在本书的Git存储库的**chapter14/shell**目录中有一个名为**makeca.sh**的脚本，它将为您生成此证书：
- en: '**$ cd Kubernetes-and-Docker-The-Complete-Guide/chapter14/shell/**'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ cd Kubernetes-and-Docker-The-Complete-Guide/chapter14/shell/**'
- en: '**$ sh ./makeca.sh**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ sh ./makeca.sh**'
- en: '**Generating RSA private key, 2048 bit long modulus (2 primes)**'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成RSA私钥，2048位长模数（2个质数）**'
- en: '**.............................................................................................................................................+++++**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**.............................................................................................................................................+++++**'
- en: '**....................+++++**'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '....................+++++'
- en: '**e is 65537 (0x010001)**'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: e为65537（0x010001）
- en: 'There is now an SSL directory with a certificate and a key. The next step is
    to create a secret from these files that will become our certificate authority:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在有一个带有证书和密钥的SSL目录。下一步是从这些文件创建一个secret，这将成为我们的证书颁发机构：
- en: '**$ cd ssl/**'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: $ cd ssl/
- en: '**$ kubectl create secret tls ca-key-pair --key=./tls.key --cert=./tls.crt
    -n cert-manager**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl create secret tls ca-key-pair --key=./tls.key --cert=./tls.crt -n
    cert-manager
- en: '**secret/ca-key-pair created**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: secret/ca-key-pair已创建
- en: 'Next, create the **ClusterIssuer** object so that all of our **Ingress** objects
    can have properly minted certificates:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建ClusterIssuer对象，以便所有的Ingress对象都可以拥有正确颁发的证书：
- en: '**$ cd ../../yaml/**'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: $ cd ../../yaml/
- en: '**$ kubectl create -f ./certmanager-ca.yaml**'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl create -f ./certmanager-ca.yaml
- en: '**clusterissuer.cert-manager.io/ca-issuer created**'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: clusterissuer.cert-manager.io/ca-issuer已创建
- en: 'With **ClusterIssuer** created, any **Ingress** object with the **cert-manager.io/cluster-issuer:
    "ca-issuer"** annotation will have a certificate signed by our authority created
    for them. One of the components we will be using for this is our container registry.
    Kubernetes uses Docker''s underlying mechanisms for pulling containers, and KinD
    will not pull images from registries running without TLS or using an untrusted
    certificate. To get around this issue, we need to import our certificate into
    both our worker and nodes:'
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '创建了ClusterIssuer后，任何带有cert-manager.io/cluster-issuer: "ca-issuer"注释的Ingress对象都将获得我们为它们创建的由我们授权签名的证书。我们将用于此的一个组件是我们的容器注册表。Kubernetes使用Docker的底层机制来拉取容器，并且KinD不会从没有TLS或使用不受信任证书的注册表中拉取镜像。为了解决这个问题，我们需要将我们的证书导入到我们的worker和节点中：'
- en: '**$ cd ~/**'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: $ cd ~/
- en: '**$ kubectl get secret ca-key-pair -n cert-manager -o json | jq -r ''.data["tls.crt"]''
    | base64 -d > internal-ca.crt**'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl get secret ca-key-pair -n cert-manager -o json | jq -r '.data["tls.crt"]'
    | base64 -d > internal-ca.crt
- en: '**$ docker cp internal-ca.crt cluster01-worker:/usr/local/share/ca-certificates/internal-ca.crt**'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker cp internal-ca.crt cluster01-worker:/usr/local/share/ca-certificates/internal-ca.crt
- en: '**$ docker exec -ti cluster01-worker update-ca-certificates**'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker exec -ti cluster01-worker update-ca-certificates
- en: '**Updating certificates in /etc/ssl/certs...**'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在/etc/ssl/certs中更新证书...
- en: '**1 added, 0 removed; done.**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 1个添加，0个移除；完成。
- en: '**Running hooks in /etc/ca-certificates/update.d...**'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在/etc/ca-certificates/update.d中运行钩子...
- en: '**done.**'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 完成。
- en: '**$ docker restart cluster01-worker**'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker restart cluster01-worker
- en: '**$ docker cp internal-ca.crt cluster01-control-plane:/usr/local/share/ca-certificates/internal-ca.crt**'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker cp internal-ca.crt cluster01-control-plane:/usr/local/share/ca-certificates/internal-ca.crt
- en: '**$ docker exec -ti cluster01-control-plane update-ca-certificates**'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker exec -ti cluster01-control-plane update-ca-certificates
- en: '**Updating certificates in /etc/ssl/certs...**'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在/etc/ssl/certs中更新证书...
- en: '**1 added, 0 removed; done.**'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 1个添加，0个移除；完成。
- en: '**Running hooks in /etc/ca-certificates/update.d...**'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在/etc/ca-certificates/update.d中运行钩子...
- en: '**done.**'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 完成。
- en: '**$ docker restart cluster01-control-plane**'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: $ docker restart cluster01-control-plane
- en: The first command extracts the certificate from the secret we created to host
    the certificate. The next set of commands copies the certificate to each container,
    instructs the container to trust it, and finally, restarts the container. Once
    your containers are restarted, wait for all the Pods to come back; it could take
    a few minutes.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令从我们创建的secret中提取证书。接下来的一系列命令将证书复制到每个容器中，指示容器信任它，并最后重新启动容器。一旦容器重新启动，等待所有Pod重新启动；可能需要几分钟。
- en: Important Note
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Now would be a good time to download **internal-ca.crt**; install it onto your
    local workstation and potentially into your browser of choice. Different operating
    systems and browsers do this differently, so check the appropriate documentation
    on how to do this. Trusting this certificate will make things much easier when
    interacting with applications, pushing containers, and using command-line tools.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是下载**internal-ca.crt**的好时机；将其安装到您的本地工作站，可能还要安装到您选择的浏览器中。不同的操作系统和浏览器的操作方式不同，因此请查阅相应的文档了解如何操作。信任此证书将使与应用程序交互、推送容器和使用命令行工具变得更加容易。
- en: With **cert-manager** ready to issue certificates and both your cluster and
    your workstation trusting those certificates, the next step is to deploy a container
    registry.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 有了**cert-manager**准备好颁发证书，以及您的集群和您的工作站信任这些证书，下一步是部署容器注册表。
- en: Deploying the Docker container registry
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署Docker容器注册表
- en: 'Docker, Inc. provides a simple registry. There is no security on this registry,
    so it is most certainly not a good option for production use. The **chapter14/yaml/docker-registry.yaml**
    file will deploy the registry for us and create an **Ingress** object. Before
    deploying, edit this file, changing all instances of **192-168-2-140** to a dash
    representation of your cluster''s IP address. For instance, my cluster is running
    on **192.168.2.114**, so I will replace **192-168-2-140** with **192-168-2-114**.
    Then, run **kubectl create** on the manifest to create the registry:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Docker, Inc.提供了一个简单的注册表。这个注册表没有安全性，因此绝对不是生产使用的好选择。**chapter14/yaml/docker-registry.yaml**文件将为我们部署注册表并创建一个**Ingress**对象。在部署之前，编辑此文件，将所有的**192-168-2-140**实例更改为集群IP地址的破折号表示法。例如，我的集群正在运行**192.168.2.114**，所以我将**192-168-2-140**替换为**192-168-2-114**。然后，运行**kubectl
    create**在清单上创建注册表：
- en: $ kubectl create -f ./docker-registry.yaml
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl create -f ./docker-registry.yaml
- en: namespace/docker-registry created
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: namespace/docker-registry created
- en: statefulset.apps/docker-registry created
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: statefulset.apps/docker-registry created
- en: service/docker-registry created
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: service/docker-registry created
- en: ingress.extensions/docker-registry created
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ingress.extensions/docker-registry created
- en: 'Once the registry is running, you can try accessing it from your browser:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 注册表运行后，您可以尝试从浏览器访问它：
- en: '![Figure 14.5 – Accessing the container registry in a browser'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.5 - 在浏览器中访问容器注册表'
- en: '](image/Fig_14.5_B15514.jpg)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.5_B15514.jpg)'
- en: Figure 14.5 – Accessing the container registry in a browser
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.5 - 在浏览器中访问容器注册表
- en: You won't see much since the registry has no web UI, but you also shouldn't
    get a certificate error. That's because we deployed **cert-manager** and are issuing
    signed certificates! With our registry running, the last component to deploy is
    OpenUnison.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 您不会看到太多，因为注册表没有Web UI，但您也不应该收到证书错误。这是因为我们部署了**cert-manager**并颁发了签名证书！当我们的注册表运行时，部署的最后一个组件是OpenUnison。
- en: Deploying OpenUnison
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署OpenUnison
- en: In [*Chapter 7*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203), *Integrating
    Authentication into Your Cluster*, we introduced OpenUnison to authenticate access
    to our KinD deployment. OpenUnison comes in two flavors. The first, which we have
    already deployed, is a login portal that lets us authenticate using a central
    source and pass group information to our RBAC policies. The second is an automation
    portal that we'll use as the basis for integrating the systems that will manage
    our pipeline. This portal will also give us a central UI for requesting projects
    to be created and managing access to our project's systems.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第7章*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203)，*将身份验证集成到您的集群中*，我们介绍了OpenUnison来验证对我们KinD部署的访问。OpenUnison有两种版本。第一种是我们已经部署的登录门户，它允许我们使用中央来源进行身份验证并将组信息传递给我们的RBAC策略。第二种是一个自动化门户，我们将以此为基础集成将管理我们的流水线的系统。该门户还将为我们提供一个中央UI，用于请求创建项目并管理对我们项目系统的访问。
- en: We defined that each project we deploy will have three "roles" that will span
    several systems. Will your enterprise let you create and manage groups for every
    project we create? Some might, but Active Directory is a critical component in
    most enterprises, and write access can be difficult to get. It's unlikely that
    the people who run your Active Directory are the same people who you report to
    when managing your cluster, complicating your ability to get an area of Active
    Directory that you have administrative rights in. The OpenUnison automation portal
    lets you manage access with local groups that can be easily queried, just like
    with Active Directory, but you have control to manage them. We'll still authenticate
    against our central SAML provider, though.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了我们部署的每个项目将具有跨多个系统的三个"角色"。您的企业是否允许您为我们创建的每个项目创建和管理组？有些可能会，但Active Directory在大多数企业中是一个关键组件，写访问权限可能难以获得。你运行Active
    Directory的人可能不是你在管理集群时向之报告的人，这会使你难以获得你具有管理权限的Active Directory区域。OpenUnison自动化门户允许您使用可以轻松查询的本地组来管理访问，就像使用Active
    Directory一样，但您有权利管理它们。不过，我们仍将对我们的中央SAML提供程序进行身份验证。
- en: 'To facilitate OpenUnison''s automation capabilities, we need to deploy a database
    to store persistent data and an SMTP server to notify users when they have open
    requests or when requests have been completed. For the database, we''ll deploy
    the open source MariaDB. For an **Simple Mail Transfer Protocol** (**SMTP**) (email)
    server, most enterprises have very strict rules about sending emails. We don''t
    want to have to worry about getting email set up for notifications, so we''ll
    run a "black hole" email service that just disregards all SMTP requests:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进OpenUnison的自动化能力，我们需要部署一个数据库来存储持久数据和一个SMTP服务器，以通知用户何时有未处理的请求或请求何时已完成。对于数据库，我们将部署开源的MariaDB。对于**简单邮件传输协议**（**SMTP**）（电子邮件）服务器，大多数企业对发送电子邮件有非常严格的规定。我们不想为通知设置电子邮件，因此我们将运行一个只会忽略所有SMTP请求的"黑洞"电子邮件服务：
- en: First, run the **chapter14/yaml/mariadb.yaml** manifest from the book's GitHub
    repository. No changes need to be made.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，从书的GitHub存储库运行**chapter14/yaml/mariadb.yaml**清单。不需要进行任何更改。
- en: 'Next, deploy the SMTP black hole:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，部署SMTP黑洞：
- en: '**$ kubectl create ns blackhole**'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create ns blackhole**'
- en: '**namespace/blackhole created**'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**命名空间/blackhole已创建**'
- en: '**$ kubectl create deployment blackhole --image=tremolosecurity/smtp-blackhole
    -n blackhole**'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create deployment blackhole --image=tremolosecurity/smtp-blackhole
    -n blackhole**'
- en: '**deployment.apps/blackhole created**'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 部署.apps/blackhole已创建
- en: '**$ kubectl expose deployment/blackhole --type=ClusterIP --port 1025 --target-port=1025
    -n blackhole**'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl expose deployment/blackhole --type=ClusterIP --port 1025 --target-port=1025
    -n blackhole**'
- en: '**service/blackhole exposed**'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务/blackhole已公开**'
- en: With MariaDB and our SMTP service deployed, we're able to deploy OpenUnison.
    Follow *steps 1–5* in the *Deploying OpenUnison* section of [*Chapter 7*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203),
    *Integrating Authentication into Your Cluster*, to deploy the OpenUnison operator
    and Kubernetes dashboard.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有了MariaDB和我们的SMTP服务部署，我们就能够部署OpenUnison。按照[*第7章*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203)的*Deploying
    OpenUnison*部分中的*步骤1-5*，部署OpenUnison操作员和Kubernetes仪表板。
- en: 'Next, create a **Secret** to store credentials for accessing MariaDB and the
    SMTP service. We hardcoded passwords into our deployment for MariaDB for simplicity''s
    sake, so make sure to generate long, random passwords for your production database
    account! Create the following **Secret** in your cluster:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在集群中创建一个**Secret**，用于存储访问MariaDB和SMTP服务的凭据。我们为MariaDB硬编码了密码，以简化部署，因此请确保为生产数据库帐户生成长且随机的密码！在集群中创建以下**Secret**：
- en: 'apiVersion: v1'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: v1'
- en: 'type: Opaque'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'type: Opaque'
- en: 'metadata:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 'metadata:'
- en: 'name: orchestra-secrets-source'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 'name: orchestra-secrets-source'
- en: 'namespace: openunison'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 'namespace: openunison'
- en: 'data:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'K8S_DB_SECRET: aW0gYSBzZWNyZXQ='
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 'K8S_DB_SECRET: aW0gYSBzZWNyZXQ='
- en: 'SMTP_PASSWORD: ""'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 'SMTP_PASSWORD: ""'
- en: 'OU_JDBC_PASSWORD: c3RhcnR0MTIz'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 'OU_JDBC_PASSWORD: c3RhcnR0MTIz'
- en: 'unisonKeystorePassword: aW0gYSBzZWNyZXQ='
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 'unisonKeystorePassword: aW0gYSBzZWNyZXQ='
- en: 'kind: Secret'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 'kind: Secret'
- en: We're going to reuse the Helm values we used in *step 2* in the *Configuring
    your cluster for impersonation* section of [*Chapter 7*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203),
    *Integrating Authentication into Your Cluster*, with three changes.
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将在[*第7章*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203)的*Configuring your
    cluster for impersonation*部分中重用我们在*步骤2*中使用的Helm值，有三个更改。
- en: First, change the image from **docker.io/tremolosecurity/openunison-k8s-login-saml2:latest**
    to **docker.io/tremolosecurity/openunison-k8s-saml2:latest**.
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将图像从**docker.io/tremolosecurity/openunison-k8s-login-saml2:latest**更改为**docker.io/tremolosecurity/openunison-k8s-saml2:latest**。
- en: 'Next, Base64-encode your **internal-ca.crt** file into a single line and add
    it to the **trusted_certs** section of **values.yaml**:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将**internal-ca.crt**文件进行Base64编码为单行，并将其添加到**values.yaml**的**trusted_certs**部分：
- en: '**$ base64 -w 0 < internal-ca.crt**'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ base64 -w 0 < internal-ca.crt**'
- en: '**LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0 tCk1JSUREVENDQWZXZ0F3SUJ…**'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0 tCk1JSUREVENDQWZXZ0F3SUJ…**'
- en: 'Add SMTP and database sections. The updates to **values.yaml** will look as
    follows. I removed most of the unchanged portions to save space:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加SMTP和数据库部分。**values.yaml**的更新如下。我删除了大部分未更改的部分以节省空间：
- en: 'trusted_certs:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 'trusted_certs:'
- en: '- name: internal-ca'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '- name: internal-ca'
- en: 'pem_b64: LS0tLS1CRUdJTiB…'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 'pem_b64: LS0tLS1CRUdJTiB…'
- en: 'saml:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 'saml:'
- en: 'idp_url: https://portal.apps.tremolo.io/idp-test/metadata/dfbe4040-cd32-470e-a9b6-809c8f857c40'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 'idp_url: https://portal.apps.tremolo.io/idp-test/metadata/dfbe4040-cd32-470e-a9b6-809c8f857c40'
- en: 'metadata_xml_b64: ""'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 'metadata_xml_b64: ""'
- en: 'database:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 'database:'
- en: 'hibernate_dialect: org.hibernate.dialect.MySQL5InnoDBDialect'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 'hibernate_dialect: org.hibernate.dialect.MySQL5InnoDBDialect'
- en: 'quartz_dialect: org.quartz.impl.jdbcjobstore.StdJDBCDelegate'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 'quartz_dialect: org.quartz.impl.jdbcjobstore.StdJDBCDelegate'
- en: 'driver: com.mysql.jdbc.Driver'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 'driver: com.mysql.jdbc.Driver'
- en: 'url: jdbc:mysql://mariadb.mariadb.svc.cluster.local:3306/unison'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 'url: jdbc:mysql://mariadb.mariadb.svc.cluster.local:3306/unison'
- en: 'user: unison'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 'user: unison'
- en: 'validation: SELECT 1'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 'validation: SELECT 1'
- en: 'smtp:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 'smtp:'
- en: 'host: blackhole.blackhole.svc.cluster.local'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 'host: blackhole.blackhole.svc.cluster.local'
- en: 'port: 1025'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 'port: 1025'
- en: 'user: none'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 'user: none'
- en: 'from: donotreply@domain.com'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 'from: donotreply@domain.com'
- en: 'tls: false'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 'tls: false'
- en: 'Deploy OpenUnison using the Helm chart:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用Helm图表部署OpenUnison：
- en: '**$ helm install orchestra tremolo/openunison-k8s-saml2 --namespace openunison
    -f ./openunison-values.yaml**'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ helm install orchestra tremolo/openunison-k8s-saml2 --namespace openunison
    -f ./openunison-values.yaml**'
- en: 'Once OpenUnison is deployed, edit the **orchestra** OpenUnison object to remove
    the **unison-ca** key. Remove the block that looks like this:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦部署了OpenUnison，编辑**orchestra** OpenUnison对象，删除**unison-ca**密钥。删除以下类似的块：
- en: '- create_data:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '- create_data:'
- en: 'ca_cert: true'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 'ca_cert: true'
- en: 'key_size: 2048'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 'key_size: 2048'
- en: 'server_name: k8sou.apps.192-168-2-114.nip.io'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 'server_name: k8sou.apps.192-168-2-114.nip.io'
- en: 'sign_by_k8s_ca: false'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 'sign_by_k8s_ca: false'
- en: 'subject_alternative_names:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 'subject_alternative_names:'
- en: '- k8sdb.apps.192-168-2-114.nip.io'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '- k8sdb.apps.192-168-2-114.nip.io'
- en: '- k8sapi.apps.192-168-2-114.nip.io'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '- k8sapi.apps.192-168-2-114.nip.io'
- en: 'import_into_ks: certificate'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 'import_into_ks: certificate'
- en: 'name: unison-ca'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 'name: unison-ca'
- en: 'tls_secret_name: ou-tls-certificate'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'tls_secret_name: ou-tls-certificate'
- en: 'Delete the **ou-tls-certificate** **Secret**:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除**ou-tls-certificate** **Secret**：
- en: '**$ kubectl delete secret ou-tls-certificate -n openunison**'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl delete secret ou-tls-certificate -n openunison**'
- en: '**secret "ou-tls-certificate" deleted**'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**secret "ou-tls-certificate" deleted**'
- en: 'Edit the **openunison** **Ingress** object, adding **cert-manager.io/cluster-issuer:
    ca-issuer** to the list of **annotations**.'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '编辑**openunison** **Ingress**对象，将**cert-manager.io/cluster-issuer: ca-issuer**添加到**annotations**列表中。'
- en: Complete the SSO integration with the testing identity provider using *steps
    4–6* from the *Configuring your cluster for impersonation* section of [*Chapter
    7*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203), *Integrating Authentication
    into Your Cluster*.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用[*第7章*](B15514_07_Final_ASB_ePub.xhtml#_idTextAnchor203)的*配置集群进行模拟*部分的*步骤4-6*完成与测试身份提供者的SSO集成。
- en: Log in to OpenUnison, then log out.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录OpenUnison，然后退出。
- en: 'The OpenUnison automation portal doesn''t do anything with the groups from
    the testing identity provider. In order to become a cluster administrator, you
    must be "bootstrapped" into the environment''s groups:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenUnison自动化门户不会处理来自测试身份提供者的组。为了成为集群管理员，您必须被“引导”到环境的组中：
- en: '**$ kubectl exec -ti mariadb-0 -n mariadb -- mysql -u \**'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl exec -ti mariadb-0 -n mariadb -- mysql -u \**'
- en: '**  unison --password=''startt123'' \**'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**  unison --password=''startt123'' \**'
- en: '**  -e "insert into userGroups (userId,groupId) values (2,1);" \**'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**  -e "insert into userGroups (userId,groupId) values (2,1);" \**'
- en: '**  unison**'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**  unison**'
- en: '**$ kubectl exec -ti mariadb-0 -n mariadb -- mysql -u \**'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl exec -ti mariadb-0 -n mariadb -- mysql -u \**'
- en: '**  unison --password=''startt123'' \**'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '**  unison --password=''startt123'' \**'
- en: '**  -e "insert into userGroups (userId,groupId) values (2,2);" \  unison**'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**  -e "insert into userGroups (userId,groupId) values (2,2);" \  unison**'
- en: Finally, log back in. You will be a global administrator and a cluster administrator
    for your cluster.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，重新登录。您将成为集群的全局管理员和集群管理员。
- en: With OpenUnison deployed, you can now remotely administer your cluster. Depending
    on how you are accessing your cluster, it may be easier to use your workstation
    to directly manage your cluster for the rest of the steps in this chapter.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 部署了OpenUnison后，您现在可以远程管理您的集群。根据您访问集群的方式，可能更容易使用您的工作站直接管理本章其余步骤中的集群。
- en: You'll notice that there are different "badges" in OpenUnison now. In addition
    to getting a token or accessing the dashboard, you can request a new namespace
    to be created or access the ActiveMQ dashboard. You'll also see that the title
    bar has additional options, such as **Request Access**. OpenUnison will become
    our self-service portal for deploying our pipelines without having to manually
    create objects in our applications or cluster. We're not going to go into these
    in detail until we talk about using OpenUnison to automate the deployment of our
    pipelines.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到OpenUnison现在有不同的“徽章”。除了获取令牌或访问仪表板外，您还可以请求创建新的命名空间或访问ActiveMQ仪表板。您还会看到标题栏有额外的选项，比如**请求访问**。OpenUnison将成为我们的自助门户，用于部署我们的流水线，而无需手动在应用程序或集群中创建对象。在谈论使用OpenUnison自动部署流水线之前，我们不会详细讨论这些内容。
- en: With your cluster prepared, the next step is to deploy the components for our
    pipeline.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 准备好您的集群后，下一步是部署我们流水线的组件。
- en: Deploying GitLab
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署GitLab
- en: When building a GitOps pipeline, one of the most important components is a Git
    repository. GitLab has many components besides just Git, including a UI for navigating
    code, a web-based **integrated development environment** (**IDE**) for editing
    code, and a robust identity implementation to manage access to projects in a multi-tenant
    environment. This makes it a great solution for our platform since we can map
    our "roles" to GitLab groups.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建GitOps流水线时，最重要的组件之一是Git存储库。除了Git之外，GitLab还有许多组件，包括用于浏览代码的UI，用于编辑代码的基于Web的**集成开发环境**（**IDE**），以及用于在多租户环境中管理对项目的访问的强大身份实现。这使得它成为我们平台的一个很好的解决方案，因为我们可以将我们的“角色”映射到GitLab组。
- en: In this section, we're going to deploy GitLab into our cluster and create two
    simple repositories that we'll use later when we deploy Tekton and ArgoCD. We'll
    focus on the automation steps when we revisit OpenUnison to automate our pipeline
    deployments.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在我们的集群中部署GitLab，并创建两个简单的存储库，以便在我们重新部署Tekton和ArgoCD时使用。当我们重新访问OpenUnison以自动化我们的流水线部署时，我们将专注于自动化步骤。
- en: 'GitLab deploys with a Helm chart. For this book, we built a custom **values**
    file to run a minimal install. While GitLab comes with features that are similar
    to ArgoCD and Tekton, we won''t be using them. We also didn''t want to worry about
    high availability. Let''s begin:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: GitLab使用Helm图表部署。对于本书，我们构建了一个自定义**values**文件来运行最小的安装。虽然GitLab具有类似于ArgoCD和Tekton的功能，但我们不会使用它们。我们也不想担心高可用性。让我们开始：
- en: 'Create a new namespace called **gitlab**:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为**gitlab**的新命名空间：
- en: '**$ kubectl create ns gitlab**'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create ns gitlab**'
- en: '**namespace/gitlab created**'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间/gitlab已创建
- en: 'We need to add our certificate authority as a secret for GitLab to trust talking
    to OpenUnison and the webhooks we will eventually create for Tekton:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要将我们的证书颁发机构作为一个秘密添加到GitLab，以便GitLab信任与OpenUnison对话以及我们最终为Tekton创建的webhooks：
- en: '**$ kubectl get secret ca-key-pair \**'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl get secret ca-key-pair \**'
- en: '**  -n cert-manager -o json | jq -r ''.data["tls.crt"]'' \**'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**  -n cert-manager -o json | jq -r ''.data["tls.crt"]'' \**'
- en: '**  | base64 -d > tls.crt**'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**  | base64 -d > tls.crt**'
- en: '**$ kubectl create secret generic \**'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create secret generic \**'
- en: '**  internal-ca --from-file=. -n gitlab**'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**  internal-ca --from-file=. -n gitlab**'
- en: 'Open **chapter14/gitlab/secret/provider** in your favorite text editor. Replace
    **local.tremolo.dev** with the full domain suffix for your cluster. For instance,
    my cluster is running on **192.168.2.114**, so I''m using the **apps.192-168-2-114.nip.io**
    suffix. Here''s my updated **Secret**:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在您喜欢的文本编辑器中打开**chapter14/gitlab/secret/provider**。用您集群的完整域后缀替换**local.tremolo.dev**。例如，我的集群运行在**192.168.2.114**上，所以我使用**apps.192-168-2-114.nip.io**后缀。这是我的更新后的**Secret**：
- en: 'name: openid_connect'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：openid_connect
- en: 'label: OpenUnison'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：OpenUnison
- en: 'args:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: 'name: openid_connect'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：openid_connect
- en: 'scope:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 范围：
- en: '- openid'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '- openid'
- en: '- profile'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '- 档案'
- en: 'response_type: code'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 响应类型：代码
- en: 'issuer: **https://k8sou.apps.192-168-2-114.nip.io/auth/idp/k8sIdp**'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 发行人：**https://k8sou.apps.192-168-2-114.nip.io/auth/idp/k8sIdp**
- en: 'discovery: true'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 发现：true
- en: 'client_auth_method: query'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端认证方法：查询
- en: 'uid_field: sub'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: uid字段：sub
- en: 'send_scope_to_token_endpoint: false'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 将范围发送到令牌端点：false
- en: 'client_options:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端选项：
- en: 'identifier: gitlab'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 标识符：gitlab
- en: 'secret: secret'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密：secret
- en: 'redirect_uri: **https://gitlab.apps.192-168-2-114.nip.io/users/auth/openid_connect/callback**'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 重定向URI：**https://gitlab.apps.192-168-2-114.nip.io/users/auth/openid_connect/callback**
- en: Important Note
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We're using a client secret of **secret**. This should not be done for a production
    cluster. If you're deploying GitLab into production using our templates as a starting
    point, make sure to change this.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用**secret**作为客户端秘密。这不应该在生产集群中执行。如果您使用我们的模板作为起点将GitLab部署到生产环境，请确保更改此设置。
- en: 'Create the **secret** for GitLab to integrate with OpenUnison for SSO. We''ll
    finish the process when we revisit OpenUnison:'
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为GitLab创建与OpenUnison集成以进行SSO的**secret**。当我们重新访问OpenUnison时，我们将完成这个过程：
- en: '**$ kubectl create secret generic gitlab-oidc --from-file=. -n gitlab**'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create secret generic gitlab-oidc --from-file=. -n gitlab**'
- en: '**secret/gitlab-oidc created**'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '**secret/gitlab-oidc已创建**'
- en: Edit **chapter14/yaml/gitlab-values.yaml**. Just as in *step 3*, replace **local.tremolo.dev**
    with the full domain suffix for your cluster. For instance, my cluster is running
    on **192.168.2.114**, so I'm using the **apps.192-168-2-114.nip.io** suffix.
  id: totrans-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/gitlab-values.yaml**。就像*步骤3*中一样，用您的集群的完整域后缀替换**local.tremolo.dev**。例如，我的集群运行在**192.168.2.114**上，所以我使用**apps.192-168-2-114.nip.io**后缀。
- en: If your cluster is running on a single virtual machine, now would be a good
    time to create a snapshot. If something goes wrong during the GitLab deployment,
    it's easier to revert back to a snapshot since the Helm chart doesn't do a great
    job of cleaning up after itself on a delete.
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您的集群在单个虚拟机上运行，现在是创建快照的好时机。如果在GitLab部署过程中出现问题，可以更容易地恢复到快照，因为Helm图表在删除后没有很好地清理自己。
- en: 'Add the chart to your local repository and deploy GitLab:'
  id: totrans-273
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图表添加到您的本地存储库并部署GitLab：
- en: '**$ helm repo add gitlab https://charts.gitlab.io**'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ helm repo add gitlab https://charts.gitlab.io**'
- en: '**$ "gitlab" has been added to your repositories**'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ "gitlab"已添加到您的存储库**'
- en: '**$ helm install gitlab gitlab/gitlab -n gitlab -f chapter14/yaml/gitlab-values.yaml**'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ helm install gitlab gitlab/gitlab -n gitlab -f chapter14/yaml/gitlab-values.yaml**'
- en: '**NAME: gitlab**'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**NAME: gitlab**'
- en: '**LAST DEPLOYED: Sat Aug  8 14:50:13 2020**'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '**LAST DEPLOYED: Sat Aug  8 14:50:13 2020**'
- en: '**NAMESPACE: gitlab**'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**NAMESPACE: gitlab**'
- en: '**STATUS: deployed**'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '**STATUS: deployed**'
- en: '**REVISION: 1**'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '**REVISION: 1**'
- en: '**WARNING: Automatic TLS certificate generation with cert-manager is disabled
    and no TLS certificates were provided. Self-signed certificates were generated.**'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：已禁用使用cert-manager进行自动TLS证书生成，并且未提供TLS证书。已生成自签名证书。**'
- en: 'It will take a few minutes to run. Even once the Helm chart has been installed,
    it can take 15–20 minutes for all the Pods to finish deploying. While GitLab is
    initializing, we need to update the web frontend''s **Ingress** object to use
    a certificate signed by our certificate authority. Edit the **gitlab-webservice**
    **Ingress** object in the **gitlab** namespace. Change the **kubernetes.io/ingress.class:
    gitlab-nginx** annotation to **kubernetes.io/ingress.class: nginx**. Also, change
    **secretName** from **gitlab-wildcard-tls** to **gitlab-web-tls**:'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '运行需要一些时间。即使Helm图表已安装，所有Pod完成部署可能需要15-20分钟。在GitLab初始化时，我们需要更新web前端的**Ingress**对象以使用由我们的证书颁发机构签名的证书。编辑**gitlab**命名空间中的**gitlab-webservice**
    **Ingress**对象。将**kubernetes.io/ingress.class: gitlab-nginx**注释更改为**kubernetes.io/ingress.class:
    nginx**。还要将**secretName**从**gitlab-wildcard-tls**更改为**gitlab-web-tls**：'
- en: 'apiVersion: extensions/v1beta1'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: extensions/v1beta1'
- en: 'kind: Ingress'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：Ingress
- en: 'metadata:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'annotations:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：
- en: 'cert-manager.io/cluster-issuer: ca-issuer'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 'cert-manager.io/cluster-issuer: ca-issuer'
- en: '**kubernetes.io/ingress.class: nginx**'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**kubernetes.io/ingress.class: nginx**'
- en: 'kubernetes.io/ingress.provider: nginx'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 'kubernetes.io/ingress.provider: nginx'
- en: .
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: .
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: .
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: 'tls:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 'tls:'
- en: '- hosts:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '- 主机：'
- en: '- gitlab.apps.192-168-2-114.nip.io'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '- gitlab.apps.192-168-2-114.nip.io'
- en: '**secretName: gitlab-web-tls**'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '**secretName: gitlab-web-tls**'
- en: 'status:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 状态：
- en: 'loadBalancer: {}'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡器：{}
- en: 'We next need to update our GitLab shell to accept SSH connections on port **2222**.
    This way, we can commit code without having to worry about blocking SSH access
    to your KinD server. Edit the **gitlab-gitlab-shell** **Deployment** in the **gitlab**
    namespace. Find **containerPort: 2222** and insert **hostPort: 2222** underneath,
    making sure to maintain the spacing. Once the Pod relaunches, you''ll be able
    to SSH to your GitLab hostname on port **2222**.'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '接下来，我们需要更新我们的GitLab shell以接受端口**2222**上的SSH连接。这样，我们就可以提交代码，而不必担心阻止对KinD服务器的SSH访问。编辑**gitlab**命名空间中的**gitlab-gitlab-shell**
    **Deployment**。找到**containerPort: 2222**并在其下插入**hostPort: 2222**，确保保持间距。一旦Pod重新启动，您就可以在端口**2222**上通过SSH连接到您的GitLab主机名。'
- en: 'To get your root password to log in to GitLab, get it from the secret that
    was generated:'
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取登录GitLab的根密码，请从生成的密钥中获取：
- en: '**$ kubectl get secret gitlab-gitlab-initial-root-password -o json -n gitlab
    | jq -r ''.data.password'' | base64 -d**'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl get secret gitlab-gitlab-initial-root-password -o json -n gitlab
    | jq -r ''.data.password'' | base64 -d**'
- en: '**10xtSWXfbvH5umAbCk9NoN0wAeYsUo9jRVbXrfLn KbzBoPLrCGZ6kYRe8wdREcDl**'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**10xtSWXfbvH5umAbCk9NoN0wAeYsUo9jRVbXrfLn KbzBoPLrCGZ6kYRe8wdREcDl**'
- en: You now can log in to your GitLab instance by going to **https://gitlab.apps.x-x-x-x.nip.io**,
    where **x-x-x-x** is the IP of your server. Since my server is running on **192.168.2.114**,
    my GitLab instance is running on **https://gitlab.apps.192-168-2-114.nip.io/**.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以通过转到**https://gitlab.apps.x-x-x-x.nip.io**登录到您的GitLab实例，其中**x-x-x-x**是您服务器的IP。由于我的服务器运行在**192.168.2.114**上，我的GitLab实例运行在**https://gitlab.apps.192-168-2-114.nip.io/**上。
- en: Creating example projects
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建示例项目
- en: 'To explore Tekton and ArgoCD, we will create two projects. One will be for
    storing a simple Python web service, while the other will store the manifests
    for running the service. Let''s begin:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 为了探索Tekton和ArgoCD，我们将创建两个项目。一个用于存储简单的Python Web服务，另一个用于存储运行服务的清单。让我们开始：
- en: The top of the GitLab screen will ask you to add an SSH key. Do that now so
    that we can commit code. Since we're going to be centralizing authentication via
    SAML, GitLab won't have a password for authentication.
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GitLab屏幕顶部将要求您添加SSH密钥。现在就这样做，以便我们可以提交代码。由于我们将通过SAML集中进行身份验证，GitLab不会有用于身份验证的密码。
- en: Create a project and call it **hello-python**. Keep the visibility **private**.
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为**hello-python**的项目。保持可见性为**私有**。
- en: Clone the project using SSH. Because we're running on port **2222**, we need
    to change the URL provided by GitLab to be a proper SSH URL. For instance, my
    GitLab instance gives me the URL [git@gitlab.apps.192-168-2-114.nip.io:root/hello-python.git](mailto:git@gitlab.apps.192-168-2-114.nip.io:root/hello-python.git).
    This needs to be changed to [ssh://git@gitlab.apps.192-168-2-114.nip.io:2222/root/hello-python.git](mailto:ssh://git@gitlab.apps.192-168-2-114.nip.io:2222/root/hello-python.git).
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用SSH克隆项目。因为我们在端口**2222**上运行，所以需要更改GitLab提供的URL为正确的SSH URL。例如，我的GitLab实例给我提供的URL是[git@gitlab.apps.192-168-2-114.nip.io:root/hello-python.git](mailto:git@gitlab.apps.192-168-2-114.nip.io:root/hello-python.git)。这需要更改为[ssh://git@gitlab.apps.192-168-2-114.nip.io:2222/root/hello-python.git](mailto:ssh://git@gitlab.apps.192-168-2-114.nip.io:2222/root/hello-python.git)。
- en: 'Once cloned, copy the contents of **chapter14/python-hello** into your repository
    and push to GitLab:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆后，将**章节14/Python-你好**的内容复制到您的存储库中，并推送到GitLab：
- en: '**$ cd chapter14/python-hello**'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ cd 章节14/Python-你好**'
- en: '**$ git archive --format=tar HEAD > /path/to/hello-python/data.tar**'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ git archive --format=tar HEAD > /path/to/hello-python/data.tar**'
- en: '**$ cd /path/to/hello-python**'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ cd /path/to/hello-python**'
- en: '**$ tar -xvf data.tar**'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ tar -xvf data.tar**'
- en: '**README.md**'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '**README.md**'
- en: '**source/**'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '**source/**'
- en: '**source/Dockerfile**'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**source/Dockerfile**'
- en: '**source/helloworld.py**'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '**source/helloworld.py**'
- en: '**source/requirements.txt**'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: '**source/requirements.txt**'
- en: '**$ git add ***'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ git add ***'
- en: '**$ git commit -m ''initial commit''**'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ git commit -m ''initial commit''**'
- en: '**$ git push**'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ git push**'
- en: In GitLab, create another project called **hello-python-operations** with visibility
    set to private. Clone this project and copy the contents of **chapter14/python-hello-operations**
    into the repository, and then push it.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GitLab中，创建另一个名为**hello-python-operations**的项目，可见性设置为私有。克隆此项目，并将**章节14/Python-你好-operations**的内容复制到存储库中，然后推送它。
- en: Now that GitLab is deployed with some example code, we are able to move on to
    the next step, building an actual pipeline!
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 现在GitLab部署了一些示例代码，我们可以继续下一步，构建一个实际的流水线！
- en: Deploying Tekton
  id: totrans-325
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署Tekton
- en: Tekton is the pipeline system we're using for our platform. Originally part
    of the Knative project for building function-as-a-service on Kubernetes, Tekton
    was broken out into its own project. The biggest difference between Tekton and
    other pipeline technologies you may have run is that Tekton is Kubernetes-native.
    Everything from its execution system, definition, and webhooks for automation
    are able to run on just about any Kubernetes distribution you can find. For example,
    we'll be running it in KinD and Red Hat has moved to Tekton as the main pipeline
    technology used for OpenShift starting in 4.1\.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: Tekton是我们平台使用的流水线系统。最初是Knative项目的一部分，用于在Kubernetes上构建函数即服务，后来Tekton被拆分为自己的项目。Tekton与您可能运行的其他流水线技术之间最大的区别在于，Tekton是Kubernetes本地的。从其执行系统、定义和用于自动化的webhooks，都可以在几乎任何您能找到的Kubernetes发行版上运行。例如，我们将在KinD中运行它，而Red
    Hat已经开始在OpenShift 4.1中将Tekton作为主要的流水线技术。
- en: 'The process of deploying Tekton is pretty straightforward. Tekton is a series
    of operators that look for the creation of custom resources that define a build
    pipeline. The deployment itself only takes a couple of **kubectl** commands:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 部署Tekton的过程非常简单。Tekton是一系列操作员，用于查找定义构建流水线的自定义资源的创建。部署本身只需要几个**kubectl**命令：
- en: $ kubectl apply --filename \  https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl apply --filename \  https://storage.googleapis.com/tekton-releases/pipeline/latest/release.yaml
- en: $ kubectl apply --filename \ https://storage.googleapis.com/tekton-releases/triggers/latest/release.yaml
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: $ kubectl apply --filename \ https://storage.googleapis.com/tekton-releases/triggers/latest/release.yaml
- en: The first command deploys the base system needed to run Tekton pipelines. The
    second command deploys the components needed to build webhooks so that pipelines
    can be launched as soon as code is pushed. Once both commands are done and the
    Pods in the **tekton-pipelines** namespace are running, you're ready to start
    building a pipeline! We'll use our Python Hello World web service as an example.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 第一条命令部署了运行Tekton流水线所需的基本系统。第二条命令部署了构建webhooks所需的组件，以便在代码推送后立即启动流水线。一旦两条命令都完成并且**tekton-pipelines**命名空间中的Pod正在运行，您就可以开始构建流水线了！我们将以Python
    Hello World web服务作为示例。
- en: Building Hello World
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建Hello World
- en: 'Our Hello World application is really straightforward. It''s a simple service
    that echoes back the obligatory "hello" and the host the service is running on
    just so we feel like our service is doing something interesting. Since the service
    is written in Python, we don''t need to "build" a binary, but we do want to build
    a container. Once the container is built, we want to update the Git repository
    for our running namespace and let our GitOps system reconcile the change to redeploy
    our application. The steps for our build will be as follows:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的Hello World应用非常简单。这是一个简单的服务，回显必要的“hello”和运行服务的主机，以便我们觉得我们的服务正在做一些有趣的事情。由于服务是用Python编写的，我们不需要“构建”二进制文件，但我们确实想要构建一个容器。构建容器后，我们希望更新我们运行命名空间的Git存储库，并让我们的GitOps系统协调更改以重新部署我们的应用程序。我们的构建步骤如下：
- en: Check out our latest code.
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检出我们的最新代码。
- en: Create a tag based on a timestamp.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于时间戳创建一个标签。
- en: Build our image.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建我们的镜像。
- en: Push to our registry.
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推送到我们的注册表。
- en: Patch a Deployment YAML file in the **operations** namespace.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**operations**命名空间中修补一个部署的YAML文件。
- en: 'We''ll build our pipeline one object at a time. The first set of tasks is to
    create an SSH key that Tekton will use to pull our source code:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将逐个构建我们的流水线对象。第一组任务是创建一个SSH密钥，Tekton将使用它来拉取我们的源代码：
- en: 'Create an SSH key pair that we''ll use for our pipeline to check out our code.
    When prompted for a passphrase, just hit *Enter* to skip adding a passphrase:'
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个SSH密钥对，我们将在流水线中使用它来检出我们的代码。在提示输入密码时，只需按*Enter*跳过添加密码：
- en: '**$ ssh-keygen -f ./gitlab-hello-python**'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ ssh-keygen -f ./gitlab-hello-python**'
- en: Log in to GitLab and navigate to the **hello-python** project we created. Click
    on **Settings** | **Repository** | **Deploy Keys**, and click **Expand**. Use
    **tekton** as the title and paste the contents of the **github-hello-python.pub**
    file you just created into the **Key** section. Keep **Write access allowed**
    *unchecked* and click **Add Key**.
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到GitLab并导航到我们创建的**hello-python**项目。 点击**设置** | **存储库** | **部署密钥**，然后点击**展开**。
    使用**tekton**作为标题，并将刚刚创建的**github-hello-python.pub**文件的内容粘贴到**密钥**部分。 保持**不允许写访问**
    *未选中*，然后点击**添加密钥**。
- en: 'Next, create the **python-hello-build** namespace and the following secret.
    Replace the **ssh-privatekey** attribute with the Base64-encoded content of the
    **gitlab-hello-python** file we created in *step 1*. The annotation is what tells
    Tekton which server to use this key with. The server name is the **Service** in
    the GitLab namespace:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建**python-hello-build**命名空间和以下秘密。 用我们在*步骤1*中创建的**gitlab-hello-python**文件的Base64编码内容替换**ssh-privatekey**属性。
    注释是告诉Tekton要使用此密钥的服务器。 服务器名称是GitLab命名空间中的**Service**：
- en: 'apiVersion: v1'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：v1
- en: 'data:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'ssh-privatekey: ...'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ssh-privatekey：...
- en: 'kind: Secret'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：秘密
- en: 'metadata:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'annotations:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：
- en: 'tekton.dev/git-0: gitlab-gitlab-shell.gitlab.svc.cluster.local'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: tekton.dev/git-0：gitlab-gitlab-shell.gitlab.svc.cluster.local
- en: 'name: git-pull'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：git-pull
- en: 'namespace: python-hello-build'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：python-hello-build
- en: 'type: kubernetes.io/ssh-auth'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：kubernetes.io/ssh-auth
- en: 'Create an SSH key pair that we''ll use for our pipeline to push to the **operations**
    repository. When prompted for a passphrase, just hit *Enter* to skip adding a
    passphrase:'
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个我们将用于我们的管道推送到**operations**存储库的SSH密钥对。 在提示输入密码时，只需按*Enter*跳过添加密码：
- en: '**$ ssh-keygen -f ./gitlab-hello-python-operations**'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ ssh-keygen -f ./gitlab-hello-python-operations**'
- en: Log in to GitLab and navigate to the **hello-python-operations** project we
    created. Click on **Settings** | **Repository** | **Deploy Keys**, and click **Expand**.
    Use **tekton** as the title and paste the contents of the **github-hello-python-operations.pub**
    file you just created into the **Key** section. Make sure **Write access allowed**
    is *checked* and click **Add Key**.
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到GitLab并导航到我们创建的**hello-python-operations**项目。 点击**设置** | **存储库** | **部署密钥**，然后点击**展开**。
    使用**tekton**作为标题，并将刚刚创建的**github-hello-python-operations.pub**文件的内容粘贴到**密钥**部分。
    确保**允许写访问**已*选中*，然后点击**添加密钥**。
- en: 'Next, create the following secret. Replace the **ssh-privatekey** attribute
    with the Base64-encoded content of the **gitlab-hello-python-operations** file
    we created in *step 4*. The annotation is what tells Tekton which server to use
    this key with. The server name is the **Service** we created in *step 6* in the
    GitLab namespace:'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建以下秘密。 用我们在*步骤4*中创建的**gitlab-hello-python-operations**文件的Base64编码内容替换**ssh-privatekey**属性。
    注释是告诉Tekton要使用此密钥的服务器。 服务器名称是我们在GitLab命名空间中*步骤6*中创建的**Service**：
- en: 'apiVersion: v1'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：v1
- en: 'data:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'ssh-privatekey: ...'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: ssh-privatekey：...
- en: 'kind: Secret'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：秘密
- en: 'metadata:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: git-write'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：git-write
- en: 'namespace: python-hello-build'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：python-hello-build
- en: 'type: kubernetes.io/ssh-auth'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 类型：kubernetes.io/ssh-auth
- en: 'Create a service account for tasks to run, as with our secret:'
  id: totrans-365
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为任务运行创建一个服务帐户，就像我们的秘密一样：
- en: '**$ kubectl create -f chapter14/tekton-serviceaccount.yaml**'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create -f chapter14/tekton-serviceaccount.yaml**'
- en: 'We need a container that contains both **git** and **kubectl** in it. We''ll
    build **chapter14/docker/PatchRepoDockerfile** and push it to our internal registry.
    Make sure to replace **192-168-2-114** with the hostname for your server''s IP
    address:'
  id: totrans-367
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要一个包含**git**和**kubectl**的容器。 我们将构建**chapter14/docker/PatchRepoDockerfile**并将其推送到我们的内部注册表。
    确保用您服务器的IP地址的主机名替换**192-168-2-114**：
- en: '**$ docker build -f ./PatchRepoDockerfile -t \**'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ docker build -f ./PatchRepoDockerfile -t \**'
- en: '**  docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit .**'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '**  docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit .**'
- en: '**$ docker push \**'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ docker push \**'
- en: '**  docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit**'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '**  docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit**'
- en: Every **Task** object can take inputs and produce results that can be shared
    with other **Task** objects. Tekton can provide runs (whether it's **TaskRun**
    or **PipelineRun**) with a workspace where the state can be stored and retrieved
    from. Writing to workspaces allows us to share data between **Task** objects.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 每个**Task**对象都可以接受输入并生成可以与其他**Task**对象共享的结果。Tekton可以为运行（无论是**TaskRun**还是**PipelineRun**）提供一个工作区，其中可以存储和检索状态。写入工作区允许我们在**Task**对象之间共享数据。
- en: 'Before deploying our task and pipeline, let''s step through the work done by
    each task. The first task generates an image tag and gets the SHA hash of the
    latest commit. The full source is in **chapter14/yaml/tekton-task1.yaml**:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署任务和流水线之前，让我们逐个步骤地了解每个任务所做的工作。第一个任务生成图像标记并获取最新提交的SHA哈希。完整的源代码在**chapter14/yaml/tekton-task1.yaml**中：
- en: '- name: create-image-tag'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '- name: create-image-tag'
- en: 'image: docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 'image: docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit'
- en: 'script: |-'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本：|-
- en: '#!/usr/bin/env bash'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '#!/usr/bin/env bash'
- en: export IMAGE_TAG=$(date +"%m%d%Y%H%M%S")
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 导出IMAGE_TAG=$(date +"%m%d%Y%H%M%S")
- en: echo -n "$(resources.outputs.result-image.url):$IMAGE_TAG" > /tekton/results/image-url
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: echo -n "$(resources.outputs.result-image.url):$IMAGE_TAG" > /tekton/results/image-url
- en: echo "'$(cat /tekton/results/image-url)'"
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: echo "'$(cat /tekton/results/image-url)'"
- en: cd $(resources.inputs.git-resource.path)
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: cd $(resources.inputs.git-resource.path)
- en: RESULT_SHA="$(git rev-parse HEAD | tr -d '\n')"
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: RESULT_SHA="$(git rev-parse HEAD | tr -d '\n')"
- en: 'echo "Last commit : $RESULT_SHA"'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: echo "最后提交：$RESULT_SHA"
- en: echo -n "$RESULT_SHA" > /tekton/results/commit-tag
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: echo -n "$RESULT_SHA" > /tekton/results/commit-tag
- en: Each step in a task is a container. In this case, we're using the container
    we built previously that has **kubectl** and **git** in it. We don't need **kubectl**
    for this task but we do need **git**. The first block of code generates an image
    name from the **result-image** URL and a timestamp. We could use the latest commit,
    but I like having a timestamp so that I can quickly tell how old a container is.
    We save the full image URL to **/text/results/image-url**, which corresponds to
    a result we defined in our task called **image-url**. This can be referenced by
    our pipeline or other tasks by referencing **$(tasks.generate-image-tag.results.image-url)**,
    where **generate-image-tag** is the name of our **Task**, and **image-url** is
    the name of our result.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 任务中的每个步骤都是一个容器。在这种情况下，我们使用了之前构建的容器，其中包含**kubectl**和**git**。我们不需要**kubectl**来执行此任务，但我们需要**git**。代码的第一个块从**result-image**
    URL和时间戳生成图像名称。我们可以使用最新的提交，但我喜欢使用时间戳，这样我就可以快速了解容器的年龄。我们将完整的图像URL保存到**/text/results/image-url**，这对应于我们在任务中定义的一个结果，名为**image-url**。这可以通过我们的流水线或其他任务引用，引用为**$(tasks.generate-image-tag.results.image-url)**，其中**generate-image-tag**是我们**Task**的名称，**image-url**是我们结果的名称。
- en: 'Our next task, in **chapter14/yaml/tekton-task2.yaml**, generates a container
    from our application''s source using Google''s Kaniko project ([https://github.com/GoogleContainerTools/kaniko](https://github.com/GoogleContainerTools/kaniko)).
    Kaniko lets you generate a container without needing access to a Docker daemon.
    This is great because you don''t need a privileged container to build your image:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一个任务，在**chapter14/yaml/tekton-task2.yaml**中，使用Google的Kaniko项目（[https://github.com/GoogleContainerTools/kaniko](https://github.com/GoogleContainerTools/kaniko)）从我们应用程序的源代码生成一个容器。Kaniko允许您生成一个容器，而无需访问Docker守护程序。这很棒，因为您不需要特权容器来构建您的镜像：
- en: 'steps:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 'steps:'
- en: '- args:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '- args:'
- en: '- --dockerfile=$(params.pathToDockerFile)'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '- --dockerfile=$(params.pathToDockerFile)'
- en: '- --destination=$(params.imageURL)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: '- --destination=$(params.imageURL)'
- en: '- --context=$(params.pathToContext)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '- --context=$(params.pathToContext)'
- en: '- --verbosity=debug'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '- --verbosity=debug'
- en: '- --skip-tls-verify'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '- --skip-tls-verify'
- en: 'command:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 命令：
- en: '- /kaniko/executor'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '- /kaniko/executor'
- en: 'env:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 环境：
- en: '- name: DOCKER_CONFIG'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：DOCKER_CONFIG'
- en: 'value: /tekton/home/.docker/'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 值：/tekton/home/.docker/
- en: 'image: gcr.io/kaniko-project/executor:v0.16.0'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 镜像：gcr.io/kaniko-project/executor:v0.16.0
- en: 'name: build-and-push'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：build-and-push
- en: 'resources: {}'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 资源：{}
- en: The Kaniko container is what's called a "distro-less" container. It's not built
    with an underlying shell, nor does it have many of the command-line tools you
    may be used to. It's just a single binary. This means that any variable manipulation,
    such as generating a tag for the image, needs to be done before this step. Notice
    that the image being created doesn't reference the result we created in the first
    task. It instead references a parameter called **imageURL**. While we could have
    referenced the result directly, it would make it harder to test this task because
    it is now tightly bound to the first task. By using a parameter that is set by
    our pipeline, we can test this task on its own. Once run, this task will generate
    and push our container.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: Kaniko 容器是所谓的“无发行版”容器。它没有构建在底层 shell 上，也没有许多您可能习惯的命令行工具。它只是一个单一的二进制文件。这意味着任何变量操作，比如为镜像生成标签，都需要在此步骤之前完成。请注意，正在创建的镜像并不引用我们在第一个任务中创建的结果。它代替引用了一个名为**imageURL**的参数。虽然我们可以直接引用结果，但这样做会使得测试这个任务变得更加困难，因为它现在与第一个任务紧密绑定。通过使用由我们的流水线设置的参数，我们可以单独测试这个任务。运行一次后，这个任务将生成并推送我们的容器。
- en: 'Our last task, in **chapter14/yaml/tekton-task-3.yaml**, does the work to trigger
    ArgoCD to roll out a new container:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在**chapter14/yaml/tekton-task-3.yaml**中的最后一个任务是触发 ArgoCD 来部署新的容器：
- en: '- image: docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: '- 镜像：docker.apps.192-168-2-114.nip.io/gitcommit/gitcommit'
- en: 'name: patch-and-push'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：patch-and-push
- en: 'resources: {}'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 资源：{}
- en: 'script: |-'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本：|-
- en: '#!/bin/bash'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: '#!/bin/bash'
- en: export GIT_URL="$(params.gitURL)"
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: export GIT_URL="$(params.gitURL)"
- en: export GIT_HOST=$(sed 's/.*[@]\(.*\)[:].*/\1/' <<< "$GIT_URL")
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: export GIT_HOST=$(sed 's/.*[@]\(.*\)[:].*/\1/' <<< "$GIT_URL")
- en: mkdir /usr/local/gituser/.ssh
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: mkdir /usr/local/gituser/.ssh
- en: cp /pushsecret/ssh-privatekey /usr/local/gituser/.ssh/id_rsa
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: cp /pushsecret/ssh-privatekey /usr/local/gituser/.ssh/id_rsa
- en: chmod go-rwx /usr/local/gituser/.ssh/id_rsa
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: chmod go-rwx /usr/local/gituser/.ssh/id_rsa
- en: ssh-keyscan -H $GIT_HOST > /usr/local/gituser/.ssh/known_hosts
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ssh-keyscan -H $GIT_HOST > /usr/local/gituser/.ssh/known_hosts
- en: cd $(workspaces.output.path)
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: cd $(workspaces.output.path)
- en: git clone $(params.gitURL) .
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: git clone $(params.gitURL) .
- en: kubectl patch --local -f src/deployments/hello-python.yaml -p '{"spec":{"template":{"spec":{"containers":[{"name":"python-hello","image":"$(params.imageURL)"}]}}}}'
    -o yaml > /tmp/hello-python.yaml
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl patch --local -f src/deployments/hello-python.yaml -p '{"spec":{"template":{"spec":{"containers":[{"name":"python-hello","image":"$(params.imageURL)"}]}}}}'
    -o yaml > /tmp/hello-python.yaml
- en: cp /tmp/hello-python.yaml src/deployments/hello-python.yaml
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: cp /tmp/hello-python.yaml src/deployments/hello-python.yaml
- en: git add src/deployments/hello-python.yaml
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: git add src/deployments/hello-python.yaml
- en: git commit -m 'commit $(params.sourceGitHash)'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: git commit -m 'commit $(params.sourceGitHash)'
- en: git push
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: git push
- en: The first block of code copies the SSH keys into our home directory, generates
    **known_hosts**, and clones our repository into a workspace we defined in the
    **Task**. We don't rely on Tekton to pull the code from our **operations** repository
    because Tekton assumes we won't be pushing code, so it disconnects the source
    code from our repository. If we try to run a commit, it will fail. Since the step
    is a container, we don't want to try to write to it, so we create a workspace
    with **emptyDir**, just like **emptyDir** in a **Pod** we might run. We could
    also define workspaces based on persistent volumes. This could come in handy to
    speed up builds where dependencies get downloaded.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 第一段代码将SSH密钥复制到我们的主目录中，生成**known_hosts**，并将我们的存储库克隆到我们在**Task**中定义的工作空间中。我们不依赖Tekton从我们的**operations**存储库中拉取代码，因为Tekton假设我们不会推送代码，所以它会断开源代码与我们的存储库的连接。如果我们尝试运行提交，它将失败。由于这一步是一个容器，我们不希望尝试向其写入，因此我们创建了一个带有**emptyDir**的工作空间，就像我们可能运行的**Pod**中的**emptyDir**一样。我们还可以基于持久卷定义工作空间。这对于加快下载依赖项的构建可能会有所帮助。
- en: We're copying the SSH key from **/pushsecret**, which is defined as a volume
    on the task. Our container runs as user **431**, but the SSH keys are mounted
    as root by Tekton. We don't want to run a privileged container just to copy the
    keys from a **Secret**, so instead, we mount it as if it were just a regular **Pod**.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在从**/pushsecret**复制SSH密钥，该密钥在任务的卷中定义。我们的容器以用户**431**身份运行，但SSH密钥由Tekton作为root挂载。我们不想运行特权容器来复制来自**Secret**的密钥，因此我们将其挂载为一个普通的**Pod**。
- en: Once we have our repository cloned, we patch our deployment with the latest
    image and finally, commit the change using the hash of the source commit in our
    application repository. Now we can track an image back to the commit that generated
    it! Just as with our second task, we don't reference the results of tasks directly
    to make it easier to test.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们克隆了我们的存储库，我们就会使用最新的镜像对部署进行修补，最后，使用我们应用程序存储库中源提交的哈希进行提交更改。现在我们可以追踪图像到生成它的提交！与我们的第二个任务一样，我们不直接引用任务的结果，以便更容易进行测试。
- en: 'We pull these tasks together in a pipeline – specifically, **chapter14/yaml/tekton-pipeline.yaml**.
    This YAML file is several pages long, but the key piece defines our tasks and
    links them together. You should never hardcode values into your pipeline. Take
    a look at our third task''s definition in the pipeline:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将这些任务汇总到一个流水线中-具体来说，**chapter14/yaml/tekton-pipeline.yaml**。这个YAML文件有好几页长，但关键部分定义了我们的任务并将它们链接在一起。您不应该在流水线中硬编码值。看一下我们流水线中第三个任务的定义：
- en: '- name: update-operations-git'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：更新操作-git'
- en: 'taskRef:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 任务引用：
- en: 'name: patch-deployment'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：patch-deployment
- en: 'params:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '- name: imageURL'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：imageURL'
- en: 'value: $(tasks.generate-image-tag.results.image-url)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 值：$(tasks.generate-image-tag.results.image-url)
- en: '- name: gitURL'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：gitURL'
- en: 'value: $(params.gitPushUrl)'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 值：$(params.gitPushUrl)
- en: '- name: sourceGitHash'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：sourceGitHash'
- en: 'value: $(tasks.generate-image-tag.results.commit-tag)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 值：$(tasks.generate-image-tag.results.commit-tag)
- en: 'workspaces:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 工作空间：
- en: '- name: output'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：输出'
- en: 'workspace: output'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 工作空间：输出
- en: 'We reference parameters and task results, but nothing is hardcoded. This makes
    our **Pipeline** reusable. We also include the **runAfter** directive in our second
    and third task to make sure that our tasks are run in order. Otherwise, tasks
    will be run in parallel. Given each task has dependencies on the task before it,
    we don''t want to run them at the same time. Next, let''s deploy our pipeline
    and run it:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引用参数和任务结果，但没有硬编码。这使得我们的**Pipeline**可重用。我们还在第二和第三个任务中包含了**runAfter**指令，以确保我们的任务按顺序运行。否则，任务将并行运行。鉴于每个任务都依赖于其前面的任务，我们不希望它们同时运行。接下来，让我们部署我们的流水线并运行它：
- en: Add the **chapter14/yaml/tekton-source-git.yaml** file to your cluster; this
    tells Tekton where to pull your application code from.
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**chapter14/yaml/tekton-source-git.yaml**文件添加到您的集群中； 这告诉Tekton从何处拉取您的应用程序代码。
- en: Edit **chapter14/yaml/tekton-image-result.yaml**, replacing **192-168-2-114**
    with the hash representation of your server's IP address, and add it to your cluster.
  id: totrans-441
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/tekton-image-result.yaml**，将**192-168-2-114**替换为服务器IP地址的哈希表示，并将其添加到您的集群中。
- en: Edit **chapter14/yaml/tekton-task1.yaml**, replacing the image host with the
    host for your Docker registry, and add the file to your cluster.
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/tekton-task1.yaml**，将图像主机替换为您的Docker注册表的主机，并将文件添加到您的集群中。
- en: Add **chapter14/yaml/tekton-task2.yaml** to your cluster.
  id: totrans-443
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**chapter14/yaml/tekton-task2.yaml**添加到您的集群。
- en: Edit **chapter14/yaml/tekton-task3.yaml**, replacing the image host with the
    host for your Docker registry, and add the file to your cluster.
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/tekton-task3.yaml**，将图像主机替换为您的Docker注册表的主机，并将文件添加到您的集群中。
- en: Add **chapter14/yaml/tekton-pipeline.yaml** to your cluster.
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**chapter14/yaml/tekton-pipeline.yaml**添加到您的集群。
- en: Add **chapter14/yaml/tekton-pipeline-run.yaml** to your cluster.
  id: totrans-446
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**chapter14/yaml/tekton-pipeline-run.yaml**添加到您的集群。
- en: You can check on the progress of your pipeline using **kubectl**, or you can
    use Tekton's CLI tool called **tkn** ([https://github.com/tektoncd/cli](https://github.com/tektoncd/cli)).
    Running **tkn pipelinerun describe build-hello-pipeline-run -n python-hello-build**
    will list out the progress of your build. You can rerun the build by recreating
    your **run** object, but that's not very efficient. Besides, what we really want
    is for our pipeline to run on a commit!
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用**kubectl**检查管道的进展，或者您可以使用Tekton的CLI工具**tkn**（[https://github.com/tektoncd/cli](https://github.com/tektoncd/cli)）。
    运行**tkn pipelinerun describe build-hello-pipeline-run -n python-hello-build**将列出构建的进度。
    您可以通过重新创建您的**run**对象来重新运行构建，但这并不是非常有效。 此外，我们真正想要的是我们的管道在提交时运行！
- en: Building automatically
  id: totrans-448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动构建
- en: 'We don''t want to manually run builds. We want builds to be automated. Tekton
    provides the trigger project to provide webhooks so whenever GitLab receives a
    commit, it can tell Tekton to build a **PipelineRun** object for us. Setting up
    a trigger involves creating a Pod, with its own service account that can create
    **PipelineRun** objects, a Service for that Pod, and an **Ingress** object to
    host HTTPS access to the Pod. You also want to protect the webhook with a secret
    so that it isn''t triggered inadvertently. Let''s deploy these objects to our
    cluster:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想手动运行构建。 我们希望构建自动化。 Tekton提供了触发器项目来提供webhooks，因此每当GitLab收到提交时，它可以告诉Tekton为我们构建一个**PipelineRun**对象。
    设置触发器涉及创建一个Pod，它有自己的服务帐户，可以创建**PipelineRun**对象，一个用于该Pod的服务，以及一个**Ingress**对象来托管对Pod的HTTPS访问。
    您还希望使用秘密保护webhook，以免意外触发。 让我们将这些对象部署到我们的集群中：
- en: Add **chapter14/yaml/tekton-webhook-cr.yaml** to your cluster. This **ClusterRole**
    will be used by any namespace that wants to provision webhooks for builds.
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**chapter14/yaml/tekton-webhook-cr.yaml**添加到您的集群。 此**ClusterRole**将被任何想要为构建提供webhook的命名空间使用。
- en: 'Edit **chapter14/yaml/tekton-webhook.yaml**. At the bottom of the file is an
    **Ingress** object. Change **192-168-2-114** to represent the IP of your cluster,
    with dashes instead of dots. Then, add the file to your cluster:'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/tekton-webhook.yaml**。 文件底部是一个**Ingress**对象。 将**192-168-2-114**更改为代表您集群的IP，用破折号代替点。
    然后，将文件添加到您的集群中：
- en: 'apiVersion: extensions/v1beta1'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：extensions/v1beta1
- en: 'kind: Ingress'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: kind：Ingress
- en: 'metadata:'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: gitlab-webhook'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：gitlab-webhook
- en: 'namespace: python-hello-build'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: namespace：python-hello-build
- en: 'annotations:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 注释：
- en: 'cert-manager.io/cluster-issuer: ca-issuer'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: cert-manager.io/cluster-issuer：ca-issuer
- en: 'spec:'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 规格：
- en: 'rules:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 规则：
- en: '- host: "python-hello-application.build.**192-168-2-114**.nip.io"'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: '- 主机："python-hello-application.build.**192-168-2-114**.nip.io"'
- en: 'http:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: http：
- en: 'paths:'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: paths：
- en: '- backend:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '- 后端：'
- en: 'serviceName: el-gitlab-listener'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: serviceName：el-gitlab-listener
- en: 'servicePort: 8080'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 'servicePort: 8080'
- en: 'pathType: ImplementationSpecific'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 'pathType: ImplementationSpecific'
- en: 'tls:'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 'tls:'
- en: '- hosts:'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: '- hosts:'
- en: '- "python-hello-application.build.**192-168-2-114**.nip.io"'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: '- "python-hello-application.build.**192-168-2-114**.nip.io"'
- en: 'secretName: ingresssecret'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 'secretName: ingresssecret'
- en: Log in to GitLab. Go to the **Admin Area** | **Network**. Click on **Expand**
    next to **Outbound Requests**. Check **Allow requests to the local network from
    web hooks and services** and click **Save changes**.
  id: totrans-472
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录GitLab。转到**管理区域** | **网络**。单击**出站请求**旁边的**展开**。勾选**允许来自Web钩子和服务的本地网络请求**，然后单击**保存更改**。
- en: Go to the **hello-python** project we created and click on **Settings** | **Webhooks**.
    For the URL, use your **Ingress** host with HTTPS – for instance, **https://python-hello-application.build.192-168-2-114.nip.io/**.
    For **Secret Token**, use **notagoodsecret**, and for **Push events**, set the
    branch name to **master**. Finally, click on **Add webhook**.
  id: totrans-473
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到我们创建的**hello-python**项目，单击**设置** | **Webhooks**。对于URL，请使用您的**Ingress**主机和HTTPS
    - 例如，**https://python-hello-application.build.192-168-2-114.nip.io/**。对于**Secret
    Token**，使用**notagoodsecret**，对于**Push events**，将分支名称设置为**master**。最后，单击**添加Webhook**。
- en: Once added, click on **Test**, choosing **Push Events**. If everything is configured
    correctly, a new **PipelineRun** object should have been created. You can run
    **tkn pipelinerun list -n python-hello-build** to see the list of runs; there
    should be a new one running. After a few minutes, you'll have a new container
    and a patched Deployment in the **python-hello-operations** project!
  id: totrans-474
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加后，单击**测试**，选择**推送事件**。如果一切配置正确，应该已创建一个新的**PipelineRun**对象。您可以运行**tkn pipelinerun
    list -n python-hello-build**来查看运行列表；应该有一个新的正在运行。几分钟后，您将在**python-hello-operations**项目中获得一个新的容器和一个已修补的部署！
- en: We covered quite a bit in this section to build our application and deploy it
    using GitOps. The good news is that everything is automated; a push will create
    a new instance of our application! The bad news is that we had to create over
    a dozen Kubernetes objects and manually make updates to our projects in GitLab.
    In the last section, we'll automate this process. First, let's deploy ArgoCD so
    that we can get our application running!
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们涵盖了相当多的内容，以构建我们的应用程序并使用GitOps进行部署。好消息是一切都是自动化的；推送将创建我们应用程序的新实例！坏消息是我们不得不创建超过十几个Kubernetes对象，并手动更新我们在GitLab中的项目。在最后一节中，我们将自动化这个过程。首先，让我们部署ArgoCD，以便我们可以运行我们的应用程序！
- en: Deploying ArgoCD
  id: totrans-476
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署ArgoCD
- en: 'So far, we have a way to get into our cluster, a way to store code, and a system
    for building our code and generating images. The last component of our platform
    is our GitOps controller. This is the piece that lets us commit manifests to our
    Git repository and make changes to our cluster. ArgoCD is a collaboration between
    Intuit and Weaveworks. It provides a great UI and is driven by a combination of
    custom resources and Kubernetes-native **ConfigMap** and **Secret** objects. It
    has a CLI tool, and both the web and CLI tools are integrated with OpenID Connect,
    so it will be easy to add SSO with our OpenUnison. Let''s deploy ArgoCD and use
    it to launch our **hello-python** web service:'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们有一种进入我们集群的方法，一种存储代码的方法，以及一个用于构建我们的代码和生成镜像的系统。我们平台的最后一个组件是我们的GitOps控制器。这是让我们将清单提交到我们的Git存储库并对我们的集群进行更改的部分。ArgoCD是Intuit和Weaveworks之间的合作。它提供了一个很好的UI，并由自定义资源和Kubernetes本机**ConfigMap**和**Secret**对象的组合驱动。它有一个CLI工具，Web和CLI工具都与OpenID
    Connect集成，因此很容易使用我们的OpenUnison添加SSO。让我们部署ArgoCD并使用它来启动我们的**hello-python**网络服务：
- en: 'Deploy using the standard YAML from [https://argoproj.github.io/argo-cd/getting_started/](https://argoproj.github.io/argo-cd/getting_started/):'
  id: totrans-478
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用标准的YAML部署[https://argoproj.github.io/argo-cd/getting_started/](https://argoproj.github.io/argo-cd/getting_started/)：
- en: '**$ kubectl create namespace argocd**'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl create namespace argocd**'
- en: '**$ kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml**'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml**'
- en: Create the **Ingress** object for ArgoCD by editing **chapter14/yaml/argocd-ingress.yaml**.
    Replace all instances of **192-168-2-140** with your IP address, replacing the
    dots with dashes. My server's IP is **192.168.2.114**, so I'm using **192-168-2-114**.
    Once done, add the file to your cluster.
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过编辑 **chapter14/yaml/argocd-ingress.yaml** 为 ArgoCD 创建 **Ingress** 对象。用你的IP地址替换所有的
    **192-168-2-140**，用破折号替换点。我的服务器IP是 **192.168.2.114**，所以我使用 **192-168-2-114**。完成后，将文件添加到你的集群中。
- en: Get the root password by running **kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server
    -o name | cut -d'/' -f 2**. Save this password.
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 **kubectl get pods -n argocd -l app.kubernetes.io/name=argocd-server -o
    name | cut -d'/' -f 2** 获取根密码。保存这个密码。
- en: 'Edit the **argocd-server** **Deployment** in the **argocd** namespace. Add
    **--insecure** to the command:'
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑 **argocd** 命名空间中的 **argocd-server** **Deployment**。在命令中添加 **--insecure**：
- en: 'spec:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'containers:'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 容器：
- en: '- command:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '- command:'
- en: '- argocd-server'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: '- argocd-server'
- en: '- --staticassets'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: '- --staticassets'
- en: '- /shared/app'
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
  zh: '- /shared/app'
- en: '**- --repo-server**'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: '**- --repo-server**'
- en: '**        - argocd-repo-server:8081**'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: '**        - argocd-repo-server:8081**'
- en: '**        - --insecure**'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: '**        - --insecure**'
- en: You can now log in to ArgoCD by going to the **Ingress** host you defined in
    *step 2*. You will need to download the ArgoCD CLI utility as well from https://github.com/argoproj/argo-cd/releases/latest.
    Once downloaded, log in by running **./argocd login grpc-argocd.apps.192-168-2-114.nip.io**,
    replacing **192-168-2-114** with the IP of your server, with dashes instead of
    dots.
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你可以通过访问你在*步骤2*中定义的 **Ingress** 主机来登录到 ArgoCD。你还需要从 https://github.com/argoproj/argo-cd/releases/latest
    下载 ArgoCD CLI 实用程序。下载完成后，运行 **./argocd login grpc-argocd.apps.192-168-2-114.nip.io**
    来登录，用你服务器的IP代替 **192-168-2-114**，用破折号代替点。
- en: Create the **python-hello** namespace.
  id: totrans-494
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 **python-hello** 命名空间。
- en: 'Before we can add our GitLab repository, we need to tell ArgoCD to trust our
    GitLab instance''s SSH host. Since we will have ArgoCD talk directly to the GitLab
    shell service, we''ll need to generate **known_host** for that Service. To make
    this easier, we included a script that will run **known_host** from outside the
    cluster but rewrite the content as if it were from inside the cluster. Run the
    **chapter14/shell/getSshKnownHosts.sh** script and pipe the output into the **argocd**
    command to import **known_host**. Remember to change the hostname to reflect your
    own cluster''s IP address:'
  id: totrans-495
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在我们添加GitLab仓库之前，我们需要告诉ArgoCD信任我们的GitLab实例的SSH主机。因为我们将让ArgoCD直接与GitLab shell服务通信，我们需要为该服务生成
    **known_host**。为了更容易做到这一点，我们包含了一个脚本，该脚本将从集群外部运行 **known_host**，但重写内容，就好像它是从集群内部运行的一样。运行
    **chapter14/shell/getSshKnownHosts.sh** 脚本，并将输出导入 **known_host** 的 **argocd**
    命令中。记得将主机名更改为反映你自己集群的IP地址：
- en: '**$ ./chapter14/shell/getSshKnownHosts.sh gitlab.apps.192-168-2-114.nip.io
    | argocd cert add-ssh --batch**'
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ ./chapter14/shell/getSshKnownHosts.sh gitlab.apps.192-168-2-114.nip.io
    | argocd cert add-ssh --batch**'
- en: '**Enter SSH known hosts entries, one per line. Press CTRL-D when finished.**'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入SSH已知主机条目，每行一个。完成后按CTRL-D。**'
- en: '**Successfully created 3 SSH known host entries**'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '**成功创建了3个SSH已知主机条目**'
- en: 'Next, we need to generate an SSH key to access the **python-hello-operations**
    repository:'
  id: totrans-499
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要生成一个SSH密钥来访问 **python-hello-operations** 仓库：
- en: '**$ ssh-keygen -f ./argocd-python-hello**'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ ssh-keygen -f ./argocd-python-hello**'
- en: 'Add the public key to the **python-hello-operations** repository by going to
    the project and clicking on **Settings** | **Repository**. Next to **Deploy Keys**,
    click **Expand**. For **Title**, use **argocd**. Use the contents of **argocd-python-hello.pub**
    and click **Add key**. Then, add the key to ArgoCD using the CLI and replace the
    public GitLab host with the **gitlab-gitlab-shell** **Service** hostname:'
  id: totrans-501
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过转到项目并单击**设置** | **存储库**，将公钥添加到**python-hello-operations**存储库。在**部署密钥**旁边，单击**展开**。对于**标题**，使用**argocd**。使用**argocd-python-hello.pub**的内容，然后单击**添加密钥**。然后，使用CLI将密钥添加到ArgoCD，并将公共GitLab主机替换为**gitlab-gitlab-shell**
    **Service**主机名：
- en: '**$ argocd repo add git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git
    --ssh-private-key-path ./argocd-python-hello**'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ argocd repo add git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git
    --ssh-private-key-path ./argocd-python-hello**'
- en: '**repository ''git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git''
    added**'
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: '**存储库''git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git''已添加**'
- en: 'Our last step is to create an **Application** object. You can create it through
    the web UI or the CLI. You can also create it by creating an **Application** object
    in the **argocd** namespace, which is what we''ll do. Create the following object
    in your cluster (**chapter14/yaml/argocd-python-hello.yaml**):'
  id: totrans-504
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的最后一步是创建一个**Application**对象。您可以通过Web UI或CLI创建它。您还可以通过在**argocd**命名空间中创建**Application**对象来创建它，这就是我们要做的。在您的集群中创建以下对象（**chapter14/yaml/argocd-python-hello.yaml**）：
- en: 'apiVersion: argoproj.io/v1alpha1'
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：argoproj.io/v1alpha1
- en: 'kind: Application'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：应用
- en: 'metadata:'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: python-hello'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：python-hello
- en: 'namespace: argocd'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：argocd
- en: 'spec:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'destination:'
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
  zh: 目的地：
- en: 'namespace: python-hello'
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：python-hello
- en: 'server: https://kubernetes.default.svc'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器：https://kubernetes.default.svc
- en: 'project: default'
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
  zh: 项目：默认
- en: 'source:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：
- en: 'directory:'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: '目录:'
- en: 'jsonnet: {}'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 'jsonnet: {}'
- en: 'recurse: true'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
  zh: 'recurse: true'
- en: 'path: src'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
  zh: 路径：src
- en: 'repoURL: git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
  zh: repoURL：git@gitlab-gitlab-shell.gitlab.svc.cluster.local:root/hello-python-operations.git
- en: 'targetRevision: HEAD'
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
  zh: 'targetRevision: HEAD'
- en: 'syncPolicy:'
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
  zh: 同步策略：
- en: 'automated: {}'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 'automated: {}'
- en: This is about as basic of a configuration as possible. We're working off of
    simple manifests. ArgoCD can work off of jsonet and Helm too. After this application
    is created, look at the Pods in the **python-hello** namespace. You should have
    one running! Making updates to your code will result in updates to the namespace.
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 这是尽可能基本的配置。我们正在使用简单的清单。ArgoCD也可以使用jsonet和Helm。创建此应用程序后，查看**python-hello**命名空间中的Pod。你应该有一个正在运行的！对代码进行更新将导致命名空间的更新。
- en: We now have a code base that can be deployed automatically with a commit. We
    spent a couple dozen pages, ran dozens of commands, and created more than 20 objects
    to get there. Instead of manually creating these objects, it would be best to
    automate the process. Now that we have the objects that need to be created, we
    can automate the onboarding. In the next section, we will take the manual process
    of building the links between GitLab, Tekton, and ArgoCD to line up with our business
    processes.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个可以通过提交自动部署的代码库。我们花了几十页，运行了几十个命令，并创建了20多个对象才达到这一点。与其手动创建这些对象，最好是自动化这个过程。现在我们已经有了需要创建的对象，我们可以自动化入职流程。在下一节中，我们将手动构建GitLab、Tekton和ArgoCD之间的链接，以符合我们的业务流程。
- en: Automating project onboarding using OpenUnison
  id: totrans-526
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OpenUnison自动化项目入职
- en: 'Earlier in this chapter, we deployed the OpenUnison automation portal. This
    portal lets users request new namspaces to be created and allows developers to
    request access to these namespaces via a self-service interface. The workflows
    built into this portal are very basic but create the namespace and appropriate
    **RoleBinding** objects. What we want to do is build a workflow that integrates
    our platform and creates all of the objects we created manually earlier in this
    chapter. The goal is that we''re able to deploy a new application into our environment
    without having to run the **kubectl** command (or at least minimize its use).
    This will require careful planning. Here''s how our developer workflow will run:'
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前面，我们部署了OpenUnison自动化门户。该门户允许用户请求创建新的命名空间，并允许开发人员通过自助服务界面请求访问这些命名空间。该门户内置的工作流程非常基本，但会创建命名空间和适当的**RoleBinding**对象。我们想要做的是构建一个集成我们平台并创建本章前面手动创建的所有对象的工作流程。我们的目标是能够在不运行**kubectl**命令（或至少最小化使用）的情况下将新应用程序部署到我们的环境中。这将需要仔细的规划。以下是我们的开发人员工作流程的运行方式：
- en: '![Figure 14.6 – Platform developer workflow'
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.6 - 平台开发人员工作流程'
- en: '](image/Fig_14.6_B15514.jpg)'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.6_B15514.jpg)'
- en: Figure 14.6 – Platform developer workflow
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.6 - 平台开发人员工作流程
- en: 'Let''s quickly run through the workflow that we see in the preceding figure:'
  id: totrans-531
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速浏览一下前面图中看到的工作流程：
- en: An application owner will request an application be created.
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序所有者将请求创建一个应用程序。
- en: The infrastructure admin approves the creation.
  id: totrans-533
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础设施管理员批准创建。
- en: At this point, OpenUnison will deploy the objects we manually created. We'll
    detail those objects shortly.
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一点上，OpenUnison将部署我们手动创建的对象。我们将很快详细介绍这些对象。
- en: Once created, a developer is able to request access to the application
  id: totrans-535
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建后，开发人员可以请求访问该应用程序
- en: The application owner(s) approve access to the application.
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序所有者批准对应用程序的访问。
- en: Once approved, the developer will fork the application source base and do their
    work. They can launch the application in their developer workspace. They can also
    fork the build project to create a pipeline and the development environment operations
    project to create manifests for the application. Once the work is done and tested
    locally, the developer will push the code into their own fork, then request a
    merge request.
  id: totrans-537
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦获得批准，开发人员将分叉应用程序源代码库并进行他们的工作。他们可以在他们的开发工作区启动应用程序。他们还可以分叉构建项目以创建流水线，并分叉开发环境操作项目以为应用程序创建清单。一旦工作完成并在本地测试通过，开发人员将代码推送到他们自己的分叉中，然后请求合并请求。
- en: The application owner will approve the request and merge the code from GitLab.
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序所有者将批准请求并从GitLab合并代码。
- en: Once the code is merged, ArgoCD will synchronize the build and operations projects.
    The webhook in the application project will kick off a Tekton pipeline that will
    build our container and update the development operations project with the tag
    for the latest container. ArgoCD will synchronize the updated manifest into our
    application's development namespace. Once testing is completed, the application
    owner submits a merge request from the development operations workspace to the
    production operations workspace, triggering ArgoCD to launch into production.
  id: totrans-539
  prefs: []
  type: TYPE_NORMAL
  zh: 代码合并后，ArgoCD将同步构建和操作项目。应用程序项目中的webhook将启动一个Tekton流水线，该流水线将构建我们的容器并使用最新容器的标记更新开发操作项目。ArgoCD将同步更新的清单到我们应用程序的开发命名空间。一旦测试完成，应用程序所有者将从开发操作工作区提交合并请求到生产操作工作区，触发ArgoCD进入生产环境。
- en: 'Nowhere in this flow is there a step called "operations staff uses **kubectl**
    to create a namespace." This is a simple flow and won''t totally avoid your operations
    staff from using **kubectl**, but it should be a good starting point. All this
    automation requires an extensive set of objects to be created:'
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个流程中，没有一步叫做“运维人员使用**kubectl**创建命名空间”。这是一个简单的流程，并不能完全避免你的运维人员使用**kubectl**，但这应该是一个很好的起点。所有这些自动化都需要创建一系列广泛的对象：
- en: '![Figure 14.7 – Application onboarding object map'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: '![图14.7 - 应用入职对象映射'
- en: '](image/Fig_14.7_B15514.jpg)'
  id: totrans-542
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_14.7_B15514.jpg)'
- en: Figure 14.7 – Application onboarding object map
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
  zh: 图14.7 - 应用入职对象映射
- en: In GitLab, we create a project for our application code, operations, and build
    pipeline. We also fork the operations project as a development operations project.
    For each project, we generate deploy keys and register webhooks. We also create
    groups to match the roles we defined earlier in this chapter.
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
  zh: 在GitLab中，我们为我们的应用程序代码、运维和构建流水线创建一个项目。我们还将运维项目作为开发运维项目进行分支。对于每个项目，我们生成部署密钥并注册webhook。我们还创建了与本章前面定义的角色相匹配的组。
- en: For Kubernetes, we create namespaces for the development and production environments.
    We also create a namespace for the Tekton pipeline. We add the keys as needed
    to **Secrets**. In the build namespace, we create all the scaffolding to support
    the webhook that will trigger automatic builds. That way, our developers only
    need to worry about creating their pipeline objects.
  id: totrans-545
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kubernetes，我们为开发和生产环境创建命名空间。我们还为Tekton流水线创建了一个命名空间。我们根据需要向**Secrets**添加密钥。在构建命名空间中，我们创建了支持触发自动构建的webhook的所有脚手架。这样，我们的开发人员只需要担心创建他们的流水线对象。
- en: In our last application, ArgoCD, we will create an **AppProject** that hosts
    our build and both operations namespaces. We will also add the SSH keys we generated
    when creating our GitLab projects. Each project also gets an **Application** object
    in our **AppProject** that instructs ArgoCD how to synchronize from GitLab. Finally,
    we add RBAC rules to ArgoCD so that our developers can view their application
    synchronization status but owners and operations can make updates and changes.
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的最后一个应用程序ArgoCD中，我们将创建一个**AppProject**，其中包含我们的构建和两个运维命名空间。我们还将添加在创建GitLab项目时生成的SSH密钥。每个项目还在我们的**AppProject**中得到一个**Application**对象，指示ArgoCD如何从GitLab同步。最后，我们向ArgoCD添加RBAC规则，以便我们的开发人员可以查看他们的应用程序同步状态，但所有者和运维人员可以进行更新和更改。
- en: You don't need to build this out yourself! **chapter14/openunison** is the source
    for OpenUnison that implements this flow. If you want to see every object we create,
    refer to **chapter14/openunison/src/main/webapp/WEB-INF/workflows/30-NewK8sNamespace.xml**.
    This workflow does everything we just described. We also included **chapter14/python-hello**
    as our example application, **chapter14/python-hello-operations** for our manifests,
    and **chapter14/python-hello-build** as our pipeline. You'll need to tweak some
    of the objects in these three folders to match your environment, mostly updating
    the hostnames.
  id: totrans-547
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要自己构建这个！**chapter14/openunison**是实现这一流程的OpenUnison的源代码。如果你想看到我们创建的每个对象，请参考**chapter14/openunison/src/main/webapp/WEB-INF/workflows/30-NewK8sNamespace.xml**。这个工作流做了我们刚才描述的一切。我们还包括了**chapter14/python-hello**作为我们的示例应用程序，**chapter14/python-hello-operations**作为我们的清单，以及**chapter14/python-hello-build**作为我们的流水线。你需要调整这三个文件夹中的一些对象以匹配你的环境，主要是更新主机名。
- en: With our developer workflow designed and example projects ready to go, next
    we'll update OpenUnison, GitLab, and ArgoCD to get all this automation to work!
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
  zh: 设计好了我们的开发人员工作流程，并准备好示例项目，接下来我们将更新OpenUnison、GitLab和ArgoCD，让所有这些自动化工作起来！
- en: Integrating GitLab
  id: totrans-549
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成GitLab
- en: 'We configured GitLab for SSO when we first deployed the Helm chart. The **gitlab-oidc**
    **Secret** we deployed has all the information GitLab needs to access SSO from
    OpenUnison. We still need to configure OpenUnison though. We could hardcode the
    SSO configuration into our OpenUnison source base or we could dynamically add
    it as a custom resource. In this instance, we''ll add the SSO connection via a
    custom resource:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首次部署Helm图表时，我们为SSO配置了GitLab。我们部署的**gitlab-oidc** **秘密**包含GitLab访问OpenUnison的所有信息。尽管我们仍需要配置OpenUnison。我们可以将SSO配置硬编码到我们的OpenUnison源代码中，也可以动态添加它作为自定义资源。在这种情况下，我们将通过自定义资源添加SSO连接：
- en: Edit **chapter14/yaml/gitlab-trust.yaml**, replacing **192-168-2-140** with
    the server IP your cluster is running on. My cluster is on **192.168.2.114**,
    so I'll replace it with **192-168-2-114**. Add **chapter14/yaml/gitlab-trust.yaml**
    to your cluster. This file tells OpenUnison to establish a trust with GitLab for
    SSO.
  id: totrans-551
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/gitlab-trust.yaml**，将**192-168-2-140**替换为集群正在运行的服务器IP。我的集群在**192.168.2.114**上，所以我将其替换为**192-168-2-114**。将**chapter14/yaml/gitlab-trust.yaml**添加到您的集群。此文件告诉OpenUnison与GitLab建立SSO信任。
- en: Edit **chapter14/yaml/gitlab-url.yaml**, replacing **192-168-2-140** with the
    server IP your cluster is running on. My cluster is on **192.168.2.114**, so I'll
    replace it with **192-168-2-114**. Add **chapter14/yaml/gitlab-url.yaml** to your
    cluster. This file tells OpenUnison to add a badge to the portal for GitLab.
  id: totrans-552
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/gitlab-url.yaml**，将**192-168-2-140**替换为集群正在运行的服务器IP。我的集群在**192.168.2.114**上，所以我将其替换为**192-168-2-114**。将**chapter14/yaml/gitlab-url.yaml**添加到您的集群。此文件告诉OpenUnison为GitLab门户添加徽标。
- en: Log in to GitLab as root. Go to your user's profile area and click on **Access
    Tokens**. For **Name**, use **openunison**. Leave **Expires** blank and check
    the API scope. Click **Create personal access token**. Copy and paste the token
    into a notepad or some other place. Once you leave this screen, you can't retrieve
    this token again.
  id: totrans-553
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以root身份登录GitLab。转到用户的个人资料区域，然后单击**访问令牌**。对于**名称**，使用**openunison**。将**过期**留空并检查API范围。单击**创建个人访问令牌**。将令牌复制并粘贴到记事本或其他地方。一旦离开此屏幕，就无法再检索此令牌。
- en: 'Edit the **orchestra-secrets-source** Secret in the **openunison** namespace.
    Add two keys:'
  id: totrans-554
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**openunison**命名空间中的**orchestra-secrets-source**秘密。添加两个键：
- en: 'apiVersion: v1'
  id: totrans-555
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：v1
- en: 'data:'
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'K8S_DB_SECRET: aW0gYSBzZWNyZXQ='
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: K8S_DB_SECRET：aW0gYSBzZWNyZXQ=
- en: 'OU_JDBC_PASSWORD: c3RhcnR0MTIz'
  id: totrans-558
  prefs: []
  type: TYPE_NORMAL
  zh: OU_JDBC_PASSWORD：c3RhcnR0MTIz
- en: 'SMTP_PASSWORD: ""'
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: SMTP_PASSWORD：""
- en: 'unisonKeystorePassword: aW0gYSBzZWNyZXQ='
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: unisonKeystorePassword：aW0gYSBzZWNyZXQ=
- en: '**  gitlab: c2VjcmV0  GITLAB_TOKEN: S7CCuqHfpw3a6GmAqEYg**'
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: gitlab：c2VjcmV0 GITLAB_TOKEN：S7CCuqHfpw3a6GmAqEYg
- en: 'kind: Secret'
  id: totrans-562
  prefs: []
  type: TYPE_NORMAL
  zh: 种类：秘密
- en: Remember to Base64-encode the values. The **gitlab** key matches the secret
    in our **oidc-provider** Secret. **GITLAB_TOKEN** is going to be used by OpenUnison
    to interact with GitLab to provision the projects and groups we defined in our
    onboarding workflow. With GitLab configured, next is ArgoCD.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 记得对值进行Base64编码。**gitlab**键与我们的**oidc-provider**秘密中的秘密匹配。**GITLAB_TOKEN**将由OpenUnison用于与GitLab交互，以提供我们在入职工作流程中定义的项目和组。配置了GitLab，接下来是ArgoCD。
- en: Integrating ArgoCD
  id: totrans-564
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成ArgoCD
- en: 'ArgoCD has built-in support for OpenID Connect. It wasn''t configured for us
    in the deployment, though:'
  id: totrans-565
  prefs: []
  type: TYPE_NORMAL
  zh: ArgoCD内置支持OpenID Connect。尽管在部署中没有为我们配置：
- en: 'Edit the **argocd-cm** **ConfigMap** in the **argocd** namespace, adding the
    **url** and **oidc.config** keys, as shown in the following cde block. Make sure
    to update **192-168-2-140** to match your cluster''s IP address. Mine is **192.168.2.114**,
    so I''ll be using **192-168-2-114**:'
  id: totrans-566
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**argocd-cm** **ConfigMap**在**argocd**命名空间中，添加**url**和**oidc.config**键，如下所示的cde块。确保更新**192-168-2-140**以匹配您集群的IP地址。我的是**192.168.2.114**，所以我将使用**192-168-2-114**：
- en: 'apiVersion: v1'
  id: totrans-567
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：v1
- en: 'data:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'url: https://argocd.apps.192-168-2-140.nip.io'
  id: totrans-569
  prefs: []
  type: TYPE_NORMAL
  zh: url：https://argocd.apps.192-168-2-140.nip.io
- en: 'oidc.config: |-'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: oidc.config：|-
- en: 'name: OpenUnison'
  id: totrans-571
  prefs: []
  type: TYPE_NORMAL
  zh: 'name: OpenUnison'
- en: 'issuer: https://k8sou.apps.192-168-2-140.nip.io/auth/idp/k8sIdp'
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 'issuer: https://k8sou.apps.192-168-2-140.nip.io/auth/idp/k8sIdp'
- en: 'clientID: argocd'
  id: totrans-573
  prefs: []
  type: TYPE_NORMAL
  zh: 'clientID: argocd'
- en: 'requestedScopes: ["openid", "profile", "email", "groups"]'
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 'requestedScopes: ["openid", "profile", "email", "groups"]'
- en: Important Note
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We don't specify a client secret with ArgoCD because it has both a CLI and a
    web component. Just like with the API server, it makes no sense to worry about
    a client secret that will need to reside on every single workstation that will
    be known to the user. It doesn't add any security in this case, so we will skip
    it.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有在ArgoCD中指定客户端密钥，因为它既有CLI又有Web组件。就像API服务器一样，在这种情况下担心需要驻留在每台工作站上并为用户所知的客户端密钥是没有意义的。在这种情况下，它不会增加任何安全性，所以我们将跳过它。
- en: Edit **chapter14/yaml/argocd-trust.yaml**, replacing **192-168-2-140** with
    the server IP your cluster is running on. My cluster is on **192.168.2.114**,
    so I'll replace it with **192-168-2-114**. Add **chapter14/yaml/argocd-trust.yaml**
    to your cluster. This file tells OpenUnison to establish a trust with ArgoCD for
    SSO.
  id: totrans-577
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/argocd-trust.yaml**，将**192-168-2-140**替换为集群正在运行的服务器IP。我的集群在**192.168.2.114**上，所以我将其替换为**192-168-2-114**。将**chapter14/yaml/argocd-trust.yaml**添加到您的集群。此文件告诉OpenUnison与ArgoCD建立SSO信任。
- en: Edit **chapter14/yaml/argocd-url.yaml**, replacing **192-168-2-140** with the
    server IP your cluster is running on. My cluster is on **192.168.2.114**, so I'll
    replace it with **192-168-2-114**. Add **chapter14/yaml/argocd-url.yaml** to your
    cluster. This file tells OpenUnison to add a badge to the portal for ArgoCD.
  id: totrans-578
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编辑**chapter14/yaml/argocd-url.yaml**，将**192-168-2-140**替换为集群正在运行的服务器IP。我的集群在**192.168.2.114**上，所以我将其替换为**192-168-2-114**。将**chapter14/yaml/argocd-url.yaml**添加到您的集群。此文件告诉OpenUnison为ArgoCD门户添加徽章。
- en: 'While most of ArgoCD is controlled with Kubernetes custom resources, there
    are some ArgoCD-specific APIs. To work with these APIs, we need to create a service
    account. We''ll need to create this account and generate a key for it:'
  id: totrans-579
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虽然大部分ArgoCD是由Kubernetes自定义资源控制的，但也有一些特定于ArgoCD的API。要使用这些API，我们需要创建一个服务账户。我们需要创建此账户并为其生成一个密钥：
- en: '**$ kubectl patch configmap argocd-cm -n argocd -p ''{"data":{"accounts.openunison":"apiKey","accounts.openunison.enabled":"true"}}''**'
  id: totrans-580
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ kubectl patch configmap argocd-cm -n argocd -p ''{"data":{"accounts.openunison":"apiKey","accounts.openunison.enabled":"true"}}''**'
- en: '**$ argocd account generate-token --account openunison**'
  id: totrans-581
  prefs: []
  type: TYPE_NORMAL
  zh: '**$ argocd account generate-token --account openunison**'
- en: Take the output of the **generate-token** command and add it as the **ARGOCD_TOKEN**
    key to the **orchestra-secrets-source** **Secret** in the **openunison** namespace.
    Don't forget to Base64-encode it.
  id: totrans-582
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取**generate-token**命令的输出，并将其添加为**orchestra-secrets-source** **Secret**中的**ARGOCD_TOKEN**键，位于**openunison**命名空间中。不要忘记对其进行Base64编码。
- en: 'Finally, we want to create ArgoCD RBAC rules so that we can control who can
    access the web UI and the CLI. Edit the **argocd-rbac-cm** **ConfigMap** and add
    the following keys. The first key will let our systems administrators and our
    API key do anything in ArgoCD. The second key maps all users that aren''t mapped
    by **policy.csv** into a role into a nonexistent role so that they won''t have
    access to anything:'
  id: totrans-583
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们想创建ArgoCD RBAC规则，以便我们可以控制谁可以访问Web UI和CLI。编辑**argocd-rbac-cm** **ConfigMap**并添加以下键。第一个键将允许我们的系统管理员和我们的API密钥在ArgoCD中执行任何操作。第二个键将所有未在**policy.csv**中映射的用户映射到一个不存在的角色中，以便他们无法访问任何内容：
- en: 'data:'
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 数据：
- en: 'policy.csv: |-'
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 'policy.csv: |-'
- en: g, k8s-cluster-administrators,role:admin
  id: totrans-586
  prefs: []
  type: TYPE_NORMAL
  zh: g，k8s-cluster-administrators，role:admin
- en: g, openunison,role:admin
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: g，openunison，role:admin
- en: 'policy.default: role:none'
  id: totrans-588
  prefs: []
  type: TYPE_NORMAL
  zh: 'policy.default: role:none'
- en: With ArgoCD integrated, the last step to world automation is updating our OpenUnison
    custom resource!
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 集成了ArgoCD，实现自动化的最后一步是更新我们的OpenUnison自定义资源！
- en: Updating OpenUnison
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新OpenUnison
- en: 'OpenUnison is already deployed. The last step to launching an automation portal
    with our developer workflows built in is to update the **orchestra** OpenUnison
    custom resource. Update the image as in the following code block. Add **non_secret_data**,
    replacing **hosts** to match with your cluster''s IP. Finally, add the new secrets
    we created to the list of secrets the operator needs to import:'
  id: totrans-591
  prefs: []
  type: TYPE_NORMAL
  zh: OpenUnison已经部署。启动自动化门户与我们构建的开发者工作流程的最后一步是更新orchestra OpenUnison自定义资源。按照以下代码块中的方式更新图像。添加non_secret_data，将hosts替换为与您的集群IP匹配。最后，将我们创建的新密钥添加到操作员需要导入的密钥列表中：
- en: .
  id: totrans-592
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-593
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-594
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: '**image: docker.io/tremolosecurity/openunison-k8s-definitive-guide:latest**'
  id: totrans-595
  prefs: []
  type: TYPE_NORMAL
  zh: '   图像：docker.io/tremolosecurity/openunison-k8s-definitive-guide:latest'
- en: .
  id: totrans-596
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-597
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-598
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'non_secret_data:'
  id: totrans-599
  prefs: []
  type: TYPE_NORMAL
  zh: 'non_secret_data:'
- en: .
  id: totrans-600
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-601
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-602
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: '**- name: GITLAB_URL**'
  id: totrans-603
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：GITLAB_URL'
- en: '**    value: https://gitlab.apps.192-168-2-140.nip.io**'
  id: totrans-604
  prefs: []
  type: TYPE_NORMAL
  zh: '   值：https://gitlab.apps.192-168-2-140.nip.io'
- en: '**  - name: GITLAB_SSH_HOST**'
  id: totrans-605
  prefs: []
  type: TYPE_NORMAL
  zh: '   - 名称：GITLAB_SSH_HOST'
- en: '**    value: gitlab-gitlab-shell.gitlab.svc.cluster.local**'
  id: totrans-606
  prefs: []
  type: TYPE_NORMAL
  zh: '   值：gitlab-gitlab-shell.gitlab.svc.cluster.local'
- en: '**  - name: GITLAB_WEBHOOK_SUFFIX**'
  id: totrans-607
  prefs: []
  type: TYPE_NORMAL
  zh: '   - 名称：GITLAB_WEBHOOK_SUFFIX'
- en: '**    value: gitlab.192-168-2-140.nip.io**'
  id: totrans-608
  prefs: []
  type: TYPE_NORMAL
  zh: '   值：gitlab.192-168-2-140.nip.io'
- en: '**  - name: ARGOCD_URL**'
  id: totrans-609
  prefs: []
  type: TYPE_NORMAL
  zh: '   - 名称：ARGOCD_URL'
- en: '**    value: https://argocd.apps.192-168-2-140.nip.io**'
  id: totrans-610
  prefs: []
  type: TYPE_NORMAL
  zh: '   值：https://argocd.apps.192-168-2-140.nip.io'
- en: '**  - name: GITLAB_WRITE_SSH_HOST**'
  id: totrans-611
  prefs: []
  type: TYPE_NORMAL
  zh: '   - 名称：GITLAB_WRITE_SSH_HOST'
- en: '**    value: gitlab-write-shell.gitlab.svc.cluster.local**'
  id: totrans-612
  prefs: []
  type: TYPE_NORMAL
  zh: '   值：gitlab-write-shell.gitlab.svc.cluster.local'
- en: .
  id: totrans-613
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-614
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: .
  id: totrans-615
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: 'secret_data:'
  id: totrans-616
  prefs: []
  type: TYPE_NORMAL
  zh: 'secret_data:'
- en: '- K8S_DB_SECRET'
  id: totrans-617
  prefs: []
  type: TYPE_NORMAL
  zh: '- K8S_DB_SECRET'
- en: '- unisonKeystorePassword'
  id: totrans-618
  prefs: []
  type: TYPE_NORMAL
  zh: '- unisonKeystorePassword'
- en: '- SMTP_PASSWORD'
  id: totrans-619
  prefs: []
  type: TYPE_NORMAL
  zh: '- SMTP_PASSWORD'
- en: '- OU_JDBC_PASSWORD'
  id: totrans-620
  prefs: []
  type: TYPE_NORMAL
  zh: '- OU_JDBC_PASSWORD'
- en: '**- GITLAB_TOKEN**'
  id: totrans-621
  prefs: []
  type: TYPE_NORMAL
  zh: '- GITLAB_TOKEN'
- en: '**  - ARGOCD_TOKEN**'
  id: totrans-622
  prefs: []
  type: TYPE_NORMAL
  zh: '   - ARGOCD_TOKEN'
- en: In just a few minutes, the automation portal will be running. When you log in,
    you'll see badges for GitLab and ArgoCD. You'll also be able to click on **New
    Application** to begin deploying applications according to our workflow! You can
    use this as a starting point for designing your own automation platform or use
    it as a map for creating the various objects needed to integrate the tools on
    your platform.
  id: totrans-623
  prefs: []
  type: TYPE_NORMAL
  zh: 只需几分钟，自动化门户就会运行。当您登录时，您将看到GitLab和ArgoCD的徽章。您还可以单击“新应用程序”开始根据我们的工作流程部署应用程序！您可以将其用作设计自己的自动化平台的起点，或者将其用作创建所需对象以集成平台工具的地图。
- en: Summary
  id: totrans-624
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: Coming into this chapter, we hadn't spent much time on deploying applications.
    We wanted to close things out with a brief introduction to application deployment
    and automation. We learned about pipelines, how they are built, and how they run
    on a Kubernetes cluster. We explored the process of building a platform by deploying
    GitLab for source control, built out a Tekton pipeline to work in a GitOps model,
    and used ArgoCD to make the GitOps model a reality. Finally, we automated the
    entire process with OpenUnison.
  id: totrans-625
  prefs: []
  type: TYPE_NORMAL
  zh: 进入本章之前，我们并没有花太多时间部署应用程序。我们希望通过简要介绍应用程序部署和自动化来结束这些内容。我们了解了流水线，它们是如何构建的，以及它们在Kubernetes集群上运行的方式。我们通过部署GitLab进行源代码控制，构建了一个Tekton流水线以适用GitOps模型，并使用ArgoCD使GitOps模型成为现实。最后，我们使用OpenUnison自动化了整个流程。
- en: Using the information in this chapter should give you direction as to how you
    want to build your own platform. Using the practical examples in this chapter
    will help you map the requirements in your organization to the technology needed
    to automate your infrastructure. The platform we built in this chapter is far
    from complete. It should give you a map for planning your own platform that matches
    your needs.
  id: totrans-626
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本章中的信息应该为您提供了构建自己平台的方向。使用本章中的实际示例将帮助您将组织中的要求映射到自动化基础设施所需的技术。我们在本章中构建的平台远非完整。它应该为您规划自己的平台提供了一个地图，以满足您的需求。
- en: Finally, thank you. Thank you for joining us on this adventure of building out
    a Kubernetes cluster. We hope you have as much fun reading this book and building
    out the examples as we did creating it!
  id: totrans-627
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，谢谢。感谢您加入我们一起构建Kubernetes集群的冒险。我们希望您阅读本书和构建示例时和我们创作时一样开心！
- en: Questions
  id: totrans-628
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'True or false: A pipeline must be implemented to make Kubernetes work.'
  id: totrans-629
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确还是错误：必须实施流水线才能使Kubernetes工作。
- en: A. True
  id: totrans-630
  prefs: []
  type: TYPE_NORMAL
  zh: A. 正确
- en: B. False
  id: totrans-631
  prefs: []
  type: TYPE_NORMAL
  zh: B. 错误
- en: What are the minimum steps of a pipeline?
  id: totrans-632
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 流水线的最低步骤是什么？
- en: A. Build, scan, test, and deploy
  id: totrans-633
  prefs: []
  type: TYPE_NORMAL
  zh: A. 构建、扫描、测试和部署
- en: B. Build and deploy
  id: totrans-634
  prefs: []
  type: TYPE_NORMAL
  zh: B. 构建和部署
- en: C. Scan, test, deploy, and build
  id: totrans-635
  prefs: []
  type: TYPE_NORMAL
  zh: C. 扫描、测试、部署和构建
- en: D. None of the above
  id: totrans-636
  prefs: []
  type: TYPE_NORMAL
  zh: D. 以上都不是
- en: What is GitOps?
  id: totrans-637
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是GitOps？
- en: A. Running GitLab on Kubernetes
  id: totrans-638
  prefs: []
  type: TYPE_NORMAL
  zh: A. 在Kubernetes上运行GitLab
- en: B. Using Git as an authoritative source for operations configuration
  id: totrans-639
  prefs: []
  type: TYPE_NORMAL
  zh: B. 使用Git作为操作配置的权威来源
- en: C. A silly marketing term
  id: totrans-640
  prefs: []
  type: TYPE_NORMAL
  zh: C. 一个愚蠢的营销术语
- en: D. A product from a new start-up
  id: totrans-641
  prefs: []
  type: TYPE_NORMAL
  zh: D. 一家新创企业的产品
- en: What is the standard for writing pipelines?
  id: totrans-642
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 编写流水线的标准是什么？
- en: A. All pipelines should be written in YAML.
  id: totrans-643
  prefs: []
  type: TYPE_NORMAL
  zh: A. 所有流水线应该用YAML编写。
- en: B. There are no standards; every project and vendor has its own implementation.
  id: totrans-644
  prefs: []
  type: TYPE_NORMAL
  zh: B. 没有标准；每个项目和供应商都有自己的实现。
- en: C. JSON combined with Go.
  id: totrans-645
  prefs: []
  type: TYPE_NORMAL
  zh: C. JSON结合Go。
- en: D. Rust.
  id: totrans-646
  prefs: []
  type: TYPE_NORMAL
  zh: D. Rust.
- en: How do you deploy a new instance of a container in a GitOps model?
  id: totrans-647
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GitOps模型中如何部署一个新的容器实例？
- en: A. Use **kubectl** to update the **Deployment** or **StatefulSet** in the namespace.
  id: totrans-648
  prefs: []
  type: TYPE_NORMAL
  zh: A. 使用**kubectl**在命名空间中更新**Deployment**或**StatefulSet**。
- en: B. Update the **Deployment** or **StatefulSet** manifest in Git, letting the
    GitOps controller update the objects in Kubernetes.
  id: totrans-649
  prefs: []
  type: TYPE_NORMAL
  zh: B. 在Git中更新**Deployment**或**StatefulSet**清单，让GitOps控制器更新Kubernetes中的对象。
- en: C. Submit a ticket that someone in operations needs to act on.
  id: totrans-650
  prefs: []
  type: TYPE_NORMAL
  zh: C. 提交一个需要运维人员处理的工单。
- en: D. None of the above.
  id: totrans-651
  prefs: []
  type: TYPE_NORMAL
  zh: D. 以上都不是。
- en: 'True or false: All objects in GitOps needs to be stored in your Git repository.'
  id: totrans-652
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确还是错误：GitOps中的所有对象都需要存储在您的Git存储库中。
- en: A. True
  id: totrans-653
  prefs: []
  type: TYPE_NORMAL
  zh: A. 正确
- en: B. False
  id: totrans-654
  prefs: []
  type: TYPE_NORMAL
  zh: B. 错误
- en: 'True or false: Your way is the right way to automate your processes.'
  id: totrans-655
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确还是错误：你的方式是自动化流程的正确方式。
- en: A. True
  id: totrans-656
  prefs: []
  type: TYPE_NORMAL
  zh: A. 正确
- en: B. False
  id: totrans-657
  prefs: []
  type: TYPE_NORMAL
  zh: B. 错误
