- en: Deploying, Updating, and Securing an Application with Kubernetes
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes部署、更新和保护应用程序
- en: In the previous chapter, we learned about the basics of the container orchestrator,
    Kubernetes. We got a high-level overview of the architecture of Kubernetes and
    learned a lot about the important objects used by Kubernetes to define and manage
    a containerized application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了容器编排器Kubernetes的基础知识。我们对Kubernetes的架构有了高层次的概述，并且学到了很多关于Kubernetes用于定义和管理容器化应用程序的重要对象。
- en: In this chapter, we will learn how to deploy, update, and scale applications
    into a Kubernetes cluster. We will also explain how zero downtime deployments
    are achieved to enable disruption-free updates and rollbacks of mission-critical
    applications. Finally, we will introduce Kubernetes secrets as a means to configure
    services and protect sensitive data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将学习如何将应用程序部署、更新和扩展到Kubernetes集群中。我们还将解释如何实现零停机部署，以实现对关键任务应用程序的无干扰更新和回滚。最后，我们将介绍Kubernetes秘密作为配置服务和保护敏感数据的手段。
- en: 'This chapter covers the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖以下主题：
- en: Deploying a first application
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署第一个应用程序
- en: Defining liveness and readiness
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义活动性和就绪性
- en: Zero downtime deployments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 零停机部署
- en: Kubernetes secrets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes秘密
- en: 'After working through this chapter, you will be able to do the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章的学习，您将能够做到以下事情：
- en: Deploy a multi-service application into a Kubernetes cluster
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将多服务应用程序部署到Kubernetes集群中
- en: Define a liveness and readiness probe for your Kubernetes application service
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为您的Kubernetes应用程序服务定义活动性和就绪性探测
- en: Update an application service running in Kubernetes without causing downtime
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在不造成停机的情况下更新在Kubernetes中运行的应用程序服务
- en: Define secrets in a Kubernetes cluster
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Kubernetes集群中定义秘密
- en: Configure an application service to use Kubernetes secrets
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用程序服务以使用Kubernetes秘密
- en: Technical requirements
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we're going to use Minikube on our local computer. Please refer
    to [Chapter 2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working
    Environment*, for more information on how to install and use Minikube.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将在本地计算机上使用Minikube。有关如何安装和使用Minikube的更多信息，请参阅[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，*设置工作环境*。
- en: 'The code for this chapter can be found here: [https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在此处找到：[https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes](https://github.com/PacktPublishing/Learn-Docker---Fundamentals-of-Docker-19.x-Second-Edition/tree/master/ch16/probes)。
- en: Please make sure you have cloned this book's GitHub repository, as described
    in [Chapter 2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working
    Environment*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您已经克隆了本书的GitHub存储库，如[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)中所述，*设置工作环境*。
- en: In your Terminal, navigate to the `~/fod/ch16` folder.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中，导航到`~/fod/ch16`文件夹。
- en: Deploying a first application
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署第一个应用程序
- en: We will take our pets application, which we first introduced in [Chapter 11](412c6f55-a00b-447f-b22a-47b305453507.xhtml), *Docker
    Compose*, and deploy it into a Kubernetes cluster. Our cluster will be Minikube,
    which, as you know, is a single-node cluster. However, from the perspective of
    a deployment, it doesn't really matter how big the cluster is and where the cluster
    is located in the cloud, in your company's data center, or on your personal workstation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将把我们在[第11章](412c6f55-a00b-447f-b22a-47b305453507.xhtml)中首次介绍的宠物应用程序，*Docker
    Compose*，部署到Kubernetes集群中。我们的集群将是Minikube，正如您所知，它是一个单节点集群。但是，从部署的角度来看，集群的大小以及集群在云中的位置、公司的数据中心或个人工作站并不重要。
- en: Deploying the web component
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署web组件
- en: 'Just as a reminder, our application consists of two application services: the
    Node-based web component and the backing PostgreSQL database. In the previous
    chapter, we learned that we need to define a Kubernetes Deployment object for
    each application service we want to deploy. Let''s do this first for the web component.
    As always in this book, we will choose the declarative way of defining our objects.
    Here is the YAML defining a Deployment object for the web component:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，我们的应用程序由两个应用程序服务组成：基于Node的web组件和支持的PostgreSQL数据库。在上一章中，我们了解到我们需要为要部署的每个应用程序服务定义一个Kubernetes
    Deployment对象。首先让我们为web组件做这个。就像本书中的所有内容一样，我们将选择声明性的方式来定义我们的对象。以下是为web组件定义Deployment对象的YAML：
- en: '![](assets/f43630a9-a410-44cf-a9f1-bcd87d583f54.png)Kubernetes deployment definition
    for the web component'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/f43630a9-a410-44cf-a9f1-bcd87d583f54.png)用于web组件的Kubernetes部署定义'
- en: 'The preceding deployment definition can be found in the `web-deployment.yaml` file
    in the `~/fod/ch16` folder. The lines of code are as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的部署定义可以在`~/fod/ch16`文件夹中的`web-deployment.yaml`文件中找到。代码行如下：
- en: 'On line `4`: We define the name for our `Deployment` object as `web`.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第4行：我们为我们的`Deployment`对象定义了名称为`web`。
- en: 'On line `6`: We declare that we want to have one instance of the `web` component
    running.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第6行：我们声明我们想要运行一个`web`组件的实例。
- en: 'From line `8` to `10`: We define which pods will be part of our deployment,
    namely those that have the `app` and `service` labels with values of `pets` and `web`,
    respectively.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第8行到第10行：我们定义了哪些pod将成为我们部署的一部分，即那些具有`app`和`service`标签，其值分别为`pets`和`web`的pod。
- en: 'On line `11`: In the template for the pods starting at line `11`, we define
    that each pod will have the `app` and `service` labels applied to them.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第11行：在从第11行开始的pod模板中，我们定义每个pod将被应用`app`和`service`标签。
- en: 'From line `17`: We define the single container that will be running in the
    pod. The image for the container is our well-known `fundamentalsofdocker/ch11-web:2.0` image
    and the name of the container will be `web`.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第17行开始：我们定义将在pod中运行的单个容器。容器的镜像是我们熟悉的`fundamentalsofdocker/ch11-web:2.0`镜像，容器的名称将是`web`。
- en: '`ports`: Finally, we declare that the container exposes port `3000` for TCP-type
    traffic.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ports`：最后，我们声明容器为TCP类型流量公开端口`3000`。'
- en: Please make sure that you have set the context of kubectl to Minikube. See [Chapter
    2](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml), *Setting Up a Working Environment*, for
    details on how to do that.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您已将kubectl的上下文设置为Minikube。有关如何执行此操作的详细信息，请参见[第2章](99a92fe1-4652-4934-9c33-f3e19483afcd.xhtml)，“设置工作环境”。
- en: 'We can deploy this Deployment object using kubectl:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用kubectl部署这个Deployment对象：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'We can double-check that the deployment has been created again using our Kubernetes
    CLI. We should see the following output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用我们的Kubernetes CLI再次检查部署是否已创建。我们应该看到以下输出：
- en: '![](assets/b631548b-c83b-4421-a037-a931a77b9ba7.png)Listing all resources running
    in Minikube'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/b631548b-c83b-4421-a037-a931a77b9ba7.png)列出在Minikube中运行的所有资源'
- en: In the preceding output, we can see that Kubernetes created three objects –
    the deployment, a pertaining ReplicaSet, and a single pod (remember that we specified
    that we want one replica only). The current state corresponds to the desired state
    for all three objects, so we are fine so far.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到Kubernetes创建了三个对象-部署、相关的ReplicaSet和一个单独的pod（请记住，我们指定了我们只想要一个副本）。当前状态与所有三个对象的期望状态相对应，所以到目前为止一切都很好。
- en: 'Now, the web service needs to be exposed to the public. For this, we need to
    define a Kubernetes Service object of the `NodePort` type. Here is the definition,
    which can be found in the `web-service.yaml` file in the `~/fod/ch16` folder:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，web服务需要暴露给公众。为此，我们需要定义一个`NodePort`类型的Kubernetes `Service`对象。以下是定义，可以在`~/fod/ch16`文件夹中的`web-service.yaml`文件中找到：
- en: '![](assets/aa181850-9aab-492a-a132-e99ecbb7f102.png)Definition of the Service
    object for our web component'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/aa181850-9aab-492a-a132-e99ecbb7f102.png)为我们的web组件定义的Service对象'
- en: 'The preceding lines of codes are as follows:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码的前几行如下：
- en: 'On line `4`: We set the `name` of this Service object to `web`.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`4`行：我们将这个`Service`对象的`name`设置为`web`。
- en: 'On line `6`: We define the `type` of Service object we''re using. Since the web component
    has to be accessible from outside of the cluster, this cannot be a Service object
    of the `ClusterIP` type and must be either of the `NodePort` or `LoadBalancer` type.
    We discussed the various types of Kubernetes services in the previous chapter,
    so will not go into further detail about this. In our sample, we''re using a `NodePort` type
    of service.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`6`行：我们定义了我们正在使用的`Service`对象的`type`。由于web组件必须从集群外部访问，这不能是`ClusterIP`类型的`Service`对象，必须是`NodePort`或`LoadBalancer`类型的。我们在上一章讨论了各种类型的Kubernetes服务，所以不会再详细讨论这个问题。在我们的示例中，我们使用了`NodePort`类型的服务。
- en: 'On lines `8` and `9`: We specify that we want to expose port `3000` for access
    through the `TCP` protocol. Kubernetes will map container port `3000` automatically
    to a free host port in the range of 30,000 to 32,768\. Which port Kubernetes effectively
    chooses can be determined using the `kubectl` get service or `kubectl` describe command for
    the service after it has been created.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第`8`行和`9`行：我们指定我们要通过`TCP`协议公开端口`3000`。Kubernetes将自动将容器端口`3000`映射到30,000到32,768范围内的空闲主机端口。Kubernetes实际上选择的端口可以在创建后使用`kubectl
    get service`或`kubectl describe`命令来确定服务。
- en: 'From line `10` to `12`: We define the filter criteria for the pods that this
    service will be a stable endpoint for. In this case, it is all the pods that have
    the `app` and `service` labels with the `pets` and `web` values, respectively.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从第`10`行到`12`行：我们为这个服务定义筛选标准，以确定这个服务将作为哪些pod的稳定端点。在这种情况下，它是所有具有`app`和`service`标签的pod，分别具有`pets`和`web`值。
- en: 'Now that we have this specification for a Service object, we can create it
    using `kubectl`:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个`Service`对象的规范，我们可以使用`kubectl`来创建它：
- en: '[PRE1]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can list all the services to see the result of the preceding command:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以列出所有的服务来查看前面命令的结果：
- en: '![](assets/68357689-66d7-4587-97d9-369552a5fe75.png)The Service object created
    for the web component'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/68357689-66d7-4587-97d9-369552a5fe75.png)为web组件创建的Service对象'
- en: In the preceding output, we can see that a service called `web` has been created.
    A unique clusterIP of `10.99.99.133` has been assigned to this service, and the
    container port `3000` has been published on port `31331` on all cluster nodes.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，我们可以看到一个名为`web`的服务已经被创建。为这个服务分配了一个唯一的`clusterIP`为`10.99.99.133`，并且容器端口`3000`已经发布到所有集群节点的端口`31331`上。
- en: 'If we want to test this deployment, we need to find out what IP address Minikube
    has, and then use this IP address to access our web service. The following is
    the command that we can use to do this:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想测试这个部署，我们需要找出Minikube的IP地址，然后使用这个IP地址来访问我们的web服务。以下是我们可以用来做这件事的命令：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: OK, the response is `Pets Demo Application`, which is what we expected. The
    web service is up and running in the Kubernetes cluster. Next, we want to deploy
    the database.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，响应是`Pets Demo Application`，这是我们预期的。web服务在Kubernetes集群中已经启动。接下来，我们要部署数据库。
- en: Deploying the database
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署数据库
- en: A database is a stateful component and has to be treated differently to stateless
    components, such as our web component. We discussed the difference between stateful
    and stateless components in a distributed application architecture in detail in [Chapter
    9](bbbf480e-3d5a-4ad7-94e9-fae735b025ae.xhtml), *Distributed Application Architecture*, and [Chapter
    12](27c0d9ce-fab6-4ce9-9034-4f2fb62931e8.xhtml), *Orchestrators*.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库是一个有状态的组件，必须与无状态的组件（如我们的web组件）有所不同对待。我们在[第9章](bbbf480e-3d5a-4ad7-94e9-fae735b025ae.xhtml)和[第12章](27c0d9ce-fab6-4ce9-9034-4f2fb62931e8.xhtml)中详细讨论了分布式应用架构中有状态和无状态组件的区别，以及编排器。
- en: 'Kubernetes has defined a special type of `ReplicaSet` object for stateful components.
    The object is called a `StatefulSet`. Let''s use this kind of object to deploy
    our database. The definition can be found in the `~fod/ch16/db-stateful-set.yaml` file.
    The details are as follows:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为有状态的组件定义了一种特殊类型的ReplicaSet对象。这个对象被称为StatefulSet。让我们使用这种对象来部署我们的数据库。定义可以在~fod/ch16/db-stateful-set.yaml文件中找到。详细信息如下：
- en: '![](assets/a0e35643-c85e-4f8d-8e9c-b62a372a42dd.png)A StatefulSet for the DB
    component'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ！[](assets/a0e35643-c85e-4f8d-8e9c-b62a372a42dd.png)DB组件的StatefulSet
- en: OK, this looks a bit scary, but it isn't. It is a bit longer than the definition
    of the deployment for the `web` component due to the fact that we also need to
    define a volume where the PostgreSQL database can store the data. The volume claim
    definition is on lines `25` to `33`. We want to create a volume with the name `pets-data` that
    has a maximum size equal to `100 MB`. On lines `22` to `24`, we use this volume and mount
    it into the container at `/var/lib/postgresql/data`, where PostgreSQL expects
    it. On line `21`, we also declare that PostgreSQL is listening at port `5432`.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，这看起来有点可怕，但其实并不是。由于我们还需要定义一个卷，让PostgreSQL数据库可以存储数据，所以它比web组件的部署定义要长一些。卷索赔定义在第25到33行。我们想要创建一个名为pets-data的卷，最大大小为100MB。在第22到24行，我们使用这个卷并将其挂载到容器中的/var/lib/postgresql/data目录，PostgreSQL期望它在那里。在第21行，我们还声明PostgreSQL正在5432端口监听。
- en: 'As always, we use kubectl to deploy the `StatefulSet`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 一如既往，我们使用kubectl来部署StatefulSet：
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, if we list all the resources in the cluster, we will be able to see the
    additional objects that were created:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们列出集群中的所有资源，我们将能够看到已创建的附加对象。
- en: '![](assets/65326383-101f-44f5-a370-5e936b3933fd.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: ！[](assets/65326383-101f-44f5-a370-5e936b3933fd.png)
- en: The StatefulSet and its pod
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet及其pod
- en: Here, we can see that a `StatefulSet` and a pod have been created. For both,
    the current state corresponds to the desired state and thus the system is healthy.
    But that doesn't mean that the web component can access the database at this time.
    Service discovery won't work so far. Remember that the web component wants to
    access the `db` service under the name `db`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到已经创建了一个StatefulSet和一个pod。对于这两者，当前状态与期望状态相符，因此系统是健康的。但这并不意味着web组件此时可以访问数据库。服务发现到目前为止还不起作用。请记住，web组件希望以db的名称访问db服务。
- en: 'To make service discovery work inside the cluster, we have to define a Kubernetes Service object
    for the database component too. Since the database should only ever be accessible
    from within the cluster, the type of Service object we need is `ClusterIP`. Here
    is the specification, which can be found in the `~/fod/ch16/db-service.yaml` file:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使服务发现在集群内部工作，我们还必须为数据库组件定义一个Kubernetes Service对象。由于数据库只能从集群内部访问，我们需要的Service对象类型是ClusterIP。以下是规范，可以在~/fod/ch16/db-service.yaml文件中找到：
- en: '![](assets/50834c86-6427-4c33-b811-089547e1aef2.png)Definition of the Kubernetes
    Service object for the database'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: ！[](assets/50834c86-6427-4c33-b811-089547e1aef2.png)数据库的Kubernetes Service对象定义
- en: 'The database component will be represented by this Service object and it can
    be reached by the name `db`, which is the name of the service, as defined on line
    `4`. The database component does not have to be publicly accessible, so we decided
    to use a Service object of the `ClusterIP` type. The selector on lines `10` to
    `12` defines that this service represents a stable endpoint for all the pods that
    have the according labels defined, that is, `app: pets` and `service: db`.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '数据库组件将由此Service对象表示，并且可以通过名称`db`访问，这是服务的名称，如第4行所定义。数据库组件不必是公开访问的，因此我们决定使用ClusterIP类型的Service对象。第10到12行的选择器定义了该服务代表具有相应标签的所有Pod的稳定端点，即`app:
    pets`和`service: db`。'
- en: 'Let''s deploy this service with the following command:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令部署此服务：
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Now, we should be ready to test the application. We can use the browser this
    time to enjoy the beautiful animal images:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们应该准备好测试应用程序了。这次我们可以使用浏览器来欣赏美丽的动物图片：
- en: '![](assets/5a43f3ff-7ac5-4b0e-af24-e2ceb59bf180.png)Testing the pets application
    running in Kubernetes'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/5a43f3ff-7ac5-4b0e-af24-e2ceb59bf180.png)在Kubernetes中运行宠物应用程序的测试'
- en: '`172.29.64.78` is the IP address of my Minikube. Verify your address using
    the `minikube ip` command. Port number `32722` is the number that Kubernetes automatically
    selected for my `web` Service object. Replace this number with the port that Kubernetes
    assigned to your service. You can get the number by using the `kubectl get services` command.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`172.29.64.78`是我的Minikube的IP地址。使用`minikube ip`命令验证您的地址。端口号`32722`是Kubernetes自动为我的`web`服务对象选择的端口号。将此数字替换为Kubernetes分配给您的服务的端口。您可以使用`kubectl
    get services`命令获取该数字。'
- en: 'Now, we have successfully deployed the pets application to Minikube, which
    is a single-node Kubernetes cluster. We had to define four artifacts to do so,
    which are as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已成功将宠物应用程序部署到了Minikube，这是一个单节点的Kubernetes集群。为此，我们必须定义四个工件，它们如下：
- en: A Deployment and a Service object for the web component
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web组件的Deployment和Service对象
- en: A StatefulSet and a Service object for the database component
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库组件的StatefulSet和Service对象
- en: 'To remove the application from the cluster, we can use the following small
    script:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 从集群中删除应用程序，我们可以使用以下小脚本：
- en: '[PRE5]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Next, we will be streamlining the deployment.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将简化部署。
- en: Streamlining the deployment
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简化部署
- en: So far, we have created four artifacts that needed to be deployed to the cluster.
    This is only a very simple application, consisting of two components. Imagine
    having a much more complex application. It would quickly become a maintenance
    nightmare. Luckily, we have several options as to how we can simplify the deployment.
    The method that we are going to discuss here is the possibility of defining all
    the components that make up an application in Kubernetes in a single file.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经创建了四个需要部署到集群的工件。这只是一个非常简单的应用程序，由两个组件组成。想象一下拥有一个更复杂的应用程序。它很快就会变成一个维护的噩梦。幸运的是，我们有几种选项可以简化部署。我们将在这里讨论的方法是在Kubernetes中定义构成应用程序的所有组件的可能性在单个文件中。
- en: Other solutions that lie outside of the scope of this book would include the
    use of a package manager, such as Helm.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 超出本书范围的其他解决方案可能包括使用Helm等软件包管理器。
- en: 'If we have an application consisting of many Kubernetes objects such as `Deployment` and `Service` objects,
    then we can keep them all in one single file and separate the individual object definitions by
    three dashes. For example, if we wanted to have the `Deployment` and the `Service`
    definition for the `web` component in a single file, this would look as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的应用程序由许多Kubernetes对象（如`Deployment`和`Service`对象）组成，那么我们可以将它们全部放在一个单独的文件中，并通过三个破折号分隔各个对象的定义。例如，如果我们想要在单个文件中为`web`组件定义`Deployment`和`Service`，则如下所示：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Here, we have collected all four object definitions for the `pets` application
    in the `~/fod/ch16/pets.yaml` file, and we can deploy the application in one go:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们已经在`~/fod/ch16/pets.yaml`文件中收集了`pets`应用程序的所有四个对象定义，并且我们可以一次性部署该应用程序：
- en: '![](assets/76a4ab56-40ed-4d1b-b372-5267d4702597.png)Using a single script to
    deploy the pets application'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/76a4ab56-40ed-4d1b-b372-5267d4702597.png)使用单个脚本部署宠物应用程序'
- en: 'Similarly, we have created a script called `~/fod/ch16/remove-pets.sh` to remove
    all the artifacts of the pets application from the Kubernetes cluster:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们创建了一个名为`~/fod/ch16/remove-pets.sh`的脚本，用于从Kubernetes集群中删除宠物应用程序的所有构件：
- en: '![](assets/5670017a-1e32-4999-8ee1-79d171f3830b.png)Removing pets from the
    Kubernetes cluster'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/5670017a-1e32-4999-8ee1-79d171f3830b.png)从Kubernetes集群中删除宠物'
- en: With this, we have taken our pets application we introduced in [Chapter 11](412c6f55-a00b-447f-b22a-47b305453507.xhtml), *Docker
    Compose*, and defined all the Kubernetes objects that are necessary to deploy
    this application into a Kubernetes cluster. In each step, we have made sure that
    we got the expected result, and once all the artifacts existed in the cluster,
    we showed the running application.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，我们已经将我们在[第11章](412c6f55-a00b-447f-b22a-47b305453507.xhtml)中介绍的宠物应用程序，*Docker
    Compose*，并定义了部署此应用程序到Kubernetes集群所必需的所有Kubernetes对象。在每个步骤中，我们确保获得了预期的结果，一旦所有构件存在于集群中，我们展示了运行中的应用程序。
- en: Defining liveness and readiness
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义存活和就绪
- en: Container orchestration systems such as Kubernetes and Docker swarm make it
    significantly easier to deploy, run, and update highly distributed, mission-critical
    applications. The orchestration engine automates many of the cumbersome tasks
    such as scaling up or down, asserting that the desired state is maintained at
    all times, and more.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 诸如Kubernetes和Docker Swarm之类的容器编排系统大大简化了部署、运行和更新高度分布式、使命关键的应用程序。编排引擎自动化了许多繁琐的任务，如扩展或缩减规模，确保始终保持所需状态等。
- en: But, the orchestration engine cannot just do everything automagically. Sometimes,
    we developers need to support the engine with some information that only we can
    know about. So, what do I mean by that?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，编排引擎并不能自动完成所有事情。有时，我们开发人员需要提供一些只有我们才知道的信息来支持引擎。那么，我是什么意思呢？
- en: Let's look at a single application service. Let's assume it is a microservice
    and let's call it **service A**. If we run service A containerized on a Kubernetes
    cluster, then Kubernetes can make sure that we have the five instances that we
    require in the service definition running at all times. If one instance crashes,
    Kubernetes can quickly launch a new instance and thus maintain the desired state.
    But, what if an instance of the service does not crash, but is unhealthy or just
    not ready yet to serve requests? It is evident that Kubernetes should know about
    both situations. But it can't, since healthy or not from an application service
    perspective is outside of the knowledge of the orchestration engine. Only we application
    developers can know when our service is healthy and when it is not.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个单个的应用服务。假设它是一个微服务，我们称之为**服务A**。如果我们在Kubernetes集群上容器化运行服务A，那么Kubernetes可以确保我们在服务定义中需要的五个实例始终运行。如果一个实例崩溃，Kubernetes可以快速启动一个新实例，从而保持所需的状态。但是，如果服务的一个实例并没有崩溃，而是不健康或者还没有准备好提供服务呢？显然，Kubernetes应该知道这两种情况。但它不能，因为从应用服务的角度来看，健康与否是编排引擎无法知道的。只有我们应用开发人员知道我们的服务何时是健康的，何时不是。
- en: The application service could, for example, be running, but its internal state
    could have been corrupted due to some bug, it could be in an endless loop, or
    in a deadlock situation. Similarly, only we application developers know if our
    service is ready to work, or if it is still initializing. Although it is highly
    recommended to keep the initialization phase of a microservice as short as possible,
    it often cannot be avoided if there is a significant time span needed by a particular
    service so that it's ready to operate. Being in this state of initialization is
    not the same thing as being unhealthy, though. The initialization phase is an
    expected part of the life cycle of a microservice or any other application service.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，应用服务可能正在运行，但由于某些错误，其内部状态可能已经损坏，它可能陷入无限循环或死锁状态。同样，只有我们应用开发人员知道我们的服务是否准备好工作，或者它是否仍在初始化。虽然建议微服务的初始化阶段尽可能短，但如果某个特定服务需要较长的时间才能准备好运行，通常是无法避免的。处于初始化状态并不等同于不健康。初始化阶段是微服务或任何其他应用服务生命周期的预期部分。
- en: Thus, Kubernetes should not try to kill our microservice if it is in the initialization
    phase. If our microservice is unhealthy, though, Kubernetes should kill it as
    quickly as possible and replace it with a fresh instance.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们的微服务处于初始化阶段，Kubernetes不应该试图终止它。但是，如果我们的微服务不健康，Kubernetes应该尽快终止它，并用新实例替换它。
- en: Kubernetes has a concept of probes to provide the seam between the orchestration
    engine and the application developer. Kubernetes uses these probes to find out
    more about the inner state of the application service at hand. Probes are executed
    locally, inside each container. There is a probe for the health – also called
    liveness – of the service, a startup probe, and a probe for the readiness of the
    service. Let's look at them in turn.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有一个探针的概念，提供编排引擎和应用程序开发人员之间的接口。Kubernetes使用这些探针来了解正在处理的应用服务的内部状态。探针在每个容器内部本地执行。有一个用于服务健康（也称为活跃性）的探针，一个用于启动的探针，以及一个用于服务就绪的探针。让我们依次来看看它们。
- en: Kubernetes liveness probe
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes活跃性探针
- en: 'Kubernetes uses the liveness probe to decide when a container needs to be killed
    and when another instance should be launched instead. Since Kubernetes operates
    at a pod level, the respective pod is killed if at least one of its containers
    reports as being unhealthy. Alternatively, we can say it the other way around:
    only if all the containers of a pod report to be healthy, is the pod considered
    to be healthy.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用活跃探针来决定何时需要终止一个容器，以及何时应该启动另一个实例。由于Kubernetes在pod级别操作，如果其至少一个容器报告为不健康，相应的pod将被终止。或者，我们可以说反过来：只有当一个pod的所有容器报告为健康时，该pod才被认为是健康的。
- en: 'We can define the liveness probe in the specification for a pod as follows:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在pod的规范中定义活跃探针如下：
- en: '[PRE7]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The relevant part is in the `livenessProbe` section. First, we define a command
    that Kubernetes will execute as a probe inside the container. In our case, we
    have a PostresSQL container and use the `netcat` Linux tool to probe port `5432`
    over TCP. The `nc localhost 5432` command is successful once Postgres listens
    at it.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 相关部分在`livenessProbe`部分。首先，我们定义一个命令，Kubernetes将在容器内部执行作为探针。在我们的例子中，我们有一个PostresSQL容器，并使用`netcat`
    Linux工具来探测TCP端口`5432`。一旦Postgres监听到它，`nc localhost 5432`命令就会成功。
- en: The other two settings, `initialDelaySeconds` and `periodSeconds`, define how
    long Kubernetes should wait after starting the container until it first executes
    the probe and how frequently the probe should be executed thereafter. In our case,
    Kubernetes waits for 10 seconds prior to executing the first probe and then executes
    a probe every 5 seconds.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 另外两个设置，`initialDelaySeconds`和`periodSeconds`，定义了Kubernetes在启动容器后应该等待多长时间才首次执行探针，以及之后探针应该以多频率执行。在我们的例子中，Kubernetes在启动容器后等待10秒才执行第一次探针，然后每5秒执行一次探针。
- en: 'It is also possible to probe an HTTP endpoint instead of using a command. Let''s
    assume we''re running a microservice from an image, `acme.com/my-api:1.0`, with
    an API that has an endpoint called `/api/health` that returns status `200 (OK)`
    if the microservice is healthy, and `50x (Error)` if it is unhealthy. Here, we
    can define the liveness probe as follows:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以探测HTTP端点，而不是使用命令。假设我们正在从一个镜像`acme.com/my-api:1.0`运行一个微服务，它有一个名为`/api/health`的端点，如果微服务健康则返回状态`200（OK）`，如果不健康则返回`50x（Error）`。在这里，我们可以定义活跃探针如下：
- en: '[PRE8]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In the preceding snippet, I have defined the liveness probe so that it uses
    the HTTP protocol and executed a `GET` request to the `/api/health` endpoint on
    port `5000` of localhost. Remember, the probe is executed inside the container,
    which means I can use localhost.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的片段中，我已经定义了活跃探针，以便它使用HTTP协议，并在本地主机的端口`5000`上执行`GET`请求到`/api/health`端点。记住，探针是在容器内执行的，这意味着我可以使用本地主机。
- en: 'We can also directly use the TCP protocol to probe a port on the container.
    But wait a second – didn''t we just do that in our first sample, where we used
    the generic liveness probe based on an arbitrary command? Yes, you''re right,
    we did. But we had to rely on the presence of the `netcat` tool in the container
    to do so. We cannot assume that this tool is always there. Thus, it is favorable
    to rely on Kubernetes to do the TCP-based probing for us out of the box. The modified
    pod spec looks like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以直接使用TCP协议来探测容器上的端口。但等一下，我们刚刚在我们的第一个示例中做过这个，我们使用了基于任意命令的通用活跃探针？是的，你说得对，我们做了。但我们必须依赖容器中`netcat`工具的存在才能这样做。我们不能假设这个工具总是存在。因此，依赖Kubernetes来为我们执行基于TCP的探测是有利的。修改后的pod规范如下：
- en: '[PRE9]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This looks very similar. The only change is that the type of probe has been
    changed from `exec` to `tcpSocket` and that, instead of providing a command, we
    provide the `port` to probe.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来非常相似。唯一的变化是探针的类型已从`exec`更改为`tcpSocket`，而不是提供一个命令，我们提供了要探测的`port`。
- en: 'Let''s try this out:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试一试：
- en: 'Navigate to the `~/fod/ch16/probes` folder and build the Docker image with
    the following command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转到`~/fod/ch16/probes`文件夹，并使用以下命令构建Docker镜像：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Use `kubectl` to deploy the sample pod that''s defined in `probes-demo.yaml`:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl`部署在`probes-demo.yaml`中定义的示例pod：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Describe the pod and specifically analyze the log part of the output:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述pod，特别分析输出的日志部分：
- en: '[PRE12]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'During the first half minute or so, you should get the following output:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的半分钟左右，你应该会得到以下输出：
- en: '![](assets/fe42b23f-d21f-4e2a-bd16-6f14c31d71b4.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/fe42b23f-d21f-4e2a-bd16-6f14c31d71b4.png)'
- en: Log output of the healthy pod
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 健康pod的日志输出
- en: 'Wait at least 30 seconds and then describe the pod again. This time, you should
    see the following output:'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待至少30秒，然后再次描述pod。这次，你应该看到以下输出：
- en: '![](assets/bb3c27de-375c-4cf1-8e23-81762ff9447f.png)Log output of the pod after
    it has changed its state to `Unhealthy`'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/bb3c27de-375c-4cf1-8e23-81762ff9447f.png)将pod的状态更改为`Unhealthy`后的日志输出'
- en: The last two lines are indicating the failure of the probe and the fact that
    the pod is going to be restarted.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两行表明了探针的失败以及pod将要重新启动的事实。
- en: 'If you get the list of pods, you will see that the pod has been restarted a
    number of times:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你获取pod列表，你会看到该pod已经重新启动了多次：
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'When you''re done with the sample, delete the pod with the following command:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成示例后，使用以下命令删除pod：
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Next, we will have a look at the Kubernetes readiness probe.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一下Kubernetes的就绪探针。
- en: Kubernetes readiness probe
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes就绪探针
- en: Kubernetes uses a readiness probe to decide when a service instance, that is,
    a container, is ready to accept traffic. Now, we all know that Kubernetes deploys
    and runs pods and not containers, so it only makes sense to talk about the readiness
    of a pod. Only if all containers in a pod report to be ready is the pod considered
    to be ready itself. If a pod reports not to be ready, then Kubernetes removes
    it from the service load balancers.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用就绪探针来决定服务实例（即容器）何时准备好接受流量。现在，我们都知道Kubernetes部署和运行的是pod而不是容器，因此谈论pod的就绪性是有意义的。只有当pod中的所有容器报告准备就绪时，pod才被认为是准备就绪的。如果一个pod报告未准备就绪，那么Kubernetes会将其从服务负载均衡器中移除。
- en: 'Readiness probes are defined exactly the same way as liveness probes: just
    switch the `livenessProbe` key in the pod spec to `readinessProbe`. Here is an
    example using our prior pod spec:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针的定义方式与活跃性探针完全相同：只需将pod规范中的`livenessProbe`键切换为`readinessProbe`。以下是使用我们之前的pod规范的示例：
- en: '[PRE15]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that, in this example, we don't really need an initial delay for the liveness
    probe anymore since we now have a readiness probe. Thus, I have replaced the initial
    delay entry for the liveness probe with an entry called `failureThreshold`, which
    is indicating how many times Kubernetes should repeat probing in case of a failure
    until it assumes that the container is unhealthy.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个例子中，我们不再需要活跃性探针的初始延迟，因为现在有了就绪探针。因此，我用一个名为`failureThreshold`的条目替换了活跃性探针的初始延迟条目，该条目指示Kubernetes在失败的情况下应重复探测多少次，直到假定容器不健康。
- en: Kubernetes startup probe
  id: totrans-129
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes启动探针
- en: It is often helpful for Kubernetes to know when a service instance has started.
    If we define a startup probe for a container, then Kubernetes does not execute
    the liveness or readiness probes, as long as the container's startup probe does
    not succeed. Once again, Kubernetes looks at pods and starts executing liveness
    and readiness probes on its containers if the startup probes of all the pod's
    containers succeed.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Kubernetes来说，了解服务实例何时启动通常是有帮助的。如果我们为容器定义了启动探针，那么只要容器的启动探针不成功，Kubernetes就不会执行活跃性或就绪性探针。再次强调，Kubernetes会查看pod，并且只有当所有pod容器的启动探针成功时，才会开始执行活跃性和就绪性探针。
- en: When would we use a startup probe, given the fact that we already have the liveness
    and readiness probes? There might be situations where we have to account for exceptionally
    long startup and initialization times, such as when containerizing a legacy application.
    We could technically configure the readiness or the liveness probes to account
    for this fact, but that would defeat the purpose of these probes. The latter probes
    are meant to provide quick feedback to Kubernetes on the health and availability
    of the container. If we configure for long initial delays or periods, then this
    would counter the desired outcome.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在什么情况下会使用启动探测，考虑到我们已经有了存活性和就绪性探测？可能会出现需要考虑异常长的启动和初始化时间的情况，比如将传统应用程序容器化时。我们可以在技术上配置就绪性或存活性探测来考虑这一事实，但这将违背这些探测的目的。后者的探测旨在为
    Kubernetes 提供有关容器健康和可用性的快速反馈。如果我们配置长时间的初始延迟或周期，那么这将抵消预期的结果。
- en: 'Unsurprisingly, the startup probe is defined exactly the same way as the readiness
    and liveness probes. Here is an example:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，启动探测的定义方式与就绪性和存活性探测完全相同。以下是一个例子：
- en: '[PRE16]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Make sure that you define the `failureThreshold * periodSeconds` product so
    that it's big enough to account for the worst startup time.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 确保定义`failureThreshold * periodSeconds`产品，以便足够大以考虑最坏的启动时间。
- en: In our example, the max startup time should not exceed 150 seconds.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，最大启动时间不应超过150秒。
- en: Zero downtime deployments
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 零停机部署
- en: 'In a mission-critical environment, it is important that the application is
    always up and running. These days, we cannot afford any downtime anymore. Kubernetes
    gives us various means of achieving this. Performing an update on an application
    in the cluster that causes no downtime is called a zero downtime deployment. In
    this section, we will present two ways of achieving this. These are as follows:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在关键任务环境中，应用程序始终保持运行是非常重要的。如今，我们不能再容忍任何停机时间。Kubernetes 给了我们各种手段来实现这一点。在集群中对应用程序执行不会导致停机的更新称为零停机部署。在本节中，我们将介绍两种实现这一目标的方法。这些方法如下：
- en: Rolling updates
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 滚动更新
- en: Blue-green deployments
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: Let's start by discussing rolling updates.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论滚动更新开始。
- en: Rolling updates
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 滚动更新
- en: In the previous chapter, we learned that the Kubernetes Deployment object distinguishes
    itself from the ReplicaSet object in that it adds rolling updates and rollbacks
    on top of the latter's functionality. Let's use our web component to demonstrate
    this. Evidently, we will have to modify the manifest or description of the deployment
    for the web component.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解到 Kubernetes 的 Deployment 对象与 ReplicaSet 对象的区别在于它在后者的功能基础上增加了滚动更新和回滚功能。让我们使用我们的
    web 组件来演示这一点。显然，我们将不得不修改 web 组件的部署清单或描述。
- en: 'We will use the same deployment definition as in the previous section, with
    one important difference – we will have five replicas of the web component running.
    The following definition can also be found in the `~/fod/ch16/web-deploy-rolling-v1.yaml` file:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用与上一节相同的部署定义，但有一个重要的区别 - 我们将有五个 web 组件的副本在运行。以下定义也可以在`~/fod/ch16/web-deploy-rolling-v1.yaml`文件中找到：
- en: '[PRE17]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we can create this deployment as usual and also, at the same time, the
    service that makes our component accessible:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像往常一样创建这个部署，同时也创建使我们的组件可访问的服务：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once we have deployed the pods and the service, we can test our web component
    with the following command:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们部署了 pod 和服务，我们可以使用以下命令测试我们的 web 组件：
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we can see, the application is up and running and returns the expected message, `Pets
    Demo Application`.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，应用程序正在运行，并返回预期的消息`Pets Demo Application`。
- en: 'Now. our developers have created a new version, 2.1, of the `web` component.
    The code of the new version of the `web` component can be found in the `~/fod/ch16/web` folder, and
    the only change is located on line `12` of the `server.js` file:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的开发人员已经创建了一个新版本2.1的`web`组件。新版本的`web`组件的代码可以在`~/fod/ch16/web`文件夹中找到，唯一的更改位于`server.js`文件的第12行：
- en: '![](assets/70fa34d3-69f4-4f3a-a7ae-593b02df74f6.png)Code change for version
    2.0 of the web component'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/70fa34d3-69f4-4f3a-a7ae-593b02df74f6.png)Web组件2.0版本的代码更改'
- en: 'The developers have built the new image as follows:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 开发人员已经按以下方式构建了新的镜像：
- en: '[PRE20]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Subsequently, they pushed the image to Docker Hub, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，他们将镜像推送到Docker Hub，如下所示：
- en: '[PRE21]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, we want to update the image that''s used by our pods that are part of
    the web Deployment object. We can do this by using the `set image` command of `kubectl`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们想要更新`web`部署对象中的pod所使用的镜像。我们可以使用`kubectl`的`set image`命令来实现这一点：
- en: '[PRE22]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If we test the application again, we''ll get a confirmation that the update
    has indeed happened:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次测试应用程序，我们将得到一个确认，更新确实已经发生：
- en: '[PRE23]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, how do we know that there hasn''t been any downtime during this update? Did
    the update really happen in a rolling fashion? What does rolling update mean at
    all? Let''s investigate. First, we can get a confirmation from Kubernetes that
    the deployment has indeed happened and was successful by using the `rollout status` command:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们如何知道在此更新过程中没有发生任何停机时间？更新确实是以滚动方式进行的吗？滚动更新到底意味着什么？让我们来调查一下。首先，我们可以通过使用`rollout
    status`命令从Kubernetes那里得到确认，部署确实已经发生并且成功了：
- en: '[PRE24]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'If we describe the deployment web with `kubectl describe deploy/web`, we get
    the following list of events at the end of the output:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们用`kubectl describe deploy/web`描述部署web，我们会在输出的最后得到以下事件列表：
- en: '![](assets/5fd7c6ba-dbce-4d6e-8d77-f6296c87dc06.png) List of events found in
    the output of the deployment description of the web component'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/5fd7c6ba-dbce-4d6e-8d77-f6296c87dc06.png)Web组件部署描述输出中找到的事件列表'
- en: 'The first event tells us that, when we created the deployment, a ReplicaSet
    called `web-769b88f67` with five replicas was created. Then, we executed the update command.
    The second event in the list tells us that this meant creating a new ReplicaSet called `web-55cdf67cd` with,
    initially, one replica only. Thus, at that particular moment, six pods existed
    on the system: the five initial pods and one pod with the new version. But, since
    the desired state of the Deployment object states that we want five replicas only,
    Kubernetes now scales down the old ReplicaSet to four instances, which we can
    see in the third event.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个事件告诉我们，在创建部署时，一个名为`web-769b88f67`的ReplicaSet被创建，有五个副本。然后，我们执行了更新命令。列表中的第二个事件告诉我们，这意味着创建一个名为`web-55cdf67cd`的新ReplicaSet，最初只有一个副本。因此，在那个特定的时刻，系统上存在六个pod：五个初始pod和一个具有新版本的pod。但是，由于部署对象的期望状态指定我们只想要五个副本，Kubernetes现在将旧的ReplicaSet缩减到四个实例，我们可以在第三个事件中看到。
- en: Then, again, the new ReplicaSet is scaled up to two instances and, subsequently,
    the old ReplicaSet scaled was down to three instances, and so on, until we had
    five new instances and all the old instances were decommissioned. Although we
    cannot see any precise time (other than 3 minutes) when that happened, the order
    of the events tells us that the whole update happened in a rolling fashion.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，新的ReplicaSet再次扩展到两个实例，随后，旧的ReplicaSet缩减到三个实例，依此类推，直到我们有了五个新实例，所有旧实例都被废弃。虽然我们无法看到确切的时间（除了3分钟），这发生的顺序告诉我们整个更新是以滚动方式进行的。
- en: During a short time period, some of the calls to the web service would have
    had an answer from the old version of the component, and some calls would have
    received an answer from the new version of the component, but, at no time would
    the service have been down.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在短时间内，对web服务的一些调用可能会得到来自组件的旧版本的答复，而一些调用可能会得到来自组件的新版本的答复，但是服务从未中断。
- en: 'We can also list the ReplicaSet objects in the cluster and will get confirmation
    of what I said in the preceding section:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以列出集群中的ReplicaSet对象，并确认我在前面部分所说的内容：
- en: '![](assets/3a04d23d-d8d2-4f3b-a4d2-4235bac45448.png)Listing all the ReplicaSet
    objects in the cluster'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/3a04d23d-d8d2-4f3b-a4d2-4235bac45448.png)列出集群中的所有ReplicaSet对象'
- en: Here, we can see that the new ReplicaSet has five instances running and that
    the old one has been scaled down to zero instances. The reason that the old ReplicaSet object
    is still lingering is that Kubernetes provides us with the possibility of rolling
    back the update and, in that case, will reuse that ReplicaSet.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以看到新的ReplicaSet有五个实例在运行，而旧的ReplicaSet已被缩减为零个实例。旧的ReplicaSet对象仍然存在的原因是Kubernetes为我们提供了回滚更新的可能性，在这种情况下，将重用该ReplicaSet。
- en: 'To roll back the update of the image in case some undetected bug sneaked into
    the new code, we can use the `rollout undo` command:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回滚图像的更新，以防一些未被检测到的错误潜入新代码，我们可以使用`rollout undo`命令：
- en: '[PRE25]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'I have also listed the test command using `curl` in the preceding snippet to
    verify that the rollback indeed happened. If we list the ReplicaSets, we will
    see the following output:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我还在前面的片段中列出了使用`curl`进行测试的命令，以验证回滚确实发生了。如果我们列出ReplicaSets，我们将看到以下输出：
- en: '![](assets/7ef8b322-07e3-43e1-81a1-9bd7af4d1a3d.png)Listing ReplicaSet objects
    after rollback'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/7ef8b322-07e3-43e1-81a1-9bd7af4d1a3d.png)回滚后列出ReplicaSet对象'
- en: This confirms that the old ReplicaSet (`web-769b88f67`) object has been reused
    and that the new one has been scaled down to zero instances.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这证实了旧的ReplicaSet（`web-769b88f67`）对象已被重用，新的ReplicaSet已被缩减为零个实例。
- en: Sometimes, though, we cannot, or do not want to, tolerate the mixed state of
    an old version coexisting with the new version. We want an *all-or-nothing* strategy.
    This is where blue-green deployments come into play, which we will discuss next.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时我们不能或不想容忍旧版本与新版本共存的混合状态。我们希望采取“全有或全无”的策略。这就是蓝绿部署发挥作用的地方，接下来我们将讨论这个问题。
- en: Blue-green deployment
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: 'If we want to do a blue-green style deployment for our component web of the
    pets application, then we can do so by using labels creatively. First, let''s
    remind ourselves how blue-green deployments work. Here is a rough step-by-step
    instruction:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要为宠物应用程序的web组件执行蓝绿部署，那么我们可以通过创造性地使用标签来实现。首先，让我们回顾一下蓝绿部署的工作原理。以下是一个大致的逐步说明：
- en: 'Deploy the first version of the `web` component as `blue`. We will label the
    pods with a label of `color: blue` to do so.'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '部署`web`组件的第一个版本为`blue`。我们将使用`color: blue`标签为pod打上标签。'
- en: 'Deploy the Kubernetes service for these pods with the `color: blue` label in
    the selector section.'
  id: totrans-179
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '使用`color: blue`标签在选择器部分为这些pod部署Kubernetes服务。'
- en: 'Now, we can deploy version 2 of the web component, but, this time, the pods
    have a label of `color: green`.'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，我们可以部署版本2的web组件，但是这一次，pod的标签是`color: green`。'
- en: We can test the green version of the service to check that it works as expected.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以测试服务的绿色版本，以检查它是否按预期工作。
- en: 'Now, we flip traffic from blue to green by updating the Kubernetes service
    for the web component. We modify the selector so that it uses the `color: green` label.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '现在，我们通过更新web组件的Kubernetes服务，将流量从蓝色切换到绿色。我们修改选择器，使其使用`color: green`标签。'
- en: 'Let''s define a Deployment object for version 1, blue:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为版本1（蓝色）定义一个Deployment对象：
- en: '![](assets/9f7a8ee5-54bb-4e8d-99f6-63deae81e7bd.png)Specification of the blue
    deployment for the web component'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Web组件的蓝色部署规范
- en: 'The preceding definition can be found in the `~/fod/ch16/web-deploy-blue.yaml` file.
    Please take note of line `4`, where we define the name of the deployment as `web-blue` to
    distinguish it from the upcoming deployment, `web-green`. Also, note that we have
    added the label `color: blue` on lines `11` and `17`. Everything else remains
    the same as before.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '前面的定义可以在“~/fod/ch16/web-deploy-blue.yaml”文件中找到。请注意第4行，我们在那里定义了部署的名称为“web-blue”，以区分它与即将到来的部署“web-green”。还要注意，我们在第11行和第17行添加了标签“color:
    blue”。其他一切与以前一样。'
- en: 'Now, we can define the Service object for the web component. It will be the
    same as the one we used before but with a minor change, as shown in the following
    screenshot:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以为Web组件定义Service对象。它将与之前使用的相同，但有一个小改变，如下面的屏幕截图所示：
- en: '![](assets/7a1661a0-137e-402c-a664-a8ad9ea1df56.png)Kubernetes service for
    the web component supporting blue-green deployments'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes服务支持蓝绿部署的Web组件
- en: 'The only difference regarding the definition of the service we used earlier
    in this chapter is line `13`, which adds the `color: blue` label to the selector.
    We can find the preceding definition in the `~/fod/ch16/web-svc-blue-green.yaml` file.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '关于我们在本章前面使用的服务定义的唯一区别是第13行，它在选择器中添加了“color: blue”标签。我们可以在“~/fod/ch16/web-svc-blue-green.yaml”文件中找到前面的定义。'
- en: 'Then, we can deploy the blue version of the web component with the following
    command:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以使用以下命令部署Web组件的蓝色版本：
- en: '[PRE26]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Once the service is up and running, we can determine its IP address and port
    number and test it:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦服务启动运行，我们可以确定其IP地址和端口号并进行测试：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'As expected, we get the response `Pets Demo Application`. Now, we can deploy
    the green version of the web component. The definition of its Deployment object
    can be found in the `~/fod/ch16/web-deploy-green.yaml` file and looks as follows:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，我们得到了“宠物演示应用程序”的响应。现在，我们可以部署Web组件的绿色版本。其部署对象的定义可以在“~/fod/ch16/web-deploy-green.yaml”文件中找到，如下所示：
- en: '![](assets/b87b509f-c2ac-4dd6-bc19-5b7f55c9143a.png)Specification of the deployment
    green for the web component'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 部署绿色Web组件的规范
- en: 'The interesting lines are as follows:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的行如下：
- en: 'Line `4`: Named `web-green` to distinguish it from `web-blue` and allow for
    parallel installation'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第4行：命名为“web-green”以区分它与“web-blue”并允许并行安装
- en: 'Lines `11` and `17`: Have the color `green`'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第11行和第17行：颜色为绿色
- en: 'Line `20`: Now using version `2.1` of the image'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第20行：现在使用图像的2.1版本
- en: 'Now, we''re ready to deploy this green version of the service. It should run
    separately from the blue service:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备部署这个绿色版本的服务。它应该与蓝色服务分开运行。
- en: '[PRE28]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We can make sure that both deployments coexist like so:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以确保两个部署共存如下：
- en: '![](assets/4bd95b70-62d5-4697-a3d4-e67b4383a4ae.png)Displaying the list of
    Deployment objects running in the cluster'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 显示在集群中运行的部署对象列表
- en: 'As expected, we have both blue and green running. We can verify that blue is
    still the active service:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，蓝色和绿色都在运行。我们可以验证蓝色仍然是活动服务：
- en: '[PRE29]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now comes the interesting part. We can flip traffic from blue to green by editing
    the existing service for the web component. To do so, execute the following command:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是有趣的部分。我们可以通过编辑Web组件的现有服务将流量从蓝色切换到绿色。为此，请执行以下命令：
- en: '[PRE30]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Change the value of the label color from `blue` to `green`. Then, save and
    quit the editor. The Kubernetes CLI will automatically update the service. When
    we now query the web service again, we get this:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 将标签颜色的值从蓝色更改为绿色。然后保存并退出编辑器。Kubernetes CLI将自动更新服务。现在再次查询web服务时，我们会得到这个：
- en: '[PRE31]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: This confirms that the traffic has indeed switched to the green version of the
    web component (note the `v2` at the end of the response to the `curl` command).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 这证实了流量确实已经切换到web组件的绿色版本（注意响应`curl`命令末尾的`v2`）。
- en: If we realize that something went wrong with our green deployment and the new
    version has a defect, we can easily switch back to the blue version by editing
    the service web again and replacing the value of the label color with blue. This
    rollback is instantaneous and should always work. Then, we can remove the buggy
    green deployment and fix the component. When we have corrected the problem, we
    can deploy the green version once again.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们意识到我们的绿色部署出了问题，新版本有缺陷，我们可以通过再次编辑服务web并将标签颜色的值替换为蓝色，轻松地切换回蓝色版本。这种回滚是瞬时的，应该总是有效的。然后，我们可以移除有问题的绿色部署并修复组件。当我们纠正了问题后，我们可以再次部署绿色版本。
- en: 'Once the green version of the component is running as expected and performing
    well, we can decommission the blue version:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦组件的绿色版本按预期运行并表现良好，我们可以停用蓝色版本：
- en: '[PRE32]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: When we're ready to deploy a new version, 3.0, this one becomes the blue version.
    We update the `~/fod/ch16/web-deploy-blue.yaml` file accordingly and deploy it.
    Then, we flip the service web from `green` to `blue`, and so on.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们准备部署新版本3.0时，这个版本成为蓝色版本。我们相应地更新`~/fod/ch16/web-deploy-blue.yaml`文件并部署它。然后，我们将服务web从绿色切换到蓝色，依此类推。
- en: We have successfully demonstrated, with our component web of the pets application,
    how blue-green deployment can be achieved in a Kubernetes cluster.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功地演示了在Kubernetes集群中如何实现蓝绿部署，使用了宠物应用程序的web组件。
- en: Kubernetes secrets
  id: totrans-215
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes秘密
- en: Sometimes, services that we want to run in the Kubernetes cluster have to use
    confidential data such as passwords, secret API keys, or certificates, to name
    just a few. We want to make sure that this sensitive information can only ever
    be seen by the authorized or dedicated service. All other services running in
    the cluster should not have any access to this data.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们希望在Kubernetes集群中运行的服务必须使用诸如密码、秘密API密钥或证书等机密数据。我们希望确保这些敏感信息只能被授权或专用服务看到。集群中运行的所有其他服务都不应该访问这些数据。
- en: For this reason, Kubernetes secrets have been introduced. A secret is a key-value
    pair where the key is the unique name of the secret and the value is the actual
    sensitive data. Secrets are stored in etcd. Kubernetes can be configured so that
    secrets are encrypted at rest, that is, in etcd, and in transit, that is, when
    the secrets are going over the wire from a master node to the worker nodes that
    the pods of the service using this secret are running on.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Kubernetes引入了秘密。秘密是一个键值对，其中键是秘密的唯一名称，值是实际的敏感数据。秘密存储在etcd中。Kubernetes可以配置为在休息时加密秘密，即在etcd中，以及在传输时，即当秘密从主节点传输到运行使用该秘密的服务的工作节点时。
- en: Manually defining secrets
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 手动定义秘密
- en: 'We can create a secret declaratively the same way as we can create any other
    object in Kubernetes. Here is the YAML for such a secret:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像在Kubernetes中创建任何其他对象一样，声明性地创建一个秘密。以下是这样一个秘密的YAML：
- en: '[PRE33]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The preceding definition can be found in the `~/fod/ch16/pets-secret.yaml` file.
    Now, you might be wondering what the values are. Are these the real (unencrypted)
    values? No, they are not. And they are also not really encrypted values, but just base64-encoded
    values. Thus, they are not really secure, since base64-encoded values can be easily
    reverted to clear text values. How did I get these values? That''s easy: follow
    these steps:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的定义可以在`~/fod/ch16/pets-secret.yaml`文件中找到。现在，你可能想知道这些值是什么。这些是真实的（未加密）值吗？不，不是。它们也不是真正加密的值，而只是base64编码的值。因此，它们并不是真正安全的，因为base64编码的值可以很容易地恢复为明文值。我是如何得到这些值的？很简单：按照以下步骤：
- en: 'Use the `base64` tool as follows to encode the values:'
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`base64`工具如下编码值：
- en: '![](assets/bbd59476-831a-40c9-b69e-96b1cacfe2f1.png)Creating base64-encoded
    values for the secret'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/bbd59476-831a-40c9-b69e-96b1cacfe2f1.png)创建秘密的base64编码值'
- en: 'Using the preceding values, we can create the secret and describe it:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用前面的值，我们可以创建秘密并描述它：
- en: '![](assets/df5c56b3-47a4-4ad5-9724-dc08beca28e5.png)Creating and describing
    the Kubernetes secret'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/df5c56b3-47a4-4ad5-9724-dc08beca28e5.png)创建和描述Kubernetes秘密'
- en: 'In the description of the secret, the values are hidden and only their length
    is given. So, maybe the secrets are safe now? No, not really. We can easily decode
    this secret using the `kubectl get` command:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在秘密的描述中，值是隐藏的，只给出了它们的长度。所以，也许现在秘密是安全的？不，不是真的。我们可以很容易地使用`kubectl get`命令解码这个秘密：
- en: '![](assets/75e781a7-6783-47aa-afe0-d26ff4e7e7b6.png)Kubernetes secret decoded'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/75e781a7-6783-47aa-afe0-d26ff4e7e7b6.png)Kubernetes秘密解码'
- en: As we can see in the preceding screenshot, we have our original secret values
    back.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的截图中看到的，我们恢复了我们的原始秘密值。
- en: 'Decode the values you got previously:'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解码之前获得的值：
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Thus, the consequences are that this method of creating a Kubernetes is not
    to be used in any environment other than development, where we deal with non-sensitive
    data. In all other environments, we need a better way to deal with secrets.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这种创建Kubernetes的方法的后果是不应该在除了开发环境之外的任何环境中使用，我们在那里处理非敏感数据。在所有其他环境中，我们需要更好的方法来处理秘密。
- en: Creating secrets with kubectl
  id: totrans-232
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用kubectl创建秘密
- en: 'A much safer way to define secrets is to use `kubectl`. First, we create files containing
    the base64-encoded secret values similar to what we did in the preceding section,
    but, this time, we store the values in temporary files:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 定义秘密的一个更安全的方法是使用`kubectl`。首先，我们创建包含base64编码的秘密值的文件，类似于我们在前面的部分所做的，但是这次，我们将值存储在临时文件中：
- en: '[PRE35]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Now, we can use `kubectl` to create a secret from those files, as follows:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用`kubectl`从这些文件中创建一个秘密，如下所示：
- en: '[PRE36]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The secret can then be used the same way as the manually created secret.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 秘密可以像手动创建的秘密一样使用。
- en: Why is this method more secure than the other one, you might ask? Well, first
    of all, there is no YAML that defines a secret and is stored in some source code
    version control system, such as GitHub, which many people have access to and so
    can see and decode the secrets. Only the admin that is authorized to know the
    secrets ever sees their values and uses them to directly create the secrets in
    the (production) cluster. The cluster itself is protected by role-based access
    control so that no unauthorized persons have access to it, nor can they possibly
    decode the secrets defined in the cluster.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么这种方法比另一种方法更安全？首先，没有定义秘密并存储在一些源代码版本控制系统（如GitHub）中的YAML，许多人都可以访问并查看和解码秘密。只有被授权知道秘密的管理员才能看到它们的值并直接在（生产）集群中创建秘密。集群本身受基于角色的访问控制的保护，因此未经授权的人员无法访问它，也无法解码集群中定义的秘密。
- en: Now, let's see how we can actually use the secrets that we have defined.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们如何实际使用我们定义的秘密。
- en: Using secrets in a pod
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在pod中使用秘密
- en: 'Let''s say we want to create a Deployment object where the web component uses
    our secret, `pets-secret`, that we introduced in the preceding section. We can
    use the following command to create the secret in the cluster:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要创建一个`Deployment`对象，其中`web`组件使用我们在前一节中介绍的秘密`pets-secret`。我们可以使用以下命令在集群中创建秘密：
- en: '[PRE37]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'In the `~/fod/ch16/web-deploy-secret.yaml` file, we can find the definition
    of the `Deployment` object. We had to add the part starting from line `23` to
    the original definition of the `Deployment` object:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在`~/fod/ch16/web-deploy-secret.yaml`文件中，我们可以找到`Deployment`对象的定义。我们不得不添加从第`23`行开始的部分到`Deployment`对象的原始定义中：
- en: '![](assets/f52d1a33-412d-4270-8f9c-8bc86346e616.png)Deployment object for the web
    component with a secret'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/f52d1a33-412d-4270-8f9c-8bc86346e616.png)带有秘密的web组件的部署对象'
- en: On lines `27` through `30`, we define a volume called `secrets` from our secret, `pets-secret`.
    Then, we use this volume in the container, as described on lines `23` through
    `26`. We mount the secrets in the container filesystem at `/etc/secrets` and we
    mount the volume in read-only mode. Thus, the secret values will be available
    to the container as files in the said folder. The names of the files will correspond
    to the key names, and the content of the files will be the values of the corresponding
    keys. The values will be provided in unencrypted form to the application running
    inside the container.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在第`27`到`30`行，我们定义了一个名为`secrets`的卷，来自我们的秘密`pets-secret`。然后，我们在容器中使用这个卷，如第`23`到`26`行所述。我们在容器文件系统中挂载秘密到`/etc/secrets`，并且以只读模式挂载卷。因此，秘密值将作为文件出现在容器中的文件夹中。文件的名称将对应于键名，文件的内容将是相应键的值。这些值将以未加密的形式提供给容器内运行的应用程序。
- en: 'In our case, since we have the `username` and `password` keys in the secret,
    we will find two files, named `username `and `password`, in the `/etc/secrets` folder
    in the container filesystem. The `username` file should contain the value `john.doe` and
    the `password` file should contain the value `sEcret-pasSw0rD`. Here is the confirmation:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，由于我们在秘密中有`username`和`password`键，我们将在容器文件系统的`/etc/secrets`文件夹中找到两个文件，名为`username`和`password`。`username`文件应包含值`john.doe`，`password`文件应包含值`sEcret-pasSw0rD`。这是确认：
- en: '![](assets/1c911dec-f905-45e6-adff-8df72c62b729.png)Confirming that secrets
    are available inside the container'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/1c911dec-f905-45e6-adff-8df72c62b729.png)确认秘密在容器内可用'
- en: On line `1` of the preceding output, we `exec` into the container where the
    web component runs. Then, on lines `2` to `5`, we list the files in the `/etc/secrets` folder,
    and, finally, on lines `6` to `8`, we show the content of the two files, which,
    unsurprisingly, show the secret values in clear text.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面输出的第`1`行，我们`exec`进入web组件运行的容器。然后，在第`2`到`5`行，我们列出了`/etc/secrets`文件夹中的文件，最后，在第`6`到`8`行，我们显示了两个文件的内容，毫不奇怪地显示了明文的秘密值。
- en: Since any application written in any language can read simple files, this mechanism
    of using secrets is very backward compatible. Even an old Cobol application can
    read clear text files from the filesystem.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任何语言编写的应用程序都可以读取简单的文件，因此使用秘密的这种机制非常向后兼容。甚至一个老的Cobol应用程序也可以从文件系统中读取明文文件。
- en: Sometimes, though, applications expect secrets to be available in environment
    variables. Let's look at what Kubernetes offers us in this case.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时应用程序希望秘密以环境变量的形式可用。让我们看看Kubernetes在这种情况下为我们提供了什么。
- en: Secret values in environment variables
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 环境变量中的秘密值
- en: 'Let''s say our web component expects the username in the environment variable, `PETS_USERNAME`,
    and the password in `PETS_PASSWORD`. If this is the case, we can modify our deployment
    YAML so that it looks as follows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的web组件期望在环境变量`PETS_USERNAME`中找到用户名，在`PETS_PASSWORD`中找到密码。如果是这种情况，我们可以修改我们的部署YAML文件，使其如下所示：
- en: '![](assets/30bcf71f-93a0-4fd9-855c-808380d22767.png)Deployment mapping secret
    values to environment variables'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/30bcf71f-93a0-4fd9-855c-808380d22767.png)部署映射秘密值到环境变量'
- en: On lines `23` through `33`, we define the two environment variables, `PETS_USERNAME` and `PETS_PASSWORD`,
    and map the corresponding key-value pair of `pets-secret` to them.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在第23到33行，我们定义了两个环境变量`PETS_USERNAME`和`PETS_PASSWORD`，并将`pets-secret`的相应键值对映射到它们。
- en: 'Note that we don''t need a volume anymore; instead, we directly map the individual
    keys of our `pets-secret` into the corresponding environment variables that are
    valid inside the container. The following sequence of commands shows that the
    secret values are indeed available inside the container in the respective environment
    variables:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们不再需要卷；相反，我们直接将`pets-secret`的各个键映射到容器内部有效的相应环境变量中。以下命令序列显示了秘密值确实在容器内部作为相应的环境变量可用：
- en: '![](assets/e8372fc5-eb69-49c9-be2d-3fe7570f0b74.png)Secret values are mapped
    to environment variables'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/e8372fc5-eb69-49c9-be2d-3fe7570f0b74.png)秘密值映射到环境变量'
- en: In this section, we have shown you how to define secrets in a Kubernetes cluster
    and how to use those secrets in containers running as part of the pods of a deployment.
    We have shown two variants of how secrets can be mapped inside a container, the
    first using files and the second using environment variables.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们向您展示了如何在Kubernetes集群中定义秘密，并如何在作为部署的一部分运行的容器中使用这些秘密。我们展示了两种在容器内部映射秘密的变体，第一种使用文件，第二种使用环境变量。
- en: Summary
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have learned how to deploy an application into a Kubernetes
    cluster and how to set up application-level routing for this application. Furthermore,
    we have learned how to update application services running in a Kubernetes cluster
    without causing any downtime. Finally, we used secrets to provide sensitive information
    to application services running in the cluster.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何将应用程序部署到Kubernetes集群中，以及如何为该应用程序设置应用程序级别的路由。此外，我们还学习了如何在Kubernetes集群中运行的应用程序服务中进行更新而不会造成任何停机时间。最后，我们使用秘密来向运行在集群中的应用程序服务提供敏感信息。
- en: In the next chapter, we are going to learn about different techniques that are
    used to monitor an individual service or a whole distributed application running
    on a Kubernetes cluster. We will also learn how we can troubleshoot an application
    service that is running in production without altering the cluster or the cluster
    nodes that the service is running on. Stay tuned.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习有关用于监视在Kubernetes集群上运行的单个服务或整个分布式应用程序的不同技术。我们还将学习如何在生产环境中运行的应用程序服务进行故障排除，而不会改变集群或运行服务的集群节点。敬请关注。
- en: Questions
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'To assess your learning progress, please answer the following questions:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估你的学习进度，请回答以下问题：
- en: You have an application consisting of two services, the first one being a web
    API and the second one being a DB, such as Mongo DB. You want to deploy this application
    into a Kubernetes cluster. In a few short sentences, explain how you would proceed.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你有一个由两个服务组成的应用程序，第一个是web API，第二个是一个数据库，比如Mongo DB。你想将这个应用程序部署到Kubernetes集群中。简要解释一下你会如何进行。
- en: Describe in your own words what components you need in order to establish layer
    7 (or application level) routing for your application.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 描述一下你需要哪些组件才能为你的应用程序建立第7层（或应用程序级）路由。
- en: List the main steps needed to implement a blue-green deployment for a simple
    application service. Avoid going into too much detail.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出实施简单应用服务的蓝绿部署所需的主要步骤。避免过多细节。
- en: Name three or four types of information that you would provide to an application
    service through Kubernetes secrets.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将通过Kubernetes秘密向应用服务提供三到四种类型的信息。
- en: Name the sources that Kubernetes accepts when creating a secret.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes在创建秘密时接受哪些来源的名称。
- en: Further reading
  id: totrans-268
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Here are a few links that provide additional information on the topics that
    were discussed in this chapter:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些链接，提供了本章讨论的主题的更多信息：
- en: Performing a rolling update: [https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行滚动更新：[https://bit.ly/2o2okEQ](https://bit.ly/2o2okEQ)
- en: Blue-green deployment: [https://bit.ly/2r2IxNJ](https://bit.ly/2r2IxNJ)
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蓝绿部署：[https://bit.ly/2r2IxNJ](https://bit.ly/2r2IxNJ)
- en: Secrets in Kubernetes: [https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes中的秘密：[https://bit.ly/2C6hMZF](https://bit.ly/2C6hMZF)
