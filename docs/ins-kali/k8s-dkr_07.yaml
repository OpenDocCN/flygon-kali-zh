- en: '*Chapter 5*: Kubernetes Bootcamp'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章：Kubernetes训练营
- en: We are sure that many of you have used Kubernetes in some capacity—you may have
    clusters running in production or you may have kicked the tires using kubeadm,
    Minikube, or Docker Desktop. Our goal for this book is to go beyond the basics
    of Kubernetes and, as such, we didn't want to rehash all of the basics of Kubernetes.
    Instead, we added this chapter as a bootcamp for anyone that may be new to Kubernetes
    or might have only played around with it a bit.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信你们中的许多人在某种程度上使用过Kubernetes——您可能在生产环境中运行集群，或者您可能使用过kubeadm、Minikube或Docker
    Desktop进行试验。我们的目标是超越Kubernetes的基础知识，因此我们不想重复Kubernetes的所有基础知识。相反，我们添加了这一章作为一个训练营，供那些可能对Kubernetes还不熟悉，或者可能只是稍微玩过一下的人参考。
- en: Since it is a bootcamp chapter we will not get in-depth on every topic, but
    by the end, you should know enough about the basics of Kubernetes to understand
    the remaining chapters. If you have a strong Kubernetes background, you may still
    find this chapter useful as a refresher, and we will get into more complex topics
    starting in [*Chapter 6*](B15514_06_Final_ASB_ePub.xhtml#_idTextAnchor174)*, Services,
    Load Balancing, and External DNS.*
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个训练营章节，我们不会深入讨论每个主题，但到最后，您应该对Kubernetes的基础知识有足够的了解，以理解剩下的章节。如果您对Kubernetes有很强的背景，您可能仍然会发现本章对您有用，因为它可以作为一个复习，我们将在第6章《服务、负载均衡和外部DNS》开始讨论更复杂的主题。
- en: In this chapter, we will cover the components of a running Kubernetes cluster,
    which include the control plane and the worker node(s). We will detail each Kubernetes
    object and its use cases. If you have used Kubernetes in the past and are comfortable
    using **kubectl** and fully understand Kubernetes objects (such as **DaemonSets**,
    **StatefulSets**, **ReplicaSets**, and so on…), you may want to jump to [*Chapter
    6*](B15514_06_Final_ASB_ePub.xhtml#_idTextAnchor174), *Services, Load Balancing,
    and External DNS*, where we will install Kubernetes using KinD.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将介绍运行中的Kubernetes集群的组件，包括控制平面和工作节点。我们将详细介绍每个Kubernetes对象及其用例。如果您以前使用过Kubernetes，并且熟悉使用kubectl并完全了解Kubernetes对象（如DaemonSets，StatefulSets，ReplicaSets等），您可能希望跳转到第6章《服务、负载均衡和外部DNS》，在那里我们将使用KinD安装Kubernetes。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: An overview of Kubernetes components
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes组件概述
- en: Exploring the control plane
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索控制平面
- en: Understanding the worker node components
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解工作节点组件
- en: Interacting with the API server
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与API服务器交互
- en: Introducing Kubernetes objects
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Kubernetes对象
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter has the following technical requirements:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章有以下技术要求：
- en: An Ubuntu 18.04 server with a minimum of 4 **gigabytes** (**GB**) of **random-access
    memory** (**RAM**)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有至少4GB随机存取内存（RAM）的Ubuntu 18.04服务器
- en: A KinD Kubernetes cluster
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个KinD Kubernetes集群
- en: 'You can access the code for this chapter at the following GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在以下GitHub存储库中访问本章的代码：[https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide](https://github.com/PacktPublishing/Kubernetes-and-Docker-The-Complete-Guide)。
- en: An overview of Kubernetes components
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes组件概述
- en: In any infrastructure, it is always a good idea to understand how the systems
    work together to provide services. With so many installer options out there today,
    many Kubernetes users have not had the need to understand how Kubernetes components
    integrate.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在任何基础设施中，了解系统如何共同提供服务总是一个好主意。如今有这么多安装选项，许多Kubernetes用户并不需要了解Kubernetes组件如何集成。
- en: A few short years ago, if you wanted to run a Kubernetes cluster, you needed
    to install and configure each component manually. It was a steep learning curve
    to install a functioning cluster, which often led to frustration, causing many
    people and companies to say *"Kubernetes is just too difficult"*. The advantage
    of installing manually was that you truly understood how each component interacted,
    and if your cluster ran into issues after installation, you knew what to look
    for.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 短短几年前，如果您想运行一个Kubernetes集群，您需要手动安装和配置每个组件。安装一个运行的集群是一个陡峭的学习曲线，经常导致挫折，让许多人和公司说“Kubernetes太难了”。手动安装的优势在于，您真正了解每个组件是如何交互的，如果安装后您的集群遇到问题，您知道要查找什么。
- en: Nowadays, most people will click a button on a cloud provider and have a fully
    functioning Kubernetes cluster in minutes. On-premise installations have become
    just as easy, with options from Google, RedHat, Rancher, and more, removing the
    complexities of installing a Kubernetes cluster. The issues we see occur when
    you run into a problem or have questions after the installation. Since you didn't
    configure the Kubernetes components, you may not be able to explain to a developer
    how a Pod is scheduled on a worker node. Lastly, since you are running an installer
    provided by a third party, they may enable or disable features that you are not
    aware of, leading to an installation that may be against your company's security
    standards.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，大多数人会在云服务提供商上点击一个按钮，几分钟内就可以拥有一个完全运行的Kubernetes集群。本地安装也变得同样简单，谷歌、红帽、牧场等提供了选项，消除了安装Kubernetes集群的复杂性。我们看到的问题是，当安装后遇到问题或有疑问时。由于您没有配置Kubernetes组件，您可能无法向开发人员解释Pod是如何在工作节点上调度的。最后，由于您正在运行第三方提供的安装程序，他们可能启用或禁用您不知道的功能，导致安装可能违反您公司的安全标准。
- en: 'To understand how Kubernetes components work together, you must first understand
    the different components of a Kubernetes cluster. The following diagram is from
    the **Kubernetes.io** site and shows a high-level overview of a Kubernetes cluster
    component:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解Kubernetes组件如何协同工作，首先必须了解Kubernetes集群的不同组件。以下图表来自**Kubernetes.io**网站，显示了Kubernetes集群组件的高级概述：
- en: '![Figure 5.1 – Kubernetes cluster components'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.1 - Kubernetes集群组件'
- en: '](image/Fig_5.1_B15514.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.1_B15514.jpg)'
- en: Figure 5.1 – Kubernetes cluster components
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 - Kubernetes集群组件
- en: As you can see, the Kubernetes cluster is made up of several components. As
    we progress through the chapter, we'll discuss these components and the role they
    play in a Kubernetes cluster.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，Kubernetes集群由多个组件组成。随着我们在本章中的进展，我们将讨论这些组件及它们在Kubernetes集群中的作用。
- en: Exploring the control plane
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索控制平面
- en: As its name suggests, the control plane controls every aspect of a cluster.
    If your control plane goes down, you can probably imagine that your cluster will
    encounter issues. Without a control plane, a cluster will not have any scheduling
    abilities, which means that workloads that are running will remain running unless
    they are stopped and restarted. Since the control plane is extremely important,
    it is always suggested that you have at least three master nodes. Many production
    installations run more than three master nodes, but the number of installed nodes
    should always be an odd number. Let's look at why the control plane and its components
    are so vital to a running cluster by examining each one.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，控制平面控制集群的每个方面。如果您的控制平面崩溃，您可能可以想象到您的集群将遇到问题。没有控制平面，集群将没有任何调度能力，这意味着正在运行的工作负载将保持运行，除非它们被停止和重新启动。由于控制平面非常重要，因此建议您至少有三个主节点。许多生产安装运行超过三个主节点，但安装节点的数量应始终是奇数。让我们看看为什么控制平面及其组件对运行中的集群如此重要，通过检查每个组件。
- en: The Kubernetes API server
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes API服务器
- en: 'The first component to understand in a cluster is the **kube-apiserver** component.
    Since Kubernetes is **application programming interface** (**API**)-driven, every
    request that comes into a cluster goes through the API server. Let''s look at
    a simple **get nodes** request using an API endpoint, as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群中要理解的第一个组件是**kube-apiserver**组件。由于Kubernetes是**应用程序编程接口**（**API**）驱动的，进入集群的每个请求都经过API服务器。让我们看一个简单的使用API端点的**获取节点**请求，如下所示：
- en: '**https://10.240.100.100:6443/api/v1/nodes?limit=500**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**https://10.240.100.100:6443/api/v1/nodes?limit=500**'
- en: 'One common method users of Kubernetes deploy to interact with the API server
    is the kubectl utility. Every command that is issued using kubectl calls an API
    endpoint behind the scenes. In the preceding example, we executed a **kubectl
    get nodes** command, which sent an API request to the **kube-apiserver** process
    on **10.240.100.100** on port **6443**. The API call requested the **/api/vi/nodes**
    endpoint, which returned a list of the nodes in the cluster, as shown in the following
    screenshot:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes用户常用的一种与API服务器交互的方法是kubectl实用程序。使用kubectl发出的每个命令在幕后调用一个API端点。在前面的示例中，我们执行了一个**kubectl
    get nodes**命令，该命令将一个API请求发送到端口**6443**上的**10.240.100.100**上的**kube-apiserver**进程。API调用请求了**/api/vi/nodes**端点，返回了集群中节点的列表，如下截图所示：
- en: '![Figure 5.2 – List of Kubernetes nodes'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.2 - Kubernetes节点列表'
- en: '](image/Fig_5.2_B15514.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.2_B15514.jpg)'
- en: Figure 5.2 – List of Kubernetes nodes
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 - Kubernetes节点列表
- en: Without a running API server, all requests to your cluster will fail. So, as
    you can see, it is very important to have a **kube-apiserver** component running
    at all times. By running three or more master nodes, we can limit any impact of
    losing a master node.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 没有运行的API服务器，集群中的所有请求都将失败。因此，可以看到，始终运行**kube-apiserver**组件非常重要。通过运行三个或更多的主节点，我们可以限制失去主节点的任何影响。
- en: Note
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: When running more than one master node, you need to have a load balancer in
    front of the cluster. The Kubernetes API server can be fronted by most standard
    solutions, including F5, HAProxy, and Seesaw.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行多个主节点时，您需要在集群前面放置一个负载均衡器。Kubernetes API服务器可以由大多数标准解决方案，包括F5、HAProxy和Seesaw。
- en: The Etcd database
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Etcd数据库
- en: 'It''s not a stretch to say that Etcd is your Kubernetes cluster. Etcd is a
    fast and highly available distributed key-value database that Kubernetes uses
    to store all cluster data. Each resource in a cluster has a key in the database.
    If you logged in to the node—or Pod—running Etcd, you could use the **etcdctl**
    executable to look at all of the keys in the database. The following code snippet
    shows an example from a cluster running KinD:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不夸张地说，Etcd就是您的Kubernetes集群。Etcd是一个快速且高可用的分布式键值数据库，Kubernetes使用它来存储所有集群数据。集群中的每个资源在数据库中都有一个键。如果您登录到运行Etcd的节点或Pod，您可以使用**etcdctl**可执行文件查看数据库中的所有键。以下代码片段显示了运行KinD集群的示例：
- en: EtcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt
    --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt
    get / --prefix --keys-only
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: EtcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt
    --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt
    get / --prefix --keys-only
- en: 'The output from the preceding command contains too much data to list it all
    in this chapter. A base KinD cluster will return approximately 317 entries. All
    keys start with **/registry/<object>**. For example, one of the keys that were
    returned is the **ClusterRole** for the **cluster-admin** key, as follows: **/registry/clusterrolebindings/cluster-admin**.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 前面命令的输出包含太多数据，无法在本章中列出。基本的KinD集群将返回大约317个条目。所有键都以**/registry/<object>**开头。例如，返回的键之一是**cluster-admin**键的**ClusterRole**，如下所示：**/registry/clusterrolebindings/cluster-admin**。
- en: 'We can use the key name to retrieve the value using the **etcdctl** utility
    by slightly modifying our previous command, as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用键名使用**etcdctl**实用程序检索值，稍微修改我们之前的命令，如下所示：
- en: EtcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt
    --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt
    get /registry/clusterrolebindings/cluster-admin
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: EtcdCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt
    --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt
    get /registry/clusterrolebindings/cluster-admin
- en: 'The output will contain characters that cannot be interpreted by your shell,
    but you will get the idea of the data stored in Etcd. For the **cluster-admin**
    key, the output shows us the following:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将包含您的shell无法解释的字符，但您将了解存储在Etcd中的数据。对于**cluster-admin**键，输出显示如下：
- en: '![](image/Fig_5.3_B15514.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: ！[](image/Fig_5.3_B15514.jpg)
- en: Figure 5.3 – etcdctl ClusterRoleBinding output
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 - etcdctl ClusterRoleBinding 输出
- en: 'The reason we explain the entries in Etcd is to provide a background on how
    Kubernetes uses it to run a cluster. You have seen the output for the **cluster-admin**
    key directly from the database, but in everyday life you would query the API server
    using **kubectl get clusterrolebinding cluster-admin -o yaml**, which would return
    the following:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们解释Etcd中的条目是为了提供Kubernetes如何使用它来运行集群的背景。您已经从数据库直接查看了**cluster-admin**键的输出，但在日常生活中，您将使用**kubectl
    get clusterrolebinding cluster-admin -o yaml**查询API服务器，它将返回以下内容：
- en: '![](image/Fig_5.4_B15514.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: ！[](image/Fig_5.4_B15514.jpg)
- en: Figure 5.4 – kubectl ClusterRoleBinding output
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 - kubectl ClusterRoleBinding 输出
- en: If you look at the output from the **kubectl** command and compare it with the
    output from the **etcdctl** query, you will see matching information. When you
    execute **kubectl** commands, the request goes to the API server, which then queries
    the Etcd database for the object's information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您查看**kubectl**命令的输出并将其与**etcdctl**查询的输出进行比较，您将看到匹配的信息。当您执行**kubectl**命令时，请求将发送到API服务器，然后API服务器将查询Etcd数据库以获取对象的信息。
- en: kube-scheduler
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: As the name suggests, the **kube-scheduler** component is in charge of scheduling
    running Pods. Whenever a Pod is started in a cluster, the API server receives
    the requests and decides where to run the workload, based on multiple pieces of
    criteria including host resources and cluster policies.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，**kube-scheduler**组件负责调度运行中的Pod。每当集群中启动一个Pod时，API服务器会接收请求，并根据多个标准（包括主机资源和集群策略）决定在哪里运行工作负载。
- en: kube-controller-manager
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: The **kube-controller-manager** component is actually a collection of multiple
    controllers that are included in a single binary. Including the four controllers
    in a single executable reduces complexity by running all four in a single process.
    The four controllers included in the **kube-controller-manager** component are
    the node, replication, endpoints, and service account and token controller.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**kube-controller-manager**组件实际上是一个包含多个控制器的集合，包含在一个单一的二进制文件中。将四个控制器包含在一个可执行文件中可以通过在单个进程中运行所有四个来减少复杂性。**kube-controller-manager**组件中包含的四个控制器是节点、复制、端点以及服务账户和令牌控制器。'
- en: 'Each controller provides a unique function to a cluster, and each controller
    and its function is listed here:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每个控制器为集群提供独特的功能，每个控制器及其功能在此列出：
- en: '![](image/B15514_table_5.1.jpg)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](image/B15514_table_5.1.jpg)'
- en: Each controller runs a non-terminating (never-ending) control loop. These control
    loops watch the state of each resource, making any changes required to normalize
    the state of the resource. For example, if you needed to scale a deployment from
    one to three nodes, the replication controller would notice that the current state
    has one Pod running, and the desired state is to have three Pods running. To move
    the current state to the desired state, two additional Pods will be requested
    by the replication controller.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 每个控制器都运行一个非终止的控制循环。这些控制循环监视每个资源的状态，进行任何必要的更改以使资源的状态正常化。例如，如果您需要将一个部署从一个节点扩展到三个节点，复制控制器会注意到当前状态有一个Pod正在运行，期望状态是有三个Pod正在运行。为了将当前状态移动到期望状态，复制控制器将请求另外两个Pod。
- en: cloud-controller-manager
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: cloud-controller-manager
- en: This is one component that you may not have run into, depending on how your
    clusters are configured. Similar to the **kube-controller-manager** component,
    this controller containers four controllers in a single binary. The included controllers
    are the node, route, service, and volume controllers—each controller is responsible
    for interacting with their respective cloud service provider offering.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个您可能没有遇到的组件，这取决于您的集群如何配置。与**kube-controller-manager**组件类似，这个控制器在一个单一的二进制文件中包含了四个控制器。包含的控制器是节点、路由、服务和卷控制器，每个控制器负责与其各自的云服务提供商进行交互。
- en: Understanding the worker node components
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解工作节点组件
- en: Worker nodes, as the name implies, are responsible for running workloads. When
    we discussed the **kube-scheduler** component of the control plane, we mentioned
    that when a new Pod is scheduled, the **kube-scheduler** component will decide
    which node to run the Pod on. It does this using information that has been sent
    to it from the worker nodes. This information is constantly updated to help spread
    Pods around a cluster to utilize resources efficiently. Here is a list of the
    worker node components.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点负责运行工作负载，正如其名称所示。当我们讨论控制平面的**kube-scheduler**组件时，我们提到当新的Pod被调度时，**kube-scheduler**组件将决定在哪个节点上运行Pod。它使用来自工作节点的信息来做出决定。这些信息不断更新，以帮助在集群中分配Pod以有效利用资源。以下是工作节点组件的列表。
- en: kubelet
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kubelet
- en: You may hear a worker node referred to as a **kubelet**. **kubelet** is an agent
    that runs on all worker nodes, and it is responsible for running the actual containers.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会听到将工作节点称为**kubelet**。**kubelet**是在所有工作节点上运行的代理，负责运行实际的容器。
- en: kube-proxy
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-proxy
- en: Contrary to the name, **kube-proxy** is not a proxy server at all. **kube-proxy**
    is responsible for routing network communication between a Pod and the outside
    network.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 与名称相反，**kube-proxy**根本不是代理服务器。**kube-proxy**负责在Pod和外部网络之间路由网络通信。
- en: Container runtime
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器运行时
- en: This is not represented in the picture, but each node also needs a container
    runtime. A container runtime is responsible for running the containers. The first
    thing you might think of is Docker. While Docker is a container runtime, it is
    not the only runtime option available. Over the last year, other options have
    become available and are quickly replacing Docker as the preferred container runtime.
    The two most prominent Docker replacements are CRI-O and containerd.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这在图片中没有体现，但每个节点也需要一个容器运行时。容器运行时负责运行容器。您可能首先想到的是Docker。虽然Docker是一个容器运行时，但它并不是唯一的运行时选项。在过去的一年里，其他选项已经可用，并且正在迅速取代Docker成为首选的容器运行时。最突出的两个Docker替代品是CRI-O和containerd。
- en: For the book exercises, we will create a Kubernetes cluster using KinD. At the
    time of this writing, KinD only offers official support for Docker as the container
    runtime, with limited support for Podman.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在书的练习中，我们将使用KinD创建一个Kubernetes集群。在撰写本文时，KinD只提供对Docker作为容器运行时的官方支持，并对Podman提供有限支持。
- en: Interacting with the API server
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与API服务器交互
- en: As we mentioned earlier, you interact with the API server using either direct
    API requests or the **kubectl** utility. We will focus on using **kubectl** for
    the majority of our interaction in this book, but we will call out using direct
    API calls where applicable.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，您可以使用直接的API请求或**kubectl**实用程序与API服务器进行交互。在本书中，我们将重点介绍使用**kubectl**进行大部分交互，但在适当的情况下，我们将介绍使用直接的API调用。
- en: Using the Kubernetes kubectl utility
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Kubernetes kubectl实用程序
- en: '**kubectl** is a single executable file that allows you to interact with the
    Kubernetes API using a **command-line interface** (**CLI**). It is available for
    most major operating systems and architectures, including Linux, Windows, and
    Mac.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**kubectl**是一个单个可执行文件，允许您使用**命令行界面**（**CLI**）与Kubernetes API进行交互。它适用于大多数主要操作系统和架构，包括Linux、Windows和Mac。'
- en: 'Installation instructions for most operating systems are located on the Kubernetes
    site at [https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/).
    Since we are using Linux as our operating system for the exercises in the book,
    we will cover installing **kubectl** on a Linux machine. Follow these steps:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数操作系统的安装说明位于Kubernetes网站的[https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)。由于我们在书中的练习中使用Linux作为操作系统，我们将介绍在Linux机器上安装**kubectl**的步骤：
- en: 'To download the latest version of **kubectl**, you can run a **curl** command
    that will download it, as follows:'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要下载**kubectl**的最新版本，您可以运行一个**curl**命令来下载它，如下所示：
- en: '**curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl
    -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl
    -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl**'
- en: 'After downloading, you need to make the file executable by running the following
    command:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载后，您需要通过运行以下命令使文件可执行：
- en: '**chmod +x ./kubectl**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**chmod +x ./kubectl**'
- en: 'Finally, we will move the executable to your path, as follows:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将将可执行文件移动到您的路径，如下所示：
- en: '**sudo mv ./kubectl /usr/local/bin/kubectl**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**sudo mv ./kubectl /usr/local/bin/kubectl**'
- en: You now have the latest **kubectl** utility on your system and can execute **kubectl**
    commands from any working directory.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在在系统上拥有最新的 **kubectl** 实用程序，并且可以从任何工作目录执行 **kubectl** 命令。
- en: 'Kubernetes is updated every 3 months. This includes upgrades to the base Kubernetes
    cluster components and the **kubectl** utility. You may run into a version mismatch
    between a cluster and your **kubectl** command, requiring you to either upgrade
    or download your **kubectl** executable. You can always check the version of both
    by running a **kubectl version** command, which will output the version of both
    the API server and the **kubectl** client. The output from a version check is
    shown in the following code snippet:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 每3个月更新一次。这包括对基本 Kubernetes 集群组件和 **kubectl** 实用程序的升级。您可能会遇到集群和 **kubectl**
    命令之间的版本不匹配，需要您升级或下载 **kubectl** 可执行文件。您可以通过运行 **kubectl version** 命令来随时检查两者的版本，该命令将输出
    API 服务器和 **kubectl** 客户端的版本。版本检查的输出如下代码片段所示：
- en: 'Client Version: version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.1", GitCommit:"d224476cd0730baca2b6e357d144171ed74192d6",
    GitTreeState:"clean", BuildDate:"2020-01-14T21:04:32Z", GoVersion:"go1.13.5",
    Compiler:"gc", Platform:"linux/amd64"}'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端版本：version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.1", GitCommit:"d224476cd0730baca2b6e357d144171ed74192d6",
    GitTreeState:"clean", BuildDate:"2020-01-14T21:04:32Z", GoVersion:"go1.13.5",
    Compiler:"gc", Platform:"linux/amd64"}
- en: 'Server Version: version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.0", GitCommit:"70132b0f130acc0bed193d9ba59dd186f0e634cf",
    GitTreeState:"clean", BuildDate:"2020-01-14T00:09:19Z", GoVersion:"go1.13.4",
    Compiler:"gc", Platform:"linux/amd64"}'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 服务器版本：version.Info{Major:"1", Minor:"17", GitVersion:"v1.17.0", GitCommit:"70132b0f130acc0bed193d9ba59dd186f0e634cf",
    GitTreeState:"clean", BuildDate:"2020-01-14T00:09:19Z", GoVersion:"go1.13.4",
    Compiler:"gc", Platform:"linux/amd64"}
- en: As you can see from the output, the **kubectl** client is running version **1.17.1**
    and the cluster is running **1.17.0**. A minor version difference in the two will
    not cause any issues. In fact, the official supported version difference is within
    one major version release. So, if your client is running version 1.16 and the
    cluster is running 1.17, you would be within the supported version difference.
    While this may be supported, it doesn't mean that you won't run into issues if
    you are trying to use any new commands or objects included in the higher version.
    In general, you should try to keep your cluster and client version in sync to
    avoid any issues.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，**kubectl** 客户端正在运行版本 **1.17.1**，而集群正在运行 **1.17.0**。两者之间的次要版本差异不会引起任何问题。事实上，官方支持的版本差异在一个主要版本发布之内。因此，如果您的客户端运行的是版本
    1.16，而集群运行的是 1.17，您将在支持的版本差异范围内。虽然这可能得到支持，但这并不意味着如果您尝试使用高版本中包含的任何新命令或对象，就不会遇到问题。通常情况下，您应该尽量保持集群和客户端版本同步，以避免任何问题。
- en: 'Through the remainder of this chapter, we will discuss Kubernetes objects and
    how you interact with the API server to manage each object. But before diving
    into the different objects, we wanted to mention one commonly overlooked option
    of the **kubectl** utility: the **verbose** option.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将讨论 Kubernetes 对象以及您如何与 API 服务器交互来管理每个对象。但在深入讨论不同对象之前，我们想提到 **kubectl**
    实用程序的一个常被忽视的选项：**verbose** 选项。
- en: Understanding the verbose option
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 verbose 选项
- en: When you execute a **kubectl** command, the only outputs you will see by default
    are any direct responses to your command. If you were to look at all Pods in the
    **kube-system** namespace, you would receive a list of all Pods. In most cases
    this is the desired output, but what if you issued a **get Pods** request and
    received an error from the API server? How could you get more information about
    what might be causing the error?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当您执行**kubectl**命令时，默认情况下您只会看到对您的命令的任何直接响应。如果您要查看**kube-system**命名空间中的所有Pod，您将收到所有Pod的列表。在大多数情况下，这是期望的输出，但是如果您发出**get
    Pods**请求并从API服务器收到错误，该怎么办？您如何获取有关可能导致错误的更多信息？
- en: By adding the **verbose** option to your **kubectl** command, you can get additional
    details about the API call itself and any replies from the API server. Often,
    the replies from the API server will contain additional information that may be
    useful to find the root cause of the issue.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将**冗长**选项添加到您的**kubectl**命令中，您可以获得有关API调用本身以及来自API服务器的任何回复的额外详细信息。通常，来自API服务器的回复将包含可能有助于找到问题根本原因的额外信息。
- en: 'The **verbose** option has multiple levels ranging from 0 to 9; the higher
    the number, the more output you will receive. The following screenshot has been
    taken from the Kubernetes site, detailing each level and what the output will
    include:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**冗长**选项有多个级别，从0到9不等；数字越高，输出越多。以下截图来自Kubernetes网站，详细说明了每个级别和输出内容：'
- en: '![Figure 5.5 – Verbosity description'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.5 - 冗长描述'
- en: '](image/Fig_5.5_B15514.jpg)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.5_B15514.jpg)'
- en: Figure 5.5 – Verbosity description
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 - 冗长描述
- en: You can experiment with the levels by adding the **-v** or **--v** option to
    any **kubectl** command.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过向任何**kubectl**命令添加**-v**或**--v**选项来尝试不同级别。
- en: General kubectl commands
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 常规kubectl命令
- en: The CLI allows you to interact with Kubernetes in an imperative and declarative
    manner. Using an imperative command involves you telling Kubernetes what to do—for
    example, **kubectl run nginx –image nginx**. This tells the API server to create
    a new deployment called **nginx** that runs an image called **nginx**. While imperative
    commands are useful for development and quick fixes or testing, you will use declarative
    commands more often in a production environment. In a declarative command, you
    tell Kubernetes what you want. To use declarative commands, you send a manifest
    to the API server, usually written in **YAML Ain't Markup Language** (**YAML**),
    which declares what you want Kubernetes to create.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: CLI允许您以命令式和声明式方式与Kubernetes进行交互。使用命令式命令涉及告诉Kubernetes要做什么-例如，**kubectl run nginx
    –image nginx**。这告诉API服务器创建一个名为**nginx**的新部署，运行一个名为**nginx**的镜像。虽然命令式命令对开发和快速修复或测试很有用，但在生产环境中，您将更频繁地使用声明式命令。在声明式命令中，您告诉Kubernetes您想要什么。要使用声明式命令，您将一个通常用**YAML
    Ain't Markup Language**（**YAML**）编写的清单发送到API服务器，声明您要Kubernetes创建什么。
- en: '**kubectl** includes commands and options that can provide general cluster
    information or information about an object. The following table contains a cheat-sheet
    of commands and what they are used for. We will use many of these commands in
    future chapters, so you will see them in action throughout the book:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**kubectl**包括可以提供一般集群信息或对象信息的命令和选项。以下表格包含了命令的速查表以及它们的用途。我们将在未来的章节中使用许多这些命令，因此您将在整本书中看到它们的实际应用：'
- en: '![](image/B15514_table_5.2.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](image/B15514_table_5.2.jpg)'
- en: With an understanding of each Kubernetes component and how to interact with
    the API server using imperative commands, we can now move on to Kubernetes objects
    and how we use **kubectl** to manage them.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解每个Kubernetes组件以及如何使用命令与API服务器进行交互，我们现在可以继续学习Kubernetes对象以及如何使用**kubectl**来管理它们。
- en: Introducing Kubernetes objects
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Kubernetes对象
- en: This section will contain a lot of information and, since this is a bootcamp,
    we will not go into deep details on each object. As you can imagine, each object
    could have its own chapter, or multiple chapters, in a book. Since there are many
    books on Kubernetes that go into detail on the base objects, we will only cover
    the required details of each to have an understanding of each one. In the following
    chapters, we will include additional details for objects as we build out our cluster
    using the book exercises.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将包含大量信息，由于这是一个训练营，我们不会深入讨论每个对象的细节。正如您可以想象的那样，每个对象都可能在一本书中有自己的章节，甚至多个章节。由于有许多关于Kubernetes的书籍详细介绍了基本对象，我们只会涵盖每个对象的必要细节，以便了解每个对象。在接下来的章节中，我们将在构建集群时包含对象的附加细节。
- en: Before we go on to understand what Kubernetes objects really are, let's first
    explain Kubernetes manifests.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续了解Kubernetes对象的真正含义之前，让我们首先解释一下Kubernetes清单。
- en: Kubernetes manifests
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes清单
- en: The files that we will use to create Kubernetes objects are referred to as manifests.
    A manifest can be created using YAML or **JavaScript Object Notation** (**JSON**)—most
    manifests use YAML, and that is the format we will use throughout the book.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用来创建Kubernetes对象的文件称为清单。清单可以使用YAML或**JavaScript对象表示法**（**JSON**）创建——大多数清单使用YAML，这也是我们在整本书中将使用的格式。
- en: 'The content of a manifest will vary depending on the object, or objects, that
    will be created. At a minimum, all manifests require a base configuration that
    include the **apiVersion**, object **KinD**, and **metadata** fields, as can be
    seen here:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 清单的内容将根据将要创建的对象或对象而变化。至少，所有清单都需要包含**apiVersion**、对象**KinD**和**metadata**字段的基本配置，如下所示：
- en: 'apiVersion: apps/v1'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：apps/v1
- en: 'KinD: Deployment'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：部署
- en: 'metadata:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'labels:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：
- en: 'app: grafana'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：grafana
- en: 'name: grafana'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：grafana
- en: 'namespace: monitoring'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：监控
- en: 'The preceding manifest alone is not complete; we are only showing the beginning
    of a full deployment manifest. As you can see in the file, we start with the three
    required fields that all manifests are required to have: the **apiVersion**, **KinD**,
    and **metadata** fields.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的清单本身并不完整；我们只是展示了完整部署清单的开头。正如您在文件中所看到的，我们从所有清单都必须具有的三个必需字段开始：**apiVersion**、**KinD**和**metadata**字段。
- en: You may also notice that there are spaces in the file. YAML is very format-specific,
    and if the format of any line is off by even a single space, you will receive
    an error when you try to deploy the manifest. This takes time to get used to,
    and even after creating manifests for a long time, formatting issues will still
    pop up from time to time.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还注意到文件中有空格。YAML非常具体格式，如果任何行的格式偏离了一个空格，您在尝试部署清单时将收到错误。这需要时间来适应，即使创建清单已经很长时间，格式问题仍然会不时出现。
- en: What are Kubernetes objects?
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes对象是什么？
- en: When you want to add or delete something from a cluster, you are interacting
    with a Kubernetes object. An object is what a cluster uses to keep a list of a
    desired state. The desired state may be to create, delete, or scale an object.
    Based on the desired state of the object, the API server will make sure that the
    current state equals the desired state.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当您想要向集群添加或删除某些内容时，您正在与Kubernetes对象进行交互。对象是集群用来保持所需状态列表的东西。所需状态可能是创建、删除或扩展对象。根据对象的所需状态，API服务器将确保当前状态等于所需状态。
- en: 'To retrieve a list of objects a cluster supports, you can use the **kubectl
    api-resources** command. The API server will reply with a list of all objects,
    including any valid short name, namespace support, and supported API group. There
    are approximately 53 base objects included with a base cluster, but an abbreviated
    list of the most common objects is shown in the following screenshot:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 检索集群支持的对象列表，可以使用**kubectl api-resources**命令。API服务器将回复一个包含所有对象的列表，包括任何有效的简称、命名空间支持和支持的API组。基本集群包括大约53个基本对象，但以下截图显示了最常见对象的缩略列表：
- en: '![Figure 5.6 – Kubernetes API resources'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.6 - Kubernetes API资源'
- en: '](image/Fig_5.6_B15514.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.6_B15514.jpg)'
- en: Figure 5.6 – Kubernetes API resources
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 - Kubernetes API资源
- en: Since this chapter is a bootcamp, we will offer a brief review of many of the
    objects in the list. In order to ensure that you can follow the remaining chapters,
    we will provide an overview of each object and how to interact with them. Some
    objects will also be explained in greater detail in future chapters, including
    **Ingress**, **RoleBindings**, **ClusterRoles**, **StorageClasses**, and more.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章是一个训练营，我们将简要回顾列表中的许多对象。为了确保您能够跟随剩余的章节，我们将提供每个对象的概述以及如何与它们交互的概述。一些对象也将在未来的章节中更详细地解释，包括**Ingress**、**RoleBindings**、**ClusterRoles**、**StorageClasses**等等。
- en: Reviewing Kubernetes objects
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查Kubernetes对象
- en: To make this section easier to follow, we will present each object in the order
    they were provided by the **kubectl api-services** command.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使本节更容易理解，我们将按照**kubectl api-services**命令提供的顺序呈现每个对象。
- en: Most objects in a cluster are run in a namespace, and to create/edit/read them,
    you should supply the **-n <namespace>** option to any **kubectl** command. To
    find a list of objects that accept a namespace option, you can reference the output
    from our previous **get api-server** command. If an object can be referenced by
    a namespace, the namespaced column will show **true**. If the object is only referenced
    by the cluster level, the namespaced column will show **false**.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的大多数对象都在命名空间中运行，要创建/编辑/读取它们，您应该向任何**kubectl**命令提供**-n <namespace>**选项。要查找接受命名空间选项的对象列表，可以参考我们之前**get
    api-server**命令的输出。如果对象可以由命名空间引用，命名空间列将显示**true**。如果对象只能由集群级别引用，命名空间列将显示**false**。
- en: ConfigMaps
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConfigMaps
- en: A ConfigMap stores data in key-value pairs, providing a way to keep your configuration
    separate from your application. ConfigMaps may contain data from a literal value,
    files, or directories.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap以键值对的形式存储数据，提供了一种将配置与应用程序分开的方法。ConfigMaps可以包含来自文字值、文件或目录的数据。
- en: 'Here is an imperative example:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个命令式的例子：
- en: kubectl create configmap <name> <data>
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl create configmap <name> <data>
- en: 'The **name** option will vary based on the source of the ConfigMap. To use
    a file or a directory, you supply the **--from-file** option and either the path
    to a file or an entire directory, as shown here:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**name**选项将根据ConfigMap的来源而变化。要使用文件或目录，您需要提供**--from-file**选项和文件路径或整个目录，如下所示：'
- en: kubectl create configmap config-test --from-file=/apps/nginx-config/nginx.conf
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl create configmap config-test --from-file=/apps/nginx-config/nginx.conf
- en: This would create a new ConfigMap named **config-test**, with the **nginx.conf**
    key containing the content of the **nginx.conf** file as the value.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为**config-test**的新ConfigMap，其中**nginx.conf**键包含**nginx.conf**文件的内容作为值。
- en: 'If you needed to have more than one key added in a single ConfigMap, you could
    put each file into a directory and create the ConfigMap using all of the files
    in the directory. As an example, you have three files in a directory located at
    **~/config/myapp**. In the directory are three files, each containing data, called
    **config1**, **config2**, and **config3**. To create a ConfigMap that would add
    each file into a key, you need to supply the **--from-file** option and point
    to the directory, as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您需要在单个ConfigMap中添加多个键，可以将每个文件放入一个目录中，并使用目录中的所有文件创建ConfigMap。例如，您在位于**~/config/myapp**的目录中有三个文件，每个文件都包含数据，分别称为**config1**，**config2**和**config3**。要创建一个ConfigMap，将每个文件添加到一个键中，您需要提供**--from-file**选项并指向该目录，如下所示：
- en: kubectl create configmap config-test --from-file=/apps/config/myapp
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl create configmap config-test --from-file=/apps/config/myapp
- en: This would create a new **ConfigMap** with three key values called **config1**,
    **config2**, and **config3**. Each key would contain a value equal to the content
    of each file in the directory.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的**ConfigMap**，其中包含三个键值，分别称为**config1**，**config2**和**config3**。每个键将包含与目录中每个文件内容相等的值。
- en: 'To quickly show a **ConfigMap**, using the example to create a **ConfigMap**
    from a directory, we can retrieve the **ConfigMap** using the get command, **kubectl
    get configmaps config-test**, resulting in the following output:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速显示一个**ConfigMap**，使用从目录创建**ConfigMap**的示例，我们可以使用get命令检索**ConfigMap**，**kubectl
    get configmaps config-test**，得到以下输出：
- en: NAME DATA AGE config-test 3 7s
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 数据 年龄 config-test 3 7s
- en: 'We can see that the ConfigMap contains three keys, shown as a **3** under the
    **DATA** column. To look in greater detail, we can use the same **get** command
    and output the value of each key as YAML by adding the **-o yaml** option to the
    **kubectl get configmaps config-test -o yaml** command, resulting in the following
    output:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到ConfigMap包含三个键，显示为**DATA**列下的**3**。为了更详细地查看，我们可以使用相同的**get**命令，并通过将**-o
    yaml**选项添加到**kubectl get configmaps config-test -o yaml**命令来输出每个键的值作为YAML，得到以下输出：
- en: '![Figure 5.7 – kubectl ConfigMap output'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.7 - kubectl ConfigMap 输出'
- en: '](image/Fig_5.7_B15514.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.7_B15514.jpg)'
- en: Figure 5.7 – kubectl ConfigMap output
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 - kubectl ConfigMap 输出
- en: Looking at the preceding output, you can see each key matches the filenames,
    and the value for each key contains the data in each respective file.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中可以看到，每个键都与文件名匹配，每个键的值都包含各自文件中的数据。
- en: One limitation of ConfigMaps that you should keep in mind is that the data is
    easily accessible to anyone with permissions to the object. As you can see from
    the preceding output, a simple **get** command shows the data in cleartext. Due
    to this design, you should never store sensitive information such as a password
    in a ConfigMap. Later in this section, we will cover an object that was designed
    to store sensitive information, called a Secret.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该记住ConfigMaps的一个限制是，数据对于具有对象权限的任何人都很容易访问。正如您从前面的输出中所看到的，一个简单的**get**命令显示了明文数据。由于这种设计，您不应该在ConfigMap中存储诸如密码之类的敏感信息。在本节的后面，我们将介绍一个专门设计用于存储敏感信息的对象，称为Secret。
- en: Endpoints
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 终端
- en: 'An endpoint maps a service to a Pod or Pods. This will make more sense when
    we explain the **Service** object. For now, you only need to know that you can
    use the CLI to retrieve endpoints by using the **kubectl get endpoints** command.
    In a new KinD cluster, you will see a value for the Kubernetes API server in the
    default namespace, as illustrated in the following code snippet:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 端点将服务映射到一个Pod或多个Pod。当我们解释**Service**对象时，这将更有意义。现在，您只需要知道您可以使用CLI通过使用**kubectl
    get endpoints**命令来检索端点。在一个新的KinD集群中，您将在默认命名空间中看到Kubernetes API服务器的值，如下面的代码片段所示：
- en: NAMESPACE   NAME     ENDPOINTS         AGE
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间 名称 终端 年龄
- en: default   kubernetes 172.17.0.2:6443   22h
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 默认 kubernetes 172.17.0.2:6443 22小时
- en: The output shows that the cluster has a service called **kubernetes** that has
    an endpoint at the **Internet Protocol** (**IP**) address **172.17.0.2** on port
    **6443**. Later, you will see when looking at endpoints that they can be used
    to troubleshoot service and ingress issues.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示集群有一个名为**kubernetes**的服务，在**Internet Protocol**（**IP**）地址**172.17.0.2**的端口**6443**上有一个端点。稍后，当查看端点时，您将看到它们可用于解决服务和入口问题。
- en: Events
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件
- en: The **Events** object will display any events for a namespace. To get a list
    of events for the **kube-system** namespace, you would use the **kubectl get events
    -n kube-system** command.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**事件**对象将显示命名空间的任何事件。要获取**kube-system**命名空间的事件列表，您将使用**kubectl get events -n
    kube-system**命令。'
- en: Namespaces
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间
- en: A namespace is an object to divide a cluster into logical units. Each namespace
    allows granular management of resources, including permissions, quotas, and reporting.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间是将集群划分为逻辑单元的对象。每个命名空间允许对资源进行细粒度管理，包括权限、配额和报告。
- en: The **namespace** object is used for namespace tasks, which are cluster-level
    operations. Using the **namespace** object, you can execute commands including
    **create**, **delete**, **edit**, and **get**.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**命名空间**对象用于命名空间任务，这些任务是集群级别的操作。使用**命名空间**对象，您可以执行包括**创建**、**删除**、**编辑**和**获取**在内的命令。'
- en: The syntax for the command is **kubectl <verb> ns <namespace name>**.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令的语法是**kubectl <动词> ns <命名空间名称>**。
- en: 'For example, to describe the **kube-system** namespace, we would execute a
    **kubectl describe namespaces kube-system** command. This will return information
    for the namespace, including any labels, annotations, and assigned quotas, as
    illustrated in the following code snippet:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要描述**kube-system**命名空间，我们将执行**kubectl describe namespaces kube-system**命令。这将返回命名空间的信息，包括任何标签、注释和分配的配额，如下面的代码片段所示：
- en: 'Name: kube-system'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：kube-system
- en: 'Labels: <none>Annotations: <none>'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：<无>注释：<无>
- en: 'Status: Active'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 状态：活动
- en: No resource quota.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 没有资源配额。
- en: No LimitRange resource.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 没有LimitRange资源。
- en: In the preceding output, you can see that this namespace does not have any labels,
    annotations, or resource quotas assigned.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述输出中，您可以看到该命名空间没有分配任何标签、注释或资源配额。
- en: This section is only meant to introduce the concept of namespaces as a management
    unit in multi-tenant clusters. If you plan to run clusters with multiple tenants,
    you need to understand how namespaces can be used to secure a cluster.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 此部分仅旨在介绍命名空间作为多租户集群中的管理单元的概念。如果您计划运行具有多个租户的集群，您需要了解如何使用命名空间来保护集群。
- en: Nodes
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 节点
- en: The **nodes** object is a cluster-level resource that is used to interact with
    the cluster's nodes. This object can be used with various actions including **get**,
    **describe**, **label**, and **annotate**.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**节点**对象是用于与集群节点交互的集群级资源。此对象可用于各种操作，包括**获取**、**描述**、**标签**和**注释**。'
- en: 'To retrieve a list of all of the nodes in a cluster using **kubectl**, you
    need to execute a **kubectl get nodes** command. On a new KinD cluster running
    a simple one-node cluster, this would display as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用**kubectl**检索集群中所有节点的列表，您需要执行**kubectl get nodes**命令。在运行简单单节点集群的新KinD集群上，显示如下：
- en: NAME STATUS ROLES AGE VERSION
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 状态 角色 年龄 版本
- en: KinD-control-plane Ready master 22h v1.17.0
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: KinD-control-plane 就绪 主节点 22小时 v1.17.0
- en: You can also use the nodes object to get details of a single node using the
    **describe** command. To get a description of the KinD node listed previously,
    we can execute **kubectl describe node KinD-control-plane**, which would return
    details on the node, including consumed resources, running Pods, IP **classless
    inter-domain routing** (**CIDR**) ranges, and more.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用nodes对象使用**describe**命令获取单个节点的详细信息。要获取先前列出的KinD节点的描述，我们可以执行**kubectl describe
    node KinD-control-plane**，这将返回有关节点的详细信息，包括消耗的资源、运行的Pods、IP **无类域间路由**（**CIDR**）范围等。
- en: Persistent Volume Claims
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持久卷索赔
- en: We will describe **Persistent Volume Claims** (**PVCs**) in more depth in a
    later chapter, but for now you just need to know that a PVC is used by a Pod to
    consume persistent storage. A PVC uses a **persistent volume** (**PV**) to map
    the storage resource. As with most other objects we have discussed, you can issue
    **get**, **describe**, and **delete** commands on a PVC object. Since these are
    used by Pods, they are a **namespaced** object, and must be created in the same
    namespace as the Pod(s) that will use the PVC.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在后面的章节中更深入地描述**持久卷索赔**（**PVCs**），但现在您只需要知道PVC用于Pod消耗持久存储。PVC使用**持久卷**（**PV**）来映射存储资源。与我们讨论过的大多数其他对象一样，您可以对PVC对象发出**get**、**describe**和**delete**命令。由于它们被Pods使用，它们是一个**命名空间**对象，并且必须在与将使用PVC的Pod相同的命名空间中创建。
- en: PVs
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 持久卷
- en: PVs are used by PVCs to create a link between the PVC and the underlying storage
    system. Manually maintaining PVs is a messy task and in the real world it should
    be avoided, since Kubernetes includes the ability to manage most common storage
    systems using the **Container Storage Interface** (**CSI**). As mentioned in the
    **PVC** object section, we will discuss how Kubernetes can automatically create
    the PVs that will be linked to PVCs.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: PVs被PVCs使用，以在PVC和底层存储系统之间创建链接。手动维护PVs是一项混乱的任务，在现实世界中应该避免，因为Kubernetes包括使用**容器存储接口**（**CSI**）管理大多数常见存储系统的能力。正如在**PVC**对象部分提到的，我们将讨论Kubernetes如何自动创建将与PVCs链接的PVs。
- en: Pods
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pods
- en: 'The Pod object is used to interact with the Pods that are running your container(s).
    Using the **kubectl** utility you can use commands such as **get**, **delete**,
    and **describe**. For example, if you wanted to get a list of all Pods in the
    **kube-system** namespace, you would execute a **kubectl get Pods -n kube-system**
    command that would return all Pods in the namespace, as follows:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Pod对象用于与运行您的容器的Pod进行交互。使用**kubectl**实用程序，您可以使用**get**、**delete**和**describe**等命令。例如，如果您想要获取**kube-system**命名空间中所有Pods的列表，您将执行一个**kubectl
    get Pods -n kube-system**命令，该命令将返回命名空间中的所有Pods，如下所示：
- en: '![Figure 5.8 – All Pods in the kube-system namespace'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.8 - kube-system命名空间中的所有Pods'
- en: '](image/Fig_5.8_B15514.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.8_B15514.jpg)'
- en: Figure 5.8 – All Pods in the kube-system namespace
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.8 - kube-system命名空间中的所有Pods
- en: While you can create a Pod directly, you should avoid doing so unless you are
    using a Pod for quick troubleshooting. Pods that are created directly cannot use
    many of the features provided by Kubernetes, including scaling, automatic restarts,
    or rolling upgrades. Instead of creating a Pod directly, you should use a Deployment,
    or in some rare cases a **ReplicaSet** object or replication controller.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以直接创建一个Pod，但除非您正在使用Pod进行快速故障排除，否则应避免这样做。直接创建的Pod无法使用Kubernetes提供的许多功能，包括扩展、自动重启或滚动升级。您应该使用部署，或在一些罕见情况下使用**ReplicaSet**对象或复制控制器，而不是直接创建Pod。
- en: Replication controllers
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制控制器
- en: Replication controllers will manage the number of running Pods, keeping the
    desired replicas specified running at all times. If you create a replication controller
    and set the replica count to **5**, the controller will always keep five Pods
    of the application running.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 复制控制器将管理运行中的Pod的数量，始终保持指定数量的副本运行。如果创建一个复制控制器并将副本计数设置为**5**，则控制器将始终保持应用程序的五个Pod运行。
- en: Replication controllers have been replaced by the **ReplicaSet** object, which
    we will discuss in its own section. While you can still use replication controllers,
    you should consider using a Deployment or a **ReplicaSet** object.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 复制控制器已被**ReplicaSet**对象取代，我们将在其专门部分讨论。虽然您仍然可以使用复制控制器，但应考虑使用部署或**ReplicaSet**对象。
- en: ResourceQuotas
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源配额
- en: 'It is becoming very common to share a Kubernetes cluster between multiple teams,
    referred to as a multi-tenant cluster. Since you will have multiple teams working
    in a single cluster, you should consider creating quotas to limit any potential
    of a single tenant consuming all the resources in a cluster or on a node. Limits
    can be set on most cluster objects, including the following:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个团队之间共享Kubernetes集群变得非常普遍，称为多租户集群。由于您将在单个集群中有多个团队工作，因此应考虑创建配额，以限制单个租户在集群或节点上消耗所有资源的潜力。可以对大多数集群对象设置限制，包括以下内容：
- en: '**Central processing unit** (**CPU**)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中央处理器（CPU）
- en: Memory
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: PVCs
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PVC
- en: ConfigMaps
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置映射
- en: Deployments
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Pods, and more
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod和更多
- en: Setting a limit will stop any additional objects being created once the limit
    is hit. If you set a limit of 10 Pods for a namespace and a user creates a new
    Deployment that attempts to start 11 Pods, the 11th Pod will fail to start up
    and the user will receive an error.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 设置限制将在达到限制后阻止创建任何其他对象。如果为命名空间设置了10个Pod的限制，并且用户创建了一个尝试启动11个Pod的新部署，则第11个Pod将无法启动，并且用户将收到错误。
- en: 'A basic manifest file to create a quota for memory and CPU would look this:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 创建内存和CPU配额的基本清单文件将如下所示：
- en: 'apiVersion: v1'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：v1
- en: 'KinD: ResourceQuota'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：ResourceQuota
- en: 'metadata:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: base-memory-cpu'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：base-memory-cpu
- en: 'spec:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'hard:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 硬：
- en: 'requests.cpu: "2"'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: requests.cpu："2"
- en: 'requests.memory: 8Gi'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: requests.memory：8Gi
- en: 'limits.cpu: "4"'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: limits.cpu："4"
- en: 'limits.memory: 16Gi'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: limits.memory：16Gi
- en: This will set a limit on the total amount of resources the namespace can use
    for CPU and memory requests and limits.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这将限制命名空间可以用于CPU和内存请求和限制的总资源量。
- en: 'Once a quota has been created, you can view the usage using the **kubectl describe**
    command. In our example, we named the **ResourceQuota** **base-memory-cpu**. To
    view the usage, we would execute the **kubectl get resourcequotas base-memory-cpu**
    command, resulting in the following output:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 创建配额后，您可以使用**kubectl describe**命令查看使用情况。在我们的示例中，我们将**ResourceQuota**命名为**base-memory-cpu**。要查看使用情况，我们将执行**kubectl
    get resourcequotas base-memory-cpu**命令，结果如下：
- en: 'Name: base-memory-cpu'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：base-memory-cpu
- en: 'Namespace: default'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：默认
- en: Resource Used Hard
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 已使用的资源硬件
- en: '-------- ---- ----'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '-------- ---- ----'
- en: limits.cpu 0 4
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: limits.cpu 0 4
- en: limits.memory 0 16Gi
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: limits.memory 0 16Gi
- en: requests.cpu 0 2
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: requests.cpu 0 2
- en: requests.memory 0 8Gi
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: requests.memory 0 8Gi
- en: '**ResourceQuota** objects are used to control a cluster''s resources. By allocating
    the resources to a namespace, you can guarantee that a single tenant will have
    the required CPU and memory to run their application, while limiting the impact
    that a poorly written application can have on other applications.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**ResourceQuota**对象用于控制集群的资源。通过为命名空间分配资源，您可以保证单个租户将拥有运行其应用程序所需的CPU和内存，同时限制糟糕编写的应用程序可能对其他应用程序造成的影响。'
- en: Secrets
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 秘密
- en: Earlier we described how to use a **ConfigMap** object to store configuration
    information. We mentioned that **ConfigMap** objects should never be used to store
    any type of sensitive data. This is the job of a Secret.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前描述了如何使用**ConfigMap**对象存储配置信息。我们提到**ConfigMap**对象不应该用于存储任何类型的敏感数据。这是Secret的工作。
- en: Secrets are stored as Base64-encoded strings, which aren't a form of encryption.
    So, why separate Secrets from **ConfigMap** objects? Providing a separate object
    type offers an easier way to maintain access controls and the ability to inject
    sensitive information using an external system.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Secrets以Base64编码的字符串形式存储，这不是一种加密形式。那么，为什么要将Secrets与**ConfigMap**对象分开呢？提供一个单独的对象类型可以更容易地维护访问控制，并且可以使用外部系统注入敏感信息。
- en: Secrets can be created using a file, directory, or from a literal string. As
    an example, we have a MySQL image we want to execute, and we would like to pass
    the password to the Pod using a Secret. On our workstation, we have a file called
    **dbpwd** in our current working directory that has our password in it. Using
    the **kubectl** command, we can create a Secret by executing **kubectl create
    secret generic mysql-admin --from-file=./dbpwd**.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Secrets可以使用文件、目录或文字字符串创建。例如，我们有一个要执行的MySQL镜像，并且我们希望使用Secret将密码传递给Pod。在我们的工作站上，我们有一个名为**dbpwd**的文件，其中包含我们的密码。使用**kubectl**命令，我们可以通过执行**kubectl
    create secret generic mysql-admin --from-file=./dbpwd**来创建一个Secret。
- en: 'This would create a new a Secret called **mysql-admin** in the current namespace,
    with the content of the **dbpwd** file. Using **kubectl**, we can get the output
    of the Secret by running the **kubectl get secret mysql-admin -o yaml** command,
    which would output the following:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在当前命名空间中创建一个名为**mysql-admin**的新Secret，其中包含**dbpwd**文件的内容。使用**kubectl**，我们可以通过运行**kubectl
    get secret mysql-admin -o yaml**命令来获取Secret的输出，该命令将输出以下内容：
- en: 'apiVersion: v1'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: v1'
- en: 'data:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 'data:'
- en: 'dbpwd: c3VwZXJzZWNyZXQtcGFzc3dvcmQK'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 'dbpwd: c3VwZXJzZWNyZXQtcGFzc3dvcmQK'
- en: 'KinD: Secret'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 'KinD: Secret'
- en: 'metadata:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 'metadata:'
- en: 'creationTimestamp: "2020-03-24T18:39:31Z"'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 'creationTimestamp: "2020-03-24T18:39:31Z"'
- en: 'name: mysql-admin'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 'name: mysql-admin'
- en: 'namespace: default'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 'namespace: default'
- en: 'resourceVersion: "464059"'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 'resourceVersion: "464059"'
- en: 'selfLink: /api/v1/namespaces/default/secrets/mysql-admin'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 'selfLink: /api/v1/namespaces/default/secrets/mysql-admin'
- en: 'uid: 69220ebd-c9fe-4688-829b-242ffc9e94fc'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 'uid: 69220ebd-c9fe-4688-829b-242ffc9e94fc'
- en: 'type: Opaque'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 'type: Opaque'
- en: Looking at the preceding output, you can see that the **data** section contains
    the name of our file and then a Base64-encoded value, which was created from the
    content of the file.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，您可以看到**data**部分包含我们文件的名称，然后是从文件内容创建的Base64编码值。
- en: 'If we copy the Base64 value from the Secret and pipe it out to the **base64**
    utility, we can easily decode the password, as follows:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从Secret中复制Base64值并将其传输到**base64**实用程序，我们可以轻松解码密码，如下所示：
- en: echo c3VwZXJzZWNyZXQtcGFzc3dvcmQK | base64 -d
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: echo c3VwZXJzZWNyZXQtcGFzc3dvcmQK | base64 -d
- en: supersecret-password
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: supersecret-password
- en: Tip
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 提示
- en: When using the **echo** command to Base64-encode strings, add the **-n** flag
    to avoid adding an additional **\n**. Instead of **echo 'test' | base64**, use
    **echo -n 'test' | base64**.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用**echo**命令对字符串进行Base64编码时，添加**-n**标志以避免添加额外的**\n**。而不是**echo 'test' | base64**，使用**echo
    -n 'test' | base64**。
- en: Everything is stored in Etcd, but we are concerned that someone may be able
    to hack into the master server and steal a copy of the Etcd database. Once someone
    has a copy of the database, they could easily use the **etcdctl** utility to look
    through the content to retrieve all of our Base64-encoded Secrets. Luckily, Kubernetes
    added a feature to encrypt Secrets when they are written to a database.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 所有内容都存储在Etcd中，但我们担心有人可能能够入侵主服务器并窃取Etcd数据库的副本。一旦有人拿到数据库的副本，他们可以轻松使用**etcdctl**实用程序浏览内容以检索我们所有的Base64编码的Secrets。幸运的是，Kubernetes添加了一个功能，可以在将Secrets写入数据库时对其进行加密。
- en: Enabling this feature can be fairly complex for many users, and while it sounds
    like a good idea, it does present some potential issues that you should consider
    before implementing it. If you would like to read the steps on encrypting your
    Secrets at rest, you can view these on the Kubernetes site at [https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对许多用户来说，启用此功能可能相当复杂，虽然听起来是个好主意，但在实施之前，它确实存在一些潜在问题，您应该考虑这些问题。如果您想阅读有关在休息时加密您的秘密的步骤，您可以在Kubernetes网站上查看[https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/)。
- en: Another option to secure Secrets is to use a third-party Secrets management
    tool such as HashiCorp's Vault or CyberArk's Conjur.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 保护秘密的另一个选择是使用第三方秘密管理工具，如HashiCorp的Vault或CyberArk的Conjur。
- en: Service accounts
  id: totrans-235
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务账户
- en: Kubernetes uses service accounts to enable access controls for workloads. When
    you create a Deployment, you may need to access other services or Kubernetes objects.
    Since Kubernetes is a secure system, each object or service your application tries
    to access will evaluate **role-based access control** (**RBAC**) rules to accept
    or deny the request.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用服务账户来为工作负载启用访问控制。当您创建一个部署时，可能需要访问其他服务或Kubernetes对象。由于Kubernetes是一个安全系统，应用程序尝试访问的每个对象或服务都将评估基于角色的访问控制（RBAC）规则以接受或拒绝请求。
- en: 'Creating a service account using a manifest is a straightforward process, requiring
    only a few lines in the manifest. The following code snippet shows a service account
    manifest to create a service account for a Grafana Deployment:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 使用清单创建服务账户是一个简单的过程，只需要在清单中添加几行代码。以下代码片段显示了用于为Grafana部署创建服务账户的服务账户清单：
- en: 'apiVersion: v1'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：v1
- en: 'KinD: ServiceAccount'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：ServiceAccount
- en: 'metadata:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: grafana'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：grafana
- en: 'namespace: monitoring'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: namespace：监控
- en: You combine the service account with role bindings and roles to allow access
    to the required services or objects.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 您将服务账户与角色绑定和角色结合在一起，以允许访问所需的服务或对象。
- en: Services
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务
- en: In order to make an application running in a Pod(s) available to the network,
    you need to create a service. A service object stores information about how to
    expose the application, including which Pods are running on the application and
    the network ports to reach them.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使在Pod(s)中运行的应用程序对网络可用，您需要创建一个服务。服务对象存储有关如何公开应用程序的信息，包括运行应用程序的Pods以及到达它们的网络端口。
- en: 'Each service has a network type that is assigned when they are created, and
    they include the following:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务在创建时都分配了一个网络类型，其中包括以下内容：
- en: '**ClusterIP**: A network type that is only accessible inside the cluster itself.
    This type can still be used for external requests using an ingress controller,
    which will be discussed in a later chapter.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ClusterIP：一种只能在集群内部访问的网络类型。这种类型仍然可以用于使用入口控制器的外部请求，这将在后面的章节中讨论。
- en: '**NodePort**: A network type that exposes the service to a random port between
    ports **30000**-**32767**.This port becomes accessible by targeting any worker
    node in a cluster on the assigned **NodePort**. Once created, each node in the
    cluster will receive the port information and incoming requests will be routed
    via **kube-proxy**.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NodePort：一种网络类型，将服务公开到端口30000-32767之间的随机端口。通过定位集群中的任何工作节点，可以访问此端口。创建后，集群中的每个节点都将接收端口信息，并且传入请求将通过kube-proxy路由。
- en: '**LoadBalancer**: This type requires an add-on to use inside a cluster. If
    you are running Kubernetes on a public cloud provider, this type will create an
    external load balancer that will assign an IP address to your service. Most on-premise
    Kubernetes installations do not include support for the **LoadBalancer** type,
    but some offerings such as Google''s Anthos do offer support for it. In a later
    chapter, we will explain how to add an open source project called **MetalLB**
    to a Kubernetes cluster to provide support for the **LoadBalancer** type.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LoadBalancer**：这种类型需要一个附加组件才能在集群内部使用。如果您在公共云提供商上运行Kubernetes，这种类型将创建一个外部负载均衡器，为您的服务分配一个IP地址。大多数本地安装的Kubernetes不包括对**LoadBalancer**类型的支持，但一些提供商，如谷歌的Anthos确实支持它。在后面的章节中，我们将解释如何向Kubernetes集群添加一个名为**MetalLB**的开源项目，以提供对**LoadBalancer**类型的支持。'
- en: '**ExternalName**: This type is different from the other three. Unlike the other
    three options, this type will not assign an IP address to the service. Instead,
    this is used to map the internal Kubernetes **Domain Name System** (**DNS**) name
    to an external service.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ExternalName**：这种类型与其他三种不同。与其他三种选项不同，这种类型不会为服务分配IP地址。相反，它用于将内部Kubernetes**域名系统**（**DNS**）名称映射到外部服务。'
- en: 'As an example, we have deployed a Pod running Nginx on port **80**. We want
    to create a service that will allow this Pod to receive incoming requests on port
    **80** from within the cluster. The code for this can be seen in the following
    snippet:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们部署了一个在端口**80**上运行Nginx的Pod。我们希望创建一个服务，使得该Pod可以在集群内从端口**80**接收传入请求。以下代码显示了这个过程：
- en: 'apiVersion: v1'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：v1
- en: 'KinD: Service'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：服务
- en: 'metadata:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'labels:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：
- en: 'app: nginx-web-frontend'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：nginx-web-frontend
- en: 'name: nginx-web'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：nginx-web
- en: 'spec:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'ports:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 端口：
- en: '- name: http'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：http'
- en: 'port: 80'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 端口：80
- en: 'targetPort: 80'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 目标端口：80
- en: 'selector:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 选择器：
- en: 'app: nginx-web'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 应用：nginx-web
- en: In our manifest, we create a label with a value of **app** and assign a value
    of **nginx-web-frontend**. We have called the service itself **nginx-web** and
    we exposed the service on port **80**, targeting the Pod port of **80**. The last
    two lines of the manifest are used to assign the Pods that the service will forward
    to, also known as endpoints. In this manifest, any Pod that has the label of **app**
    with a value of **nginx-web** in the namespace will be added as an endpoint to
    the service.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的清单中，我们创建了一个标签，其值为**app**，并分配了一个值**nginx-web-frontend**。我们将服务本身称为**nginx-web**，并将服务暴露在端口**80**上，目标是**80**端口的Pod。清单的最后两行用于分配服务将转发到的Pod，也称为端点。在此清单中，任何在命名空间中具有标签**app**值为**nginx-web**的Pod都将被添加为服务的端点。
- en: CustomResourceDefinitions
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自定义资源定义
- en: '**CustomResourceDefinitions** (**CRDs**) allow anyone to extend Kubernetes
    by integrating your application into a cluster as a standard object. Once a CRD
    is created, you can reference it using an API endpoint, and it can be interacted
    with using standard **kubectl** commands.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**自定义资源定义**（**CRD**）允许任何人通过将应用程序集成到集群中作为标准对象来扩展Kubernetes。创建CRD后，您可以使用API端点引用它，并且可以使用标准**kubectl**命令与之交互。'
- en: DaemonSets
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 守护进程集
- en: A **DaemonSet** allows you to deploy a Pod on every node in a cluster, or a
    subset of nodes. A common use for a **DaemonSet** is to deploy a log forwarding
    Pod such as FluentD to every node in a cluster. Once deployed, the **DaemonSet**
    will create a FluentD Pod on all existing nodes. Since a **DaemonSet** deploys
    to all nodes, any additional nodes that are added to a cluster will have a FluentD
    Pod started once the node has joined the cluster.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '**DaemonSet**允许您在集群中的每个节点或节点子集上部署一个Pod。**DaemonSet**的常见用途是部署日志转发Pod，如FluentD到集群中的每个节点。部署后，**DaemonSet**将在所有现有节点上创建一个FluentD
    Pod。由于**DaemonSet**部署到所有节点，一旦将节点添加到集群中，就会启动一个FluentD Pod。'
- en: Deployments
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署
- en: 'We mentioned earlier that you should never deploy a Pod directly, and we also
    introduced the **ReplicationContoller** object as an alternative to creating Pods
    directly. While both of these will create your Pods, each comes with the following
    limitation: Pods created directly cannot be scaled and cannot be upgraded using
    rolling updates.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，您永远不应该直接部署Pod，并且我们还介绍了ReplicationContoller对象作为创建Pod的替代方法。虽然这两种方法都会创建您的Pod，但每种方法都有以下限制：直接创建的Pod无法扩展，并且无法使用滚动更新进行升级。
- en: Pods created by a **ReplicationController** can be scaled, and can perform rolling
    updates. However, they do not support rollbacks, and upgrades cannot be done declaratively.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 由ReplicationController创建的Pod可以进行扩展，并可以执行滚动更新。但是，它们不支持回滚，并且无法以声明方式进行升级。
- en: 'Deployments offer you a few advantages, including a way to manage your upgrades
    declaratively and the ability to roll back to previous revisions. Creating a Deployment
    is actually a three-step process executed by the API server: a Deployment is created,
    which creates a ReplicaSet object, which then creates the Pod(s) for the application.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 部署为您提供了一些优势，包括以声明方式管理升级的方法以及回滚到先前版本的能力。创建部署实际上是由API服务器执行的一个三步过程：创建部署，创建一个ReplicaSet对象，然后为应用程序创建Pod(s)。
- en: Even if you don't plan to use these features, you should use Deployments by
    default so that you can leverage the features at a future date.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 即使您不打算使用这些功能，也应该默认使用部署，以便在将来利用这些功能。
- en: ReplicaSets
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReplicaSets
- en: ReplicaSets can be used to create a Pod or a set of Pods (replicas). Similar
    to the **ReplicationController** object, a **ReplicaSet** object will maintain
    the set number of Pods defined in the replica count of the object. If there are
    too few Pods, Kubernetes will reconcile the difference and create the missing
    Pods. If there are too many Pods for a ReplicaSet, Kubernetes will delete Pods
    until the number is equal to the replica count set in the object.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSets可用于创建一个Pod或一组Pod（副本）。与ReplicationController对象类似，ReplicaSet对象将维护对象中定义的副本计数的一组Pod。如果Pod太少，Kubernetes将协调差异并创建缺少的Pod。如果ReplicaSet有太多的Pod，Kubernetes将删除Pod，直到数量等于对象中设置的副本计数为止。
- en: In general, you should avoid creating ReplicaSets directly. Instead, you should
    create a Deployment, which will create and manage a ReplicaSet.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，您应该避免直接创建ReplicaSets。相反，您应该创建一个部署，它将创建和管理一个ReplicaSet。
- en: StatefulSets
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StatefulSets
- en: 'StatefulSets offer some unique features when creating Pods. They provide features
    that none of the other Pod creation methods offer, including the following:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建Pod时，StatefulSets提供了一些独特的功能。它们提供了其他Pod创建方法所没有的功能，包括以下内容：
- en: Known Pod names
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知的Pod名称
- en: Ordered Deployment and scaling
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序部署和扩展
- en: Ordered updates
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序更新
- en: Persistent storage creation
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久存储创建
- en: 'The best way to understand the advantages of a StatefulSet is to review an
    example manifest from the Kubernetes site, shown in the following screenshot:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 了解StatefulSet的优势的最佳方法是查看Kubernetes网站上的示例清单，如下截图所示：
- en: '![Figure 5.9 – StatefulSet manifest example'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '![图5.9 - StatefulSet清单示例'
- en: '](image/Fig_5.9_B15514.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '](image/Fig_5.9_B15514.jpg)'
- en: Figure 5.9 – StatefulSet manifest example
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.9 - StatefulSet清单示例
- en: Now, we can look at the objects that the **StatefulSet** object created.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看一下StatefulSet对象创建的对象。
- en: 'The manifest specifies that there should be three replicas of a Pod named **nginx**.
    When we get a list of Pods, you will see that three Pods were created using the
    **nginx** name, with an additional dash and an incrementing number. This is what
    we meant in the overview when we mentioned that Pods will be created with known
    names, as illustrated in the following code snippet:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 清单指定应该有三个名为**nginx**的Pod副本。当我们获取Pod列表时，您会看到使用**nginx**名称创建了三个Pod，另外带有一个破折号和递增的数字。这就是我们在概述中提到的Pod将使用已知名称创建的意思，如下面的代码片段所示：
- en: NAME READY STATUS RESTARTS AGE
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 准备状态 状态 重启 年龄
- en: web-0 1/1 Running 0 4m6s
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: web-0 1/1 运行中 0 4m6s
- en: web-1 1/1 Running 0 4m2s
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: web-1 1/1 运行中 0 4m2s
- en: web-2 1/1 Running 0 3m52s
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: web-2 1/1 运行中 0 3m52s
- en: The Pods are also created in order – w**eb-0** must be fully deployed before
    **web-1** is created, and then finally **web-2**.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: Pod也是按顺序创建的——**web-0**必须在创建**web-1**之前完全部署，然后最后是**web-2**。
- en: 'Finally, for this example, we also added a PVC to each Pod using the **VolumeClaimTemplate**
    in the manifest. If you look at the output of the **kubectl get pvc** command,
    you would see that three PVCs were created with names we expected (note that we
    removed the **VOLUME** column due to space), as illustrated in the following code
    snippet:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于这个示例，我们还在清单中使用**VolumeClaimTemplate**为每个Pod添加了一个PVC。如果您查看**kubectl get
    pvc**命令的输出，您会看到创建了三个PVC，名称与我们预期的相同（请注意，由于空间原因，我们删除了**VOLUME**列），如下面的代码片段所示：
- en: NAME STATUS CAPACITY ACCESS MODES STORAGECLASS AGE
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 状态 容量 访问模式 存储类 年龄
- en: www-web-0 Bound 1Gi RWO nfs 13m
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: www-web-0 已绑定 1Gi RWO nfs 13m
- en: www-web-1 Bound 1Gi RWO nfs 13m
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: www-web-1 已绑定 1Gi RWO nfs 13m
- en: www-web-2 Bound 1Gi RWO nfs 12m
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: www-web-2 已绑定 1Gi RWO nfs 12m
- en: In the **VolumeClaimTemplate** section of the manifest, you will see that we
    assigned the name **www** to the PVC claim. When you assign a volume in a StatefulSet,
    the PVC name will combine the name used in the claim template, combined with the
    name of the Pod. Using this naming, you can see why Kubernetes assigned the PVC
    names **www-web-0**, **www-web-1**, and **www-web-2**.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单的**VolumeClaimTemplate**部分，您会看到我们将名称**www**分配给了PVC声明。当您在StatefulSet中分配卷时，PVC名称将结合在声明模板中使用的名称，与Pod的名称结合在一起。使用这种命名，您可以看到为什么Kubernetes分配了PVC名称**www-web-0**、**www-web-1**和**www-web-2**。
- en: HorizontalPodAutoscalers
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HorizontalPodAutoscalers
- en: One of the biggest advantages of running a workload on a Kubernetes cluster
    is the ability to easily scale your Pods. While you can scale using the **kubectl**
    command or by editing a manifest's replica count, these are not automated and
    require manual intervention.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes集群上运行工作负载的最大优势之一是能够轻松扩展您的Pod。虽然您可以使用**kubectl**命令或编辑清单的副本计数来进行扩展，但这些都不是自动化的，需要手动干预。
- en: '**HorizontalPodAutoscalers** (**HPAs**) provide the ability to scale an application
    based on a set of criteria. Using metrics such as CPU and memory usage, or your
    own custom metrics, you can set a rule to scale your Pods up when you need more
    Pods to maintain your service level. After a cooldown period, Kubernetes will
    scale the application back to the minimum number of Pods defined in the policy.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**HorizontalPodAutoscalers**（**HPAs**）提供了根据一组条件扩展应用程序的能力。使用诸如CPU和内存使用率或您自己的自定义指标等指标，您可以设置规则，在需要更多Pod来维持服务水平时扩展您的Pod。冷却期后，Kubernetes将应用程序缩减到策略中定义的最小Pod数。'
- en: 'To quickly create an HPA for an **nginx** Deployment, we can execute a **kubectl**
    command using the **autoscale** option, as follows:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速为**nginx**部署创建HPA，我们可以使用**autoscale**选项执行**kubectl**命令，如下所示：
- en: kubectl autoscale deployment nginx --cpu-percent=50 --min=1 --max=5
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl autoscale deployment nginx --cpu-percent=50 --min=1 --max=5
- en: 'You can also create a Kubernetes manifest to create your HPAs. Using the same
    options as those we did in the CLI, our manifest would look like this:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以创建一个Kubernetes清单来创建您的HPAs。使用与我们在CLI中使用的相同选项，我们的清单将如下所示：
- en: 'apiVersion: autoscaling/v1'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：autoscaling/v1
- en: 'KinD: HorizontalPodAutoscaler'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：HorizontalPodAutoscaler
- en: 'metadata:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: nginx-deployment'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：nginx-deployment
- en: 'spec:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'maxReplicas: 5'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 最大副本数：5
- en: 'minReplicas: 1'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 最小副本数：1
- en: 'scaleTargetRef:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: scaleTargetRef：
- en: 'apiVersion: apps/v1'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：apps/v1
- en: 'KinD: Deployment'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：部署
- en: 'name: nginx-deployment'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：nginx-deployment
- en: 'targetCPUUtilizationPercentage: 50'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: targetCPU利用率百分比：50
- en: Both options will create an HPA that will scale our **nginx-deployment nginx**
    Deployment up to five replicas when the Deployment hits a CPU utilization of 50%.
    Once the Deployment usage falls below 50% and the cooldown period is reached (by
    default, 5 minutes), the replica count will be reduced down to 1.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个选项都将创建一个HPA，当部署达到50%的CPU利用率时，将使我们的**nginx-deployment nginx**部署扩展到五个副本。一旦部署使用率低于50％并且达到冷却期（默认为5分钟），副本计数将减少到1。
- en: CronJobs
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Cron作业
- en: If you have used Linux cronjobs in the past, then you already know what a Kubernetes
    **CronJob** object is. If you don't have a Linux background, a cronjob is used
    to create a scheduled task. As another example, if you are a Windows person, it's
    similar to Windows scheduled tasks.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您以前使用过Linux cron作业，那么您已经知道Kubernetes **CronJob**对象是什么。如果您没有Linux背景，cron作业用于创建定期任务。另一个例子，如果您是Windows用户，它类似于Windows定期任务。
- en: 'An example manifest that creates a **CronJob** is shown in the following code
    snippet:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 创建**CronJob**的示例清单如下所示：
- en: 'apiVersion: batch/v1beta1'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：batch/v1beta1
- en: 'KinD: CronJob'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：CronJob
- en: 'metadata:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: hello-world'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：hello-world
- en: 'spec:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'schedule: "*/1 * * * *"'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 计划：“*/1 * * * *”
- en: 'jobTemplate:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 作业模板：
- en: 'spec:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'template:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 模板：
- en: 'spec:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'containers:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 容器：
- en: '- name: hello-world'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '- 名称：hello-world'
- en: 'image: busybox'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图像：busybox
- en: 'args:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 参数：
- en: '- /bin/sh'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '- /bin/sh'
- en: '- -c'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: '- -c'
- en: '- date; echo Hello World!'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '- 日期；回声你好，世界！'
- en: 'restartPolicy: OnFailure'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 重启策略：失败时
- en: 'The **schedule** format follows the standard **cron** format. From left to
    right, each ***** represents the following:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '**计划**格式遵循标准**cron**格式。从左到右，每个*****代表以下内容：'
- en: Minute (0 – 59)
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分钟（0-59）
- en: Hour (0 -23)
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小时（0-23）
- en: Day (1 -31)
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期（1-31）
- en: Month (1 – 12)
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月份（1-12）
- en: Day of the week (0 – 6) (Sunday = 0, Saturday = 6)
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一周的日期（0-6）（星期日= 0，星期六= 6）
- en: Cron jobs accept step values, which allow you to create a schedule that can
    execute every minute, every 2 minutes, or every hour.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: Cron作业接受步骤值，允许您创建可以每分钟、每2分钟或每小时执行的计划。
- en: Our example manifest will create a **cronjob** that runs an image called **hello-world**
    every minute and outputs **Hello World!** in the Pod log.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例清单将创建一个每分钟运行名为**hello-world**的图像的**cronjob**，并在Pod日志中输出**Hello World!**。
- en: Jobs
  id: totrans-349
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 作业
- en: Jobs allow you to execute a specific number of executions of a Pod or Pods.
    Unlike a **cronjob** object, these Pods are not run on a set schedule, but rather
    they will execute once created. Jobs are used to execute a task that may only
    need to be executed at the initial Deployment stage.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 作业允许您执行特定数量的Pod或Pod的执行。与**cronjob**对象不同，这些Pod不是按照固定的时间表运行的，而是它们一旦创建就会执行。作业用于执行可能只需要在初始部署阶段执行的任务。
- en: An example use case would be an application that may require the creation of
    Kubernetes CRDs that must exist before the main application is deployed. The Deployment
    would wait until the job execution completed successfully.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例用例可能是一个应用程序，可能需要在主应用程序部署之前创建必须存在的Kubernetes CRD。部署将等待作业执行成功完成。
- en: Events
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件
- en: Events objects store information about events for Kubernetes objects. You do
    not create events; rather, you can only retrieve events. For example, to retrieve
    events for the **kube-system** namespace, you would execute **kubectl get events
    -n kube-system**, or to show events for all namespaces, you'd execute **kubectl
    get events --all-namespaces**.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 事件对象存储有关Kubernetes对象的事件信息。您不会创建事件；相反，您只能检索事件。例如，要检索**kube-system**命名空间的事件，您将执行**kubectl
    get events -n kube-system**，或者要显示所有命名空间的事件，您将执行**kubectl get events --all-namespaces**。
- en: Ingresses
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 入口
- en: You may have noticed that the **Ingress** object was listed twice in our **api-server**
    output. This will happen to objects as Kubernetes upgrades are released and objects
    changed in the API server. In the case of Ingress, it was original part of the
    extensions API and was moved to the **networking.k8s.io** API in version 1.16\.
    The project will wait a few releases before deprecating the old API call, so in
    our example cluster running Kubernetes 1.17, using either API will work. In version
    1.18, they have plans to fully deprecate the Ingress extensions.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到我们的api-server输出中**Ingress**对象被列两次。随着Kubernetes的升级和API服务器中对象的更改，这种情况会发生。在Ingress的情况下，它最初是扩展API的一部分，并在1.16版本中移至**networking.k8s.io**
    API。该项目将在废弃旧的API调用之前等待几个版本，因此在我们的示例集群中运行Kubernetes 1.17时，使用任何API都可以正常工作。在1.18版本中，他们计划完全废弃Ingress扩展。
- en: NetworkPolicies
  id: totrans-356
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络策略
- en: '**NetworkPolicy** objects let you define how network traffic can flow through
    your cluster. They allow you to use Kubernetes native constructs to define which
    Pods can talk to other Pods. If you''ve ever used Security Groups in **Amazon
    Web Services** (**AWS**) to lock down access between two groups of systems, it''s
    a similar concept. As an example, the following policy will allow traffic on port
    **443** to Pods in the **myns** namespace from any namespace with the **app.kubernetes.io/name:
    ingress-nginx** label on it (which is the default label for the **nginx-ingress**
    namespace):'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '**NetworkPolicy**对象允许您定义网络流量如何在集群中流动。它们允许您使用Kubernetes本机构造来定义哪些Pod可以与其他Pod通信。如果您曾经在**Amazon
    Web Services**（**AWS**）中使用安全组来锁定两组系统之间的访问权限，那么这是一个类似的概念。例如，以下策略将允许来自任何带有**app.kubernetes.io/name:
    ingress-nginx**标签的命名空间的Pod上的端口**443**的流量（这是**nginx-ingress**命名空间的默认标签）到**myns**命名空间中的Pod：'
- en: 'apiVersion: networking.k8s.io/v1'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: api版本：networking.k8s.io/v1
- en: 'KinD: NetworkPolicy'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：网络策略
- en: 'metadata:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: allow-from-ingress'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：allow-from-ingress
- en: 'namespace: myns'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：myns
- en: 'spec:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 规范：
- en: 'PodSelector: {}'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: Pod选择器：{}
- en: 'policyTypes:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 策略类型：
- en: '- Ingress'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '- 入口'
- en: 'ingress:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 入口：
- en: '- from:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '- 来自：'
- en: '- namespaceSelector:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '- 命名空间选择器：'
- en: 'matchLabels:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配标签：
- en: 'app.kubernetes.io/name: ingress-nginx ports:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: app.kubernetes.io/name：ingress-nginx端口：
- en: '- protocol: TCP'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '- 协议：TCP'
- en: 'port: 443'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 端口：443
- en: A **NetworkPolicy** object is another object that you can use to secure a cluster.
    They should be used in all production clusters, but in a multi-tenant cluster
    they should be considered a **must-have** to secure each namespace in the cluster.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '**NetworkPolicy**对象是另一个可以用来保护集群的对象。它们应该在所有生产集群中使用，但在多租户集群中，它们应该被视为保护集群中每个命名空间的**必备**。'
- en: PodSecurityPolicies
  id: totrans-375
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pod安全策略
- en: '**PodSecurityPolicies** (**PSPs**) are how your cluster protects your nodes
    from your containers. They allow you to limit the actions that a Pod can execute
    in a cluster. Some examples include denying access to the HostIPC and HostPath,
    and running a container in a privileged mode.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pod安全策略**（**PSPs**）是集群如何保护节点免受容器影响的方式。它们允许您限制Pod在集群中可以执行的操作。一些示例包括拒绝访问HostIPC和HostPath，并以特权模式运行容器。'
- en: We'll get into the details of PSPs in [*Chapter 10*](B15514_10_Final_ASB_ePub.xhtml#_idTextAnchor260),
    *Creating Pod Security Policies*. The key point to remember about PSPs is that
    without them, your containers can do almost anything on your nodes.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第10章*](B15514_10_Final_ASB_ePub.xhtml#_idTextAnchor260)中详细介绍PSPs，*创建Pod安全策略*。关于PSPs要记住的关键点是，如果没有它们，您的容器几乎可以在节点上执行任何操作。
- en: ClusterRoleBindings
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClusterRoleBindings
- en: Once you have defined a **ClusterRole**, you bind it to a subject via a **ClusterRoleBinding**.
    A **ClusterRole** can be bound to a User, Group, or ServiceAccount.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您定义了**ClusterRole**，您可以通过**ClusterRoleBinding**将其绑定到主题。**ClusterRole**可以绑定到用户、组或ServiceAccount。
- en: We'll explore **ClusterRoleBinding** details in [*Chapter 8*](B15514_08_Final_ASB_ePub.xhtml#_idTextAnchor228)*,
    RBAC Policies and Auditing*.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第8章*](B15514_08_Final_ASB_ePub.xhtml#_idTextAnchor228)*，RBAC Policies
    and Auditing*中探讨**ClusterRoleBinding**的细节。
- en: ClusterRoles
  id: totrans-381
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 集群角色
- en: 'A **ClusterRole** combines a set of permissions for interacting with your cluster''s
    API. A **ClusterRole** combines a verb or action with an API group to define a
    permission. For instance, if you only want your **continuous integration/continuous
    delivery** (**CI/CD**) pipeline to be able to patch your Deployments so that it
    can update your image tag, you might use a **ClusterRole** like this:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '**ClusterRole**结合了一组权限，用于与集群的API交互。**ClusterRole**将动词或操作与API组合在一起，以定义权限。例如，如果您只希望您的**持续集成/持续交付**（**CI/CD**）流水线能够修补您的部署，以便它可以更新您的图像标记，您可以使用这样的**ClusterRole**：'
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：rbac.authorization.k8s.io/v1
- en: 'KinD: ClusterRole'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：ClusterRole
- en: 'metadata:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: patch-deployment'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：patch-deployment
- en: 'rules:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 规则：
- en: '- apiGroups: ["apps/v1"]'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: '- apiGroups：["apps/v1"]'
- en: 'resources: ["deployments"]'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 资源：["deployments"]
- en: 'verbs: ["get", "list", "patch"]'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 动词：["get", "list", "patch"]
- en: A **ClusterRole** can apply to APIs at both the cluster and namespace level.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '**ClusterRole**可以适用于集群和命名空间级别的API。'
- en: RoleBindings
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RoleBindings
- en: 'The **RoleBinding** object is how you associate a Role or **ClusterRole** to
    a subject and namespace. For instance, the following **RoleBinding** object will
    allow the **aws-codebuild** user to apply the **patch-openunison** ClusterRole
    to the **openunison** namespace:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**RoleBinding**对象是您如何将角色或**ClusterRole**与主题和命名空间关联起来的。例如，以下**RoleBinding**对象将允许**aws-codebuild**用户将**patch-openunison**
    ClusterRole应用于**openunison**命名空间：'
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: apiVersion：rbac.authorization.k8s.io/v1
- en: 'KinD: RoleBinding'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：RoleBinding
- en: 'metadata:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: patch-openunison'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：patch-openunison
- en: 'namespace: openunison'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间：openunison
- en: 'subjects:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 主题：
- en: '- KinD: User'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: '- KinD：用户'
- en: 'name: aws-codebuild'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：aws-codebuild
- en: 'apiGroup: rbac.authorization.k8s.io'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: apiGroup：rbac.authorization.k8s.io
- en: 'roleRef:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: roleRef：
- en: 'KinD: ClusterRole'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: KinD：ClusterRole
- en: 'name: patch-deployment'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：patch-deployment
- en: 'apiGroup: rbac.authorization.k8s.io'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: apiGroup：rbac.authorization.k8s.io
- en: Even though this references a **ClusterRole**, it will only apply to the **openunison**
    namespace. If the **aws-codebuild** user tries to patch a Deployment in another
    namespace, the API server will stop it.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这引用了**ClusterRole**，它只适用于**openunison**命名空间。如果**aws-codebuild**用户尝试在另一个命名空间中修补部署，API服务器将阻止它。
- en: Roles
  id: totrans-408
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 角色
- en: As with a **ClusterRole**, Roles combine API groups and actions to define a
    set of permissions that can be assigned to a subject. The difference between a
    **ClusterRole** and a **Role** is that a **Role** can only have resources defined
    at the namespace level and applies only within a specific namespace.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 与**ClusterRole**一样，角色将API组和操作组合起来，以定义可以分配给主题的一组权限。**ClusterRole**和**Role**之间的区别在于**Role**只能在命名空间级别定义资源，并且仅适用于特定命名空间。
- en: CsiDrivers
  id: totrans-410
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CsiDrivers
- en: Kubernetes uses the **CsiDriver** object to connect nodes to a storage system.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用**CsiDriver**对象将节点连接到存储系统。
- en: 'You can list all CSI drivers that are available on a cluster by executing the
    **kubectl get csidriver** command. In one of our clusters we are using Netapp''s
    SolidFire for storage, so our cluster has the Trident CSI driver installed, as
    can be seen here:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行**kubectl get csidriver**命令列出集群中所有可用的CSI驱动程序。在我们的一个集群中，我们使用Netapp的SolidFire进行存储，因此我们的集群安装了Trident
    CSI驱动程序，如下所示：
- en: NAME CREATED AT
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 名称 创建于
- en: csi.trident.netapp.io 2019-09-04T19:10:47Z
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: csi.trident.netapp.io 2019-09-04T19:10:47Z
- en: CsiNodes
  id: totrans-415
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CsiNodes
- en: To avoid storing storage information in the node API object, the **CSINode**
    object was added to the API server to store information generated by the CSI drivers.
    The information that is stored includes mapping Kubernetes node names to CSI node
    names, CSI driver availability, and the volume topology.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免在节点API对象中存储存储信息，**CSINode**对象被添加到API服务器中，用于存储CSI驱动程序生成的信息。存储的信息包括将Kubernetes节点名称映射到CSI节点名称、CSI驱动程序的可用性和卷拓扑。
- en: StorageClasses
  id: totrans-417
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StorageClasses
- en: Storage classes are used to define a storage endpoint. Each storage class can
    be assigned labels and policies, allowing a developer to select the best storage
    location for their persistent data. You may create a storage class for a backend
    system that has all **Non-Volatile Memory Express** (**NVMe**) drives, assigning
    it the name **fast**, while assigning a different class to a Netapp **Network
    File System** (**NFS**) volume running standard drives, using the name **standard**.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类用于定义存储端点。每个存储类都可以分配标签和策略，允许开发人员为其持久数据选择最佳存储位置。您可以为具有所有**非易失性内存表达**（**NVMe**）驱动器的后端系统创建一个存储类，将其命名为**fast**，同时为运行标准驱动器的Netapp
    **网络文件系统**（**NFS**）卷分配一个不同的类，使用名称**standard**。
- en: When a PVC is requested, the user can assign a **StorageClass** that they wish
    to use. When the API server receives the request, it finds the matching name and
    uses the **StorageClass** configuration to create the volume on the storage system
    using a provisioner.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求PVC时，用户可以分配他们希望使用的**StorageClass**。当API服务器接收到请求时，它会找到匹配的名称，并使用**StorageClass**配置来使用provisioner在存储系统上创建卷。
- en: 'At a very high level, a **StorageClass** manifest does not require a lot of
    information. Here is an example of a storage class using a provisioner from the
    Kubernetes incubator project to provide NFS auto-provisioned volumes, named **nfs**:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常高的层面上，**StorageClass**清单不需要太多的信息。以下是一个使用Kubernetes孵化器项目中的provisioner提供NFS自动配置卷的存储类的示例：
- en: 'apiVersion: storage.k8s.io/v1 KinD: StorageClass'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 'apiVersion: storage.k8s.io/v1 KinD: StorageClass'
- en: 'metadata:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'name: nfs'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 名称：nfs
- en: 'provisioner: nfs'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 'provisioner: nfs'
- en: Storage classes allow you to offer multiple storage solutions to your users.
    You may create a class for cheaper, slower storage while offering a second class
    that supports high throughput for high data requirements. By providing a different
    class to each offering, you allow developers to select the best choice for their
    application.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类允许您为用户提供多种存储解决方案。您可以为更便宜、更慢的存储创建一个类，同时为高数据需求提供高吞吐量支持的第二类。通过为每个提供不同的类，您允许开发人员为其应用程序选择最佳选择。
- en: Summary
  id: totrans-426
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you were thrown into a Kubernetes bootcamp that presented a
    lot of technical material in a short amount of time. Try to remember that this
    will all become easier as you get into the Kubernetes world in more depth. We
    realize that this chapter had a lot of information on many objects. Many of the
    objects will be used in later chapters, and they will be explained in greater
    detail.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你被投入了一个Kubernetes训练营，短时间内呈现了大量的技术材料。试着记住，随着你更深入地了解Kubernetes世界，这一切都会变得更容易。我们意识到这一章包含了许多对象的信息。许多对象将在后面的章节中使用，并且将会有更详细的解释。
- en: You learned about each Kubernetes component and how they interact to create
    a cluster. With this knowledge, you have the required skills to look at errors
    in a cluster and determine which component may be causing an error or issue. We
    covered the control plane of a cluster where the **api-server**, **kube-scheduler**,
    Etcd, and control managers run. The control plane is how users and services interact
    with a cluster; using the **api-server** and the **kube-scheduler** will decide
    which worker node to schedule your Pod(s) on. You also learned about Kubernetes
    nodes that run the **kubelet** and **kube-proxy** components, and a container
    runtime.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 你了解了每个Kubernetes组件以及它们如何相互作用来创建一个集群。有了这些知识，你就有了查看集群中的错误并确定哪个组件可能导致错误或问题的必要技能。我们介绍了集群的控制平面，其中**api-server**、**kube-scheduler**、Etcd和控制管理器运行。控制平面是用户和服务与集群交互的方式；使用**api-server**和**kube-scheduler**将决定将你的Pod(s)调度到哪个工作节点上。你还了解了运行**kubelet**和**kube-proxy**组件以及容器运行时的Kubernetes节点。
- en: We covered the **kubectl** utility that you will use to interact with a cluster.
    You also learned some common commands that you will use on a daily basis, including
    **logs** and **describe**.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 我们介绍了**kubectl**实用程序，你将用它与集群进行交互。你还学习了一些你将在日常使用的常见命令，包括**logs**和**describe**。
- en: In the next chapter, we will create a development Kubernetes cluster that we
    will use as the base cluster for the remaining chapters. Throughout the remainder
    of the book, we will reference many of the objects that were presented in this
    chapter, helping to explain them by using them in real-world examples.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将创建一个开发Kubernetes集群，这将成为剩余章节的基础集群。在本书的其余部分，我们将引用本章介绍的许多对象，通过在实际示例中使用它们来解释它们。
- en: Questions
  id: totrans-431
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A Kubernetes control plane does not include which of the following components?
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes控制平面不包括以下哪个组件？
- en: A. **api-server**
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: A. **api-server**
- en: B. **kube-scheduler**
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: B. **kube-scheduler**
- en: C. Etcd
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: C. Etcd
- en: D. Ingress controller
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: D. Ingress控制器
- en: What is the name of the component that keeps all of the cluster information?
  id: totrans-437
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个组件负责保存集群的所有信息？
- en: A. **api-server**
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: A. **api-server**
- en: B. Master controller
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: B. 主控制器
- en: C. **kubelet**
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: C. **kubelet**
- en: D. Etcd
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: D. Etcd
- en: Which component is responsible for selecting the node that will run a workload?
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个组件负责选择运行工作负载的节点？
- en: A. **kubelet**
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: A. **kubelet**
- en: B. **api-server**
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: B. **api-server**
- en: C. **kube-scheduler**
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: C. **kube-scheduler**
- en: D. **Pod-scheduler**
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: D. **Pod-scheduler**
- en: Which option would you add to a **kubectl** command to see additional output
    from a command?
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会在**kubectl**命令中添加哪个选项来查看命令的额外输出？
- en: A. **Verbose**
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: A. **冗长**
- en: B. **-v**
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: B. **-v**
- en: C. **–verbose**
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: C. **–verbose**
- en: D. **-log**
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: D. **-log**
- en: Which service type creates a randomly generated port, allowing incoming traffic
    to any worker node on the assigned port to access the service?
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种服务类型会创建一个随机生成的端口，允许分配端口的任何工作节点上的传入流量访问该服务？
- en: A. **LoadBalancer**
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: A. **LoadBalancer**
- en: B. **ClusterIP**
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: B. **ClusterIP**
- en: C. None—it's the default for all services
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: C. 没有—这是所有服务的默认设置
- en: D. **NodePort**
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: D. **NodePort**
- en: If you need to deploy an application on a Kubernetes cluster that requires known
    node names and a controlled startup of each Pod, which object would you create?
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你需要在Kubernetes集群上部署一个需要已知节点名称和控制每个Pod启动的应用程序，你会创建哪个对象？
- en: A. **StatefulSet**
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: A. **StatefulSet**
- en: B. **Deployment**
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: B. **Deployment**
- en: C. **ReplicaSet**
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: C. **ReplicaSet**
- en: D. **ReplicationController**
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: D. **ReplicationController**
