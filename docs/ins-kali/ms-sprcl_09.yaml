- en: Distributed Logging and Tracing
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分布式日志记录和跟踪
- en: When breaking down a monolith into microservices, we usually spend a lot of
    time thinking about business boundaries or the partitioning of our application
    logic, but we forget about the logs. From my own experience as a developer and
    software architect, I can say that developers do not usually pay much attention
    to logging. On the other hand, operation teams, which are responsible for application
    maintenance, are mainly dependent on logs. Regardless of one's area of expertise,
    it is indisputable that logging is something that all applications have to do,
    whether they have monolithic or microservices architecture. However, microservices
    force adding a whole new dimension to design and arrangement of application logs. There
    are many small, independent, horizontally scaled, intercommunicating services
    that are running on multiple machines. Requests are often processed by multiple
    services. We have to correlate these requests and store all the logs in a single,
    central place in order to make it easier to view them. Spring Cloud introduces
    a dedicated library that implements a distributed tracing solution, Spring Cloud
    Sleuth.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 将大型单体应用程序分解为微服务时，我们通常会花费大量时间思考业务边界或应用程序逻辑的分区，但我们忽略了日志。从我作为开发人员和软件架构师的经验来看，我可以说开发人员通常不太关注日志记录。另一方面，负责应用程序维护的运维团队主要依赖日志。无论一个人的专业领域是什么，日志记录都是所有应用程序都必须做的事情，无论它们是单体架构还是微服务架构。然而，微服务强制性地为应用程序日志的设计和安排增加了一个全新的维度。有许多小型、独立、水平扩展、相互通信的服务在多台机器上运行。请求通常由多个服务处理。我们必须将这些请求相关联，并将所有日志存储在一个单一的中心位置，以便更容易查看它们。Spring
    Cloud引入了一个专门的库，实现了分布式跟踪解决方案Spring Cloud Sleuth。
- en: There is also one thing that should be discussed here. Logging is not the same
    as tracing! It is worth pointing out the differences between them. Tracing is
    following your program's data flow. It is typically used by technical support
    teams to diagnose where a problem occurs. You have to trace your system flow to
    discover performance bottlenecks or times when the error occurs. Logging is used
    for error reporting and detecting. It should always be enabled, in contrast to
    tracing. When you design a large system and you would like to have good and flexible
    error reporting across machines, you should definitely think about collecting
    log data in a centralized way. The recommended and most popular solution for this
    is the **ELK** stack (**Elasticsearch** + **Logstash** + **Kibana**). There is
    no dedicated library for this stack in Spring Cloud, but the integration may be
    realized with Java logging frameworks, such as Logback or Log4j. There is another
    tool that will be discussed in this chapter, Zipkin. It is a typical tracing tool
    that helps gather timing data that can be used to troubleshoot latency problems
    in microservice architecture.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有一件事情需要讨论。日志记录不同于跟踪！值得指出它们之间的区别。跟踪是跟踪程序的数据流。通常由技术支持团队用于诊断问题发生的位置。您必须跟踪系统流程以发现性能瓶颈或错误发生的时间。日志记录用于错误报告和检测。与跟踪相比，它应该始终处于启用状态。当您设计一个大型系统，并且希望在多台机器上实现良好和灵活的错误报告时，您应该考虑以集中的方式收集日志数据。推荐的最流行的解决方案是ELK堆栈（Elasticsearch
    + Logstash + Kibana）。Spring Cloud中没有针对此堆栈的专用库，但可以使用Java日志框架（如Logback或Log4j）实现集成。本章还将讨论另一个工具Zipkin。这是一个典型的跟踪工具，可帮助收集用于解决微服务架构中延迟问题的时间数据。
- en: 'The topics we will cover in this chapter include the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: The best practices for logging in microservices-based systems
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于微服务的系统的日志记录最佳实践
- en: Using Spring Cloud Sleuth to append tracing information to messages and correlating
    events
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Spring Cloud Sleuth将跟踪信息附加到消息并关联事件
- en: Integrating the Spring Boot application with Logstash
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Spring Boot应用程序与Logstash集成
- en: Displaying and filtering log entries using Kibana
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Kibana显示和过滤日志条目
- en: Using Zipkin as a distributed tracing tool and integrating it with the application
    through Spring Cloud Sleuth
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Zipkin作为分布式跟踪工具，并通过Spring Cloud Sleuth将其集成到应用程序中
- en: Best logging practices for microservices
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务的最佳日志记录实践
- en: 'One of the most important best practices for dealing with logging is to trace
    all the incoming requests and outgoing responses. Maybe it seems obvious to you,
    but I have seen a couple of applications that did not comply with that requirement.
    If you meet this demand, there is one consequence that occurs with microservices-based
    architecture. The overall number of logs in your system increases compared to
    monolithic applications, where there is no messaging. This, in turn, requires
    us to pay even more attention to logging than before. We should do our best to
    generate as little information as possible, even though this information can tell
    us much about the situation. How do we achieve this? First of all, it is good
    to have the same log message format across all the microservices. For example,
    let''s consider how to print variables in the application logs. I suggest you
    use the JSON notation in view of the fact that, usually, messages exchanged between
    microservices are formatted with JSON. This format has a very straightforward
    standard, which makes your logs easily readable and parseable, as shown in the
    following code fragment:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 处理日志的最重要的最佳实践之一是跟踪所有传入请求和传出响应。也许对您来说这似乎是显而易见的，但我见过一些应用程序没有满足这一要求。如果满足了这一要求，那么在基于微服务的架构中会出现一个后果。与没有消息传递的单体应用程序相比，系统中的日志总数会增加。这反过来要求我们比以前更加关注日志记录。我们应该尽量生成尽可能少的信息，即使这些信息可以告诉我们很多情况。我们如何做到这一点？首先，最好在所有微服务中使用相同的日志消息格式。例如，让我们考虑如何在应用程序日志中打印变量。我建议您使用JSON表示法，因为通常微服务之间交换的消息都是用JSON格式化的。这种格式具有非常直观的标准，使您的日志易于阅读和解析，如下面的代码片段所示：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding format is much easier to analyze than something like the following:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的格式比以下格式要容易分析得多：
- en: '[PRE1]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'But generally, the most important thing here is standardization. No matter
    which format you choose, it is crucial to use it everywhere. You should also be
    careful to ensure that your logs are meaningful. Try to avoid sentences that do
    not contain any information. For example, from the following format, it is not
    clear which order is being processed:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但总的来说，这里最重要的是标准化。无论您选择哪种格式，都很重要的是在所有地方都使用它。您还应该小心确保您的日志是有意义的。尽量避免不包含任何信息的句子。例如，从以下格式中，不清楚正在处理哪个订单：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'However, if you really want this kind of log entry format, try to assign it
    to different log levels. It is really a bad practice to log everything with the
    same level of `INFO`. Some kinds of information are more important than others,
    so the one difficulty here is to decide what level the log entry should be logged
    at. Here are some suggestions:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，如果您真的想要这种日志条目格式，尝试将其分配给不同的日志级别。使用相同级别的`INFO`记录所有内容是一个非常糟糕的做法。某些类型的信息比其他信息更重要，因此这里的一个困难是决定日志条目应该记录在哪个级别。以下是一些建议：
- en: '`TRACE`: This is for very detailed information, intended only for development.
    You might keep it for a short period of time, just after deployment to a production
    environment, but treat it as a temporary file.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TRACE`：这是非常详细的信息，仅用于开发目的。您可能会在部署到生产环境后的短时间内保留它，但应将其视为临时文件。'
- en: '`DEBUG`: At this level, log anything that happens in the program. This is mostly
    used for debugging or troubleshooting by developers. The distinction between `DEBUG`
    and `TRACE` is probably the most difficult.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DEBUG`：在这个级别，记录程序中发生的任何事情。这主要用于开发人员进行调试或故障排除。`DEBUG`和`TRACE`之间的区别可能是最困难的。'
- en: '`INFO`: At this level, you should log the most important information during
    the operation. These messages have to be easily understandable, not just for developers,
    but also for administrators or advanced users, to let them quickly find out what
    the application is doing.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`INFO`：在这个级别，您应该记录操作期间最重要的信息。这些消息必须易于理解，不仅适用于开发人员，还适用于管理员或高级用户，以便让他们快速了解应用程序正在做什么。'
- en: '`WARN`: At this level, log all events that could potentially become errors.
    Such a process may be continued, but you should take extra caution with it.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`WARN`：在这个级别，记录可能成为错误的所有事件。这样的过程可能会继续进行，但您应该对其格外小心。'
- en: '`ERROR`: Usually, you print exceptions at this level. The important thing here
    is not to throw exceptions everywhere if, for example, only one business logic
    execution has not succeeded.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ERROR`：通常在这个级别打印异常。这里重要的是，如果例如只有一个业务逻辑执行未成功，就不要到处抛出异常。'
- en: '`FATAL`: This Java logging level designates very severe error events that will
    probably cause the application to stop.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`FATAL`：这个Java日志级别指定了可能导致应用程序停止的非常严重的错误事件。'
- en: There are other good logging practices, but I have mentioned the most important
    ones for use in microservices-based systems. It is also worth mentioning one more
    aspect of logging, normalization. If you would like to easily understand and interpret
    your logs, you should definitely know how and when they were collected, what they
    contain, and why they were emitted. There are some especially important characteristics
    that should be normalized across all microservices, such as `Time` (when), `Hostname`
    (where), and `AppName` (who). As you will see in the next part of this chapter,
    this kind of normalization is very useful when a centralized method of collecting
    logs is implemented in your system.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他良好的日志记录实践，但我已经提到了在基于微服务的系统中使用的最重要的实践。还值得一提的是日志记录的另一个方面，即规范化。如果您想要轻松理解和解释您的日志，您绝对应该知道它们是如何以及何时被收集的，它们包含什么以及为什么被发出。在所有微服务中应该规范化一些特别重要的特征，例如`时间`（何时）、`主机名`（在哪里）和`应用名称`（谁）。正如您将在本章的下一部分中看到的，当在系统中实施集中式日志收集方法时，这种规范化非常有用。
- en: Logging with Spring Boot
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Spring Boot进行日志记录
- en: Spring Boot uses Apache Commons Logging for internal logging, but if you are
    including dependencies with starters, Logback will be used by default in your
    application. It doesn't inhibit the possibility of using other logging frameworks
    in any way. The default configurations are also provided for Java Util Logging,
    Log4J2, and SLF4J. Logging settings may be configured in the `application.yml`
    file with `logging.*` properties. The default log output contains the date and
    time in milliseconds, log level, process ID, thread name, the full name of the
    class that has emitted the entry, and the message. It may be overridden by using
    the `logging.pattern.console` and `logging.pattern.file` properties respectively
    for the console and file appenders.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Boot使用Apache Commons Logging进行内部日志记录，但如果您包含了启动器依赖项，则默认情况下您的应用将使用Logback。这并不妨碍以任何方式使用其他日志记录框架。还为Java
    Util Logging、Log4J2和SLF4J提供了默认配置。可以使用`application.yml`文件中的`logging.*`属性配置日志记录设置。默认日志输出包含毫秒级的日期和时间、日志级别、进程ID、线程名称、发出条目的类的完整名称和消息。可以分别使用`logging.pattern.console`和`logging.pattern.file`属性覆盖它们，用于控制台和文件附加器。
- en: By default, Spring Boot only logs on to a console. In order to allow the writing
    of log files in addition to a console output, you should set a `logging.file`
    or `logging.path` property. If you specify the `logging.file` property, the logs
    would be written to the file at an exact location or a location relative to the
    current directory. If you set `logging.path`, it creates a `spring.log` file in
    the specified directory. Log files will be rotated after reaching 10 MB.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Boot只记录到控制台。为了允许除控制台输出之外写入日志文件，您应该设置`logging.file`或`logging.path`属性。如果指定了`logging.file`属性，日志将被写入到精确位置或相对于当前目录的位置。如果设置了`logging.path`，它将在指定目录中创建一个`spring.log`文件。日志文件在达到10MB后将被轮换。
- en: 'The last thing that can be customized in the `application.yml` settings file
    is the log levels. By default, Spring Boot writes messages with `ERROR`, `WARN`,
    and `INFO` levels. We may override this setting for every single package or class
    with `logging.level.*` properties. The root logger can also be configured using
    `logging.level.root`. Here''s an example configuration in the `application.yml`
    file, which changes the default pattern format, as well as a few log levels, and
    sets the location of the logging file:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在`application.yml`设置文件中可以定制的最后一件事是日志级别。默认情况下，Spring Boot会使用`ERROR`、`WARN`和`INFO`级别写入消息。我们可以使用`logging.level.*`属性为每个包或类覆盖此设置。根记录器也可以使用`logging.level.root`进行配置。以下是`application.yml`文件中的示例配置，它更改了默认的模式格式，以及一些日志级别，并设置了日志文件的位置。
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'As you can see in the preceding example, such a configuration is pretty simple,
    but, in some cases, it is not enough. If you would like to define additional appenders
    or filters, you should definitely include the configuration for one of the available
    logging systems—Logback (`logback-spring.xml`), Log4j2 (`log4j2-spring.xml`),
    or Java Util Logging (`logging.properties`). As I have mentioned earlier, by default, Spring
    Boot uses Logback for the application logs. If you provide the `logback-spring.xml`
    file in the root of the classpath, it will override all settings defined in `application.yml`.
    For example, you may create file appenders that rotate logs daily and retain a
    maximum history of 10 days. This feature is very commonly used in applications.
    In the next section of this chapter, you will also learn that a custom appender
    is required to integrate your microservice with Logstash. Here''s an example Logback
    configuration file''s fragment that sets a daily rolling policy for the `logs/order.log`
    file:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在前面的示例中所看到的，这样的配置非常简单，但在某些情况下可能不够。如果您想定义额外的附加器或过滤器，您应该包含一个可用的日志系统的配置，如Logback（`logback-spring.xml`）、Log4j2（`log4j2-spring.xml`）或Java
    Util Logging（`logging.properties`）。正如我之前提到的，默认情况下，Spring Boot使用Logback记录应用程序日志。如果您在类路径的根目录中提供了`logback-spring.xml`文件，它将覆盖`application.yml`中定义的所有设置。例如，您可以创建每天轮换日志并保留最多10天历史记录的文件附加器。这个功能在应用程序中非常常见。在本章的下一节中，您还将了解到，需要一个自定义附加器来将您的微服务与Logstash集成。以下是一个设置`logs/order.log`文件每天滚动的Logback配置文件片段的示例。
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'It is also worth mentioning that Spring recommends using `logback-spring.xml`
    for Logback instead of the default `logback.xml`. Spring Boot includes a couple
    of extensions to Logback that may be helpful for an advanced configuration. They
    cannot be used in the standard `logback.xml`, but only with `logback-spring.xml`.
    We have listed some of these extensions that will allow you to define profile-specific
    configurations or surface properties from the Spring Environment:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Spring建议使用`logback-spring.xml`来代替默认的`logback.xml`来配置Logback。Spring Boot包含了一些对Logback的扩展，这对于高级配置可能会有所帮助。它们不能在标准的`logback.xml`中使用，只能在`logback-spring.xml`中使用。我们列出了一些这些扩展，它们允许您定义特定配置或从Spring环境中获取属性。
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Centralizing logs with ELK Stack
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用ELK Stack集中日志
- en: ELK is the acronym for three open source tools—Elasticsearch, Logstash, and
    Kibana. It is also called **Elastic Stack**. The heart of this system is **Elasticsearch**, a
    search engine based on another open source project written in Java, Apache Lucene. This
    library is especially suitable for applications that require full-text searches
    in cross-platform environments. The main reason for the popularity of Elasticsearch
    is its performance. Of course, it has some other advantages, such as scalability,
    flexibility, and easy integration by providing a RESTful, JSON-based API for searching
    stored data. It has a large community and many use cases, but the most interesting
    one for us is its ability to store and search logs generated by applications.
    Logging is the main reason for including Logstash in ELK Stack. This open source
    data-processing pipeline allows us to collect, process, and input data into Elasticsearch.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ELK是三个开源工具Elasticsearch、Logstash和Kibana的缩写。它也被称为**Elastic Stack**。这个系统的核心是**Elasticsearch**，这是一个基于另一个用Java编写的开源项目Apache
    Lucene的搜索引擎。这个库特别适合需要在跨平台环境中进行全文搜索的应用程序。Elasticsearch受欢迎的主要原因是其性能。当然，它还有一些其他优点，比如可伸缩性、灵活性和通过提供基于RESTful、基于JSON的API来搜索存储数据的易集成性。它有一个庞大的社区和许多用例，但对我们来说最有趣的是它存储和搜索应用程序生成的日志的能力。日志是将Logstash包含在ELK
    Stack中的主要原因。这个开源的数据处理管道允许我们收集、处理和输入数据到Elasticsearch中。
- en: '**Logstash** supports many inputs that pull events from external sources. What
    is interesting is that it has many outputs, and Elasticsearch is only one of them.
    For example, it can write events to Apache Kafka, RabbitMQ, or MongoDB, and it
    can write metrics to InfluxDB or Graphite. It not only receives and forwards data
    to their destinations, but can also parse and transform it on the fly.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash支持许多输入，可以从外部来源获取事件。有趣的是它有许多输出，Elasticsearch只是其中之一。例如，它可以将事件写入Apache
    Kafka、RabbitMQ或MongoDB，还可以将指标写入InfluxDB或Graphite。它不仅接收和转发数据到它们的目的地，还可以实时解析和转换数据。
- en: '**Kibana** is the last element of ELK Stack. It is an open source, data-visualization
    plugin for Elasticsearch. It allows you to visualize, explore, and discover data
    from Elasticsearch. We may easily display and filter all the logs collected from
    our application by creating search queries. On this basis, we can export data
    to PDF or CSV formats to provide reports.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kibana**是ELK Stack的最后一个元素。它是一个用于Elasticsearch的开源数据可视化插件。它允许您从Elasticsearch中可视化、探索和发现数据。我们可以通过创建搜索查询轻松地显示和过滤从我们的应用程序收集的所有日志。基于此，我们可以将数据导出为PDF或CSV格式以提供报告。'
- en: Setting up ELK Stack on the machine
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在机器上设置ELK Stack
- en: Before we try to send any logs from our application to Logstash, we have to
    configure ELK Stack on the local machine. The most suitable way to run it is through
    Docker containers. All the products in the stack are available as Docker images.
    There is a dedicated Docker registry hosted by Elastic Stack's vendor. A full
    list of published images and tags can be found at [www.docker.elastic.co](http://www.docker.elastic.co).
    All of them use `centos:7` as the base image.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试将任何日志从我们的应用程序发送到Logstash之前，我们必须在本地机器上配置ELK Stack。运行它的最合适的方式是通过Docker容器。堆栈中的所有产品都作为Docker映像提供。由Elastic
    Stack的供应商托管了专用的Docker注册表。可以在[www.docker.elastic.co](http://www.docker.elastic.co)找到已发布映像和标签的完整列表。它们都使用`centos:7`作为基本映像。
- en: 'We will begin from the Elasticsearch instance. Its development can be started
    with the following command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从Elasticsearch实例开始。可以使用以下命令启动其开发：
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Running Elasticsearch in development mode is the most convenient way of running
    it because we don''t have to provide any additional configuration. If you would
    like to launch it in production mode, the `vm.max_map_count` Linux kernel setting
    needs to be set to at least `262144`. The procedure for modifying it is different
    depending on the OS platform. For Windows with Docker Toolbox, it must be set
    via `docker-machine`:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发模式下运行Elasticsearch是运行它的最便捷方式，因为我们不必提供任何额外的配置。如果您想以生产模式启动它，需要将`vm.max_map_count`
    Linux内核设置至少设置为`262144`。根据操作系统平台的不同，修改它的过程也不同。对于使用Docker Toolbox的Windows，必须通过`docker-machine`进行设置。
- en: '[PRE7]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The next step is to run a container with Logstash. In addition to launching
    a container with Logstash, we should also define an input and output. The output
    is obvious—Elasticsearch, which is now available under the default Docker machine
    address, `192.168.99.100`. As an input, we define the simple TCP plugin `logstash-input-tcp`,
    which is compatible with `LogstashTcpSocketAppender` used as a logging appender
    in our sample application. All the logs from our microservices will be sent in
    JSON format. For now, it is important to set the `json` codec for that plugin. Each
    microservice will be indexed in Elasticsearch with its name and `micro` prefix.
    Here''s the Logstash configuration file, `logstash.conf`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是运行一个带有Logstash的容器。除了启动一个带有Logstash的容器之外，我们还应该定义一个输入和输出。输出是显而易见的——Elasticsearch，现在可以在默认的Docker机器地址`192.168.99.100`下使用。作为输入，我们定义了简单的TCP插件`logstash-input-tcp`，它与我们示例应用程序中使用的`LogstashTcpSocketAppender`兼容。所有来自我们微服务的日志都将以JSON格式发送。现在，重要的是为该插件设置`json`编解码器。每个微服务将以其名称和`micro`前缀在Elasticsearch中进行索引。这是Logstash配置文件`logstash.conf`：
- en: '[PRE8]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Here''s the command that runs Logstash and exposes it on port `5000`. It also
    copies the file with  the preceding settings to the container and overrides the
    default location of the Logstash configuration file:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是运行Logstash并将其暴露在端口`5000`上的命令。它还将带有上述设置的文件复制到容器中，并覆盖Logstash配置文件的默认位置：
- en: '[PRE9]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Finally, we can run the last element of the stack, Kibana. By default, this
    is exposed on port `5601` and connects to the Elasticsearch API available on port `9200` in
    order to be able to load data from there:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以运行堆栈的最后一个元素Kibana。默认情况下，它在端口`5601`上公开，并连接到端口`9200`上的Elasticsearch API，以便能够从那里加载数据：
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: If you would like to run all Elastic Stack products on your Docker machine on
    Windows, you would probably have to increase the default RAM memory for your Linux
    virtual image to a minimum of 2 GB. After launching all containers, you may finally
    access the Kibana dashboard available under `http://192.168.99.100:5601` and then
    proceed to integrate your application with Logstash.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在Windows的Docker机器上运行所有Elastic Stack产品，您可能需要将Linux虚拟映像的默认RAM内存增加到至少2GB。启动所有容器后，您最终可以访问Kibana仪表板，该仪表板位于`http://192.168.99.100:5601`下，然后继续将您的应用程序与Logstash集成。
- en: Integrating an application with ELK Stack
  id: totrans-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将应用程序集成到ELK Stack中
- en: There are many ways of integrating Java applications with ELK Stack via Logstash.
    One of the methods involves using Filebeat, which is a log data shipper for local
    files. This approach requires a beats (`logstash-input-beats`) input configured
    for the instance of Logstash, which is, in fact, the default option. You should
    also install and launch a Filebeat daemon on the server machine. It is responsible
    for the delivery of the logs to Logstash.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多种方法可以通过Logstash将Java应用程序集成到ELK Stack中。其中一种方法涉及使用Filebeat，它是用于本地文件的日志数据船。这种方法需要为Logstash的实例配置一个beats（`logstash-input-beats`）输入，这实际上是默认选项。您还应该在服务器上安装和启动Filebeat守护程序。它负责将日志传递到Logstash。
- en: Personally, I prefer a configuration based on Logback and dedicated appenders.
    It seems to be simpler than using a Filebeat agent. Besides having to deploy an
    additional service, Filebeat requires us to play with a parsing expression, such
    as the Grok filter. When using a Logback appender, you don't require any log shippers.
    This appender is available within the project Logstash JSON encoder. You may enable
    it for your application by declaring the `net.logstash.logback.appender.LogstashSocketAppender`
    appender inside the `logback-spring.xml` file.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 就个人而言，我更喜欢基于Logback和专用appender的配置。这似乎比使用Filebeat代理更简单。除了必须部署额外的服务外，Filebeat还要求我们使用解析表达式，例如Grok过滤器。使用Logback
    appender时，您不需要任何日志发货人。该appender在项目Logstash JSON编码器中可用。您可以通过在`logback-spring.xml`文件中声明`net.logstash.logback.appender.LogstashSocketAppender`
    appender来为应用程序启用它。
- en: We will also discuss an alternative approach for sending data to Logstash, using
    a message broker. In the example that we will shortly examine, I'm going to show
    you how to use Spring `AMQPAppender` to publish logging events to a RabbitMQ exchange.
    In this case, Logstash subscribes to the exchange and consumes published messages.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将讨论将数据发送到Logstash的另一种替代方法，即使用消息代理。在我们即将讨论的示例中，我将向您展示如何使用Spring `AMQPAppender`将日志事件发布到RabbitMQ交换机。在这种情况下，Logstash订阅交换并消耗发布的消息。
- en: Using LogstashTCPAppender
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用LogstashTCPAppender
- en: 'The library `logstash-logback-encoder` provides three types of appenders—UDP,
    TCP, and async. The TCP appender is most commonly used. What is worth mentioning
    is that TCP appenders are asynchronous, and all the encoding and communication
    is delegated to a single thread. In addition to appenders, the library also provides
    some encoders and layouts to enable you to log in the JSON format. Because Spring
    Boot includes a Logback library by default, as well as `spring-boot-starter-web`,
    we only have to add one dependency to Maven `pom.xml`:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '`logstash-logback-encoder`库提供了三种类型的附加程序——UDP、TCP和async。TCP附加程序是最常用的。值得一提的是，TCP附加程序是异步的，所有的编码和通信都委托给单个线程。除了附加程序，该库还提供了一些编码器和布局，使您能够以JSON格式记录日志。由于Spring
    Boot默认包含Logback库，以及`spring-boot-starter-web`，我们只需要在Maven的`pom.xml`中添加一个依赖项：'
- en: '[PRE11]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The next step is to define the appender with the `LogstashTCPAppender` class in
    the Logback configuration file. Every TCP appender requires you to configure an
    encoder. You may choose between `LogstashEncoder` and `LoggingEventCompositeJsonEncoder`.
    `LoggingEventCompositeJsonEncoder` gives you more flexibility. It is composed
    of one or more JSON providers that are mapped to the JSON output. By default,
    there are no providers configured. It doesn''t work that way with `LogstashTCPAppender`.
    By default, it includes several standard fields, such as timestamp, version, logger
    name, and stack trace. It also adds all entries from the **m****apped diagnostic
    context** (**MDC**) and the context, unless you disable it by setting one of the
    `includeMdc` or `includeContext` properties to `false`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是在Logback配置文件中使用`LogstashTCPAppender`类定义附加程序。每个TCP附加程序都需要您配置一个编码器。您可以在`LogstashEncoder`和`LoggingEventCompositeJsonEncoder`之间进行选择。`LoggingEventCompositeJsonEncoder`给您更多的灵活性。它由一个或多个映射到JSON输出的JSON提供程序组成。默认情况下，没有配置提供程序。这与`LogstashTCPAppender`的工作方式不同。默认情况下，它包括几个标准字段，例如时间戳、版本、记录器名称和堆栈跟踪。它还添加了来自**映射诊断上下文**（**MDC**）和上下文的所有条目，除非您通过将`includeMdc`或`includeContext`属性之一设置为`false`来禁用它：
- en: '[PRE12]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, I would like to come back for a moment to our sample system. We are still
    in the same Git repository ([https://github.com/piomin/sample-spring-cloud-comm.git](https://github.com/piomin/sample-spring-cloud-comm.git))
    and `feign_with_discovery` branch ([https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery](https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery)).
    I have added some logging entries in the source code in accordance with the recommendations
    described in the *Best logging practices for microservices* section. Here''s the
    current version of the `POST` method inside `order-service`. I have used Logback
    over SLF4J as a logger by calling the `getLogger` method from `org.slf4j.LoggerFactory`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我想回到我们的示例系统。我们仍然在同一个Git存储库（[https://github.com/piomin/sample-spring-cloud-comm.git](https://github.com/piomin/sample-spring-cloud-comm.git)）和`feign_with_discovery`分支（[https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery](https://github.com/piomin/sample-spring-cloud-comm/tree/feign_with_discovery)）。我根据“微服务的最佳日志记录实践”部分中描述的建议，在源代码中添加了一些日志条目。这是`order-service`内部`POST`方法的当前版本。我使用了Logback
    over SLF4J作为记录器，通过调用`org.slf4j.LoggerFactory`的`getLogger`方法：
- en: '[PRE13]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let''s take a look at the Kibana dashboard. It is available at `http://192.168.99.100:5601`.
    The application logs may be easily discovered and analyzed there. You can select
    the required index name in the menu on the left side of the page (labeled **1**
    in the following screenshot). Log statistics are presented on the timeline graph
    (**2**). You can narrow down the time taken as search parameter by clicking a
    concrete bar or choosing a group of bars. All logs for a given period of time
    are displayed on the panel present below the graph (**3**):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看Kibana仪表板。它可以在`http://192.168.99.100:5601`上找到。应用程序日志可以很容易地在那里发现和分析。您可以在页面左侧的菜单中选择所需的索引名称（在以下截图中标有**1**）。日志统计数据显示在时间轴图上（**2**）。您可以通过单击具体的条或选择一组条来缩小搜索参数所花费的时间。给定时间段内的所有日志都显示在图下面的面板上（**3**）：
- en: '![](img/3e56b172-f8c5-4a8a-84c3-0bece490c7a5.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3e56b172-f8c5-4a8a-84c3-0bece490c7a5.png)'
- en: 'Each entry can be expanded to look at its details. In the detailed table view,
    we can see, for example, the name of the Elasticsearch index (`_index`) and the
    level or name of the microservice (`appName`). Most of those fields have been
    set by `LoggingEventCompositeJsonEncoder`. I have only defined one application-specific
    field, `appName`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每个条目都可以展开以查看其详细信息。在详细的表格视图中，我们可以看到例如Elasticsearch索引的名称（`_index`）和微服务的级别或名称（`appName`）。大多数这些字段都是由`LoggingEventCompositeJsonEncoder`设置的。我只定义了一个特定于应用程序的字段`appName`：
- en: '![](img/032646e3-4508-404b-b1cc-9ad63012db02.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![](img/032646e3-4508-404b-b1cc-9ad63012db02.png)'
- en: 'Kibana gives us a great ability to search for particular entries. We may define
    filters just by clicking on the selected entries in order to define a set of search
    criteria. In the preceding screenshot, you can see how I filtered out all the
    entries with incoming HTTP requests. As you probably remember, the `org.springframework.web.filter.CommonsRequestLoggingFilter`
    class is responsible for logging them. I have just defined the filter whose name
    is equal to a fully-qualified logger class name. Here''s the screen from my Kibana
    dashboard, which displays the logs generated only by `CommonsRequestLoggingFilter`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana为我们提供了搜索特定条目的强大能力。我们可以通过点击所选条目来定义一组搜索条件。在前面的截图中，您可以看到我如何过滤掉所有传入的HTTP请求的条目。正如您可能记得的那样，`org.springframework.web.filter.CommonsRequestLoggingFilter`类负责记录它们。我刚刚定义了一个名称等于完全限定的记录器类名称的过滤器。这是我Kibana仪表板上的屏幕，它只显示由`CommonsRequestLoggingFilter`生成的日志：
- en: '![](img/f1b536fc-7f08-4f9a-b12a-cc92d8fe5ebc.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f1b536fc-7f08-4f9a-b12a-cc92d8fe5ebc.png)'
- en: Using AMQP appender and a message broker
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用AMQP附加程序和消息代理
- en: 'The configuration with the Spring AMQP appender and message broker is a little
    bit more complicated than the method that uses the simple TCP appender. First,
    you need to launch a message broker on your local machine. I have described this
    process in [Chapter 5](37142825-02d0-48a0-99df-1a1a88a1bbd4.xhtml), *Distributed
    Configuration with Spring Cloud Config*, where I introduced RabbitMQ for dynamic
    configuration reloading with Spring Cloud Bus. Assuming you have started an instance
    of RabbitMQ locally or as a Docker container, you can proceed to configuration.
    We have to create a queue for publishing incoming events and then bind it to the
    exchange. To achieve this, you should log in to the Rabbit management console
    and then go to the Queues section. I have created the queue with the name `q_logstash`.
    I defined the new exchange with the name `ex_logstash`, which is visible in the
    following screenshot. The queue has been bound to the exchange with routing keys
    for all the example microservices:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 与使用简单TCP appender的方法相比，使用Spring AMQP appender和消息代理的配置要复杂一些。首先，您需要在本地机器上启动消息代理。我在[第5章](37142825-02d0-48a0-99df-1a1a88a1bbd4.xhtml)中描述了这个过程，*使用Spring
    Cloud Bus进行分布式配置*，在那里我介绍了RabbitMQ用于Spring Cloud Bus动态配置重新加载。假设您已经在本地或作为Docker容器启动了RabbitMQ的实例，您可以继续进行配置。我们必须创建一个用于发布传入事件的队列，然后将其绑定到交换。为了实现这一点，您应该登录到Rabbit管理控制台，然后转到*Queues*部分。我创建了名为`q_logstash`的队列。我定义了名为`ex_logstash`的新交换，它在以下截图中可见。队列已绑定到交换，用于所有示例微服务的路由键：
- en: '![](img/6af1e4a9-b02d-4c4f-9e24-dea67478f24b.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6af1e4a9-b02d-4c4f-9e24-dea67478f24b.png)'
- en: 'After we have launched and configured the instance of RabbitMQ, we may start
    integrating on the application side. First, you have to include `spring-boot-starter-amqp` in
    the project dependencies to provide implementations of the AMQP client and AMQP
    appender:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动和配置了RabbitMQ实例之后，我们可以开始在应用程序端进行集成。首先，您必须在项目依赖项中包含`spring-boot-starter-amqp`，以提供AMQP客户端和AMQP
    appender的实现：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, the only thing you have to do is to define the appender with the `org.springframework.amqp.rabbit.logback.AmqpAppender` class in
    the Logback configuration file. The most important properties that need to be
    set are the RabbitMQ network address (`host`, `port`), the name of the declared
    exchange (`exchangeName`), and the routing key (`routingKeyPattern`), which has
    to match one of the keys declared for the exchange bindings. In comparison with
    the TCP appender, a disadvantage of this approach is the need to prepare a JSON
    message sent to Logstash by yourself. Here''s a fragment of the Logback configuration
    for `order-service`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您唯一需要做的就是在Logback配置文件中使用`org.springframework.amqp.rabbit.logback.AmqpAppender`类定义appender。需要设置的最重要的属性是RabbitMQ网络地址（`host`，`port`），已声明交换的名称（`exchangeName`）和路由键（`routingKeyPattern`），它必须与交换绑定的键之一匹配。与TCP
    appender相比，这种方法的一个缺点是需要自己准备发送到Logstash的JSON消息。以下是`order-service`的Logback配置片段：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Logstash may be easily integrated with RabbitMQ by declaring the `rabbitmq`
    (`logstash-input-rabbitmq`) input:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Logstash可以通过声明`rabbitmq` (`logstash-input-rabbitmq`)输入轻松集成RabbitMQ：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Spring Cloud Sleuth
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth
- en: Spring Cloud Sleuth is a rather small, simple project, which nevertheless provides
    some useful features for logging and tracing. If you refer to the example discussed
    in the *Using LogstashTCPAppender* section, you can easily see that there is no
    possibility to filter all the logs related to single request. In a microservices-based
    environment, it is also very important to correlate messages exchanged by the
    applications when handling requests that are coming into the system. This is the
    main motivation in creating the Spring Cloud Sleuth project.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth是一个相当小而简单的项目，尽管如此，它仍然提供了一些有用的日志记录和跟踪功能。如果您参考*使用LogstashTCPAppender*部分中讨论的示例，您很容易看到没有可能过滤与单个请求相关的所有日志。在基于微服务的环境中，还非常重要的是在处理进入系统的请求时，相关应用程序交换的消息进行关联。这是创建Spring
    Cloud Sleuth项目的主要动机。
- en: If Spring Cloud Sleuth is enabled for the application, it adds some HTTP headers
    to the requests, which allows you to link requests with the responses and the
    messages exchanged by independent applications, for example, through RESTful API.
    It defines two basic units of work—span and trace. Each of these is identified
    by a unique 64 bit ID. The value of the trace ID is equal to the initial value
    of the span ID. Span refers to a single exchange, where the response is sent as
    a reaction to the request. Trace is something that is usually called **correlation
    IT**, and it helps us to link all the logs from different applications generated
    during the processing of requests coming into the system.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果为应用程序启用了Spring Cloud Sleuth，则它会向请求添加一些HTTP头，这样您就可以将请求与响应以及独立应用程序交换的消息进行关联，例如通过RESTful
    API。它定义了两个基本工作单元——跨度和跟踪。这两者都由唯一的64位ID标识。跟踪ID的值等于跨度ID的初始值。跨度指的是单个交换，响应作为对请求的反应发送。跟踪通常被称为**关联IT**，它帮助我们链接在处理进入系统的请求期间生成的来自不同应用程序的所有日志。
- en: 'Every trace and span ID is added to the Slf4J **MDC** (**mapped diagnostic
    context**), so you will able to extract all the logs with a given trace or span
    in a log aggregator. MDC is just a map that stores the context data of the current
    thread. Every client request coming to the server is handled by a different thread.
    Thanks to this, each thread can have access to the values of its MDC within the
    thread lifecycle. As well as `spanId` and `traceId`, Spring Cloud Sleuth also
    adds the following two spans to the MDC:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 每个跟踪和跨度ID都添加到Slf4J **MDC**（**映射诊断上下文**）中，因此您将能够从日志聚合器中提取具有给定跟踪或跨度的所有日志。MDC只是一个存储当前线程的上下文数据的映射。每个客户端请求到达服务器时都由不同的线程处理。由于这一点，每个线程都可以在其线程生命周期内访问其MDC的值。除了`spanId`和`traceId`，Spring
    Cloud Sleuth还将以下两个跨度添加到MDC中：
- en: '`appName`: The name of the application that has generated the log entry'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`appName`：生成日志条目的应用程序名称'
- en: '`exportable`: This specifies whether the log should be exported to Zipkin or
    not'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exportable`：这指定了日志是否应该导出到Zipkin'
- en: 'In addition to the preceding features, Spring Cloud Sleuth also provides:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 除了前面的功能，Spring Cloud Sleuth还提供：
- en: An abstraction over common distributed tracing data models, which allows integrating
    with Zipkin.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种常见的分布式跟踪数据模型的抽象，允许与Zipkin集成。
- en: Records timing information in order to aid it in latency analysis. It also includes
    different sampling policies to manage the volume of data exported to Zipkin.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录时间信息以帮助进行延迟分析。它还包括不同的采样策略来管理导出到Zipkin的数据量。
- en: Integrates with common Spring components taking part in communication like servlet
    filter, asynchronous endpoints, RestTemplate, message channels, Zuul filters and
    Feign client.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与参与通信的常见Spring组件集成，如servlet过滤器、异步端点、RestTemplate、消息通道、Zuul过滤器和Feign客户端。
- en: Integrating Sleuth with an application
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Sleuth与应用程序集成
- en: 'In order to enable Spring Cloud Sleuth features for the application, just add
    the `spring-cloud-starter-sleuth` starter to the dependencies:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 要为应用程序启用Spring Cloud Sleuth功能，只需将`spring-cloud-starter-sleuth`启动器添加到依赖项中：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'After including this dependency, the format of the log entries generated by
    the application has been changed. You can see this as follows:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在包含此依赖项之后，应用程序生成的日志条目的格式已更改。您可以如下所示：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Searching events using Kibana
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kibana搜索事件
- en: 'Spring Cloud Sleuth automatically adds HTTP headers `X-B3-SpanId` and `X-B3-TraceId`
    to all the requests and responses. These fields are also included to the MDC as
    `spanId` and `traceId`. But before moving to the Kibana dashboard, I would like
    you to take a look at the following figure. This is a sequence diagram that illustrates
    the communication flow between sample microservices:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth会自动向所有请求和响应添加HTTP头`X-B3-SpanId`和`X-B3-TraceId`。这些字段也作为`spanId`和`traceId`包含在MDC中。但在转到Kibana仪表板之前，我想让您看一下以下图。这是一个序列图，说明了示例微服务之间的通信流程：
- en: '![](img/d8eb077a-8417-4960-9e12-f67cb2cf2070.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d8eb077a-8417-4960-9e12-f67cb2cf2070.png)'
- en: There are two available methods that are exposed by `order-service`. The first
    is for creating a new order and the second is for confirming it. The first `POST
    /` method, in fact, calls endpoints from all other services directly from `customer-service`,
    `product-service`, and `account-service` through `customer-service`. The second
    `PUT /{id}` method integrates with only one endpoint from `account-service`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '`order-service`公开了两种可用方法。第一种是创建新订单，第二种是确认订单。实际上，第一个`POST /`方法直接从`customer-service`调用所有其他服务的端点，通过`customer-service`从`product-service`和`account-service`。第二个`PUT
    /{id}`方法仅与`account-service`的一个端点集成。'
- en: 'The flow described previously may now be mapped by the log entries stored in
    ELK Stack. When using Kibana as a log aggregator, together with fields generated
    by Spring Cloud Sleuth, we may easily find entries by filtering them using trace
    or span IDs. Here''s an example, where we have discovered all the events related
    to a call of the `POST /` endpoint from `order-service` with the `X-B3-TraceId` field equal
    to `103ec949877519c2`:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 先前描述的流程现在可以通过ELK Stack中存储的日志条目进行映射。当使用Kibana作为日志聚合器时，结合Spring Cloud Sleuth生成的字段，我们可以通过使用跟踪或跨度ID轻松找到条目。以下是一个示例，我们已经发现了与`order-service`从`POST
    /`端点调用相关的所有事件，其`X-B3-TraceId`字段等于`103ec949877519c2`：
- en: '![](img/c108158a-5db0-419a-88dd-a10b8f87d796.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c108158a-5db0-419a-88dd-a10b8f87d796.png)'
- en: 'Here''s an example similar to the previous one, but where all events stored
    during the processing request are sent to the `PUT /{id}` endpoint. These entries
    have been also filtered out by the `X-B3-TraceId` field, the value of which is
    equal to `7070b90bfb36c961`:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个类似于上一个示例的示例，但在处理请求期间存储的所有事件都发送到`PUT /{id}`端点。这些条目也已通过`X-B3-TraceId`字段进行过滤，其值等于`7070b90bfb36c961`：
- en: '![](img/4587b4f2-9b08-4ba3-8f56-662bdf8ee49a.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](img/4587b4f2-9b08-4ba3-8f56-662bdf8ee49a.png)'
- en: 'Here, you can see the full list of fields, which has been sent to Logstash
    by the microservice application. The fields with the `X-` prefix have been included
    in the message by the Spring Cloud Sleuth library:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到已被微服务应用程序发送到Logstash的字段的完整列表。带有`X-`前缀的字段是由Spring Cloud Sleuth库在消息中包含的：
- en: '![](img/dda5a4be-8e5e-4cc0-aa93-eb13883dbcbb.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](img/dda5a4be-8e5e-4cc0-aa93-eb13883dbcbb.png)'
- en: Integrating Sleuth with Zipkin
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Sleuth与Zipkin集成
- en: Zipkin is a popular, open source, distributed tracing system, which helps in
    gathering timing data needed to analyze latency problems in microservices-based
    architecture. It is able to collect, look up, and visualize data using a UI web
    console. The Zipkin UI provides a dependency diagram showing how many traced requests
    were processed by all applications within the system. Zipkin consists of four
    elements. I have already mentioned one of them, Web UI. The second one is Zipkin
    collector, which is responsible for validating, storing, and indexing all incoming
    trace data. Zipkin uses Cassandra as a default backend store. It also natively
    supports Elasticsearch and MySQL. The last element is query service, which provides
    a simple JSON API for finding and retrieving traces. It is mostly consumed by
    Web UI.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin是一个流行的开源分布式跟踪系统，可帮助收集分析微服务架构中的延迟问题所需的时间数据。它能够使用UI Web控制台收集、查找和可视化数据。Zipkin
    UI提供了一个依赖关系图，显示了系统中所有应用程序处理了多少跟踪请求。Zipkin由四个元素组成。我已经提到了其中一个，Web UI。第二个是Zipkin收集器，负责验证、存储和索引所有传入的跟踪数据。Zipkin使用Cassandra作为默认后端存储。它还原生支持Elasticsearch和MySQL。最后一个元素是查询服务，为查找和检索跟踪提供了一个简单的JSON
    API。它主要由Web UI消耗。
- en: Running the Zipkin server
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行Zipkin服务器
- en: 'We may run the Zipkin server locally in several ways. One of these ways involves
    using a Docker container. The following command launches an in-memory server instance:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以以几种方式在本地运行Zipkin服务器。其中一种方式涉及使用Docker容器。以下命令启动一个内存中的服务器实例：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'After running the Docker container, the Zipkin API is available at `http://192.168.99.100:9411`.
    Alternatively, you can start it using Java libraries and the Spring Boot application.
    To enable Zipkin for your application, you should include the following dependencies
    to your Maven `pom.xml` file, as shown in the following code fragment. The default
    versions are managed by `spring-cloud-dependencies`. For our example application,
    I have used `Edgware.RELEASE` Spring Cloud Release Train:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行Docker容器后，Zipkin API可在`http://192.168.99.100:9411`上使用。或者，您可以使用Java库和Spring
    Boot应用程序启动它。要为应用程序启用Zipkin，您应该将以下依赖项包含到Maven的`pom.xml`文件中，如下面的代码片段所示。默认版本由`spring-cloud-dependencies`管理。对于我们的示例应用程序，我使用了`Edgware.RELEASE`
    Spring Cloud Release Train：
- en: '[PRE20]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'I have added a new `zipkin-service` module to our example system. It is really
    simple. The only thing that has to be implemented is the application main class,
    which is annotated with `@EnableZipkinServer`. Thanks to this, the Zipkin instance
    is embedded in the Spring Boot application:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经向我们的示例系统添加了一个新的`zipkin-service`模块。它非常简单。唯一需要实现的是应用程序主类，该类带有`@EnableZipkinServer`注解。由于这个，Zipkin实例嵌入在Spring
    Boot应用程序中：
- en: '[PRE21]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In order to launch the Zipkin instance on its default port, we have to override
    the default server port in the `application.yml` file. After launching the application,
    the Zipkin API is available at `http://localhost:9411`:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在默认端口上启动Zipkin实例，我们必须在`application.yml`文件中覆盖默认的服务器端口。启动应用程序后，Zipkin API可在`http://localhost:9411`上使用：
- en: '[PRE22]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Building the client application
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建客户端应用程序
- en: 'If you would like to use both Spring Cloud Sleuth and Zipkin in your project,
    just add starter `spring-cloud-starter-zipkin` to the dependencies. It enables
    integration with Zipkin via the HTTP API. If you have started the Zipkin server
    as an embedded instance inside the Spring Boot application, you don''t have to
    provide any additional configuration containing connection address. If you use
    the Docker container, you should override the default URL in `application.yml`:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在项目中同时使用Spring Cloud Sleuth和Zipkin，只需将starter `spring-cloud-starter-zipkin`添加到依赖项中。它通过HTTP
    API启用与Zipkin的集成。如果您已将Zipkin服务器作为Spring Boot应用程序中的嵌入式实例启动，则无需提供包含连接地址的任何其他配置。如果您使用Docker容器，应该在`application.yml`中覆盖默认URL：
- en: '[PRE23]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'You can always take advantage of integration with service discovery. If you
    have the discovery client enabled through `@EnableDiscoveryClient` for your application
    with the embedded Zipkin server, you may just set the property `spring.zipkin.locator.discovery.enabled`
    to `true`. In that case, even if it is not available under the default port, all
    applications will be able to localize it through the registered name. You should
    also override the default Zipkin application name with the `spring.zipkin.baseUrl` property:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以始终利用与服务发现的集成。如果您已通过`@EnableDiscoveryClient`为具有嵌入式Zipkin服务器的应用程序启用了发现客户端，您可以将`spring.zipkin.locator.discovery.enabled`属性设置为`true`。在这种情况下，即使它不在默认端口下可用，所有应用程序也将能够通过注册的名称定位它。您还应该使用`spring.zipkin.baseUrl`属性覆盖默认的Zipkin应用程序名称：
- en: '[PRE24]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'By default, Spring Cloud Sleuth sends only a few selected incoming requests.
    It is determined by the property `spring.sleuth.sampler.percentage`, the value
    of which needs to be a double between 0.0 and 1.0\. The sampling solution has
    been implemented because data volumes exchanged between distributed systems can
    be sometimes very high. Spring Cloud Sleuth provides sampler interface that can
    be implemented to take control over the sampling algorithm. The default implementation
    is available in class `PercentageBasedSampler`. If you would like to trace all
    the requests exchanged by your applications, just declare `AlwaysSampler` bean.
    It may be useful for the test purposes:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Spring Cloud Sleuth仅发送少量选定的传入请求。这由属性`spring.sleuth.sampler.percentage`决定，其值需要是0.0到1.0之间的双精度。采样解决方案已经实施，因为分布式系统之间交换的数据量有时可能非常高。Spring
    Cloud Sleuth提供了可以实现以控制采样算法的采样器接口。默认实现可在`PercentageBasedSampler`类中找到。如果您想要跟踪应用程序交换的所有请求，只需声明`AlwaysSampler`
    bean。这对测试目的可能很有用：
- en: '[PRE25]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Analyze data with the Zipkin UI
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Zipkin UI分析数据
- en: Let's go back for a moment to our example system. As I have mentioned before,
    the new `zipkin-service` module has been added. I have also enabled Zipkin tracing
    for all the microservices, including `gateway-service`.  By default, Sleuth takes
    the value `spring.application.name` as a span's service name. You may override
    that name with the `spring.zipkin.service.name` property.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到我们的示例系统。如我之前提到的，已添加了新的`zipkin-service`模块。我还为所有微服务启用了Zipkin跟踪，包括`gateway-service`。默认情况下，Sleuth将`spring.application.name`的值作为跨度的服务名称。您可以使用`spring.zipkin.service.name`属性覆盖该名称。
- en: To successfully test our system with Zipkin, we have to start the microservices,
    gateway, discovery, and Zipkin servers. To generate and send some test data, you
    could just run the JUnit test implemented by the `pl.piomin.services.gateway.GatewayControllerTest` class.
    It sends 100 messages to `order-service` via `gateway-service`, available at `http://localhost:8080/api/order/**`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要成功地使用Zipkin测试我们的系统，我们必须启动微服务、网关、发现和Zipkin服务器。要生成并发送一些测试数据，您可以运行`pl.piomin.services.gateway.GatewayControllerTest`类实现的JUnit测试。它通过`gateway-service`向`order-service`发送100条消息，可在`http://localhost:8080/api/order/**`上使用。
- en: 'Let''s analyze the data collected from all the services by Zipkin. You may
    easily check it out using its UI web console. All the traces are tagged with the
    service''s name spans. If there are five spans for the entry, it means that the
    request coming into the system has been processed by five different services.
    You can see this in the following screenshot:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分析Zipkin收集的所有服务的数据。您可以轻松使用其UI Web控制台进行检查。所有的跟踪都标记有服务的名称跨度。如果入口有五个跨度，这意味着进入系统的请求已经被五个不同的服务处理。您可以在以下截图中看到这一点：
- en: '![](img/22f22dfd-2f85-4951-a595-58f9d9f2e542.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/22f22dfd-2f85-4951-a595-58f9d9f2e542.png)'
- en: 'You may filter the entries with different criteria, such as the service name,
    span name, trace ID, request time, or duration. Zipkin also visualizes failed
    requests and sorts them by duration, in descending or ascending order:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用不同的标准来过滤条目，比如服务名称、跨度名称、跟踪ID、请求时间或持续时间。Zipkin还可视化了失败的请求，并按持续时间的降序或升序进行排序：
- en: '![](img/838af6f7-c7cb-4894-8a9e-1f13a49baa51.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/838af6f7-c7cb-4894-8a9e-1f13a49baa51.png)'
- en: 'You can take a look at the details of every entry. Zipkin visualizes the flow
    between all the microservices taking part in communication. It is considering
    timing the data of every incoming request. You may uncover the reasons for latency
    in your system:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看每个条目的详细信息。Zipkin可视化了参与通信的所有微服务之间的流程。它考虑了每个传入请求的时间数据。您可以发现系统中延迟的原因：
- en: '![](img/c8eef8c1-15f9-4bd9-8ea3-41cc319da73a.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c8eef8c1-15f9-4bd9-8ea3-41cc319da73a.png)'
- en: 'Zipkin provides some additional interesting features. One of these is the ability
    to visualize dependencies between applications. The following screenshot illustrates
    the communication flow of our sample system:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Zipkin提供了一些额外的有趣功能。其中之一是可视化应用程序之间的依赖关系。以下截图说明了我们示例系统的通信流程：
- en: '![](img/7ac3b51e-bbae-409f-8fd2-515abf55c6ea.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/7ac3b51e-bbae-409f-8fd2-515abf55c6ea.png)'
- en: 'You may check out how many messages have been exchanged between services just
    by clicking on the relevant element:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过点击相关元素来查看服务之间交换了多少消息：
- en: '![](img/6d479575-78db-4869-8be4-77bc371c36e3.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![](img/6d479575-78db-4869-8be4-77bc371c36e3.png)'
- en: Integration via message broker
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过消息代理进行集成
- en: 'Integration with Zipkin via HTTP is not the only option. As is usual with Spring
    Cloud, we may use a message broker as a proxy. There are two available brokers—RabbitMQ
    and Kafka. The first of these can be included in the project by using the `spring-rabbit`
    dependency, while the second can be included with `spring-kafka`. The default
    destination name for both of these brokers is `zipkin`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通过HTTP与Zipkin集成并不是唯一的选择。与Spring Cloud一样，我们可以使用消息代理作为代理。有两个可用的代理——RabbitMQ和Kafka。第一个可以通过使用`spring-rabbit`依赖项包含在项目中，而第二个可以通过`spring-kafka`包含在项目中。这两个代理的默认目标名称都是`zipkin`：
- en: '[PRE26]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'This feature also requires changes on the Zipkin server side. We have configured
    a consumer that is listening for the data coming into the RabbitMQ or Kafka queue.
    To achieve this, just include the following dependencies in your project. You
    still need to have the `zipkin-server` and `zipkin-autoconfigure-ui` artifacts
    in the classpath:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个功能还需要在Zipkin服务器端进行更改。我们已经配置了一个消费者，它正在监听进入RabbitMQ或Kafka队列的数据。为了实现这一点，只需在项目中包含以下依赖项。您仍然需要在类路径中拥有`zipkin-server`和`zipkin-autoconfigure-ui`的构件：
- en: '[PRE27]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should annotate the main application class with `@EnableZipkinStreamServer`
    instead of `@EnableZipkinServer`. Fortunately, `@EnableZipkinStreamServer` is
    also annotated with `@EnableZipkinServer`, which means that you may also use the
    standard Zipkin server endpoints for collecting spans over HTTP, and for searching
    them with the UI web console:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该使用`@EnableZipkinStreamServer`注解主应用程序类，而不是`@EnableZipkinServer`。幸运的是，`@EnableZipkinStreamServer`也带有`@EnableZipkinServer`的注解，这意味着您也可以使用标准的Zipkin服务器端点来通过HTTP收集跨度，并在UI
    Web控制台上搜索它们：
- en: '[PRE28]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Logging and tracing are usually not very important during development, but these
    are the key features that are used in the maintenance of the system. In this chapter,
    I have placed emphasis on the fields of development and operations. I have shown
    you how to integrate a Spring Boot microservice application with Logstash and
    Zipkin in several ways. I have also shown you some examples to illustrate how
    to enable Spring Cloud Sleuth features for an application in order to make it
    easier to monitor calls between many microservices. After reading this chapter,
    you should also be able to effectively use Kibana as a log aggregator tool and
    Zipkin as a tracing tool for discovering bottlenecks in communication inside your
    system.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录和跟踪通常在开发过程中并不是非常重要，但它们是系统维护中使用的关键功能。在本章中，我强调了开发和运营领域。我向您展示了如何以多种方式将Spring
    Boot微服务应用程序与Logstash和Zipkin集成。我还向您展示了一些示例，以说明如何为应用程序启用Spring Cloud Sleuth功能，以便更轻松地监视多个微服务之间的调用。阅读完本章后，您还应该能够有效地使用Kibana作为日志聚合工具和Zipkin作为跟踪工具，以发现系统内部通信中的瓶颈。
- en: Spring Cloud Sleuth, in conjunction with Elastic Stack and Zipkin, seems to
    be a very powerful ecosystem, which removes any doubts you might have about problems
    with monitoring systems that consist of many independent microservices.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Spring Cloud Sleuth与Elastic Stack和Zipkin结合起来，似乎是一个非常强大的生态系统，它消除了您对由许多独立微服务组成的监控系统可能存在的任何疑虑。
