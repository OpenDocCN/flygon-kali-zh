- en: Organizing Distributed Solutions with Docker Compose
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose组织分布式解决方案
- en: Shipping software is an integral part of the Docker platform. The official repositories
    on Docker Hub make it easy to design a distributed solution using tried-and-tested
    components. In the previous chapter, I showed you how to integrate these components
    into your own solution, taking a container-first design approach. The end result
    is a distributed solution with several moving parts. In this chapter, you'll learn
    how to organize all those moving parts into one unit, using Docker Compose.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 软件的交付是Docker平台的一个重要组成部分。Docker Hub上的官方存储库使得使用经过验证的组件设计分布式解决方案变得容易。在上一章中，我向你展示了如何将这些组件集成到你自己的解决方案中，采用了以容器为先的设计方法。最终结果是一个具有多个运动部件的分布式解决方案。在本章中，你将学习如何将所有这些运动部件组织成一个单元，使用Docker
    Compose。
- en: Docker Compose is another open source product from Docker, Inc., that extends
    the Docker ecosystem. The Docker **command-line interface** (**CLI**) and Docker
    API work on individual resources, like images and containers. Docker Compose works
    at a higher level, with services and applications. An *application* is a single
    unit composed of one or more services which are deployed as containers at runtime.
    You use Docker Compose to define all the resources of the application-services,
    networks, volumes, and other Docker objects—and the dependencies between them.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose是Docker，Inc.的另一个开源产品，它扩展了Docker生态系统。Docker命令行界面（CLI）和Docker API在单个资源上工作，比如镜像和容器。Docker
    Compose在更高的级别上工作，涉及服务和应用程序。一个应用程序是一个由一个或多个服务组成的单个单元，在运行时作为容器部署。你可以使用Docker Compose来定义应用程序的所有资源-服务、网络、卷和其他Docker对象-以及它们之间的依赖关系。
- en: 'There are two parts to Docker Compose. The design-time element captures the
    application definition in a markup file using a YAML specification, and at runtime
    Docker Compose can manage an application from the YAML file. We''ll cover both
    in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose有两个部分。设计时元素使用YAML规范在标记文件中捕获应用程序定义，而在运行时，Docker Compose可以从YAML文件管理应用程序。我们将在本章中涵盖这两个部分：
- en: Defining applications with Docker Compose
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose定义应用程序
- en: Managing applications with Docker Compose
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Compose管理应用程序
- en: Configuring application environments
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置应用程序环境
- en: Docker Compose is installed as part of Docker Desktop on Windows. If you install
    Docker on Windows Server using the PowerShell installer, that doesn't give you
    Docker Compose. You can download it from the releases on GitHub at `docker/compose`.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose是作为Docker Desktop在Windows上的一部分安装的。如果你使用PowerShell安装程序在Windows
    Server上安装Docker，那就不会得到Docker Compose。你可以从GitHub的发布页面`docker/compose`上下载它。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You will need Docker running on Windows 10 with update 18.09, or Windows Server
    2019 to follow along with the examples. The code for this chapter is available
    at [https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch06](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch06).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要在Windows 10上运行Docker，更新到18.09版，或者在Windows Server 2019上运行，以便跟随示例。本章的代码可在[https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch06](https://github.com/sixeyed/docker-on-windows/tree/second-edition/ch06)上找到。
- en: Defining applications with Docker Compose
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose定义应用程序
- en: The Docker Compose file format is very simple. YAML is a human-readable markup
    language, and the Compose file specification captures your application configuration,
    using the same option names that the Docker CLI uses. In the Compose file, you
    define the services, networks, and volumes that make up your application. Networks
    and volumes are the same concepts that you use with the Docker engine. Services
    are an abstraction over containers.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose文件格式非常简单。YAML是一种人类可读的标记语言，Compose文件规范捕获了您的应用程序配置，使用与Docker CLI相同的选项名称。在Compose文件中，您定义组成应用程序的服务、网络和卷。网络和卷是您在Docker引擎中使用的相同概念。服务是容器的抽象。
- en: 'A *container* is a single instance of a component, which could be anything
    from a web app to a message handler. A service can be multiple instances of the
    same component running in different containers, all using the same Docker image
    and the same runtime options. You could have three containers in the service used
    for your web application and two containers in the service you use for a message
    handler:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是组件的单个实例，可以是从Web应用到消息处理程序的任何内容。服务可以是同一组件的多个实例，在不同的容器中运行，都使用相同的Docker镜像和相同的运行时选项。您可以在用于Web应用程序的服务中有三个容器，在用于消息处理程序的服务中有两个容器：
- en: '![](Images/350dcfa9-dead-4008-84d7-0c4d7e999a8e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/350dcfa9-dead-4008-84d7-0c4d7e999a8e.png)'
- en: A *service* is like a template to run a container from an image, with a known
    configuration. Using services, you can scale up the components of the application—running
    multiple containers from the same image and configuring and managing them as a
    single unit. Services are not used in the standalone Docker engine, but they are
    used in Docker Compose, and also with a cluster of Docker engines running in Docker
    Swarm mode (which I cover in the next chapter, [Chapter 7](bf6a5e90-bbba-435b-b0a0-734611e0e834.xhtml),
    *Orchestrating Distributed Solutions with Docker Swarm*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务*就像是从图像运行容器的模板，具有已知配置。使用服务，您可以扩展应用程序的组件——从相同图像运行多个容器，并将它们配置和管理为单个单元。服务不在独立的Docker引擎中使用，但它们在Docker
    Compose中使用，并且在运行Docker Swarm模式的Docker引擎集群中也使用（我将在下一章[第7章](bf6a5e90-bbba-435b-b0a0-734611e0e834.xhtml)中介绍，*使用Docker
    Swarm编排分布式解决方案*）。'
- en: Docker provides discoverability for services in the same way that it does for
    containers. Consumers access the service by name, and Docker can load-balance
    requests across multiple containers in a service. The number of instances in the
    service is transparent to consumers; they always refer to the service name, and
    the traffic is always directed to a single container by Docker.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Docker为服务提供了与容器相同的可发现性。消费者通过名称访问服务，Docker可以在服务中的多个容器之间负载均衡请求。服务中的实例数量对消费者是透明的；他们总是引用服务名称，并且流量始终由Docker定向到单个容器。
- en: In this chapter, I'll use Docker Compose to organize the distributed solution
    I built in the previous chapter, replacing the brittle `docker container run`
    PowerShell scripts with a reliable and production-ready Docker Compose file.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将使用Docker Compose来组织我在上一章中构建的分布式解决方案，用可靠且适用于生产的Docker Compose文件替换脆弱的`docker
    container run` PowerShell脚本。
- en: Capturing service definitions
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 捕获服务定义
- en: Services can be defined in any order in the Compose file. To make it easier
    to read, I prefer to start with the simplest services, which have no dependencies—**infrastructure
    components**, such as the message queue, reverse proxy, and databases.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 服务可以在Compose文件中以任何顺序定义。为了更容易阅读，我更喜欢从最简单的服务开始，这些服务没有依赖关系——**基础设施组件**，如消息队列、反向代理和数据库。
- en: 'Docker Compose files are conventionally called `docker-compose.yml`, and they
    start with an explicit statement of the API version; the latest is version 3.7\.
    Application resources are defined at the top level—this is a template Compose
    file with sections for services, networks, and volumes:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose文件通常被称为`docker-compose.yml`，并且以API版本的明确声明开头；最新版本是3.7。应用程序资源在顶层定义
    - 这是一个模板Compose文件，包含了服务、网络和卷的部分：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The Docker Compose specification is documented at the Docker website at [https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/).
    This lists the full specification for all supported versions, and the changes
    between the versions.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose规范在Docker网站[https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/)上有文档。这列出了所有支持的版本的完整规范，以及版本之间的更改。
- en: All resources need a unique name, and the name is how resources refer to other
    resources. Services may have a dependency on networks, volumes, and other services,
    which are all captured by name. The configuration for each resource is in its
    own section, and the attributes available are broadly the same as the respective
    `create` command in the Docker CLI, such as `docker network create` and `docker
    volume create`.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 所有资源都需要一个唯一的名称，名称是资源引用其他资源的方式。服务可能依赖于网络、卷和其他服务，所有这些都通过名称来捕获。每个资源的配置都在自己的部分中，可用的属性与Docker
    CLI中相应的`create`命令大致相同，比如`docker network create`和`docker volume create`。
- en: In this chapter, I'll build a Compose file for the distributed NerdDinner application
    and show you how to use Docker Compose to manage the application. I'll start my
    Compose file with the common services first.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将为分布式NerdDinner应用程序构建一个Compose文件，并向您展示如何使用Docker Compose来管理应用程序。我将首先从常见服务开始我的Compose文件。
- en: Defining infrastructure services
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义基础设施服务
- en: 'The simplest service I have is the message queue **NATS**, which has no dependencies.
    Each service needs a name and the image name to start containers from. Optionally,
    you can include parameters that you would use in `docker container run`. For the
    NATS message queue, I add a network name, which means any containers created for
    this service will all be attached to the `nd-net` network:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我拥有的最简单的服务是消息队列**NATS**，它没有任何依赖关系。每个服务都需要一个名称和一个镜像名称来启动容器。可选地，您可以包括您在`docker
    container run`中使用的参数。对于NATS消息队列，我添加了一个网络名称，这意味着为此服务创建的任何容器都将连接到`nd-net`网络：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'In this service definition, I have all the parameters required to start message
    queue containers:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个服务定义中，我拥有启动消息队列容器所需的所有参数：
- en: '`message-queue` is the name of the service. This becomes the DNS entry for
    other services to access NATS.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`message-queue`是服务的名称。这将成为其他服务访问NATS的DNS条目。'
- en: '`image` is the full name of the image to start containers from. In this case,
    it''s my Windows Server 2019 variation of the official NATS image from Docker
    Hub, but you can also use an image from a private registry by including the registry
    domain in the image name.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`是启动容器的完整镜像名称。在这种情况下，它是我从Docker Hub的官方NATS镜像中获取的我的Windows Server 2019变体，但您也可以通过在镜像名称中包含注册表域来使用来自私有注册表的镜像。'
- en: '`networks` is a list of the networks to connect containers to when they start.
    This service connects to one network named `nd-net`. This will be a Docker network
    used for all the services in this application. Later in the Docker Compose file,
    I''ll explicitly capture the details of the network.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`networks`是连接容器启动时要连接到的网络列表。此服务连接到一个名为`nd-net`的网络。这将是此应用程序中所有服务使用的Docker网络。稍后在Docker
    Compose文件中，我将明确捕获网络的详细信息。'
- en: I haven't published any ports for the NATS service. The message queue is only
    used internally by other containers. Within a Docker network, containers can access
    ports on other containers without them being published to the host. This keeps
    the message queue secure, as it is only accessible through the Docker platform
    by other containers in the same network. No external server and no applications
    running on the server can access the message queue.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有为NATS服务发布任何端口。消息队列仅在其他容器内部使用。在Docker网络中，容器可以访问其他容器上的端口，而无需将它们发布到主机上。这使得消息队列安全，因为它只能通过相同网络中的其他容器通过Docker平台访问。没有外部服务器，也没有在服务器上运行的应用程序可以访问消息队列。
- en: Elasticsearch
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Elasticsearch
- en: 'The next infrastructure service is **Elasticsearch**, which also has no dependencies
    on other services. It will be used by the message handler, which also uses the
    NATS message queue, so I will need to join all these services to the same Docker
    network. For Elasticsearch, I also want to limit the amount of memory it uses
    and use a volume for the data so it will be stored outside the container:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个基础设施服务是Elasticsearch，它也不依赖于其他服务。它将被消息处理程序使用，该处理程序还使用NATS消息队列，因此我需要将所有这些服务加入到相同的Docker网络中。对于Elasticsearch，我还希望限制其使用的内存量，并使用卷来存储数据，以便它存储在容器之外：
- en: '[PRE2]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, `elasticsearch` is the name of the service and `sixeyed/elasticsearch`
    is the name of the image, which is my public image on Docker Hub. I'm connecting
    the service to the same `nd-net` network, and I also mount a volume to a known
    location in the container. When Elasticsearch writes data to `C:\data` on the
    container, it will actually be stored in a volume.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`elasticsearch`是服务的名称，`sixeyed/elasticsearch`是镜像的名称，这是我在Docker Hub上的公共镜像。我将服务连接到相同的`nd-net`网络，并且还挂载一个卷到容器中的已知位置。当Elasticsearch将数据写入容器上的`C:\data`时，实际上会存储在一个卷中。
- en: Just as with networks, volumes are first-class resources in the Docker Compose
    file. For Elasticsearch, I'm mapping a volume called `es-data` to the data location
    in the container. I'll specify how the `es-data` volume should be created later
    in the Compose file.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 就像网络一样，卷在Docker Compose文件中是一流资源。对于Elasticsearch，我正在将一个名为`es-data`的卷映射到容器中的数据位置。我将稍后在Compose文件中指定`es-data`卷应该如何创建。
- en: Traefik
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Traefik
- en: 'Next is the reverse proxy, Traefik. The proxy builds its routing rules from
    labels when containers are created, so it needs to connect to the Docker API:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是反向代理Traefik。代理从标签中构建其路由规则，当容器创建时，它需要连接到Docker API：
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The Traefik container publishes to port `80` on the host, connects to the application
    network, and uses a volume for the Docker API-named pipe. These are the same options
    that I used when I started Traefik using `docker container run`; typically, you
    can just copy your run commands into your Docker Compose file.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Traefik容器发布到主机上的端口`80`，连接到应用程序网络，并使用卷用于Docker API命名管道。这些是我在使用`docker container
    run`启动Traefik时使用的相同选项；通常，您可以将运行命令复制到Docker Compose文件中。
- en: Port publishing is the same in Docker Compose as it is when running a container.
    You specify which container port to publish and which host port it should publish
    to, so Docker routes incoming host traffic to the container. The `ports` section
    allows multiple mappings, and you can optionally specify TCP or UDP protocols
    if you have a specific requirement.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 端口发布在Docker Compose中与在运行容器时相同。您指定要发布的容器端口和应该发布到哪个主机端口，因此Docker会将传入的主机流量路由到容器。`ports`部分允许多个映射，并且如果有特定要求，您可以选择指定TCP或UDP协议。
- en: I'm also publishing port `8080` and using the `--api` flag in the Traefik configuration.
    This gives me access to Traefik's dashboard, where I can see all the routing rules
    Traefik has configured. This is useful in non-production environments, to check
    your proxy rules are correct, but this is not something you want exposed publicly
    in production.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我还发布了端口`8080`，并在Traefik配置中使用了`--api`标志。这使我可以访问Traefik的仪表板，我可以在那里查看Traefik配置的所有路由规则。这在非生产环境中很有用，可以检查代理规则是否正确，但在生产环境中，这不是您希望公开的东西。
- en: Docker Compose also supports extended definitions, which I'm using for the `volume`
    specification. Rather than using a single line to define the volume mount, I've
    split out the type of the volume, the source, and the target into different lines.
    This is optional, but it makes the file easier to read.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose还支持扩展定义，我正在使用`volume`规范。我将卷的类型、源和目标拆分成不同的行，而不是使用单行来定义卷挂载。这是可选的，但它使文件更容易阅读。
- en: Kibana
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kibana
- en: '**Kibana** is the first service that depends on other services—it needs Elasticsearch
    running so that it can connect to the database. Docker Compose doesn''t give any
    guarantees about the order in which it creates containers, so if you have a start-up
    dependency between services, you need to capture that in the service definition:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kibana**是第一个依赖于其他服务的服务——它需要Elasticsearch运行，以便它可以连接到数据库。Docker Compose不会对创建容器的顺序做出任何保证，因此如果服务之间存在启动依赖关系，您需要在服务定义中捕获该依赖关系：'
- en: '[PRE4]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `depends_on` attribute shows how to capture dependencies between services.
    In this case, Kibana is dependent on Elasticsearch, so Docker will ensure the
    `elasticsearch` service is up and running before starting the `kibana` service.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`depends_on`属性显示了如何捕获服务之间的依赖关系。在这种情况下，Kibana依赖于Elasticsearch，因此Docker将确保在启动`kibana`服务之前，`elasticsearch`服务已经启动并运行。'
- en: Capturing dependencies like this is fine for running distributed applications
    on a single machine, but it doesn't scale. When you're running in a cluster you
    want the orchestrator to manage distributing the workload. It can't do that effectively
    if you have explicit dependencies, because it needs to make sure all the containers
    running the dependent service are healthy before it starts the consuming containers.
    There are better ways of managing dependencies that we'll see when we look at
    Docker Swarm.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 像这样捕获依赖关系对于在单台机器上运行分布式应用程序是可以的，但它不具有可扩展性。当您在集群中运行时，您希望编排器来管理分发工作负载。如果您有显式依赖关系，它无法有效地执行此操作，因为它需要确保所有运行依赖服务的容器在启动消费容器之前都是健康的。在我们看Docker
    Swarm时，我们将看到更好的管理依赖关系的方法。
- en: Kibana will be proxied by Traefik, but Traefik does not need to be running before
    Kibana. When Traefik starts, it gets a list of running containers from the Docker
    API to build its initial routing map. Then it subscribes to the event stream from
    Docker to update the routing rules when containers are created or removed. So,
    Traefik can start before or after the web containers.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana将由Traefik代理，但Kibana之前不需要运行Traefik。当Traefik启动时，它会从Docker API获取正在运行的容器列表，以构建其初始路由映射。然后，它订阅来自Docker的事件流，以在创建或删除容器时更新路由规则。因此，Traefik可以在web容器之前或之后启动。
- en: Containers for the `kibana` service also connect to the application network.
    In an alternative configuration, I could have separate backend and frontend networks.
    All the infrastructure services would connect to the backend network, and the
    public-facing services would connect to the backend and frontend networks. These
    are both Docker networks, but separating them would give me the flexibility to
    configure the networks differently.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`kibana`服务的容器也连接到应用程序网络。在另一种配置中，我可以有单独的后端和前端网络。所有基础设施服务都将连接到后端网络，而面向公众的服务将连接到后端和前端网络。这两个都是Docker网络，但将它们分开可以让我灵活地配置网络。'
- en: Configuring application services
  id: totrans-51
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置应用程序服务
- en: The infrastructure services I've specified so far haven't needed much application-level
    configuration. I've configured the integration points between the containers and
    the Docker platform with networks, volumes, and ports, but the applications use
    the configuration built into each Docker image.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我指定的基础设施服务并不需要太多的应用程序级配置。我已经使用网络、卷和端口配置了容器与Docker平台之间的集成点，但应用程序使用了内置到每个Docker镜像中的配置。
- en: The Kibana image connects to Elasticsearch by convention using the hostname
    `elasticsearch`, which is the service name I've used in the Docker Compose file
    to support that convention. The Docker platform will route any requests to the
    `elasticsearch` hostname to the service, load-balancing between containers if
    there are multiple containers running the service, so Kibana will be able to find
    Elasticsearch at the expected domain name.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Kibana镜像按照惯例使用主机名`elasticsearch`连接到Elasticsearch，这是我在Docker Compose文件中使用的服务名称，以支持该惯例。Docker平台将任何对`elasticsearch`主机名的请求路由到该服务，如果有多个运行该服务的容器，则在容器之间进行负载均衡，因此Kibana将能够在预期的域名找到Elasticsearch。
- en: My custom applications need configuration settings specified, which I can include
    in the Compose file using environment variables. Defining environment variables
    for a service in the Compose file sets these environment variables for every container
    running the service.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我的自定义应用程序需要指定配置设置，我可以在Compose文件中使用环境变量来包含这些设置。在Compose文件中为服务定义环境变量会为运行该服务的每个容器设置这些环境变量。
- en: 'The index-dinner message handler service subscribes to the NATS message queue
    and inserts documents in Elasticsearch, so it needs to connect to the same Docker
    network, and it also depends on these services. I can capture these dependencies
    in the Compose file and specify the configuration for the application:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: index-dinner消息处理程序服务订阅NATS消息队列并在Elasticsearch中插入文档，因此它需要连接到相同的Docker网络，并且还依赖于这些服务。我可以在Compose文件中捕获这些依赖关系，并指定应用程序的配置。
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Here, I'm using the `environment` section to specify two environment variables—each
    with a key-value pair—to configure the URLs for the message queue and Elasticsearch.
    These are actually the default values baked into the message handler image, so
    I don't need to include them in the Compose file, but it can be useful to explicitly
    set them.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我使用`environment`部分来指定两个环境变量——每个都有一个键值对——来配置消息队列和Elasticsearch的URL。这实际上是默认值内置到消息处理程序镜像中的，所以我不需要在Compose文件中包含它们，但明确设置它们可能会有用。
- en: You can think of the Compose file as the complete deployment guide for the distributed
    solution. If you explicitly specify the environment values, it makes it clear
    what configuration options are available, at the cost of making your Compose file
    less manageable.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以将Compose文件视为分布式解决方案的完整部署指南。如果您明确指定环境值，可以清楚地了解可用的配置选项，但这会使您的Compose文件变得不太可管理。
- en: 'Storing configuration variables in plain text is fine for simple application
    settings, but using a separate environment file is better for sensitive values,
    which is the approach I used in the previous chapter. This is also supported in
    the Compose file format. For the database service, I can use an environment file
    for the administrator password, specified with the `env-file` attribute:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 将配置变量存储为明文对于简单的应用程序设置来说是可以的，但对于敏感值，最好使用单独的环境文件，这是我在上一章中使用的方法。这也受到Compose文件格式的支持。对于数据库服务，我可以使用一个环境文件来指定管理员密码，使用`env-file`属性：
- en: '[PRE6]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'When the database service starts, Docker will set up the environment variables
    from the file called `db-credentials.env`. I''ve used a relative path, so that
    file needs to be in the same location as the Compose file. As earlier, the contents
    of that file are key-value pairs with one line per environment variable. In this
    file, I''ve included the connection strings for the application, as well as the
    password for the database, so the credentials are all in one place:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当数据库服务启动时，Docker将从名为`db-credentials.env`的文件中设置环境变量。我使用了相对路径，所以该文件需要与Compose文件在同一位置。与之前一样，该文件的内容是每个环境变量一行的键值对。在这个文件中，我包括了应用程序的连接字符串，以及数据库的密码，所以凭据都在一个地方：
- en: '[PRE7]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The sensitive data is still in plain text, but by isolating it in a separate
    file, I can do two things:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据仍然是明文的，但通过将其隔离到一个单独的文件中，我可以做两件事：
- en: First, I can secure the file to restrict access.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我可以保护文件以限制访问。
- en: Second, I can take advantage of the separation of the service configuration
    from the application definition and use the same Docker Compose file for different
    environments, substituting different environment files.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，我可以利用服务配置与应用程序定义的分离，并在不同环境中使用相同的Docker Compose文件，替换不同的环境文件。
- en: Environment variables are not secure even if you secure access to the file.
    You can view environment variable values when you inspect a container, so anyone
    with access to the Docker API can read this data. For sensitive data such as passwords
    and API keys, you should use Docker secrets with Docker Swarm, which I cover in
    the next chapter.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 环境变量即使你保护文件访问也不安全。当你检查一个容器时，你可以查看环境变量的值，所以任何有Docker API访问权限的人都可以读取这些数据。对于诸如密码和API密钥之类的敏感数据，你应该在Docker
    Swarm中使用Docker secrets，这将在下一章中介绍。
- en: 'For the save-dinner message handler, I can make use of the same environment
    file for database credentials. The handler depends on the message queue and database
    services, but there are no new attributes in this definition:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于save-dinner消息处理程序，我可以利用相同的环境文件来获取数据库凭据。处理程序依赖于消息队列和数据库服务，但在这个定义中没有新的属性：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next are my frontend services that are proxied by Traefik—the REST API, the
    new home page, and the legacy NerdDinner web application. The REST API uses the
    same credentials file to configure the SQL Server connection, and includes the
    Traefik-routing rule:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是我的前端服务，它们由Traefik代理——REST API、新的主页和传统的NerdDinner网页应用。REST API使用相同的凭据文件来配置SQL
    Server连接，并包括Traefik路由规则：
- en: '[PRE9]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The home page includes the Traefik-routing rule, and also a high-priority value,
    to ensure this rule gets evaluated before the more general rule the NerdDinner
    web app uses:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 主页包括Traefik路由规则，还有一个高优先级值，以确保在NerdDinner网页应用使用的更一般的规则之前评估此规则：
- en: '[PRE10]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The last service is the website itself. Here, I''m using a combination of environment
    variables and environment files. Variable values that are typically consistent
    across environments can be explicitly stated to make the configuration clear—I''m
    doing that for the feature flags. Sensitive data can be read from separate files,
    in this case containing the database credentials and the API keys:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个服务是网站本身。在这里，我正在使用环境变量和环境文件的组合。通常在各个环境中保持一致的变量值可以明确地说明配置，我正在为功能标志做到这一点。敏感数据可以从单独的文件中读取，本例中包含数据库凭据和API密钥：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The website containers don't need to be publicly available, so there's no port
    publishing. The application needs access to the other services, so it's connected
    to the same network.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 网站容器不需要对外公开，因此不需要发布端口。应用程序需要访问其他服务，因此连接到同一个网络。
- en: All the services are configured now, so I just need to specify the network and
    volume resources to complete the Compose file.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所有服务现在都已配置好，所以我只需要指定网络和卷资源，以完成Compose文件。
- en: Specifying application resources
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定应用程序资源
- en: Docker Compose separates network and volume definitions from service definitions,
    which allows flexibility between environments. I'll cover this flexibility later
    in the chapter, but to finish the NerdDinner Compose file, I'll start with the
    simplest approach, using default values.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose将网络和卷的定义与服务的定义分开，这允许在环境之间灵活性。我将在本章后面介绍这种灵活性，但为了完成NerdDinner Compose文件，我将从最简单的方法开始，使用默认值。
- en: The services in my Compose file all use a network called `nd-net`, which needs
    to be specified in the Compose file. Docker networks are a good way to segregate
    applications. You could have several solutions that all use Elasticsearch but
    that have different SLAs and storage requirements. If you have a separate network
    for each application, you can run separate Elasticsearch services in different
    Docker networks, individually configured for each application, but all named `elasticsearch`.
    This keeps to the expected conventions but segregates by the network, so services
    only see the Elasticsearch instance in their own network.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我的Compose文件中的所有服务都使用一个名为`nd-net`的网络，需要在Compose文件中指定。Docker网络是隔离应用程序的好方法。您可以有几个解决方案都使用Elasticsearch，但具有不同的SLA和存储要求。如果每个应用程序都有一个单独的网络，您可以在不同的Docker网络中运行单独配置的Elasticsearch服务，但所有都命名为`elasticsearch`。这保持了预期的约定，但通过网络进行隔离，因此服务只能看到其自己网络中的Elasticsearch实例。
- en: 'Docker Compose can create networks at runtime, or you can define the resource
    to use an external network that already exists on the host. This specification
    for the NerdDinner network uses the default `nat` network that Docker creates
    when it is installed, so this setup will work for all standard Docker hosts:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose可以在运行时创建网络，或者您可以定义资源以使用主机上已经存在的外部网络。这个NerdDinner网络的规范使用了Docker在安装时创建的默认`nat`网络，因此这个设置将适用于所有标准的Docker主机：
- en: '[PRE12]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Volumes also need to be specified. Both of my stateful services, Elasticsearch
    and SQL Server, use named volumes for data storage:  `es-data` and `nd-data`,
    respectively. As with other networks, volumes can be specified as external, so
    Docker Compose will use existing volumes. Docker doesn''t create any default volumes,
    so if I use an external volume, I would need to create it on each host before
    running the application. Instead, I''ll specify the volumes without any options,
    so Docker Compose will create them for me:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 卷也需要指定。我的两个有状态服务，Elasticsearch和SQL Server，都使用命名卷进行数据存储：分别是`es-data`和`nd-data`。与其他网络一样，卷可以被指定为外部，因此Docker
    Compose将使用现有卷。Docker不会创建任何默认卷，因此如果我使用外部卷，我需要在每个主机上运行应用程序之前创建它。相反，我将指定卷而不带任何选项，这样Docker
    Compose将为我创建它们：
- en: '[PRE13]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: These volumes will store the data on the host, rather than in the container's
    writeable layer. They're not host-mounted volumes, so although the data is stored
    on the local disk, I'm not specifying the location. Each volume will write its
    data in the Docker data directory at `C:\ProgramData\Docker`. I'll look at managing
    these volumes later in the chapter.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这些卷将在主机上存储数据，而不是在容器的可写层中。它们不是主机挂载的卷，因此尽管数据存储在本地磁盘上，但我没有指定位置。每个卷将在Docker数据目录`C:\ProgramData\Docker`中写入其数据。我将在本章后面看一下如何管理这些卷。
- en: My Compose file has services, networks and volumes all specified, so it's ready
    to run. The full file is in the source code for this chapter at `ch06\ch06-docker-compose`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我的Compose文件已经指定了服务、网络和卷，所以它已经准备就绪。完整文件在本章的源代码`ch06\ch06-docker-compose`中。
- en: Managing applications with Docker Compose
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose管理应用程序
- en: Docker Compose presents a similar interface to the Docker CLI. The `docker-compose`
    command uses some of the same command names and arguments for the functionality
    it supports—which is a subset of the functionality of the full Docker CLI. When
    you run commands through the Compose CLI, it sends requests to the Docker engine
    to act on the resources in the Compose file.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose提供了与Docker CLI类似的界面。`docker-compose`命令使用一些相同的命令名称和参数来支持其功能，这是完整Docker
    CLI功能的子集。当您通过Compose CLI运行命令时，它会向Docker引擎发送请求，以对Compose文件中的资源进行操作。
- en: The Docker Compose file is the desired state of your application. When you run
    `docker-compose` commands, it compares the Compose file to the objects that already
    exist in Docker and makes any changes needed to get to the desired state. That
    could be stopping containers, starting containers, or creating volumes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose文件是应用程序的期望状态。当您运行`docker-compose`命令时，它会将Compose文件与Docker中已经存在的对象进行比较，并进行任何必要的更改以达到期望的状态。这可能包括停止容器、启动容器或创建卷。
- en: Compose treats all the resources in a Compose file as a single application,
    and to disambiguate applications running on the same host, the runtime adds a
    project name to all the resources it creates for the application. When you run
    an application through Compose and then look at the containers running on your
    host, you won't see a container with a name that exactly matches the service name.
    Compose adds the project name and an index to container names to support multiple
    containers in the service, but this doesn't affect Docker's DNS system, so containers
    still access one another by the service name.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Compose将Compose文件中的所有资源视为单个应用程序，并为了消除在同一主机上运行的应用程序的歧义，运行时会向为应用程序创建的所有资源添加项目名称。当您通过Compose运行应用程序，然后查看在主机上运行的容器时，您不会看到一个名称完全匹配服务名称的容器。Compose会向容器名称添加项目名称和索引，以支持服务中的多个容器，但这不会影响Docker的DNS系统，因此容器仍然通过服务名称相互访问。
- en: Running applications
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行应用程序
- en: 'I have the first Compose file for NerdDinner in the `ch06-docker-compose` directory,
    which also contains the environment variable files. From that directory, I can
    start the whole application with a single `docker-compose` command:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我在`ch06-docker-compose`目录中有NerdDinner的第一个Compose文件，该目录还包含环境变量文件。从该目录，我可以使用单个`docker-compose`命令启动整个应用程序：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Let''s see the description of the preceding command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下前面命令的描述：
- en: The `up` command is used to start the application, creating networks, volumes,
    and running containers.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`up`命令用于启动应用程序，创建网络、卷和运行容器。'
- en: The `-d` option runs all the containers in the background, and is the same as
    the `--detach` option in `docker container run`.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-d`选项在后台运行所有容器，与`docker container run`中的`--detach`选项相同。'
- en: You can see that Docker Compose honors the `depends_on` settings for services.
    Any services that are dependencies for others are created first. Services that
    don't have any dependencies will be created in a random order. In this case, the
    `message-queue` service was created first, as many other services depend on it,
    and the `nerd-dinner-web` and `nerd-dinner-save-handler` services are the last
    of all, as they have the most dependencies.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到Docker Compose遵守服务的`depends_on`设置。任何作为其他服务依赖项的服务都会首先创建。没有任何依赖项的服务将以随机顺序创建。在这种情况下，`message-queue`服务首先创建，因为许多其他服务依赖于它，而`nerd-dinner-web`和`nerd-dinner-save-handler`服务是最后创建的，因为它们有最多的依赖项。
- en: The names in the output are the individual container names, with the naming
    format `{project}_{service}_{index}`. Each service has only one container running,
    which is the default, so the indexes are all `1`. The project name is a sanitized
    version of the directory name where I ran the `compose` command.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 输出中的名称是各个容器的名称，命名格式为`{project}_{service}_{index}`。每个服务只有一个运行的容器，这是默认的，所以索引都是`1`。项目名称是我运行`compose`命令的目录名称的经过清理的版本。
- en: 'When you run a `docker-compose up` command and it completes, you can manage
    the containers with Docker Compose or with the standard Docker CLI. The containers
    are just normal Docker containers, with some extra metadata used by compose to
    manage them as a whole unit. Listing containers shows me all the service containers
    created by `compose`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行`docker-compose up`命令并完成后，您可以使用Docker Compose或标准的Docker CLI来管理容器。这些容器只是普通的Docker容器，compose使用一些额外的元数据来将它们作为一个整体单元进行管理。列出容器会显示由`compose`创建的所有服务容器：
- en: '[PRE15]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The container running Traefik publishes port `80` to the local machine, and
    I have entries in my hosts file for the local NerdDinner domains. The NerdDinner
    application with its new home page, the REST API, and the Kibana analytics will
    behave as expected, because the full configuration is captured in the Compose
    file, and all the components are started by Docker Compose.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 运行Traefik的容器将端口`80`发布到本地计算机，并且我的hosts文件中有本地NerdDinner域的条目。NerdDinner应用程序及其新首页、REST
    API和Kibana分析将按预期运行，因为所有配置都包含在Compose文件中，并且所有组件都由Docker Compose启动。
- en: This is one of the most powerful features of the Compose file format. The file
    contains the complete specification to run your application, and anyone can use
    it to run your app. In this case, all the components use public Docker images
    on Docker Hub, so anyone can start the app from this Compose file. You don't need
    any prerequisites other than Docker and Docker Compose to run NerdDinner, which
    is now a distributed application containing .NET Framework, .NET Core, Java, Go,
    and Node.js components.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Compose文件格式中最强大的功能之一。该文件包含了运行应用程序的完整规范，任何人都可以使用它来运行您的应用程序。在这种情况下，所有组件都使用Docker
    Hub上的公共Docker镜像，因此任何人都可以从这个Compose文件启动应用程序。您只需要Docker和Docker Compose来运行NerdDinner，它现在是一个包含.NET
    Framework、.NET Core、Java、Go和Node.js组件的分布式应用程序。
- en: Scaling application services
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展应用程序服务
- en: Docker Compose lets you scale services up and down easily, adding or removing
    containers to a running service. When a service is running with multiple containers,
    it's still accessible to other services in the network. Consumers use the service
    name for discovery, and the DNS server in Docker load-balances requests across
    all the containers in the service.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose让您轻松地扩展服务，向正在运行的服务添加或删除容器。当一个服务使用多个容器运行时，它仍然可以被网络中的其他服务访问。消费者使用服务名称进行发现，Docker中的DNS服务器会在所有服务的容器之间平衡请求。
- en: Adding more containers doesn't automatically give scale and resilience to your
    service, though; that depends on the application running the service. You won't
    get a SQL Server failover cluster just by adding another container to a SQL database
    service, because SQL Server needs to be explicitly configured for failover. If
    you add another container, you'll have just two distinct database instances with
    separate data stores.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，添加更多的容器并不会自动为您的服务提供规模和弹性；这取决于运行服务的应用程序。只是向SQL数据库服务添加另一个容器并不会自动给您提供SQL Server故障转移集群，因为SQL
    Server需要显式配置故障转移。如果您添加另一个容器，您将只有两个具有单独数据存储的不同数据库实例。
- en: Web applications typically scale well if they are designed to support scale-out.
    Stateless applications can run in any number of containers because any container
    can handle any request. But if your application maintains the session state locally,
    requests from the same user need to be handled by the same service, which prevents
    you from load-balancing across many containers, unless you use sticky sessions.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: Web应用程序通常在设计时支持横向扩展时可以很好地扩展。无状态应用程序可以在任意数量的容器中运行，因为任何容器都可以处理任何请求。但是，如果您的应用程序在本地维护会话状态，则来自同一用户的请求需要由同一服务处理，这将阻止您在许多容器之间进行负载平衡，除非您使用粘性会话。
- en: Services that publish ports to the host can't be scaled if they're running on
    a single Docker engine. Ports can have one only operating system process listening
    on them, and that's also true for Docker—you can't have the same host port mapped
    to multiple container ports. On a Docker Swarm where you have multiple hosts,
    you can scale services with published ports, and Docker will run each containers
    on different hosts.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 将端口发布到主机的服务，如果它们在单个Docker引擎上运行，则无法扩展。端口只能有一个操作系统进程在其上监听，对于Docker也是如此——您不能将相同的主机端口映射到多个容器端口。在具有多个主机的Docker
    Swarm上，您可以扩展具有发布端口的服务，Docker将在不同的主机上运行每个容器。
- en: In NerdDinner, the message handlers are truly stateless components. They receive
    a message from the queue that contains all the information they need, and they
    process it. NATS supports grouping of subscribers on the same message queue, which
    means I can have several containers running the save-dinner handler, and NATS
    will ensure only one handler gets a copy of each message, so I don't have duplicate
    message processing. The code in the message handlers already takes advantage of
    that.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在NerdDinner中，消息处理程序是真正无状态的组件。它们从包含它们所需的所有信息的队列中接收消息，然后对其进行处理。NATS支持在同一消息队列上对订阅者进行分组，这意味着我可以运行几个包含save-dinner处理程序的容器，并且NATS将确保只有一个处理程序获得每条消息的副本，因此我不会有重复的消息处理。消息处理程序中的代码已经利用了这一点。
- en: 'Scaling up the message handler is something I can do at peak time to increase
    the throughput for message processing. I can do that with the `up` command and
    the `--scale` option, specifying the service name and the desired number of instances:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展消息处理程序是我在高峰时期可以做的事情，以增加消息处理的吞吐量。我可以使用`up`命令和`--scale`选项来做到这一点，指定服务名称和所需的实例数量：
- en: '[PRE16]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Docker Compose compares the state of the running application with the configuration
    in the Compose file and the overrides specified in the command. In this case,
    all the services are unchanged except for the save-dinner handler, so they are
    listed as `up-to-date`. The save-handler has a new service level, so Docker Compose
    creates two more containers.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose将运行应用程序的状态与Compose文件中的配置和命令中指定的覆盖进行比较。在这种情况下，除了save-dinner处理程序之外，所有服务都保持不变，因此它们被列为`up-to-date`。save-handler具有新的服务级别，因此Docker
    Compose创建了两个更多的容器。
- en: With three instances of the save-message handler running, they share the incoming
    message load in a round-robin approach. That's a great way to increase scale.
    The handlers concurrently process messages and write to the SQL database, which
    increases the throughput for saves and reduces the time taken for messages to
    be handled. But there is still a strict limit to the number of processes writing
    to SQL Server, so the database won't become a bottleneck for this feature.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有三个save-message处理程序实例运行时，它们以循环方式共享传入消息负载。这是增加规模的好方法。处理程序同时处理消息并写入SQL数据库，这增加了保存的吞吐量并减少了处理消息所需的时间。但对于写入SQL
    Server的进程数量仍然有严格的限制，因此数据库不会成为此功能的瓶颈。
- en: 'I can create multiple dinners through the web application, and the message
    handlers will share the load when the event messages are published. I can see
    in the logs that different handlers process different messages, and there is no
    duplicate processing of events:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以通过web应用程序创建多个晚餐，当事件消息被发布时，消息处理程序将共享负载。我可以在日志中看到不同的处理程序处理不同的消息，并且没有重复处理事件：
- en: '[PRE17]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'I''m running on a single Docker engine, so I can''t scale the Traefik service,
    because only one container can be published to port `80`. But I can scale the
    frontend containers that Traefik is proxying, which is a great way to test that
    my application works correctly when it''s scaled out to multiple instances. I''ll
    add another two instances of the original NerdDinner web application:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在单个Docker引擎上运行，所以无法扩展Traefik服务，因为只能发布一个容器到端口`80`。但我可以扩展Traefik代理的前端容器，这是测试我的应用程序在扩展到多个实例时是否正常工作的好方法。我将再添加两个原始NerdDinner
    web应用程序的实例：
- en: '[PRE18]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Look closely at this output—something happened here that is correct, but is
    not what I intended. Compose has created two new NerdDinner web containers, to
    meet the scale of 3 that I specified, but it's also stopped and removed two of
    the save-handler containers.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细看这个输出——发生了一些正确的事情，但并不是我想要的。Compose已经创建了两个新的NerdDinner web容器，以满足我指定的规模为3，但它也停止并移除了两个save-handler容器。
- en: This is because Compose is implicitly using my `docker-compose.yml` file as
    the application definition, which uses a single instance of each service. Then
    it adds the scale value from the command for the web service, and builds a desired
    state that says every service should have one container running, except the web
    service, which should have three. It sees the web service only has one container,
    so it creates two more. And it sees the save-handler has three containers, so
    it removes two.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为Compose隐式地使用我的`docker-compose.yml`文件作为应用程序定义，该文件使用每个服务的单个实例。然后它从web服务的命令中添加了规模值，并构建了一个期望的状态，即每个服务应该有一个正在运行的容器，除了web服务应该有三个。它发现web服务只有一个容器，所以创建了另外两个。它发现save-handler有三个容器，所以移除了两个。
- en: 'Mixing the Compose file definition with changes from the command is not recommended,
    precisely because of this situation. The Compose file alone should be the desired
    state of your application. But in this case, you can''t specify a scale option
    in the Compose file (you could in older versions, but not from v3 of the specification),
    so you need to explicitly add scale levels for all services:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 混合Compose文件定义和命令的更改是不推荐的，正是因为这种情况。Compose文件本身应该是应用程序的期望状态。但在这种情况下，您无法在Compose文件中指定规模选项（在旧版本中可以，但从规范的v3开始不行），因此您需要显式地为所有服务添加规模级别：
- en: '[PRE19]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now I have three save-handler containers, which are sharing work from the message
    queue, and three web containers. Traefik will load-balance requests between these
    three web containers. I can check that configuration from the Traefik dashboard,
    which I have published on port `8080`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我有三个save-handler容器，它们正在共享消息队列的工作，还有三个web容器。Traefik将在这三个web容器之间负载均衡请求。我可以从Traefik仪表板上检查该配置，我已经发布在端口`8080`上：
- en: '![](Images/dc786f47-93ea-4ef3-a5dc-2bb67d24bacd.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dc786f47-93ea-4ef3-a5dc-2bb67d24bacd.png)'
- en: Traefik shows the frontend routing rules in blue boxes on the left, and the
    backend services they map to as green boxes on the right. There is a frontend
    routing rule for `nerddinner.local` with a path prefix of `/`, which sends all
    traffic to the `nerd-dinner-web` backend (except the home page, which has a different
    rule). The backend is shown with three servers listed, which are the three containers
    I scaled with Docker Compose. The `172.20.*.*` server addresses are the internal
    IP address on the Docker network that containers can use to communicate.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Traefik在左侧以蓝色框显示前端路由规则，以绿色框显示它们映射到的后端服务。对于`nerddinner.local`有一个路径前缀为`/`的前端路由规则，它将所有流量发送到`nerd-dinner-web`后端（除了首页，它有不同的规则）。后端显示有三个列出的服务器，它们是我用Docker
    Compose扩展的三个容器。`172.20.*.*`服务器地址是Docker网络上的内部IP地址，容器可以用来通信。
- en: 'I can browse the NerdDinner app, and it works correctly, with Traefik load-balancing
    requests across the backend containers. As soon as I try to log in, though, I''ll
    find that NerdDinner wasn''t designed to scale out to multiple instances:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以浏览NerdDinner应用程序，并且它可以正确运行，Traefik会在后端容器之间负载均衡请求。但是，一旦我尝试登录，我会发现NerdDinner并不是设计为扩展到多个实例：
- en: '![](Images/3819e3df-ac67-4493-9326-587e96033019.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/3819e3df-ac67-4493-9326-587e96033019.png)'
- en: 'That error message tells me that NerdDinner expects all the requests from one
    user to be handled by the same instance of the web app. Traefik supports sticky
    sessions for exactly this situation, so to fix this, I just need to add a new
    label to the web service definition in my Compose file. This enables sticky sessions
    for the NerdDinner backend:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 该错误消息告诉我，NerdDinner希望一个用户的所有请求都由web应用程序的同一实例处理。Traefik支持粘性会话，正是为了解决这种情况，因此要解决这个问题，我只需要在Compose文件中的web服务定义中添加一个新的标签。这将为NerdDinner后端启用粘性会话：
- en: '[PRE20]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now I can deploy again, making sure to include my scale arguments:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我可以再次部署，确保包括我的规模参数：
- en: '[PRE21]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Compose recreates the web service containers, removing the old containers and
    starting new ones with the new configuration. Now, Traefik is using sticky sessions,
    so every request from my browser session will go to the same container. Traefik
    powers this with a custom cookie that specifies the container IP address the request
    should route to:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: Compose重新创建web服务容器，删除旧容器，并使用新配置启动新容器。现在，Traefik正在使用粘性会话，因此我的浏览器会话中的每个请求都将发送到相同的容器。Traefik使用自定义cookie来实现这一点，该cookie指定请求应路由到的容器IP地址：
- en: '![](Images/d8aba133-97bc-4aa2-bdea-94bf34bd68d6.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/d8aba133-97bc-4aa2-bdea-94bf34bd68d6.png)'
- en: In this case, the cookie is called `_d18b8` and it fixes all my requests to
    be routed to the container with the IP address `172.20.26.74`.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，cookie被称为`_d18b8`，它会将所有我的请求定向到具有IP地址`172.20.26.74`的容器。
- en: Finding issues when you run at scale used to only happen in test environments,
    or even in production. Running everything in Docker means I can test the functionality
    of my app at scale on my dev laptop, and find these problems before release. Using
    modern technology such as Traefik also means there are nice ways to fix these
    problems, without having to change my legacy application.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模运行时发现问题以前只会发生在测试环境，甚至在生产环境中。在Docker中运行所有内容意味着我可以在我的开发笔记本上测试应用程序的功能，以便在发布之前发现这些问题。使用现代技术，如Traefik，也意味着有很好的方法来解决这些问题，而无需更改我的传统应用程序。
- en: Stopping and starting application services
  id: totrans-133
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 停止和启动应用程序服务
- en: There are several commands for managing the container life cycle in Docker Compose.
    It's important to understand the differences between the options, so you don't
    remove resources unexpectedly.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose中有几个管理容器生命周期的命令。重要的是要理解选项之间的区别，以免意外删除资源。
- en: The `up` and `down` commands are blunt tools to start and stop the whole application.
    The `up` command creates any resources specified in the Compose file that don't
    exist, and it creates and starts containers for all the services. The `down` command
    does the reverse—it stops any running containers and removes the application resources.
    Containers and networks are removed if they were created by Docker Compose, but
    volumes are not removed—so any application data you have is retained.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '`up`和`down`命令是启动和停止整个应用程序的粗糙工具。`up`命令创建Compose文件中指定的任何不存在的资源，并为所有服务创建和启动容器。`down`命令则相反-它停止任何正在运行的容器并删除应用程序资源。如果是由Docker
    Compose创建的容器和网络，则会被删除，但卷不会被删除-因此您拥有的任何应用程序数据都将被保留。'
- en: The `stop` command just stops all the running containers without removing them
    or other resources. Stopping the container ends the running process with a graceful
    shutdown. The `kill` command stops all the containers by forcibly ending the running
    process. Stopped application containers can be started again with `start`, which
    runs the entry point program in the existing container.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`stop`命令只是停止所有正在运行的容器，而不会删除它们或其他资源。停止容器会以优雅的方式结束运行的进程。可以使用`start`再次启动已停止的应用程序容器，它会在现有容器中运行入口点程序。'
- en: 'Stopped containers retain all their configuration and data, but they don''t
    use any compute resources. Starting and stopping containers is a very efficient
    way to switch context if you work on multiple projects. If I''m developing on
    NerdDinner when another piece of work comes in as a priority, I can stop the whole
    NerdDinner application to free up my development environment:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 停止的容器保留其所有配置和数据，但它们不使用任何计算资源。启动和停止容器是在多个项目上工作时切换上下文的非常有效的方式。如果我在NerdDinner上开发，当另一个工作作为优先级而来时，我可以停止整个NerdDinner应用程序来释放我的开发环境：
- en: '[PRE22]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now I have no containers running, and I can switch to the other project. When
    that work is done, I can fire up NerdDinner again by running `docker-compose start`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我没有运行的容器，我可以切换到另一个项目。当工作完成时，我可以通过运行`docker-compose start`再次启动NerdDinner。
- en: 'You can also stop individual services by specifying a name, which is very useful
    if you want to test how your application manages failures. I can check how the
    index-dinner handlers behave if they can''t access Elasticsearch by stopping the
    Elasticsearch service:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以通过指定名称来停止单个服务，如果您想测试应用程序如何处理故障，这将非常有用。我可以通过停止Elasticsearch服务来检查索引晚餐处理程序在无法访问Elasticsearch时的行为：
- en: '[PRE23]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: All of these commands are processed by comparing the Compose file to the services
    running in Docker. You need to have access to the Docker Compose file to run any
    Docker Compose commands. This is one of the biggest drawbacks of using Docker
    Compose on a single host to run your applications. The alternative is to use the
    same Compose file but to deploy it as a stack to a Docker Swarm, which I'll cover
    in the next chapter.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些命令都是通过将Compose文件与在Docker中运行的服务进行比较来处理的。你需要访问Docker Compose文件才能运行任何Docker
    Compose命令。这是在单个主机上使用Docker Compose运行应用程序的最大缺点之一。另一种选择是使用相同的Compose文件，但将其部署为Docker
    Swarm的堆栈，我将在下一章中介绍。
- en: The `stop` and `start` commands use the Compose file, but they work on the containers
    that currently exist, not just the definition in the Compose file. So, if you
    scale a service, then stop the whole application and then start it again—you'll
    still have all the containers you scaled to. Only the `up` command uses the Compose
    file to reset the application to the desired state.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`stop`和`start`命令使用Compose文件，但它们作用于当前存在的容器，而不仅仅是Compose文件中的定义。因此，如果你扩展了一个服务，然后停止整个应用程序，然后再次启动它——你仍然会拥有你扩展的所有容器。只有`up`命令使用Compose文件将应用程序重置为所需的状态。'
- en: Upgrading application services
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级应用程序服务
- en: If you run `docker compose up` repeatedly from the same Compose file, no changes
    will be made after the first run. Docker Compose compares the configuration in
    the Compose file with the active containers at runtime and won't change resources
    unless the definition has changed. This means you can use Docker Compose to manage
    application upgrades.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你从同一个Compose文件重复运行`docker compose up`，在第一次运行之后不会进行任何更改。Docker Compose会将Compose文件中的配置与运行时的活动容器进行比较，并且不会更改资源，除非定义已经改变。这意味着你可以使用Docker
    Compose来管理应用程序的升级。
- en: My Compose file is currently using the database service from the image I built
    in [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing Dockerized
    .NET Framework and .NET Core Applications*, tagged `dockeronwindows/ch03-nerd-dinner-db:2e`.
    For this chapter, I've added audit fields to the tables in the database schema
    and built a new version of the database image, tagged `dockeronwindows/ch06-nerd-dinner-db:2e`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我的Compose文件目前正在使用我在[第3章](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml)中构建的数据库服务的镜像，*开发Docker化的.NET
    Framework和.NET Core应用程序*，标记为`dockeronwindows/ch03-nerd-dinner-db:2e`。对于本章，我已经在数据库架构中添加了审计字段，并构建了一个新版本的数据库镜像，标记为`dockeronwindows/ch06-nerd-dinner-db:2e`。
- en: 'I have a second Compose file in the same `ch06-docker-compose` directory, called
    `docker-compose-db-upgrade.yml`. The upgrade file is not a full application definition;
    all it contains is a single part of the database service definition, using the
    new image tag:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我在同一个`ch06-docker-compose`目录中有第二个Compose文件，名为`docker-compose-db-upgrade.yml`。升级文件不是完整的应用程序定义；它只包含数据库服务定义的一个部分，使用新的镜像标签：
- en: '[PRE24]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Docker Compose supports override files. You can run `docker-compose` commands
    and pass multiple Compose files as arguments. Compose will join all the files
    together in the order specified in the command, from left to right. Override files
    can be used to add new sections to the application definition, or they can replace
    existing values.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose支持覆盖文件。你可以运行`docker-compose`命令并将多个Compose文件作为参数传递。Compose将按照命令中指定的顺序从左到右将所有文件合并在一起。覆盖文件可以用于向应用程序定义添加新的部分，或者可以替换现有的值。
- en: 'While the application is running, I can execute `docker compose up` again,
    specifying both the original Compose file, and the `db-upgrade` override file:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 当应用程序正在运行时，我可以再次执行`docker compose up`，同时指定原始Compose文件和`db-upgrade`覆盖文件：
- en: '[PRE25]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This command uses the `db-upgrade` file as an override to the main `docker-compose.yml`
    file. Docker Compose merges them both, so the final service definition contains
    all the values from the original file, except the image specification that comes
    from the override. The new service definition doesn't match what's running in
    Docker, so Compose recreates the database service.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令使用`db-upgrade`文件作为主`docker-compose.yml`文件的覆盖。Docker Compose将它们合并在一起，因此最终的服务定义包含原始文件中的所有值，除了来自覆盖的镜像规范。新的服务定义与Docker中正在运行的内容不匹配，因此Compose重新创建数据库服务。
- en: Docker Compose recreates services by removing the old container and starting
    a new one, using the new image specification. Services that don't depend on the
    database are left as they are, with the log entry `up-to-date`, and any services
    that do depend on the database are also recreated once the new database container
    is running.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose通过移除旧容器并启动新容器来重新创建服务，使用新的镜像规范。不依赖于数据库的服务保持不变，日志条目为`up-to-date`，任何依赖于数据库的服务在新的数据库容器运行后也会被重新创建。
- en: 'My database container uses the pattern I described in [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml), *Developing
    Dockerized .NET Framework and .NET Core Applications,* with a volume to store
    the data and a script that can upgrade the database schema when a container is
    replaced. In the Compose file, I use a default definition for the volume called
    `db-data`, so Docker Compose creates it for me. Just like the containers created
    by Compose, volumes are a standard Docker resource and can be managed with the
    Docker CLI. The `docker volume ls` lists all the volumes on the host:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我的数据库容器使用了我在[第3章](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml)中描述的模式，使用卷存储数据和一个脚本，可以在容器被替换时升级数据库模式。在Compose文件中，我使用了一个名为`db-data`的卷的默认定义，因此Docker
    Compose为我创建了它。就像Compose创建的容器一样，卷是标准的Docker资源，可以使用Docker CLI进行管理。`docker volume
    ls`列出主机上的所有卷：
- en: '[PRE26]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'I have two volumes for my NerdDinner deployment. They both use the local driver,
    which means the data is stored on the local disk. I can inspect the SQL Server
    volume to see where the data is physically stored on the host (in the `Mountpoint`
    attribute) and then check the contents to see the database files:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我有两个卷用于我的NerdDinner部署。它们都使用本地驱动程序，这意味着数据存储在本地磁盘上。我可以检查SQL Server卷，看看数据在主机上的物理存储位置（在`Mountpoint`属性中），然后检查内容以查看数据库文件：
- en: '[PRE27]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The volume is stored outside of the container, so when Docker Compose removes
    the old container database, all the data is preserved. The new database image
    bundles a Dacpac and is configured to do schema upgrades for the existing data
    file in the same way as the SQL Server database from [Chapter 3](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml),
    *Developing Dockerized .NET Framework and .NET Core Applications*.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 卷存储在容器之外，因此当Docker Compose移除旧容器数据库时，所有数据都得到保留。新的数据库镜像捆绑了一个Dacpac，并配置为对现有数据文件进行模式升级，方式与[第3章](ee527f27-ee07-40e1-a39d-86aa2d11da72.xhtml)中的SQL
    Server数据库相同，*开发Docker化的.NET Framework和.NET Core应用*。
- en: 'When the new container has started, I can check the logs and see that the new
    container attached the database files from the volume and then altered the Dinners
    table to add the new audit column:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 新容器启动后，我可以检查日志，看到新容器从卷中附加了数据库文件，然后修改了Dinners表以添加新的审计列：
- en: '[PRE28]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The new audit column adds a timestamp when rows are updated, so now when I
    create a dinner through the web UI, I can see when the row was last updated in
    the database. In my development environment, I haven''t published the SQL Server
    port for client connections, but I can run `docker container inspect` to get the
    container''s local IP address. Then I can connect my SQL client directly to the
    container and run a query to see the new audit timestamp:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 新的审计列在更新行时添加了时间戳，因此现在当我通过Web UI创建晚餐时，我可以看到数据库中上次更新行的时间。在我的开发环境中，我还没有为客户端连接发布SQL
    Server端口，但我可以运行`docker container inspect`来获取容器的本地IP地址。然后我可以直接连接我的SQL客户端到容器并运行查询以查看新的审计时间戳：
- en: '![](Images/eb36d243-f04d-4ed7-a10c-cad9ea1d5188.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/eb36d243-f04d-4ed7-a10c-cad9ea1d5188.png)'
- en: Docker Compose looks for any differences between resources and their definitions,
    and not just the name of the Docker image. If you change the environment variables,
    port mappings, volume setup, or any other configuration, Docker Compose will remove
    or create resources to bring the running application to the desired state.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose寻找资源及其定义之间的任何差异，而不仅仅是Docker镜像的名称。如果更改环境变量、端口映射、卷设置或任何其他配置，Docker
    Compose将删除或创建资源，以将运行的应用程序带到所需的状态。
- en: You need to be careful with modifying Compose files to run applications. If
    you remove the definition for a running service from the file, Docker Compose
    won't recognize that the existing service containers are part of the application,
    so they won't be included in the difference checks. You can end up with orphaned
    service containers.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 修改Compose文件以运行应用程序时需要小心。如果从文件中删除正在运行的服务的定义，Docker Compose将不会识别现有的服务容器是应用程序的一部分，因此它们不会包含在差异检查中。您可能会遇到孤立的服务容器。
- en: Monitoring application containers
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监视应用程序容器
- en: Treating a distributed application as a single unit makes it easier to monitor
    and trace problems. Docker Compose provides its own `top` and `logs` commands,
    which operate over all the containers in the application services and display
    the collected results.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将分布式应用程序视为单个单元可以更容易地监视和跟踪问题。Docker Compose提供了自己的`top`和`logs`命令，这些命令可以在应用程序服务的所有容器上运行，并显示收集的结果。
- en: 'To check the memory and CPU usage of all the components, run `docker-compose
    top`:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查所有组件的内存和CPU使用情况，请运行`docker-compose top`：
- en: '[PRE29]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Containers are listed in alphabetical order by name, and processes in each container
    are listed without a specific order. There's no way to change the ordering, so
    you can't show the most intensive processes in the hardest-working container first,
    but the result is in plain text, so you can manipulate it in PowerShell.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 容器按名称按字母顺序列出，每个容器中的进程没有特定的顺序列出。无法更改排序方式，因此无法首先显示最密集的进程所在的最努力工作的容器，但结果是以纯文本形式呈现的，因此可以在PowerShell中对其进行操作。
- en: 'To see the log entries from all the containers, run `docker-compose logs`:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有容器的日志条目，请运行`docker-compose logs`：
- en: '[PRE30]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: On the screen, the container names are color-coded, so you can easily distinguish
    entries from different components. One advantage of reading logs through Docker
    Compose is that it shows output for all the containers, even if the component
    has shown errors and the container is stopped. These error messages are useful
    to see in context—you may see that one component throws a connection error before
    another component logs that it has started, which may highlight a missing dependency
    in the Compose file.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕上，容器名称以颜色编码，因此您可以轻松区分来自不同组件的条目。通过Docker Compose阅读日志的一个优势是，它显示所有容器的输出，即使组件显示错误并且容器已停止。这些错误消息对于在上下文中查看很有用-您可能会看到一个组件在另一个组件记录其已启动之前抛出连接错误，这可能突出了Compose文件中缺少的依赖关系。
- en: Docker Compose shows all the log entries for all the service containers, so
    the output can be extensive. You can limit this with the `--tail` option, restricting
    the output to a specified number of the most recent log entries for each container.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose显示所有服务容器的所有日志条目，因此输出可能很多。您可以使用`--tail`选项限制输出，将输出限制为每个容器的指定数量的最近日志条目。
- en: These are useful commands when you are running in development or in a low-scale
    project with a single server running a small number of containers. It doesn't
    scale for large projects running on multiple containers across multiple hosts
    with Docker Swarm. For those, you need container-centric administration and monitoring,
    which I'll demonstrate in [Chapter 8](98e12163-b4ad-4b5d-aecc-827f5e204caa.xhtml),
    *Administering and Monitoring Dockerized Solutions*.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这些命令在开发或在单个服务器上运行少量容器的低规模项目中非常有用。对于在Docker Swarm上运行的跨多个主机的大型项目，它不具备可扩展性。对于这些项目，您需要以容器为中心的管理和监控，我将在[第8章](98e12163-b4ad-4b5d-aecc-827f5e204caa.xhtml)中进行演示，*管理和监控Docker化解决方案*。
- en: Managing application images
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理应用程序图像
- en: Docker Compose can manage Docker images, as well as containers. In the Compose
    file, you can include attributes that tell Docker Compose how to build your images.
    You can specify the location of the build context to send to the Docker service,
    which is the root folder for all your application content—and the location of
    the Dockerfile.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose可以管理Docker图像，以及容器。在Compose文件中，您可以包括属性，告诉Docker Compose如何构建您的图像。您可以指定要发送到Docker服务的构建上下文的位置，这是所有应用程序内容的根文件夹，以及Dockerfile的位置。
- en: The context path is relative to the location of the Compose file, and the Dockerfile
    path is relative to the context. This is very useful for complex source trees,
    such as the demo source for this book, where the context for each image is in
    a different folder. In the `ch06-docker-compose-build` folder, I have a full Compose
    file with application specification, complete with the build attributes specified.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文路径是相对于Compose文件的位置，而Dockerfile路径是相对于上下文的。这对于复杂的源树非常有用，比如本书的演示源，其中每个图像的上下文位于不同的文件夹中。在`ch06-docker-compose-build`文件夹中，我有一个完整的Compose文件，其中包含了应用程序规范，包括指定的构建属性。
- en: 'This is how the build details are specified for my images:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我为我的图像指定构建细节的方式：
- en: '[PRE31]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: When you run `docker-compose build`, any services that have the `build` attribute
    specified will be built and tagged with the name in the `image` attribute. The
    build process uses the normal Docker API, so the image layer cache is still used,
    and only changed layers are rebuilt. Adding build details to your Compose file
    is a very efficient way of building all your application images, and it's also
    a central place to capture how the images are built.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行`docker-compose build`时，任何具有指定`build`属性的服务将被构建并标记为`image`属性中的名称。构建过程使用正常的Docker
    API，因此仍然使用图像层缓存，只重新构建更改的层。向Compose文件添加构建细节是构建所有应用程序图像的一种非常有效的方式，也是捕获图像构建方式的中心位置。
- en: 'One other useful feature of Docker Compose is the ability to manage whole groups
    of images. The Compose file for this chapter uses images that are all publicly
    available on Docker Hub, so you can run the full application with `docker-compose
    up`—but the first time you run it, all the images will be downloaded, which is
    going to take a while. You can preload images before you use them with `docker-compose
    pull`, which will pull all the images:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose的另一个有用功能是能够管理整个图像组。本章的Compose文件使用的图像都是在Docker Hub上公开可用的，因此您可以使用`docker-compose
    up`运行完整的应用程序，但第一次运行时，所有图像都将被下载，这将需要一些时间。您可以在使用`docker-compose pull`之前预加载图像，这将拉取所有图像：
- en: '[PRE32]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Similarly, you can use `docker-compose push` to upload images to remote repositories.
    For both commands, Docker Compose uses the authenticated user from the most recent
    `docker login` command. If your Compose file contains images you don't have access
    to push, those pushes will fail. For any repositories you are authorized to write
    to, whether in Docker Hub or a private registry, these images will be pushed.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，您可以使用`docker-compose push`将图像上传到远程存储库。对于这两个命令，Docker Compose使用最近`docker login`命令的经过身份验证的用户。如果您的Compose文件包含您无权推送的图像，这些推送将失败。对于您有写入权限的任何存储库，无论是在Docker
    Hub还是私有注册表中，这些图像都将被推送。
- en: Configuring application environments
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置应用程序环境
- en: When you define your application in Docker Compose, you have a single artifact
    that describes all the components of the application and the integration points
    between them. This is often referred to as the **application manifest**—a document
    that lists all the parts of your app. In the same way that the Dockerfile explicitly
    defines the steps to install and configure one piece of software, the Docker Compose
    file explicitly defines the steps to deploy the whole solution.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当您在Docker Compose中定义应用程序时，您有一个描述应用程序所有组件和它们之间集成点的单个工件。这通常被称为**应用程序清单**，它是列出应用程序所有部分的文档。就像Dockerfile明确定义了安装和配置软件的步骤一样，Docker
    Compose文件明确定义了部署整个解决方案的步骤。
- en: Docker Compose also lets you capture application definitions that can be deployed
    to different environments, so your Compose files are usable throughout the deployment
    pipeline. Usually, there are differences between environments, either in the infrastructure
    setup or the application settings. Docker Compose gives you two options to manage
    these environmental differences—using external resources, or using override files.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose还允许您捕获可以部署到不同环境的应用程序定义，因此您的Compose文件可以在整个部署流程中使用。通常，环境之间存在差异，无论是在基础设施设置还是应用程序设置方面。Docker
    Compose为您提供了两种选项来管理这些环境差异——使用外部资源或使用覆盖文件。
- en: Infrastructure typically differs between production and non-production environments,
    which affects volumes and networks in Docker applications. On a development laptop,
    your database volume may be mapped to a known location on the local disk, which
    you periodically clean up. In production, you could have a volume plugin for a
    shared storage hardware device. Similarly, with networks, production environments
    may need to be explicit about subnet ranges, which are not a concern in development.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施通常在生产和非生产环境之间有所不同，这影响了Docker应用程序中的卷和网络。在开发笔记本电脑上，您的数据库卷可能映射到本地磁盘上的已知位置，您会定期清理它。在生产环境中，您可以为共享存储硬件设备使用卷插件。同样，对于网络，生产环境可能需要明确指定子网范围，而这在开发中并不是一个问题。
- en: Docker Compose lets you specify resources as being external to the Compose file,
    so the application will use resources that already exist. These resources need
    to be created in advance, but that means each environment can be configured differently
    and still use the same Compose file.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose允许您将资源指定为Compose文件之外的资源，因此应用程序将使用已经存在的资源。这些资源需要事先创建，但这意味着每个环境可以被不同配置，但仍然使用相同的Compose文件。
- en: Compose also supports an alternative approach, where you explicitly capture
    the configuration of your resources for each environment in different Compose
    files and use multiple Compose files when you run the application. I'll demonstrate
    both of these options. As with other design decisions, Docker doesn't impose specific
    practices, and you can use whichever best suits your processes.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Compose还支持另一种方法，即在不同的Compose文件中明确捕获每个环境的资源配置，并在运行应用程序时使用多个Compose文件。我将演示这两种选项。与其他设计决策一样，Docker不会强加特定的实践，您可以使用最适合您流程的任何方法。
- en: Specifying external resources
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指定外部资源
- en: Volume and network definitions in the Compose file follow the same pattern as
    service definitions—each resource is named and can be configured using the same
    options available in the relevant `docker ... create` command. There's an extra
    option in Compose files to point to an existing resource.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Compose文件中的卷和网络定义遵循与服务定义相同的模式——每个资源都有名称，并且可以使用与相关的`docker ... create`命令中可用的相同选项进行配置。Compose文件中有一个额外的选项，可以指向现有资源。
- en: 'To use existing volumes for my SQL Server and Elasticsearch data, I need to
    specify the `external` attribute and optionally, a name for the resource. In the
    `ch06-docker-compose-external` directory, my Docker Compose file has these volume
    definitions:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用现有卷来存储我的SQL Server和Elasticsearch数据，我需要指定`external`属性，以及可选的资源名称。在`ch06-docker-compose-external`目录中，我的Docker
    Compose文件具有这些卷定义：
- en: '[PRE33]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'With external resources declared, I can''t just run the application using `docker-compose
    up`. Compose won''t create volumes defined as external; they need to exist before
    the application starts. And these volumes are required by services, so Docker
    Compose won''t create any containers either. Instead, you''ll see an error message:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 声明外部资源后，我不能只使用`docker-compose up`来运行应用程序。Compose不会创建定义为外部的卷；它们需要在应用程序启动之前存在。而且这些卷是服务所必需的，因此Docker
    Compose也不会创建任何容器。相反，您会看到一个错误消息：
- en: '[PRE34]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'The error message tells you the command you need to run to create the missing
    resource. This will create basic volumes with default configurations, and that
    will allow Docker Compose to start the application:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 错误消息告诉您需要运行的命令来创建缺失的资源。这将使用默认配置创建基本卷，这将允许Docker Compose启动应用程序：
- en: '[PRE35]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Docker lets you create volumes with different configuration options, so you
    can specify an explicit mount point—such as a RAID array or an NFS share. Windows
    doesn't support options for the local driver currently, but you can use mapped
    drives as a workaround. There are drivers for other types of storage—using volume
    plugins for cloud services, such as Azure storage, and enterprise storage units,
    such as HPE 3PAR.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Docker允许您使用不同的配置选项创建卷，因此您可以指定显式的挂载点，例如RAID阵列或NFS共享。Windows目前不支持本地驱动器的选项，但您可以使用映射驱动器作为解决方法。还有其他类型存储的驱动程序——使用云服务的卷插件，例如Azure存储，以及企业存储单元，例如HPE
    3PAR。
- en: 'The same approach can be used to specify networks as external resources. In
    my Compose file, I initially used the default `nat` network, but in this Compose
    file, I specify a custom external network for the application:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用相同的方法来指定网络作为外部资源。在我的Compose文件中，我最初使用默认的`nat`网络，但在这个Compose文件中，我为应用程序指定了一个自定义的外部网络：
- en: '[PRE36]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Docker on Windows has several networking options. The default, and the easiest,
    is network address translation, with the `nat` network. This driver isolates containers
    from the physical network, and each container gets its own IP address in a subnet
    managed by Docker. On the host, you can access containers by their IP address,
    but outside the host, you can only access containers through published ports.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Windows上的Docker有几个网络选项。默认和最简单的是网络地址转换，使用`nat`网络。这个驱动器将容器与物理网络隔离，每个容器在Docker管理的子网中都有自己的IP地址。在主机上，您可以通过它们的IP地址访问容器，但在主机外部，您只能通过发布的端口访问容器。
- en: 'You can create other networks with the `nat` driver, or you can also use other
    drivers for different network configurations:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`nat`驱动程序创建其他网络，或者您还可以使用其他驱动程序进行不同的网络配置：
- en: The `transparent` driver, which gives each container an IP address provided
    by the physical router
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`transparent`驱动器，为每个容器提供物理路由器提供的IP地址'
- en: The `l2bridge` driver, which is for specifying static container IP addresses
    on the physical network
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l2bridge`驱动器，用于在物理网络上指定静态容器IP地址'
- en: The `overlay` driver, which is for running distributed applications in Docker
    Swarm
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`overlay`驱动器，用于在Docker Swarm中运行分布式应用程序'
- en: 'For my setup with Traefik on a single server, `nat` is the best option, so
    I''ll create a custom network for my application:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我在单个服务器上使用Traefik的设置，`nat`是最佳选项，因此我将为我的应用程序创建一个自定义网络：
- en: '[PRE37]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: When the containers start, I can access Traefik using the `nerddinner.local`
    domains I have set up in my `hosts` file.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器启动时，我可以使用我在`hosts`文件中设置的`nerddinner.local`域来访问Traefik。
- en: Using external resources lets you have a single Docker Compose file, which is
    used for every environment, with the actual implementation of the network and
    volume resources different between environments. Developers can use basic storage
    and networking options, and in production, the ops team can deploy a more complex
    infrastructure.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用外部资源可以让您拥有一个单一的Docker Compose文件，该文件用于每个环境，网络和卷资源的实际实现在不同环境之间有所不同。开发人员可以使用基本的存储和网络选项，在生产环境中，运维团队可以部署更复杂的基础设施。
- en: Using Docker Compose overrides
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker Compose覆盖
- en: Resources aren't the only things that change between environments, though. You
    will also have different configuration settings, different ports being published,
    different setups for your container health checks, and more. It can be tempting
    to have completely different Docker Compose files for each environment, but that's
    something you should try hard to avoid.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 资源并不是环境之间唯一变化的东西。您还将有不同的配置设置，不同的发布端口，不同的容器健康检查设置等。对于每个环境拥有完全不同的Docker Compose文件可能很诱人，但这是您应该努力避免的事情。
- en: Having multiple Compose files means additional overhead to keep them in sync—and,
    more importantly, there's a risk of environments drifting if they aren't kept
    in sync. Using Docker Compose overrides addresses this and means your requirements
    for each environment are explicitly stated.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有多个Compose文件意味着额外的开销来保持它们同步 - 更重要的是，如果它们不保持同步，环境漂移的风险。使用Docker Compose覆盖可以解决这个问题，并且意味着每个环境的要求都是明确说明的。
- en: Docker Compose looks for files called `docker-compose.yml` and `docker-compose.override.yml`
    by default, and if it finds both, it will use the override file to add to or replace
    parts of the definitions in the main Docker Compose file. When you run the Docker
    Compose CLI, you can pass additional files to be combined for the whole application
    specification. This lets you keep the core solution definition in one file and
    have explicit environment-dependent overrides in other files.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose默认寻找名为`docker-compose.yml`和`docker-compose.override.yml`的文件，如果两者都找到，它将使用覆盖文件来添加或替换主Docker
    Compose文件中的定义的部分。当您运行Docker Compose CLI时，可以传递其他文件以组合整个应用程序规范。这使您可以将核心解决方案定义保存在一个文件中，并在其他文件中具有明确的环境相关覆盖。
- en: 'In the `ch06-docker-compose-override` folder, I''ve taken this approach. The
    core `docker-compose.yml` file has the service definitions that describe the structure
    of the solution and the environment configuration to run in development. There
    are three override files in the same folder:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在`ch06-docker-compose-override`文件夹中，我采取了这种方法。核心的`docker-compose.yml`文件包含了描述解决方案结构和运行开发环境的环境配置的服务定义。在同一个文件夹中有三个覆盖文件：
- en: '`docker-compose.test.yml`  adds configuration settings for the test environment.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker-compose.test.yml`添加了用于测试环境的配置设置。'
- en: '`docker-compose.production.ym` adds configuration settings for the live environment.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker-compose.production.yml`添加了用于生产环境的配置设置。'
- en: '`docker-compose.build.yml` adds configuration settings for building the images.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docker-compose.build.yml`添加了用于构建图像的配置设置。'
- en: The standard `docker-compose.yml` file can be used on its own, and it will just
    work. This is important to make sure that your deployment process doesn't make
    life difficult for developers. Specifying the development settings in the main
    file means developers can just run `docker-compose up -d`, as they don't need
    to know anything about the overrides to get started.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的`docker-compose.yml`文件可以单独使用，它会正常工作。这很重要，以确保部署过程不会给开发人员带来困难。在主文件中指定开发设置意味着开发人员只需运行`docker-compose
    up -d`，因为他们不需要了解任何关于覆盖的信息就可以开始工作。
- en: 'This is the reverse proxy configuration in  `docker-compose.yml`, and it''s
    set up to publish random ports and to start the Traefik dashboard:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`docker-compose.yml`中的反向代理配置，并且设置为发布随机端口并启动Traefik仪表板：
- en: '[PRE38]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'This is useful for developers who may be using port `80` for other apps, and
    who want to dig into the dashboard to see Traefik''s routing rules. The `test`
    override file changes the port definition to use `80` and `8080` on the host server,
    but the dashboard is still exposed, so the command section is unchanged:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于可能正在为其他应用程序使用端口`80`的开发人员以及希望深入了解仪表板以查看Traefik的路由规则的开发人员非常有用。`test`覆盖文件将端口定义更改为在主机服务器上使用`80`和`8080`，但仪表板仍然暴露，因此命令部分保持不变：
- en: '[PRE39]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `production` override changes the startup command, removing the `--api`
    flag in the command, so the dashboard doesn''t run, and it only publishes port
    `80`:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`production`覆盖更改了启动命令，删除了命令中的`--api`标志，因此仪表板不会运行，它只发布端口`80`：'
- en: '[PRE40]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The rest of the service configuration, the image to use, the volume mount for
    the Docker Engine-named pipe and the network to connect to are the same in every
    environment, so the override files don't need to specify them.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 服务配置的其余部分，要使用的图像，Docker Engine命名管道的卷挂载和要连接的网络在每个环境中都是相同的，因此覆盖文件不需要指定它们。
- en: 'Another example is the new home page, which contains the domain name for the
    URL in the Traefik labels for the service. That''s environment-specific, and in
    the development Docker Compose file, it''s set to use `nerddinner.local`:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子是新的主页，其中包含了Traefik标签中的URL的域名。这是特定于环境的，在开发Docker Compose文件中，它被设置为使用`nerddinner.local`：
- en: '[PRE41]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'In the `test` override file, the domain is `nerd-dinner.test`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在`test`覆盖文件中，域是`nerd-dinner.test`：
- en: '[PRE42]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In production, it''s `nerd-dinner.com`:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产中，是`nerd-dinner.com`：
- en: '[PRE43]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The rest of the configuration is the same in every environment, so the override
    files only specify the new labels.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个环境中，其余配置都是相同的，因此覆盖文件只指定新标签。
- en: Docker Compose doesn't merge the contents of a list when it adds the override;
    the new list replaces the old list completely. That's why the `traefik.frontend.priority`
    label is there in every file, so you can't just have the frontend rule value in
    the labels in the override file, because the priority value wouldn't be merged
    in from the labels in the main file.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose在添加覆盖时不会合并列表的内容；新列表完全替换旧列表。这就是为什么每个文件中都有`traefik.frontend.priority`标签，因此您不能只在覆盖文件中的标签中有前端规则值，因为优先级值不会从主文件中的标签中合并过来。
- en: 'There are other differences in the test environment that are captured in the
    override file:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在覆盖文件中捕获了测试环境中的其他差异：
- en: The SQL Server and Elasticsearch ports are published, to help troubleshooting.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL Server和Elasticsearch端口被发布，以帮助故障排除。
- en: The volumes for the databases are mounted from paths on the `E:` drive, which
    is a RAID array on the server.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库的卷从服务器上的`E:`驱动器上的路径挂载，这是服务器上的RAID阵列。
- en: The Traefik rules all use the `nerd-dinner.test` domain.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Traefik规则都使用`nerd-dinner.test`域。
- en: The application network is specified as external, to allow admins to create
    their own network configuration.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序网络被指定为外部，以允许管理员创建他们自己的网络配置。
- en: 'These are different again in the production override file:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 这些在生产覆盖文件中又有所不同：
- en: The SQL Server and Elasticsearch ports are not published, to keep them as private
    components.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SQL Server和Elasticsearch端口不被发布，以保持它们作为私有组件。
- en: The volumes for the databases are specified as external, so admins can configure
    their own storage.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库的卷被指定为外部，因此管理员可以配置他们自己的存储。
- en: The Traefik rules all use the `nerd-dinner.com` domain.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Traefik规则都使用`nerd-dinner.com`域。
- en: The application network is specified as external, to allow admins to create
    their own network configuration.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序网络被指定为外部，允许管理员创建他们自己的网络配置。
- en: 'Deployment to any environment is as simple as running `docker-compose up`,
    specifying the override file to use:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 部署到任何环境都可以简单地运行`docker-compose up`，指定要使用的覆盖文件：
- en: '[PRE44]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: This approach is a great way to keep your Docker Compose files simple, and to
    capture all the variable environment settings in separate files. You can even
    combine several Docker Compose files. If you have multiple test environments that
    share a lot of commonality, you can define the application setup in the base Compose
    file, shared test configuration in one override file, and each specific test environment
    in an additional override file.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法是保持Docker Compose文件简单的好方法，并在单独的文件中捕获所有可变环境设置。甚至可以组合几个Docker Compose文件。如果有多个共享许多共同点的测试环境，可以在基本Compose文件中定义应用程序设置，在一个覆盖文件中共享测试配置，并在另一个覆盖文件中定义每个特定的测试环境。
- en: Summary
  id: totrans-247
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter I covered Docker Compose, the tool used to organize distributed
    Docker solutions. With Compose, you explicitly define all the components of your
    solution, the configuration of the components, and the relationship between them
    in a simple, clean format.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我介绍了Docker Compose，这是用于组织分布式Docker解决方案的工具。使用Compose，您可以明确定义解决方案的所有组件、组件的配置以及它们之间的关系，格式简单、清晰。
- en: The Compose file lets you manage all the application containers as a single
    unit. You learned in this chapter how you can use the `docker-compose` command
    line to spin up and tear down the application, creating all the resources and
    starting or stopping containers. You also learned that you can use Docker Compose
    to scale components up or down and to release upgrades to your solution.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: Compose文件让您将所有应用程序容器作为单个单元进行管理。您在本章中学习了如何使用`docker-compose`命令行来启动和关闭应用程序，创建所有资源并启动或停止容器。您还了解到，您可以使用Docker
    Compose来扩展组件或发布升级到您的解决方案。
- en: Docker Compose is a powerful tool for defining complex solutions. The Compose
    file effectively replaces lengthy deployment documents and fully describes every
    part of the application. With external resources and Compose overrides, you can
    even capture the differences between environments and build a set of YAML files
    that you can use to drive your whole deployment pipeline.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose是定义复杂解决方案的强大工具。Compose文件有效地取代了冗长的部署文档，并完全描述了应用程序的每个部分。通过外部资源和Compose覆盖，甚至可以捕获环境之间的差异，并构建一组YAML文件，用于驱动整个部署流水线。
- en: The limitation of Docker Compose is that it's a client-side tool. The `docker-compose`
    command needs access to the Compose file to execute any commands. There is a logical
    grouping of resources into a single application, but that happens only in the
    Compose file. The Docker engine only sees a set of resources; it does not recognize
    them as being part of the same application. Docker Compose is also limited to
    single-node Docker deployments.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose的局限性在于它是一个客户端工具。`docker-compose`命令需要访问Compose文件来执行任何命令。资源被逻辑地分组成一个单一的应用程序，但这只发生在Compose文件中。Docker引擎只看到一组资源；它不认为它们是同一个应用程序的一部分。Docker
    Compose也仅限于单节点Docker部署。
- en: In the next chapter, I'll move on to clustered Docker deployments, with multiple
    nodes running in a Docker Swarm. In a production environment, this gives you high
    availability and scale. Docker Swarm is a powerful orchestrator for container
    solutions, and it is very easy to use. It also supports the Compose file format,
    so you can use your existing Compose files to deploy applications, but Docker
    stores the logical architecture within the swarm, allowing you to manage your
    application without needing the Compose file.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我将继续讲解集群化的Docker部署，多个节点在Docker Swarm中运行。在生产环境中，这为您提供了高可用性和可扩展性。Docker
    Swarm是容器解决方案的强大编排器，非常易于使用。它还支持Compose文件格式，因此您可以使用现有的Compose文件部署应用程序，但Docker将逻辑架构存储在Swarm中，无需Compose文件即可管理应用程序。
