- en: Docker Swarm in AWS
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS中的Docker Swarm
- en: Docker Swarm represents Docker's native container management platform that is
    built right into the Docker Engine, and for many people who are using Docker for
    the first time, Docker Swarm is the first container management platform that they
    read and learn about, given that it is an integrated feature of the Docker Engine.
    Docker Swarm is naturally a competitor to the ECS, Fargate, Elastic Beanstalk,
    and recent Elastic Kubernetes Service (EKS) offerings supported by AWS, so you
    might be wondering why a book on Docker in AWS would have a chapter dedicated
    to Docker Swarm. Many organizations prefer to use cloud-agnostic container management
    platforms that they can run on AWS, other cloud providers such as Google Cloud
    and Azure, as well as on premises, and if this is the case for you and your organization,
    then Docker Swarm is certainly an option worth considering.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm代表了Docker的本机容器管理平台，直接内置到Docker Engine中，对于许多第一次使用Docker的人来说，Docker
    Swarm是他们首次了解和学习的容器管理平台，因为它是Docker Engine的集成功能。Docker Swarm自然是AWS支持的ECS、Fargate、弹性Beanstalk和最近的弹性Kubernetes服务（EKS）的竞争对手，因此您可能会想知道为什么一本关于AWS中的Docker的书会有一个专门介绍Docker
    Swarm的章节。许多组织更喜欢使用与云提供商无关的容器管理平台，可以在AWS、谷歌云和Azure等其他云提供商以及本地运行，如果这对您和您的组织是这种情况，那么Docker
    Swarm肯定是值得考虑的选项。
- en: In this chapter, you will learn how to deploy Docker Swarm to AWS using the
    Docker for AWS solution that makes it very easy to get a Docker Swarm cluster
    up and running in AWS. You will learn the basics of how to manage and access your
    Swarm cluster, how to create and deploy services to Docker Swarm, and how to leverage
    a number of AWS services that are integrated with Swarm in the Docker for AWS
    solution. This will include integrating Docker Swarm with the Elastic Container
    Registry (ECR), publishing your application to the outside world by integrating
    with AWS Elastic Load Balancing (ELB), creating shared volumes using the AWS Elastic
    File System (EFS), and creating persistent volumes using the AWS Elastic Block
    Store (EBS).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何使用Docker for AWS解决方案将Docker Swarm部署到AWS，该解决方案使得在AWS上快速启动和运行Docker
    Swarm集群变得非常容易。您将学习如何管理和访问Swarm集群的基础知识，如何创建和部署服务到Docker Swarm，以及如何利用与Docker for
    AWS解决方案集成的许多AWS服务。这将包括将Docker Swarm与弹性容器注册表（ECR）集成，通过与AWS弹性负载均衡（ELB）集成将应用程序发布到外部世界，使用AWS弹性文件系统（EFS）创建共享卷，以及使用AWS弹性块存储（EBS）创建持久卷。
- en: Finally, you will learn how to address key operational challenges, including
    running one-shot deployment tasks, performing secrets management using Docker
    secrets, and deploying your application using rolling updates. By the end of this
    chapter, you will know how to deploy a Docker Swarm cluster to AWS, how to integrate
    Docker Swarm with AWS services, and how to deploy your production applications
    to Docker Swarm.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将学习如何解决关键的运营挑战，包括运行一次性部署任务，使用Docker secrets进行秘密管理，以及使用滚动更新部署应用程序。通过本章的学习，您将了解如何将Docker
    Swarm集群部署到AWS，如何将Docker Swarm与AWS服务集成，以及如何将生产应用程序部署到Docker Swarm。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introduction to Docker Swarm
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Swarm简介
- en: Installing Docker for AWS
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Docker for AWS
- en: Accessing Docker Swarm
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问Docker Swarm
- en: Deploying Docker services to Docker Swarm
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Docker服务部署到Docker Swarm
- en: Deploying Docker stacks to Docker Swarm
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Docker堆栈部署到Docker Swarm
- en: Integrating Docker Swarm with the ECR
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Docker Swarm与ECR集成
- en: Creating shared Docker volumes using EFS
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用EFS创建共享Docker卷
- en: Creating persistent Docker volumes using EBS
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用EBS创建持久Docker卷
- en: Supporting one-shot deployment tasks
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持一次性部署任务
- en: Performing rolling updates
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行滚动更新
- en: Technical requirements
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following are the technical requirements for this chapter:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是本章的技术要求：
- en: Administrative access to an AWS account
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对AWS账户的管理访问权限
- en: Local environment configured as per the instructions in Chapter 1
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地环境按照第1章的说明进行配置
- en: A local AWS profile, configured as per the instructions in Chapter 3
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地AWS配置文件，按照第3章的说明进行配置
- en: AWS CLI version 1.15.71 or higher
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI版本1.15.71或更高版本
- en: Docker 18.06 CE or higher
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 18.06 CE或更高版本
- en: Docker Compose 1.22 or higher
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose 1.22或更高版本
- en: GNU Make 3.82 or higher
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GNU Make 3.82或更高版本
- en: This chapter assumes that you have completed all of the preceding chapters in
    this book
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本章假定您已经完成了本书中的所有前一章节
- en: The following GitHub URL contains the code samples that are used in this chapter: [https://github.com/docker-in-aws/docker-in-aws/tree/master/ch16](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch16).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下GitHub URL包含本章中使用的代码示例：[https://github.com/docker-in-aws/docker-in-aws/tree/master/ch16](https://github.com/docker-in-aws/docker-in-aws/tree/master/ch16)。
- en: 'Check out the following video to see the Code in Action:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下视频以查看代码的实际操作：
- en: '[http://bit.ly/2ogdBpp](http://bit.ly/2ogdBpp)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[http://bit.ly/2ogdBpp](http://bit.ly/2ogdBpp)'
- en: Docker Swarm introduction
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm介绍
- en: '**Docker Swarm** is a native integrated feature of the Docker Engine, providing
    cluster management and container orchestration features that allow you to run
    Docker containers at scale in production. Every Docker Engine running version
    1.13 or greater includes the ability to operate in swarm mode, which provides
    the following features:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker Swarm**是Docker Engine的一个本地集成功能，提供集群管理和容器编排功能，允许您在生产环境中规模化运行Docker容器。每个运行版本1.13或更高版本的Docker
    Engine都包括在swarm模式下运行的能力，提供以下功能：'
- en: '**Cluster management**: All nodes operating in swarm mode include native cluster
    features that allow you to quickly establish clusters that you can deploy your
    applications to.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群管理**：所有在swarm模式下运行的节点都包括本地集群功能，允许您快速建立集群，以便部署您的应用程序。'
- en: '**Multi-host networking**: Docker supports overlay networking that allows you
    to create virtual networks over which all containers attached to the network can
    communicate privately. This networking layer is completely independent of the
    physical networking topology that connects your Docker Engines, meaning you typically
    don''t have to worry about traditional networking constraints such as IP addressing
    and network segmentation—Docker takes care of all of this for you.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多主机网络**：Docker支持覆盖网络，允许您创建虚拟网络，所有连接到网络的容器可以私下通信。这个网络层完全独立于连接Docker Engines的物理网络拓扑，这意味着您通常不必担心传统的网络约束，比如IP地址和网络分割——Docker会为您处理所有这些。'
- en: '**Service discovery and load balancing**: Docker Swarm supports a simple service
    discovery model based upon DNS that allows your applications to discover each
    other without requiring complex service discovery protocols or infrastructure.
    Docker Swarm also supports automatic load balancing of traffic to your applications
    using DNS round robin, and can integrate with an external load balancer such as
    the AWS Elastic Load Balancer service.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务发现和负载均衡**：Docker Swarm支持基于DNS的简单服务发现模型，允许您的应用程序发现彼此，而无需复杂的服务发现协议或基础设施。Docker
    Swarm还支持使用DNS轮询自动负载均衡流量到您的应用程序，并可以集成外部负载均衡器，如AWS Elastic Load Balancer服务。'
- en: '**Service scaling and rolling updates**: You can easily scale your services
    up and down, and when it''s time to update your services, Docker supports intelligent
    rolling update features with support for rollbacks in the event of a deployment
    failure.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务扩展和滚动更新**：您可以轻松地扩展和缩小您的服务，当需要更新您的服务时，Docker支持智能的滚动更新功能，并在部署失败时支持回滚。'
- en: '**Declarative service model**: Docker Swarm uses the popular Docker Compose
    specification to declaratively define application services, networks, volumes,
    and more in an easy to understand and maintained format.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 声明式服务模型：Docker Swarm使用流行的Docker Compose规范来声明性地定义应用程序服务、网络、卷等，以易于理解和维护的格式。
- en: '**Desired state**: Docker Swarm continuously monitors application and runtime
    state, ensuring that your services are operating in accordance with the desired
    state you have configured. For example, if you configure a service with an instance
    or replica count of 2, Docker Swarm will always try and maintain this count and
    automatically deploy new replicas to a new node when an existing node fails.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**期望状态**：Docker Swarm持续监视应用程序和运行时状态，确保您配置的服务按照期望的状态运行。例如，如果您配置一个具有2个实例或副本计数的服务，Docker
    Swarm将始终尝试维持这个计数，并在现有节点失败时自动部署新的副本到新节点。'
- en: '**Production-grade operational features such as secrets and configuration management**:
    Some features such as Docker secrets and Docker configurations are exclusive to
    Docker Swarm, and provide solutions for real-world production issues such as the
    ability to securely distribute secrets and configuration data to your applications.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**生产级运维功能，如秘密和配置管理**：一些功能，如Docker秘密和Docker配置，是Docker Swarm独有的，并为实际的生产问题提供解决方案，例如安全地将秘密和配置数据分发给您的应用程序。'
- en: When it comes to running Docker Swarm on AWS, Docker provides a community edition
    offering referred to as Docker for AWS CE, which you can find further information
    about at [https://store.docker.com/editions/community/docker-ce-aws](https://store.docker.com/editions/community/docker-ce-aws).
    At present, Docker for AWS CE is deployed via a pre-defined CloudFormation template
    that integrates Docker Swarm with a number of AWS services, including EC2 Auto
    Scaling, Elastic Load Balancing, Elastic File System, and Elastic Block Store.
    As you will soon see, this makes it very easy to stand up a new Docker Swarm cluster
    in AWS.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上运行Docker Swarm时，Docker提供了一个名为Docker for AWS CE的社区版产品，您可以在[https://store.docker.com/editions/community/docker-ce-aws](https://store.docker.com/editions/community/docker-ce-aws)找到更多信息。目前，Docker
    for AWS CE是通过预定义的CloudFormation模板部署的，该模板将Docker Swarm与许多AWS服务集成在一起，包括EC2自动扩展、弹性负载均衡、弹性文件系统和弹性块存储。很快您将会看到，这使得在AWS上快速搭建一个新的Docker
    Swarm集群变得非常容易。
- en: Docker Swarm versus Kubernetes
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker Swarm与Kubernetes的比较
- en: First and foremost, as evidenced by the majority of the content of this book,
    I am an ECS guy, and if you are running your container workloads exclusively on
    AWS, my recommendation, at least at the time of the writing of this book, is almost
    always going to be ECS. However, many organizations don't want to be locked into
    AWS and want a cloud agnostic approach, and this is where Docker Swarm is one
    of the leading solutions available at present.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，正如本书的大部分内容所证明的那样，我是一个ECS专家，如果您的容器工作负载完全在AWS上运行，那么我的建议，至少在撰写本书时，几乎总是会选择ECS。然而，许多组织不想被锁定在AWS上，他们希望采用云无关的方法，这就是Docker
    Swarm目前是其中一种领先的解决方案的原因。
- en: Right now, Docker Swarm competes head-on with Kubernetes, which we will discuss
    in the next chapter. It's fair to say that Kubernetes looks to have established
    itself as the leading cloud agnostic container management platform of choice,
    but that doesn't mean you should necessarily overlook Docker Swarm.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，Docker Swarm与Kubernetes直接竞争，我们将在下一章讨论。可以说，Kubernetes似乎已经确立了自己作为首选的云无关容器管理平台，但这并不意味着您一定要忽视Docker
    Swarm。
- en: In general, I personally find Docker Swarm easier to set up and use, and a key
    benefit for me at least, is that it uses familiar tools such as Docker Compose,
    which means you can get up and running very quickly, especially if you have used
    these tools previously. For smaller organizations that just want to get up and
    running fast and ensure that things just work with minimal fuss, Docker Swarm
    is an attractive choice. The Docker for AWS solution makes it very easy to establish
    a Docker Swarm cluster in AWS, although AWS recently made Kubernetes a whole lot
    easier on AWS with the launch of the Elastic Kubernetes Service (EKS)—more on
    this in the next chapter.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我个人认为Docker Swarm更容易设置和使用，至少对我来说，一个关键的好处是它使用熟悉的工具，比如Docker Compose，这意味着你可以非常快速地启动和运行，特别是如果你之前使用过这些工具。对于只想快速启动并确保事情顺利进行的较小组织来说，Docker
    Swarm是一个有吸引力的选择。Docker for AWS解决方案使在AWS中建立Docker Swarm集群变得非常容易，尽管AWS最近通过推出弹性Kubernetes服务（EKS）大大简化了在AWS上使用Kubernetes的过程——关于这一点，我们将在下一章中详细介绍。
- en: Ultimately, I encourage you to try out both with an open mind and make your
    own decisions as to what container management platform works best for you and
    your organization's goals.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我鼓励你以开放的心态尝试两者，并根据你和你的组织目标的最佳容器管理平台做出自己的决定。
- en: Installing Docker for AWS
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Docker for AWS
- en: The recommended and fastest way to get Docker Swarm up and running in AWS is
    to use Docker for AWS, which you can read more about at [https://docs.docker.com/docker-for-aws/](https://docs.docker.com/docker-for-aws/).
    If you browse to this page, in the Setup & prerequisites section, you will be
    presented with links that allow you to install both Docker Enterprise Edition
    (EE) and Docker Community Edition (CE) for AWS.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS中快速启动Docker Swarm的推荐方法是使用Docker for AWS，你可以在[https://docs.docker.com/docker-for-aws/](https://docs.docker.com/docker-for-aws/)上了解更多。如果你浏览到这个页面，在设置和先决条件部分，你将看到允许你安装Docker企业版（EE）和Docker社区版（CE）for
    AWS的链接。
- en: 'We will be using the free Docker CE for AWS (stable) variant, and notice that
    you can choose to deploy to a brand new VPC or to an existing VPC:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用免费的Docker CE for AWS（稳定版），请注意你可以选择部署到全新的VPC或现有的VPC：
- en: '![](assets/b3c18990-a854-4275-925f-e86d1f0410e2.png)Selecting a Docker CE for
    AWS option'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/b3c18990-a854-4275-925f-e86d1f0410e2.png)选择Docker CE for AWS选项'
- en: 'Given, we already have an existing VPC, if you click on the Deploy Docker CE
    for AWS (stable) users your existing VPC option, you will be redirected to the
    AWS CloudFormation console, where you are prompted to create a new stack from
    a template published by Docker:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于我们已经有一个现有的VPC，如果你点击部署Docker CE for AWS（稳定版）用户现有的VPC选项，你将被重定向到AWS CloudFormation控制台，在那里你将被提示使用Docker发布的模板创建一个新的堆栈：
- en: '![](assets/5df1c0f5-b40b-442c-9b7b-2c67dea80f12.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/5df1c0f5-b40b-442c-9b7b-2c67dea80f12.png)'
- en: Creating a Docker for AWS stack
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Docker for AWS堆栈
- en: 'After clicking Next, you will be prompted to specify a number of parameters
    that control the configuration of your Docker Swarm Docker installation. I won''t
    describe all of the options available, so assume that you should leave the default
    configuration for any parameters that I do not mention here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 点击下一步后，你将被提示指定一些参数，这些参数控制了你的Docker Swarm Docker安装的配置。我不会描述所有可用的选项，所以假设对于我没有提到的任何参数，你应该保留默认配置。
- en: '**Stack name**: Specify an appropriate name for your stack — for example docker-swarm.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆栈名称**：为你的堆栈指定一个合适的名称，例如docker-swarm。'
- en: '**Swarm Size**: Here, you can specify the number of Swarm managers and worker
    nodes. At a minimum, you can specify just one manager, however I recommend also
    configuring a worker node so that you can test deploying your applications to
    a multi-node Swarm cluster.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Swarm Size**: 在这里，您可以指定Swarm管理器和工作节点的数量。最少可以指定一个管理器，但我建议还配置一个工作节点，以便您可以测试将应用程序部署到多节点Swarm集群。'
- en: '**Swarm Properties**: Here, you should configure the Swarm EC2 instances to
    use your existing admin SSH key (EC2 key pair) and also enable the Create EFS
    prerequisites for Store property, as we will use EFS to provide a shared volume
    later on in this chapter.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Swarm Properties**: 在这里，您应该配置Swarm EC2实例以使用您现有的管理员SSH密钥（EC2密钥对），并启用创建EFS存储属性的先决条件，因为我们将在本章后面使用EFS提供共享卷。'
- en: '**Swarm Manager Properties**: Change the Manager ephemeral storage volume type
    to gp2 (SSD).'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Swarm Manager Properties**: 将Manager临时存储卷类型更改为gp2（SSD）。'
- en: '**Swarm Worker Properties**: Change the Worker ephemeral storage volume type
    to gp2 (SSD).'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Swarm Worker Properties**: 将工作节点临时存储卷类型更改为gp2（SSD）。'
- en: '**VPC/Network**: Select your existing default VPC and then ensure that you
    specify the VPC CIDR Range that is displayed when you select the VPC (for example,
    `172.31.0.0/16`), and then select appropriate subnets from your default VPC for
    Public Subnets 1 through 3.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VPC/网络**: 选择现有的默认VPC，然后确保您指定选择VPC时显示的VPC CIDR范围（例如`172.31.0.0/16`），然后从默认VPC中选择适当的子网作为公共子网1至3。'
- en: After completing the preceding configuration, click on the Next button twice,
    and finally on the Review screen, select the I acknowledge that AWS CloudFormation
    might create IAM resources option and then click on the Create button.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 完成上述配置后，点击两次“下一步”按钮，最后在“审阅”屏幕上，选择“我承认AWS CloudFormation可能创建IAM资源”选项，然后点击“创建”按钮。
- en: At this point, your new CloudFormation stack will be created, and should be
    complete within 10-15 minutes. Note that if you ever want to increase the number
    of managers and/or worker nodes in your cluster, the recommended way to do this
    is to perform a CloudFormation stack update, modifying the appropriate input parameters
    that define manager and worker count. Also, to upgrade Docker for AWS Swarm Cluster,
    you should apply the latest CloudFormation template that includes updates to Docker
    Swarm and various other resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您的新CloudFormation堆栈将被创建，并且应在10-15分钟内完成。请注意，如果您想要增加集群中的管理器和/或工作节点数量，建议的方法是执行CloudFormation堆栈更新，修改定义管理器和工作节点计数的适当输入参数。另外，要升级Docker
    for AWS Swarm Cluster，您应该应用包含Docker Swarm和其他各种资源更新的最新CloudFormation模板。
- en: Resources created by the Docker for AWS CloudFormation stack
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 由Docker for AWS CloudFormation堆栈创建的资源
- en: 'If you review the Resources tab in the CloudFormation console for your new
    stack, you will notice a variety of resources are created, the most important
    of which are listed as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在CloudFormation控制台的新堆栈中查看资源选项卡，您将注意到创建了各种资源，其中最重要的资源列在下面：
- en: '**CloudWatch Logs Group**: This stores all logs for the container''s schedule
    via your Swarm cluster. This resource is only created if you enable the Use Cloudwatch
    for container logging parameter during stack creation (by default, this parameter
    is enabled).'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CloudWatch日志组**: 这存储了通过您的Swarm集群安排的所有容器日志。只有在堆栈创建期间启用了使用Cloudwatch进行容器日志记录参数时（默认情况下，此参数已启用），才会创建此资源。'
- en: '**External Load Balancer**: A classic Elastic Load Balancer is created, which
    is used to publish public access to your Docker applications.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部负载均衡器**: 创建了一个经典的弹性负载均衡器，用于发布对您的Docker应用程序的公共访问。'
- en: '**Elastic Container Registry IAM Policy**: An IAM policy is created and attached
    to all Swarm manager and worker EC2 instance roles that permit read/pull access
    to ECR. This is required if you store your Docker images in ECR, which is applicable
    to our scenario.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性容器注册表IAM策略**：创建了一个IAM策略，并附加到所有Swarm管理器和工作节点EC2实例角色，允许对ECR进行读取/拉取访问。如果您将Docker镜像存储在ECR中，这是必需的，适用于我们的场景。'
- en: '**Other resources**: A variety of resources are also created such as a DynamoDB
    table that is used for cluster management operations, and a Simple Queue Service
    (SQS) queue is used for EC2 auto-scaling life cycle hooks during Swarm manager
    upgrade scenarios.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**其他资源**：还创建了各种资源，例如用于集群管理操作的DynamoDB表，以及用于EC2自动扩展生命周期挂钩的简单队列服务（SQS）队列，用于Swarm管理器升级场景。'
- en: 'If you click on the Outputs tab, you will notice an output property called
    DefaultDNSTarget, which references the public URL of the external load balancer.
    Take note of this URL, as this is where the sample application will be accessible
    from later on in this chapter:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果单击“输出”选项卡，您会注意到一个名为DefaultDNSTarget的输出属性，它引用了外部负载均衡器的公共URL。请注意这个URL，因为稍后在本章中，示例应用将可以从这里访问：
- en: '![](assets/0b5dd42f-03a6-4ac0-ae85-7e7b9d625a70.png)Docker for AWS stack outputs'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/0b5dd42f-03a6-4ac0-ae85-7e7b9d625a70.png)Docker for AWS堆栈输出'
- en: Accessing the Swarm cluster
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问Swarm集群
- en: 'In the CloudFormation stack outputs, there is also a property called Managers,
    which provides a link to the EC2 instance(s) for each of the Swarm managers:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在CloudFormation堆栈输出中，还有一个名为Managers的属性，它提供了指向每个Swarm管理器的EC2实例的链接：
- en: '![](assets/12a015a1-5fcc-4756-abf3-d7312af16cac.png)Swarm Manager Auto Scaling
    group'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/12a015a1-5fcc-4756-abf3-d7312af16cac.png)Swarm Manager自动扩展组'
- en: 'You can use this information to obtain the public IP address or DNS name of
    one of your Swarm managers. Once you have this IP address, you can establish an
    SSH connection to the manager:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用这些信息来获取您的Swarm管理器之一的公共IP地址或DNS名称。一旦您有了这个IP地址，您就可以建立到管理器的SSH连接。
- en: '[PRE0]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Notice that you must specify a user name of `docker` when accessing the manager,
    and if you run the `docker ps` command, you can see that there are four system
    containers running on the manager by default:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，当访问管理器时，您必须指定一个用户名为`docker`，如果运行`docker ps`命令，您会看到默认情况下管理器上运行着四个系统容器：
- en: '**shell-aws**: This provides SSH access to the manager, meaning the SSH session
    that you establish to the Swarm manager is actually running *inside* this container.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**shell-aws**：这提供了对管理器的SSH访问，这意味着您建立到Swarm管理器的SSH会话实际上是在这个容器内运行的。'
- en: '**meta-aws**: Provides general metadata services, including providing tokens
    that allow new members to join the cluster.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**meta-aws**：提供通用的元数据服务，包括提供允许新成员加入集群的令牌。'
- en: '**guide-aws**: Performs cluster state management operations such as adding
    each manager to DynamoDB, and other housekeeping tasks such as cleaning up unused
    images and volumes and stopped containers.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**guide-aws**：执行集群状态管理操作，例如将每个管理器添加到DynamoDB，以及其他诸如清理未使用的镜像和卷以及停止的容器等日常任务。'
- en: '**l4controller-aws**: Manages integration with the external load balancer for
    the Swarm cluster. This component is responsible for publishing new ports and
    ensuring they are accessible on the elastic load balancer. Note that you should
    never modify the ELB for your cluster directly, and instead rely on the `l4controller-aws`
    component to manage the ELB.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**l4controller-aws**：管理与Swarm集群的外部负载均衡器的集成。该组件负责发布新端口，并确保它们可以在弹性负载均衡器上访问。请注意，您不应直接修改集群的ELB，而应依赖`l4controller-aws`组件来管理ELB。'
- en: 'To view and access the other nodes in your cluster, you can use the `docker
    node ls` command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看和访问集群中的其他节点，您可以使用`docker node ls`命令：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Note that worker nodes do not allow public SSH access, so you can only access
    worker nodes via SSH from a manager. There is a problem, however: you can''t establish
    an SSH session to the worker node, given that the manager node does not have the
    private key of the admin EC2 key pair stored locally.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，工作节点不允许公共SSH访问，因此您只能通过管理器从SSH访问工作节点。然而，有一个问题：鉴于管理节点没有本地存储管理员EC2密钥对的私钥，您无法建立与工作节点的SSH会话。
- en: Setting up local access to Docker Swarm
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置本地访问Docker Swarm
- en: Although you can run Docker commands remotely via an SSH session to a Swarm
    manager, it is much easier to be able to interact with the remote Swarm manager
    daemon using your local Docker client, where you have access to your local Docker
    service definitions and configurations. We also have the problem of not being
    able to access our worker nodes via SSH, and we can solve both of these problems by
    using a couple of techniques known as SSH agent forwarding and SSH tunneling.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以通过SSH会话远程运行Docker命令到Swarm管理器，但是能够使用本地Docker客户端与远程Swarm管理器守护程序进行交互要容易得多，在那里您可以访问本地Docker服务定义和配置。我们还有一个问题，即无法通过SSH访问工作节点，我们可以通过使用SSH代理转发和SSH隧道这两种技术来解决这两个问题。
- en: Configuring SSH agent forwarding
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置SSH代理转发
- en: 'To set up SSH agent forwarding, first add your admin SSH key to your local
    SSH agent using the `ssh-add` command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 设置SSH代理转发，首先使用`ssh-add`命令将您的管理员SSH密钥添加到本地SSH代理中：
- en: '[PRE2]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `-K` flag is specific to macOS and adds the passphrase for your SSH key
    to your OS X keychain, meaning that this configuration will persist across reboots.
    If you are not using macOS, you can just omit the `-K` flag.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`-K`标志是特定于macOS的，并将您的SSH密钥的密码添加到您的OS X钥匙串中，这意味着此配置将在重新启动后持续存在。如果您不使用macOS，可以省略`-K`标志。'
- en: 'You can now access your Swarm manager using the `-A` flag, which configures
    the SSH client to use your SSH agent identities. Using the SSH agent also enables
    SSH agent forwarding, which means that the SSH key used to establish your SSH
    session with the Swarm manager can be automatically used or forwarded for other
    SSH connections you might establish from within your SSH session:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用`-A`标志访问您的Swarm管理器，该标志配置SSH客户端使用您的SSH代理身份。使用SSH代理还可以启用SSH代理转发，这意味着用于与Swarm管理器建立SSH会话的SSH密钥可以自动用于或转发到您可能在SSH会话中建立的其他SSH连接：
- en: '[PRE3]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: As you can see, using SSH agent forwarding solves the issue of being able to
    access your worker nodes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，使用SSH代理转发解决了访问工作节点的问题。
- en: Configuring SSH tunneling
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置SSH隧道
- en: '**SSH tunneling** is a powerful technique that allows you to tunnel network
    communications securely over an encrypted SSH session to a remote host. SSH tunneling
    works by exposing a local socket or port that is wired to a remote socket or port
    on the remote host. This can provide the illusion that you are communicating with
    a local service, which is particularly useful when working with Docker.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**SSH隧道**是一种强大的技术，允许您通过加密的SSH会话安全地隧道网络通信到远程主机。 SSH隧道通过暴露一个本地套接字或端口，该套接字或端口连接到远程主机上的远程套接字或端口。这可以产生您正在与本地服务通信的错觉，当与Docker一起工作时特别有用。'
- en: 'The following command demonstrates how you can make the Docker socket running
    on a Swarm manager appear as a port running on your local host:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令演示了如何使运行在Swarm管理器上的Docker套接字显示为运行在本地主机上的端口：
- en: '[PRE4]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `-N` flag passed to the first SSH command instructs the client not to send
    a remote command, while the `-L` or local forwarding flag configures maps TCP
    port `2374` on the localhost to the `/var/run/docker.sock` Docker Engine socket
    on the remote Swarm manager. The ampersand (`&`) character at the end of the command
    causes the command to be run in the background, with the process ID published
    as the output of this command.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给第一个SSH命令的“-N”标志指示客户端不发送远程命令，而“-L”或本地转发标志配置了将本地主机上的TCP端口“2374”映射到远程Swarm管理器上的“/var/run/docker.sock”
    Docker Engine套接字。命令末尾的和符号（`&`）使命令在后台运行，并将进程ID作为此命令的输出发布。
- en: With this configuration in place, you can now run the Docker client, locally
    referencing `localhost:2374` as a local endpoint that is wired to your remote
    Swarm manager. Notice that you can specify the host using the `-H` flag, or by
    exporting the environment variable `DOCKER_HOST`. This will allow you to execute
    remote Docker operations while referencing local files in your local environment,
    making it much easier to manage and deploy to your Swarm cluster.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个配置，现在您可以运行Docker客户端，本地引用`localhost:2374`作为连接到远程Swarm管理器的本地端点。请注意，您可以使用“-H”标志指定主机，也可以通过导出环境变量`DOCKER_HOST`来指定主机。这将允许您在引用本地文件的同时执行远程Docker操作，从而更轻松地管理和部署到Swarm集群。
- en: Although Docker does include a client/server model that enables communications
    between a Docker client and remote Docker Engine, to do so securely requires mutual
    transport layer security (TLS) and public key infrastructure (PKI) technologies,
    which are complex to set up and maintain. Using SSH tunneling to expose the remote
    Docker socket is much easier to set up and maintain, and is considered as secure
    as any form of remote SSH access.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Docker确实包括了一个客户端/服务器模型，可以在Docker客户端和远程Docker Engine之间进行通信，但要安全地进行这样的通信需要相互传输层安全性（TLS）和公钥基础设施（PKI）技术，这些技术设置和维护起来很复杂。使用SSH隧道来暴露远程Docker套接字要容易得多，而且被认为与任何形式的远程SSH访问一样安全。
- en: Deploying applications to Docker Swarm
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将应用程序部署到Docker Swarm
- en: Now that you have installed Docker Swarm using Docker for AWS and established
    management connectivity to the Swarm cluster, we are ready to start deploying
    applications. Deploying applications to Docker Swarm requires use of the `docker
    service` and `docker stack` commands, which we have not covered to date in this
    book, so we will get acquainted with these commands by deploying a few example
    applications before tackling the deployment of our todobackend application.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经使用Docker for AWS安装了Docker Swarm，并建立了与Swarm集群的管理连接，我们准备开始部署应用程序。将应用程序部署到Docker
    Swarm需要使用`docker service`和`docker stack`命令，这些命令在本书中尚未涉及，因此在处理todobackend应用程序的部署之前，我们将通过部署一些示例应用程序来熟悉这些命令。
- en: Docker services
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker服务
- en: Although you can technically deploy a single container to a Swarm cluster, you
    should avoid doing this and always work with Docker *services* as the standard
    unit of deployment to your Swarm clusters. We have actually worked with Docker
    services already using Docker Compose, however when used in conjunction with Docker
    Swarm, they are elevated to a new level.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管您在Swarm集群中可以技术上部署单个容器，但应避免这样做，并始终使用Docker *服务*作为部署到Swarm集群的标准单位。实际上，我们已经使用Docker
    Compose来使用Docker服务，但是与Docker Swarm一起使用时，它们被提升到了一个新的水平。
- en: 'To create a Docker service, you can use the `docker service create` command,
    and the following example demonstrates standing up a very simple web application
    using the popular Nginx web server:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个Docker服务，您可以使用`docker service create`命令，下面的示例演示了如何使用流行的Nginx Web服务器搭建一个非常简单的Web应用程序：
- en: '[PRE5]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `--name` flag provides a friendly name for the services, while the `--publish`
    flag allows you to publish an external port the service will be accessible from
    (in this case, port `80`). The `--replicas` flag defines now many containers should
    be deployed for the service, and finally you specify the name of the image (nginx,
    in this case) for the service that you want to run. Note that you can use the
    `docker service ps` command to list the individual containers and nodes that are
    running for the service.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`--name`标志为服务提供了友好的名称，而`--publish`标志允许您发布服务将从中访问的外部端口（在本例中为端口`80`）。`--replicas`标志定义了服务应部署多少个容器，最后您指定了要运行的服务的图像的名称（在本例中为nginx）。请注意，您可以使用`docker
    service ps`命令来列出运行服务的各个容器和节点。'
- en: 'If you now attempt to browse to the URL of the external load balancer, you
    should receive the default **Welcome to nginx!** web page:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果现在尝试浏览外部负载均衡器的URL，您应该收到默认的**Welcome to nginx!**网页：
- en: '![](assets/13d5f811-507a-4314-8724-213ed904269e.png)Nginx welcome pageTo remove
    a service, you can simply use the `docker service rm` command:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/13d5f811-507a-4314-8724-213ed904269e.png)Nginx欢迎页面要删除一个服务，您可以简单地使用`docker
    service rm`命令：'
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Docker stacks
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Docker堆栈
- en: A **Docker stack** is defined as a complex, self-contained environment that
    consists of multiple services, networks and/or volumes, and is defined in a Docker
    Compose file.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**Docker堆栈**被定义为一个复杂的、自包含的环境，由多个服务、网络和/或卷组成，并在Docker Compose文件中定义。'
- en: A good example of a Docker stack that will immediately add some value to our
    Swarm cluster is an open source Swarm management tool called **swarmpit**, which
    you can read more about at [https://swarmpit.io/](https://swarmpit.io/). To get
    started using swarmpit, clone the [https://github.com/swarmpit/swarmpit](https://github.com/swarmpit/swarmpit)
    repository to a local folder, and then open the `docker-compose.yml` file at the
    root of the repository.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的Docker堆栈的例子，将立即为我们的Swarm集群增加一些价值，是一个名为**swarmpit**的开源Swarm管理工具，您可以在[https://swarmpit.io/](https://swarmpit.io/)上了解更多。要开始使用swarmpit，请克隆[https://github.com/swarmpit/swarmpit](https://github.com/swarmpit/swarmpit)存储库到本地文件夹，然后打开存储库根目录中的`docker-compose.yml`文件。
- en: '[PRE8]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: I have highlighted my modifications to the file, which are to update the Docker
    Compose file specification version to 3.6, modify the ports property for the app
    service to publish the management UI externally on port 8888, and ensure that
    the database is only deployed to the Swarm manager in your cluster. The reason
    for pinning the database is to ensure that in the event the database container
    failed for any reason, Docker Swarm will attempt to re-deploy the database container
    to the same node where the local database volume is stored.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经突出显示了对文件的修改，即将Docker Compose文件规范版本更新为3.6，修改app服务的端口属性，以便在端口8888上外部发布管理UI，并确保数据库仅部署到集群中的Swarm管理器。固定数据库的原因是确保在任何情况下，如果数据库容器失败，Docker
    Swarm将尝试将数据库容器重新部署到存储本地数据库卷的同一节点。
- en: In the event that you inadvertently wipe the swarmpit database, be warned that
    the admin password will be reset to the default value of admin, representing a
    significant security risk if you have published the swarmpit management interface
    to the public internet.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您意外地擦除了swarmpit数据库，请注意管理员密码将被重置为默认值admin，如果您已将swarmpit管理界面发布到公共互联网上，这将构成重大安全风险。
- en: 'With these changes in place, you can now run the `docker stack deploy` command
    to deploy the swarmpit management application:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些更改，现在可以运行`docker stack deploy`命令来部署swarmpit管理应用程序：
- en: '[PRE10]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You can see that the `docker stack deploy` command is much simpler than the
    `docker service create` command, given that the Docker Compose file contains all
    of the service configuration details. Browse to your external URL on port 8888
    and login with the default username and password of `admin`/`admin`, you should
    immediately change the admin password by selecting the admin drop-down in the
    top right-hand corner and selecting **Change Password**. Once you have changed
    the admin password, you can take a look around the swarmpit management UI, which
    provides a lot of information about your Swarm cluster. The following screenshot
    demonstrates the **Infrastructure** | **Nodes** page, which lists the nodes in
    your cluster and displays detailed information about each node:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到`docker stack deploy`命令比`docker service create`命令简单得多，因为Docker Compose文件包含了所有的服务配置细节。在端口8888上浏览您的外部URL，并使用默认用户名和密码`admin`/`admin`登录，然后立即通过选择右上角的管理员下拉菜单并选择**更改密码**来更改管理员密码。更改管理员密码后，您可以查看swarmpit管理UI，该界面提供了有关您的Swarm集群的大量信息。以下截图展示了**基础设施**
    | **节点**页面，其中列出了集群中的节点，并显示了每个节点的详细信息：
- en: '![](assets/77a22746-4832-40ca-b63a-1eefeb5c58d6.png)The swarmkit management
    interface'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/77a22746-4832-40ca-b63a-1eefeb5c58d6.png)swarmkit管理界面'
- en: Deploying the sample application to Docker Swarm
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将示例应用部署到Docker Swarm
- en: 'We are now down to the business end of the chapter, which is to deploy our
    sample todobackend application to our newly created Docker swarm cluster. As you
    might expect, there are a few challenges we are going to encounter, which require
    the following configuration tasks to be performed:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在进入了本章的业务端，即将我们的示例todobackend应用部署到新创建的Docker swarm集群。正如你所期望的那样，我们将遇到一些挑战，需要执行以下配置任务：
- en: Integrating Docker Swarm with the Elastic Container Registry
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将Docker Swarm集成到弹性容器注册表
- en: Defining a stack
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义堆栈
- en: Creating shared storage for hosting static content
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于托管静态内容的共享存储
- en: Creating a collectstatic service
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建collectstatic服务
- en: Creating persistent storage for storing the todobackend database
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建用于存储todobackend数据库的持久性存储
- en: Secrets management using Docker Swarm
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker Swarm进行秘密管理
- en: Running database migrations
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行数据库迁移
- en: Integrating Docker Swarm with the Elastic Container Registry
  id: totrans-128
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将Docker Swarm集成到弹性容器注册表
- en: The todobackend application is already published in an existing Elastic Container
    Registry (ECR) repository, and ideally we want to be able to integrate our Docker
    swarm cluster so that we can pull private images from ECR. As of the time of writing
    this book, ECR integration is supported in a somewhat limited fashion, in that
    you can pass registry credentials to your Docker swarm manager at the time of
    deployment, which will be shared across all nodes in the cluster. However, these
    credentials expire after 12 hours, and there is currently no native mechanism
    to automatically refresh these credentials.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: todobackend应用已经发布在现有的弹性容器注册表（ECR）存储库中，理想情况下，我们希望能够集成我们的Docker swarm集群，以便我们可以从ECR拉取私有镜像。截至撰写本书时，ECR集成在某种程度上得到支持，即您可以在部署时将注册表凭据传递给Docker
    swarm管理器，这些凭据将在集群中的所有节点之间共享。但是，这些凭据在12小时后会过期，目前没有本机机制来自动刷新这些凭据。
- en: 'In order to periodically refresh ECR credentials so that your Swarm cluster
    can always pull images from ECR, you need to perform the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定期刷新ECR凭据，以便您的Swarm集群始终可以从ECR拉取镜像，您需要执行以下操作：
- en: Ensure that your manager and worker instances have permissions to pull from
    ECR. The Docker for AWS CloudFormation template configures this access by default,
    so you shouldn't have to worry about configuring this.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保您的管理器和工作节点具有从ECR拉取的权限。Docker for AWS CloudFormation模板默认配置了此访问权限，因此您不必担心配置此项。
- en: Deploy the `docker-swarm-aws-ecr-auth` auto-login system container as a service,
    which is published at [https://github.com/mRoca/docker-swarm-aws-ecr-auth](https://github.com/mRoca/docker-swarm-aws-ecr-auth).
    When installed, this service automatically refreshes ECR credentials on all nodes
    in your cluster.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将`docker-swarm-aws-ecr-auth`自动登录系统容器部署为服务，发布在[https://github.com/mRoca/docker-swarm-aws-ecr-auth](https://github.com/mRoca/docker-swarm-aws-ecr-auth)。安装后，此服务会自动刷新集群中所有节点上的ECR凭据。
- en: 'To deploy the `docker-swarm-aws-ecr-auth` service, you use the `docker service
    create` command as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署`docker-swarm-aws-ecr-auth`服务，您可以使用以下`docker service create`命令：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Note that once this service is up and running, you must include the `--with-registry-auth`
    flag for any services that you deploy that use ECR images.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，一旦此服务启动运行，您必须为使用ECR镜像部署的任何服务包括`--with-registry-auth`标志。
- en: 'The following code demonstrates deploying the todobackend application using
    the `docker service create` command, along with the `--with-registry-auth` flag:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了使用`docker service create`命令部署todobackend应用程序，以及`--with-registry-auth`标志：
- en: '[PRE13]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You can verify the todobackend service did indeed deploy by browsing to the
    external load balancer URL:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过浏览到外部负载均衡器URL来验证todobackend服务确实已部署：
- en: '![](assets/c4dd84d5-c966-4f0d-adcc-8539b3ca7ff6.png)Deploying the todobackend
    service'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '![](assets/c4dd84d5-c966-4f0d-adcc-8539b3ca7ff6.png)部署todobackend服务'
- en: Note that because we haven't generated any static files the todobackend service
    is missing static content.  We will resolve this later on when we create a Docker
    Compose file and deploy a stack for the todobackend application.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，因为我们还没有生成任何静态文件，todobackend服务缺少静态内容。稍后当我们创建Docker Compose文件并为todobackend应用程序部署堆栈时，我们将解决这个问题。
- en: Defining a stack
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义一个堆栈
- en: Although you can deploy services using commands like `docker service create`,
    you can very quickly deploy a complete multi-service environment as we saw earlier
    using the `docker stack deploy` command, referencing a Docker Compose file that
    captures the configuration of the various services, networks, and volumes that
    comprise your stack. Deploying stacks to Docker Swarm requires version 3 of the
    Docker Compose file specification, so we can't use the existing `docker-compose.yml`
    file at the root of the todobackend repository to define our Docker Swarm environments,
    and I recommend keeping your development and test workflow separate, as the Docker
    Compose version 2 specification exclusively supports features that work well for
    continuous delivery workflows.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然您可以使用`docker service create`等命令部署服务，但是您可以使用`docker stack deploy`命令非常快速地部署完整的多服务环境，引用捕获各种服务、网络和卷配置的Docker
    Compose文件，构成您的堆栈。将堆栈部署到Docker Swarm需要Docker Compose文件规范的版本3，因此我们不能使用`todobackend`存储库根目录下的现有`docker-compose.yml`文件来定义我们的Docker
    Swarm环境，并且我建议保持开发和测试工作流分开，因为Docker Compose版本2规范专门支持适用于持续交付工作流的功能。
- en: 'Now, let''s get started defining a stack for the todobackend application that
    we can deploy to our Docker Swarm cluster in AWS by creating a file called `stack.yml`
    at the root of the `todobackend` repository:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们开始为todobackend应用程序定义一个堆栈，我们可以通过在`todobackend`存储库的根目录创建一个名为`stack.yml`的文件来部署到AWS的Docker
    Swarm集群中：
- en: '[PRE14]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The first property we specify is the mandatory `version` property, which we
    define as version 3.6, which was the latest version supported at the time of writing
    this book. Next, we configure the top-level networks property, which specifies
    Docker networks that the stack will use. You will create a network called `net` that
    implements the `overlay` driver, which creates a virtual network segment across
    all nodes in the Swarm cluster over which the various services defined in the
    stack can communicate with each other. In general, each stack that you deploy
    should specify its own overlay network, which provides segmentation between each
    of your stacks and means that you don't need to worry about IP addressing or the
    physical network topology of your cluster.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定的第一个属性是强制性的`version`属性，我们将其定义为3.6版本，这是在撰写本书时支持的最新版本。接下来，我们配置顶级网络属性，该属性指定了堆栈将使用的Docker网络。您将创建一个名为`net`的网络，该网络实现了`overlay`驱动程序，该驱动程序在Swarm集群中的所有节点之间创建了一个虚拟网络段，堆栈中定义的各种服务可以在其中相互通信。通常，您部署的每个堆栈都应该指定自己的覆盖网络，这样可以在每个堆栈之间提供分割，并且无需担心集群的IP寻址或物理网络拓扑。
- en: Next, you must define a single service called `app`, which represents the main
    todobackend web application and via the `image` property specifies the fully qualified
    name of the ECR image for the todobackend application that you published in earlier
    chapters. Note that Docker stacks do not support the `build` property and must
    reference a published Docker image, which is a good reason why you should always
    have a separate Docker Compose specification for your development, test, and build
    workflow.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您必须定义一个名为`app`的单个服务，该服务代表了主要的todobackend web应用程序，并通过`image`属性指定了您在之前章节中发布的todobackend应用程序的完全限定名称的ECR镜像。请注意，Docker堆栈不支持`build`属性，必须引用已发布的Docker镜像，这是为什么您应该始终为开发、测试和构建工作流程分别拥有单独的Docker
    Compose规范的一个很好的理由。
- en: The `ports` property uses the long style configuration syntax (in previous chapters,
    you have use the short style syntax), which provides access to more configuration
    options, allowing you to specify that the container port 8000 (as specified by
    the `target` property) will be published externally on port 80 (as specified by
    the `published` property), while the `networks` property configures the `app`
    service to be attached to the `net` network you previously defined. Notice that
    the `environment` property does not specify any database configuration settings—the
    focus for now is to just get the application up and running, albeit in a somewhat
    broken state, but we will shall configure database access later on in this chapter.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '`ports`属性使用了长格式配置语法（在之前的章节中，您使用了短格式语法），这提供了更多的配置选项，允许您指定容器端口8000（由`target`属性指定）将在端口80上对外发布（由`published`属性指定），而`networks`属性配置`app`服务附加到您之前定义的`net`网络。请注意，`environment`属性没有指定任何数据库配置设置，现在的重点只是让应用程序运行起来，尽管状态可能有些混乱，但我们将在本章后面配置数据库访问。'
- en: Finally, the `deploy` property allows you to control how the service should
    be deployed, with the `replica` property specifying to deploy two instances of
    our service, and the `update_config` property configuring rolling updates to update
    one instance at a time (as specified by the `parallelism` property) with a delay
    of 30 seconds between deploying each updated instance.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`deploy`属性允许您控制服务的部署方式，`replica`属性指定部署两个服务实例，`update_config`属性配置滚动更新，以便一次更新一个实例（由`parallelism`属性指定），每个更新实例之间延迟30秒。
- en: 'With this configuration in place, you can now deploy your stack using the `docker
    stack deploy` command:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个配置，您现在可以使用`docker stack deploy`命令部署您的堆栈了：
- en: '[PRE16]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Notice that I first login to ECR—this step is not absolutely required, however
    if are not logged into ECR, the Docker client is unable to determine the current
    image hash associated with the latest tag and you will be presented with this
    warning:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我首先登录到 ECR——这一步并非绝对必需，但如果未登录到 ECR，Docker 客户端将无法确定与最新标签关联的当前图像哈希，并且会出现以下警告：
- en: '[PRE17]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: If you now browse the external load balancer URL, the todobackend application
    should load, however you will notice that the application is missing static content
    and if you attempt to access `/todos`, a database configuration error will be
    presented, which is to be expected given we haven't configured any database settings
    or considered how to run the **collectstatic** process in Docker swarm.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在浏览外部负载均衡器 URL，todobackend 应用程序应该加载，但您会注意到应用程序缺少静态内容，如果您尝试访问 `/todos`，将会出现数据库配置错误，这是可以预料的，因为我们尚未配置任何数据库设置或考虑如何在
    Docker Swarm 中运行 **collectstatic** 过程。
- en: Creating shared storage for hosting static content
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为托管静态内容创建共享存储
- en: The Docker for AWS solution includes the Cloudstor volume plugin, which is a
    storage plugin built by Docker and designed to support popular cloud storage mechanisms
    for persistent storage.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: Docker for AWS 解决方案包括 Cloudstor 卷插件，这是由 Docker 构建的存储插件，旨在支持流行的云存储机制以实现持久存储。
- en: 'In the case of AWS, this plugin provides out of the box integration with the following
    types of persistent storage:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 的情况下，此插件提供了与以下类型的持久存储的开箱即用集成：
- en: '**Elastic Block Store** (**EBS**): Provides block level storage intended for
    dedicated (non-shared) access. This provides a high level of performance with
    the ability to detach and attach volumes to different instances, and supports
    snapshot and restore operations. EBS storage is suitable for database storage
    or any applications that require high throughput and minimal latency for reading
    and writing local data.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性块存储**（**EBS**）：提供面向专用（非共享）访问的块级存储。这提供了高性能，能够将卷分离和附加到不同的实例，并支持快照和恢复操作。EBS
    存储适用于数据库存储或任何需要高吞吐量和最小延迟来读写本地数据的应用程序。'
- en: '**Elastic File System** (**EFS**): Provides shared file system access using
    the **Network File System** (**NFS**) version 4 protocol. NFS allows for sharing
    storage at the same time across multiple hosts, however this is much less performant
    than EBS storage. NFS storage is suitable for applications that share common files
    and do not require high performance. Earlier, when you deployed the Docker for
    AWS solution, you selected to create the prerequisites for EFS, which sets up
    an EFS file system for the Swarm cluster that the Cloudstor volume plugin integrates
    with.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性文件系统**（**EFS**）：使用 **网络文件系统**（**NFS**）版本 4 协议提供共享文件系统访问。NFS 允许在多个主机之间同时共享存储，但这比
    EBS 存储要低得多。NFS 存储适用于共享常见文件并且不需要高性能的应用程序。在之前部署 Docker for AWS 解决方案时，您选择了为 EFS 创建先决条件，这为
    Cloudstor 卷插件集成了一个用于 Swarm 集群的 EFS 文件系统。'
- en: 'As you know from previous chapters, the todobackend application has a specific
    requirement for storing static content, and although I would typically not recommend
    EFS for such a use case, the static content requirement represents a good opportunity
    to demonstrate how to configure and use EFS as a shared volume in a Docker Swarm
    environment:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您在之前的章节中所了解的，todobackend 应用程序对存储静态内容有特定要求，尽管我通常不建议将 EFS 用于这种用例，但静态内容的要求代表了一个很好的机会，可以演示如何在
    Docker Swarm 环境中配置和使用 EFS 作为共享卷。
- en: '[PRE18]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You must first create a volume called `public` and specify a driver of `cloudstor:aws`,
    which ensures that the Cloudstor driver is loaded with AWS support. To create
    an EFS volume, you simply configure a driver option called `backing` with a value
    of `shared`, and then mount the volume at `/public` in the `app` service.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您必须创建一个名为`public`的卷，并指定驱动程序为`cloudstor:aws`，这可以确保Cloudstor驱动程序加载了AWS支持。要创建一个EFS卷，您只需配置一个名为`backing`的驱动选项，值为`shared`，然后在`app`服务中挂载到`/public`。
- en: 'If you now deploy your changes using the `docker stack deploy` command, the
    `volume` will be created and the `app` service instances will be updated:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在使用`docker stack deploy`命令部署您的更改，卷将被创建，并且`app`服务实例将被更新：
- en: '[PRE20]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You can use the `docker volume ls` command to view current volumes, and you
    will see that a new volume named according to the convention `<stack name>_<volume
    name>` (for example, `todobackend_public`) is created with a driver of `cloudstor:aws`.
    Notice that the `docker service ps` command output shows that `todobackend.app.1`
    was updated first, and then `todobackend.app.2` was updated 30 seconds later,
    which is based upon the earlier rolling update configuration you applied in the
    `deploy` settings for the `app` service.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`docker volume ls`命令查看当前卷，您会看到一个新的卷，根据约定命名为`<stack name>_<volume name>`（例如，`todobackend_public`），并且驱动程序为`cloudstor:aws`。请注意，`docker
    service ps`命令输出显示`todobackend.app.1`首先被更新，然后30秒后`todobackend.app.2`被更新，这是基于您在`app`服务的`deploy`设置中应用的早期滚动更新配置。
- en: 'To verify that the volume was successfully mounted, you can use the `docker
    ps` command to query the Swarm manager for any app service containers running
    locally, and then use `docker exec` to verify that the `/public` mount exists
    and is readable/writable by the `app` user that the todobackend container runs
    as:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证卷是否成功挂载，您可以使用`docker ps`命令查询Swarm管理器上运行的任何app服务容器，然后使用`docker exec`来验证`/public`挂载是否存在，并且`app`用户可以读写todobackend容器运行的。
- en: '[PRE21]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'One important point to note is that the `docker volume` and other `docker`
    commands shown in the preceding example are only executed in the context of the
    current Swarm node you are connected to, and won''t display volumes or allow you
    to access containers running on other nodes in the cluster. To verify that the
    volume is indeed shared and accessible by the app service container running on
    the other Swarm node in our cluster, you need to first SSH to the Swarm manager
    and then SSH to the single worker node in the cluster:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的要点是，在前面的示例中显示的`docker volume`和其他`docker`命令只在您连接的当前Swarm节点的上下文中执行，并且不会显示卷或允许您访问集群中其他节点上运行的容器。要验证卷确实是共享的，并且可以被我们集群中其他Swarm节点上运行的app服务容器访问，您需要首先SSH到Swarm管理器，然后SSH到集群中的单个工作节点：
- en: '[PRE22]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, the volume is available on the worker node, who can see the
    `/public/test` file we created on the other instance, proving the volume is indeed
    shared and accessible to all `app` service instances, regardless of underlying
    nodes.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，该卷在工作节点上是可用的，可以看到我们在另一个实例上创建的`/public/test`文件，证明该卷确实是共享的，并且可以被所有`app`服务实例访问，而不管底层节点如何。
- en: Creating a collectstatic service
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个collectstatic服务
- en: Now that you have a shared volume in place, we need to consider how we will
    define and execute the collectstatic process to generate static content. To date,
    throughout this book, you have performed the collectstatic process as an imperative
    task that needs to happen at a specific point in time within a defined deployment
    sequence, however Docker Swarm promotes the concept of eventual consistency so
    you should be able to deploy your stack and have a collectstatic process running
    that may fail but will eventually succeed, at which point the desired state of
    your application is reached. This approach is quite different from the imperative
    approach we have taken previously, but is accepted as a best practice for well-architected
    modern cloud native applications.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了一个共享卷，我们需要考虑如何定义和执行 collectstatic 过程来生成静态内容。迄今为止，在本书中，您已经将 collectstatic
    过程作为一个需要在定义的部署序列中的特定时间发生的命令式任务执行，然而 Docker Swarm 提倡最终一致性的概念，因此您应该能够部署您的堆栈，并且有一个可能失败但最终会成功的
    collectstatic 过程运行，此时达到了应用程序的期望状态。这种方法与我们之前采取的命令式方法非常不同，但被认为是良好架构的现代云原生应用程序的最佳实践。
- en: 'To demonstrate how this works, we first need to tear down the todobackend stack
    so that you can observe failures that will occur in the collectstatic process
    while the Docker storage engine is creating and mounting the EFS backed volume:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这是如何工作的，我们首先需要拆除 todobackend 堆栈，这样您就可以观察在 Docker 存储引擎创建和挂载 EFS 支持的卷时 collectstatic
    过程中将发生的失败：
- en: '[PRE23]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: One point to note is that Docker Swarm does not remove volumes when you destroy
    a stack, so you need to manually remove the volume to fully clean up the environment.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的一点是，Docker Swarm 在销毁堆栈时不会删除卷，因此您需要手动删除卷以完全清理环境。
- en: 'We can now add a collectstatic service to our stack:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以向堆栈添加一个 collectstatic 服务：
- en: '[PRE24]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The `collectstatic` service mounts the `public` shared volume and runs the appropriate
    `manage.py` task to generate static content. In the `deploy` section, we configure
    a replica count of 1, given that the `collectstatic` service only needs be run
    once per deployment, and then configure a `restart_policy` that states Docker
    Swarm should attempt to restart the service on failure, with a delay of 30 seconds
    between each restart attempt up to a maximum of 6 attempts. This provides eventual
    consistency behavior as it allows collectstatic to fail initially while EFS volume
    mounting operations are taking place, and then eventually succeed once the volume
    is mounted and ready.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '`collectstatic` 服务挂载 `public` 共享卷，并运行适当的 `manage.py` 任务来生成静态内容。在 `deploy` 部分，我们配置了一个副本数量为1，因为
    `collectstatic` 服务只需要在部署时运行一次，然后配置了一个 `restart_policy`，指定Docker Swarm在失败时应尝试重新启动服务，每次重新启动尝试之间间隔30秒，最多尝试6次。这提供了最终一致的行为，因为它允许
    collectstatic 在 EFS 卷挂载操作正在进行时最初失败，然后在卷挂载和准备就绪后最终成功。'
- en: 'If you now deploy the stack and monitor the collectstatic service, you may
    notice some initial failures:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在部署堆栈并监视 collectstatic 服务，您可能会注意到一些最初的失败：
- en: '[PRE25]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `docker service ps` command displays not only the current service state,
    but also service history (such as any previous attempts to run the service), and
    you can see that 32 seconds ago the first attempt to run `collectstatic` failed,
    after which Docker Swarm attempted to restart the service. This attempt succeeds,
    and although the `collectstatic` service will eventually complete and exit, because
    the restart policy is set to failure, Docker Swarm will not attempt to start the
    service again, given that the service exited with no error. This supports the
    concept of a "one-shot" service with retry capabilities in the event of a failure,
    and the only time Swarm will attempt to run the service again is in the event
    that a new configuration for the service is deployed to the cluster.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '`docker service ps`命令不仅显示当前服务状态，还显示服务历史（例如任何先前尝试运行服务），您可以看到32秒前第一次尝试运行`collectstatic`失败，之后Docker
    Swarm尝试重新启动服务。这次尝试成功了，尽管`collectstatic`服务最终会完成并退出，但由于重启策略设置为失败，Docker Swarm不会尝试重新启动服务，因为服务没有错误退出。这支持了在失败时具有重试功能的“一次性”服务的概念，Swarm尝试再次运行服务的唯一时机是在为服务部署新配置到集群时。'
- en: If you now browse to the external load balancer URL, you should find that the
    static content of the todobackend application is now presented correctly, however
    the database configuration error still exists.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在浏览外部负载均衡器的URL，您应该会发现todobackend应用程序的静态内容现在被正确呈现，但是数据库配置错误仍然存在。
- en: Creating persistent storage for storing the application database
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建用于存储应用程序数据库的持久存储
- en: We can now shift our attention to the application database, which is an essential
    supporting component of the todobackend application. If you are running in AWS,
    my typical recommendation would be, regardless of container orchestration platform,
    to use the Relational Database Service (RDS) as we have done throughout this book,
    however the application database requirement for the todobackend application provides
    an opportunity to demonstrate how you can support persistent storage using the
    Docker for AWS solution.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以将注意力转向应用程序数据库，这是todobackend应用程序的一个基本支持组件。如果您在AWS上运行，我的典型建议是，无论容器编排平台如何，都要像我们在本书中一样使用关系数据库服务（RDS），但是todobackend应用程序对应用程序数据库的要求提供了一个机会，可以演示如何使用Docker
    for AWS解决方案支持持久存储。
- en: 'In addition to EFS-backed volumes, the Cloudstor volume plugin also supports
    *relocatable* Elastic Block Store (EBS) volumes. Relocatable means that the plugin
    will automatically relocate the currently assigned EBS volume for a container
    to another node in the event Docker Swarm determines it has to relocate a container
    from one node to another. What actually happens during relocation of the EBS volume
    depends on the scenario:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 除了EFS支持的卷之外，Cloudstor卷插件还支持*可重定位*的弹性块存储（EBS）卷。可重定位意味着插件将自动将容器当前分配的EBS卷重新分配到另一个节点，以防Docker
    Swarm确定必须将容器从一个节点重新分配到另一个节点。在重新分配EBS卷时实际发生的情况取决于情况：
- en: '**New node is in the same availability zone**: The plugin simply detaches the
    volume from the EC2 instance of the existing node and reattaches the volume on
    the new node.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新节点位于相同的可用区：插件只是从现有节点的EC2实例中分离卷，并在新节点上重新附加卷。
- en: '**New node is in a different availability zone**: Here, the plugin takes a
    snapshot of the existing volume and then creates a new volume in the new availability
    zone from the snapshot. Once complete, the previous volume is destroyed.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新节点位于不同的可用区：在这里，插件对现有卷进行快照，然后从快照在新的可用区创建一个新卷。完成后，之前的卷将被销毁。
- en: It is important to note that Docker only supports singular access to a relocatable
    EBS-backed volume—that is, there should only ever be a single container that reads/writes
    to the volume at any given time. If you require shared access to a volume, then
    you must create an EFS-backed shared volume.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，Docker仅支持对可移动的EBS支持卷的单一访问，也就是说，在任何给定时间，应该只有一个容器读取/写入该卷。如果您需要对卷进行共享访问，那么必须创建一个EFS支持的共享卷。
- en: 'Now, let''s define a volume called `data` to store the todobackend database,
    and create a `db` service that will run MySQL and attach to the `data` volume:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们定义一个名为`data`的卷来存储todobackend数据库，并创建一个`db`服务，该服务将运行MySQL并附加到`data`卷：
- en: '[PRE26]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: First, we create a volume called `data` and configure the driver as `cloudstor:aws`.
    In the driver options, we specify a backing of relocatable to create an EBS volume,
    specifying a size of 10 GB and an EBS type of `gp2` (SSD) storage. We then define
    a new service called `db` that runs the official MySQL 5.7 image, attaching the
    `db` service to the previously defined net network and mounting the data volume
    at `/var/lib/mysql`, which is where MySQL stores its database. Note that because
    the Cloudstor plugin formats the mounted volume as `ext4`, a folder called `lost+found`
    is automatically created during the formatting process, which causes the [MySQL
    container to abort](https://github.com/docker-library/mysql/issues/69#issuecomment-365927214)
    as it thinks an existing database called `lost+found` is present.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建一个名为`data`的卷，并将驱动程序配置为`cloudstor:aws`。在驱动程序选项中，我们指定了一个可移动的后端来创建一个EBS卷，指定了10GB的大小和`gp2`（SSD）存储的EBS类型。然后，我们定义了一个名为`db`的新服务，该服务运行官方的MySQL
    5.7镜像，将`db`服务附加到先前定义的net网络，并将数据卷挂载到`/var/lib/mysql`，这是MySQL存储其数据库的位置。请注意，由于Cloudstor插件将挂载的卷格式化为`ext4`，在格式化过程中会自动创建一个名为`lost+found`的文件夹，这会导致[MySQL容器中止](https://github.com/docker-library/mysql/issues/69#issuecomment-365927214)，因为它认为存在一个名为`lost+found`的现有数据库。
- en: To overcome this, we pass in a single flag called `--ignore-db-dir` that references
    the `lost+found` folder, which is passed to the MySQL image entrypoint and configures
    the MySQL daemon to ignore this folder.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服这一点，我们传入一个称为`--ignore-db-dir`的单个标志，该标志引用`lost+found`文件夹，该文件夹传递给MySQL镜像入口点，并配置MySQL守护进程忽略此文件夹。
- en: Finally, we define a placement constraint that will force the `db` service to
    be deployed to the Swarm manager, which will allow us to test the relocatable
    features of the data volume by changing this placement constraint to a worker
    later on.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们定义了一个放置约束，将强制`db`服务部署到Swarm管理器，这将允许我们通过将此放置约束更改为工作程序来测试数据卷的可移动特性。
- en: 'If you now deploy the stack and monitor the `db` service, you should observe
    that the service takes some time to come up while the data volume is initializing:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在部署堆栈并监视`db`服务，您应该观察到服务需要一些时间才能启动，同时数据卷正在初始化：
- en: '[PRE27]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To verify, an EBS volume has actually been created, you can use the AWS CLI
    as follows:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证EBS卷是否已创建，可以使用AWS CLI如下：
- en: '[PRE28]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that EBS volumes created by the Cloudstor plugin are tagged with a key
    of `CloudstorVolumeName` and a value of the Docker Swarm volume name. In the preceding
    example, you can also see that the volume has been created in the us-east-1b availability
    zone.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由Cloudstor插件创建的EBS卷标记为`CloudstorVolumeName`的键和Docker Swarm卷名称的值。在上面的示例中，您还可以看到该卷已在us-east-1b可用区创建。
- en: Relocating an EBS volume
  id: totrans-200
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移EBS卷
- en: 'Now that you have successfully created and attached an EBS-backed data volume,
    let''s test migrating the `db` service from the manager node to the worker node
    by changing its placement constraint:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已成功创建并附加了一个EBS支持的数据卷，让我们通过更改其放置约束来测试将`db`服务从管理节点迁移到工作节点：
- en: '[PRE29]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If you now deploy your changes, you should be able to observe the EBS relocation
    process:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你现在部署你的更改，你应该能够观察到EBS迁移过程：
- en: '[PRE30]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: We first define a `volumes` query that displays the current Cloudstor volume
    status, and a `snapshots` query that displays any EBS snapshots that are in progress.
    After deploying the placement constraint change, we run the volumes query several
    times and observe the current volume located in `us-east-1b`, transition to a
    state of `detaching`, and to a state of `None` (detached).
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个`volumes`查询，显示当前Cloudstor卷的状态，以及一个`snapshots`查询，显示任何正在进行中的EBS快照。在部署放置约束更改后，我们运行卷查询多次，并观察当前位于`us-east-1b`的卷，过渡到`分离`状态，然后到`无`状态（分离）。
- en: We then run the snapshot query where you can see that a snapshot is being created
    for the volume that was just detached, and once this snapshot is complete, we
    run the volumes query several times to observe that the old volume is removed
    and a new volume is created in `us-east-1a`, which is then attached. At this point,
    the `todobackend_data` volume has been relocated from the manager in `us-east-1b`
    to `us-east-1a`, and you can verify that the `db` service is now up and running
    again by executing the `docker service ps` command.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们运行快照查询，在那里你可以看到一个快照正在为刚刚分离的卷创建，一旦这个快照完成，我们运行卷查询多次来观察旧卷被移除并且在`us-east-1a`创建了一个新卷，然后被附加。在这一点上，`todobackend_data`卷已经从`us-east-1b`的管理者迁移到了`us-east-1a`，你可以通过执行`docker
    service ps`命令来验证`db`服务现在已经重新启动并运行。
- en: Because the Docker for AWS CloudFormation template creates separate auto scaling
    groups for managers and workers, there is a possibility the manager and worker
    are running in the same subnet and availability zone, which will change the behavior
    of the example above.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Docker for AWS CloudFormation模板为管理者和工作者创建了单独的自动扩展组，有可能管理者和工作者正在相同的子网和可用区中运行，这将改变上面示例的行为。
- en: 'Before we proceed to the next section, we actually need to tear down our stack
    as the current password management strategy of using cleartext passwords in our
    stack file is not ideal, and our database has already been initialized with these
    passwords:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续下一节之前，实际上我们需要拆除我们的堆栈，因为在我们的堆栈文件中使用明文密码的当前密码管理策略并不理想，而且我们的数据库已经使用这些密码进行了初始化。
- en: '[PRE31]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Remember that, whenever you tear down a stack, you must remove any volumes you
    may have used in that stack manually.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，每当你拆除一个堆栈时，你必须手动删除在该堆栈中使用过的任何卷。
- en: Secrets management using Docker secrets
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Docker secrets进行秘密管理
- en: In the preceding examples when we created the `db` service, we didn't actually
    configure the application to integrate with the `db` service, as although we were
    focusing on how to create persistent storage, another reason I did not integrate
    the `app` service with the `db` service is because we are currently configuring
    passwords for the `db` service in plaintext, which is not ideal.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，当我们创建`db`服务时，我们实际上并没有配置应用程序与`db`服务集成，因为虽然我们专注于如何创建持久存储，但我没有将`app`服务与`db`服务集成的另一个原因是因为我们目前正在以明文配置`db`服务的密码，这并不理想。
- en: Docker Swarm includes a feature called Docker secrets, which provide a secure
    secrets management solution for providing secrets to applications running on your
    Docker Swarm clusters. Secrets are stored in an internal encrypted storage mechanism
    called the *raft log*, which is replicated to all nodes in your cluster, ensuring
    that any service and associated containers that are granted access to a secret
    can access the secret securely.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Swarm包括一个名为Docker secrets的功能，为在Docker Swarm集群上运行的应用程序提供安全的密钥管理解决方案。密钥存储在内部加密的存储机制中，称为*raft
    log*，该机制被复制到集群中的所有节点，确保被授予对密钥访问权限的任何服务和相关容器可以安全地访问密钥。
- en: 'To create a Docker secret, you can use the `docker secret create` command:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建Docker密钥，您可以使用`docker secret create`命令：
- en: '[PRE32]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In the preceding example, we use the `openssl rand` command to generate random
    secrets in Base64 format, which we then pass as standard input to the `docker
    secret create` command. We create 32 character secrets for the todobackend user's
    MySQL password and MySQL root password, and finally create a secret of 50 characters
    for the Django `SECRET_KEY` setting that is required for cryptographic operations
    performed by the todobackend application.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，我们使用`openssl rand`命令以Base64格式生成随机密钥，然后将其作为标准输入传递给`docker secret create`命令。我们为todobackend用户的MySQL密码和MySQL根密码创建了32个字符的密钥，最后创建了一个50个字符的密钥，用于todobackend应用程序执行的加密操作所需的Django
    `SECRET_KEY`设置。
- en: 'Now that we have created several secrets, we can configure our stack to consume
    these secrets:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了几个密钥，我们可以配置我们的堆栈来使用这些密钥：
- en: '[PRE33]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: We first declare the top level `secrets` parameter, specifying the names of
    each of the secrets we previously created and configuring each secret as `external`,
    given we created the secrets outside of the stack. If you don't use external secrets,
    you must define your secrets in a file, which does not solve the issue of storing
    passwords securely outside of your stack definitions and configurations, so creating
    your secrets as separate entities independent of your stack is much more secure.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先声明顶级`secrets`参数，指定我们之前创建的每个密钥的名称，并将每个密钥配置为`external`，因为我们在堆栈之外创建了这些密钥。如果您不使用外部密钥，必须在文件中定义您的密钥，这并不能解决安全地存储密码在堆栈定义和配置之外的问题，因此将您的密钥作为独立于堆栈的单独实体创建会更安全。
- en: 'We then reconfigure the `app` service to consume each secret via the `secrets`
    property. Notice that we specify a target of `MYSQL_PASSWORD` and `SECRET_KEY`.
    Whenever you attach a secret to a service, an in-memory tmpfs-backed mount will
    be created at `/run/secrets`, with each secret stored at the location `/run/secrets/<target-name>`,
    so for the `app` service, the following secrets will be mounted:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们重新配置`app`服务以通过`secrets`属性消耗每个密钥。请注意，我们指定了`MYSQL_PASSWORD`和`SECRET_KEY`的目标。每当您将密钥附加到服务时，将在`/run/secrets`创建一个基于内存的tmpfs挂载点，每个密钥存储在位置`/run/secrets/<target-name>`，因此对于`app`服务，将挂载以下密钥：
- en: '`/run/secrets/MYSQL_PASSWORD`'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/run/secrets/MYSQL_PASSWORD`'
- en: '`/run/secrets/SECRET_KEY`'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/run/secrets/SECRET_KEY`'
- en: We will learn how to configure our application to consume these secrets later
    on, but also note that we configure the `MYSQL_HOST` and `MYSQL_USER` environment
    variables so that our application knows how to connect to the `db` service and
    which user to authenticate as.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在以后学习如何配置我们的应用程序来使用这些密钥，但也请注意，我们配置了`MYSQL_HOST`和`MYSQL_USER`环境变量，以便我们的应用程序知道如何连接到`db`服务以及要进行身份验证的用户。
- en: 'Next, we configure the `db` service to consume the MySQL password and root
    password secrets, and here we configure the targets for each secret so that the
    following secrets are mounted in the `db` service container:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们配置`db`服务以使用MySQL密码和根密码密钥，并在这里配置每个密钥的目标，以便以下密钥在`db`服务容器中挂载：
- en: '`/run/secrets/mysql_password`'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/run/secrets/mysql_password`'
- en: '`/run/secrets/mysql_root_password`'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/run/secrets/mysql_root_password`'
- en: Finally, we remove the `MYSQL_PASSWORD` and `MYSQL_ROOT_PASSWORD` environment
    variables from the `db` service and replace these with their file-based equivalents,
    referencing the path to each of the configured secrets.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们从`db`服务中删除了`MYSQL_PASSWORD`和`MYSQL_ROOT_PASSWORD`环境变量，并用它们的基于文件的等效项替换，引用了每个配置的秘密的路径。
- en: 'At this point, if you deploy the newly updated stack (if you haven''t previously
    removed the stack, you will need to do this prior to ensure that you can recreate
    the database with the new credentials), once your todobackend services have started
    successfully, you can determine the container ID of the `app` service instance
    running on the Swarm manager by running the `docker ps` command, after which you
    can examine the contents of the `/run/secrets` directory:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，如果您部署了新更新的堆栈（如果您之前没有删除堆栈，您需要在此之前执行此操作，以确保您可以使用新凭据重新创建数据库），一旦您的todobackend服务成功启动，您可以通过运行`docker
    ps`命令来确定在Swarm管理器上运行的`app`服务实例的容器ID，之后您可以检查`/run/secrets`目录的内容：
- en: '[PRE34]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'As you can see, the secrets you created earlier are available in the `/run/secrets`
    folder, and if you now browse to the `/todos` path on the external load balancer
    URL where your application is published, unfortunately you will receive an `access
    denied` error:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，您之前创建的秘密现在可以在`/run/secrets`文件夹中使用，如果您现在浏览发布应用程序的外部负载均衡器URL上的`/todos`路径，不幸的是，您将收到`访问被拒绝`的错误：
- en: '![](assets/bade4a1e-0aa5-4a04-870a-04c2dbed709d.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/bade4a1e-0aa5-4a04-870a-04c2dbed709d.png)'
- en: Database authentication error
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库认证错误
- en: The problem here is that although we have mounted the database secret in the
    `app` service, our todobackend application does not know how to consume these
    secrets, so we need to make some modifications to the todobackend application
    to be able to consume these secrets.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，尽管我们已经在`app`服务中挂载了数据库秘密，但我们的todobackend应用程序不知道如何使用这些秘密，因此我们需要对todobackend应用程序进行一些修改，以便能够使用这些秘密。
- en: Configuring applications to consume secrets
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置应用程序以使用秘密
- en: In previous chapters, we have used an entrypoint script to add support for features
    such as injecting secrets at container startup, however an equally valid (and
    actually better and more secure) approach is to configure your application to
    natively support your secrets management strategy.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，我们使用了一个入口脚本来支持诸如在容器启动时注入秘密等功能，然而同样有效（实际上更好更安全）的方法是配置您的应用程序以原生方式支持您的秘密管理策略。
- en: 'In the case of Docker secrets, this is very straightforward, given that the
    secrets are mounted at a well-known location (`/run/secrets`) in the local filesystem
    of the container. The following demonstrates modifying the `src/todobackend/settings_release.py`
    file in the `todobackend` repository to support Docker secrets, which, as you
    should recall, are the settings we pass to our `app` service, as specified by
    the environment variable configuration `DJANGO_SETTINGS_MODULE=todobackend.settings_release.`:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Docker秘密，这非常简单，因为秘密被挂载在容器的本地文件系统中的一个众所周知的位置（`/run/secrets`）。以下演示了修改`todobackend`存储库中的`src/todobackend/settings_release.py`文件以支持Docker秘密，正如您应该记得的那样，这些是我们传递给`app`服务的设置，由环境变量配置`DJANGO_SETTINGS_MODULE=todobackend.settings_release`指定。
- en: '[PRE35]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: We first create a simple function called `secret()`, which takes as input the
    name of the setting or `key`, and an optional default value if the secret cannot
    be found. This function then attempts to look up the path `/run/secrets` (this
    can be overridden by setting the environment variable `SECRETS_ROOT`) and looks
    for a file with the same name as the requested key. If this file is found, the
    contents of the file is read using the `f.read().rstrip()` call, with the `rstrip()`
    function stripping the line break that is returned by the `read()` function. Otherwise,
    the function looks for an environment variable with the same name of key, and
    if all of these lookups fail, it returns the `default` value that was passed to
    the `secret()` function (which itself has a default value of `None`).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先创建一个名为`secret()`的简单函数，该函数以设置或`key`的名称作为输入，并在无法找到秘密时提供一个可选的默认值。然后，该函数尝试查找路径`/run/secrets`（可以通过设置环境变量`SECRETS_ROOT`来覆盖此路径），并查找与请求的键相同名称的文件。如果找到该文件，则使用`f.read().rstrip()`调用读取文件的内容，`rstrip()`函数会去除`read()`函数返回的换行符。否则，该函数将查找与键相同名称的环境变量，如果所有这些查找都失败，则返回传递给`secret()`函数的`default`值（该值本身具有默认值`None`）。
- en: 'With this function in place, we can then simply call the secret function, as
    demonstrated for the `SECRET_KEY` and `DATABASES[''PASSWORD'']` settings, and
    using the `SECRET_KEY` setting as an example, the function will return in the
    following order of preference:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个函数，我们可以简单地调用秘密函数，如对`SECRET_KEY`和`DATABASES['PASSWORD']`设置进行演示，并以`SECRET_KEY`设置为例，该函数将按以下优先顺序返回：
- en: Value of the contents of the `/run/secrets/SECRET_KEY`
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`/run/secrets/SECRET_KEY`的内容值'
- en: Value of the environment variable `SECRET_KEY`
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 环境变量`SECRET_KEY`的值
- en: Value of the default value passed to the `secrets()` function (in this case,
    the `SECRET_KEY` setting imported from the base settings file)
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 传递给`secrets()`函数的默认值的值（在本例中，从基本设置文件导入的`SECRET_KEY`设置）
- en: 'Now that we have updated the todobackend application to support Docker secrets,
    you need to commit your changes and then test, build, and publish your changes.
    Note that will need to do this in a separate shell that is connected to your local
    Docker Engine (rather than your Docker Swarm cluster):'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经更新了todobackend应用程序以支持Docker secrets，您需要提交您的更改，然后测试、构建和发布您的更改。请注意，您需要在连接到本地Docker引擎的单独shell中执行此操作（而不是连接到Docker
    Swarm集群）：
- en: '[PRE36]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Once your image has been successfully published, switch back to your Terminal
    session that is connected to your Swarm cluster and redeploy your stack using
    the `docker stack deploy` command:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的镜像成功发布，切换回连接到Swarm集群的终端会话，并使用`docker stack deploy`命令重新部署您的堆栈：
- en: '[PRE37]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If you run the `docker service ps` command as demonstrated in the preceding
    example, you may notice that your todobackend service is not redeployed (note
    in some cases the service may be redeployed). The reason for this is that we are
    using the latest image by default in our stack file. To ensure that we can continuously
    deliver and deploy our application, we need to reference a specific version or
    build tag, which is the best practice approach you should always take, as it will
    force an explicit version of your image to be deployed on each service update.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您运行`docker service ps`命令，如前面的示例所示，您可能会注意到您的todobackend服务没有重新部署（在某些情况下，服务可能会重新部署）。原因是我们在堆栈文件中默认使用最新的镜像。为了确保我们能够持续交付和部署我们的应用程序，我们需要引用特定版本或构建标签，这是您应该始终采取的最佳实践方法，因为它将强制在每次服务更新时部署显式版本的镜像。
- en: 'To do this with our local workflow, we can leverage the `Makefile` that already
    exists in the todobackend application repository and include an `APP_VERSION`
    environment variable that returns the current Git commit hash, which we can subsequently
    reference in our stack file:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 通过我们的本地工作流程，我们可以利用todobackend应用程序存储库中已经存在的`Makefile`，并包含一个`APP_VERSION`环境变量，返回当前的Git提交哈希，随后我们可以在我们的堆栈文件中引用它：
- en: '[PRE38]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'With this configuration in place, we now need to add a deploy recipe to the
    `Makefile` in the root of the `todobackend` repository, which will automatically
    make the `APP_VERSION` environment variable available to the Docker client when
    it parses the stack file:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这个配置，我们现在需要在`todobackend`存储库的根目录中添加一个`Makefile`的部署配方，当Docker客户端解析堆栈文件时，它将自动使`APP_VERSION`环境变量可用：
- en: '[PRE39]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The `deploy` recipe references the `login` recipe, ensuring that we always
    run the equivalent of `make login` first before running the tasks in the `deploy`
    recipe. This recipe simply runs the `docker stack deploy` command so that we can
    now deploy the updates to our stack by running `make deploy`:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '`deploy`配方引用`login`配方，确保我们始终首先运行等效的`make login`，然后再运行`deploy`配方中的任务。这个配方只是运行`docker
    stack deploy`命令，这样我们现在可以通过运行`make deploy`来部署对我们堆栈的更新：'
- en: '[PRE40]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Because our stack is now configured with a specific image tag, as defined by
    the `APP_VERSION` variable (`3db46c4` in the preceding example), a change is detected
    and the `app` service is updated. You can confirm this using the `docker service
    ps` command, as demonstrated previously, and recall that we have configured this
    service to update a single instance at a time with a 30 second delay between each
    update.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的堆栈现在配置了一个特定的图像标记，由`APP_VERSION`变量（在前面的示例中为`3db46c4`）定义，所以一旦检测到更改，`app`服务就会被更新。您可以使用`docker
    service ps`命令来确认这一点，就像之前演示的那样，并且我们已经配置这个服务以每次更新一个实例，并且每次更新之间有30秒的延迟。
- en: 'If you now browse to the `/todos` path on the external load balancer URL, the
    authentication error should now be replaced with a `table does not exist` error,
    which proves that we are now able to at least connect to the database, but haven''t
    yet dealt with database migrations as part of our Docker Swarm solution:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在浏览外部负载均衡器URL上的`/todos`路径，认证错误现在应该被替换为`表不存在`错误，这证明我们现在至少能够连接到数据库，但还没有处理数据库迁移作为我们的Docker
    Swarm解决方案的一部分：
- en: '![](assets/4421dad8-2e82-412a-9d29-3122345044ae.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/4421dad8-2e82-412a-9d29-3122345044ae.png)'
- en: Database error
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库错误
- en: Running database migrations
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行数据库迁移
- en: 'Now that we have established a mechanism to securely access the db service
    in our stack, the final configuration task we need to perform is to add a service
    that will run database migrations. This is similar to the collectstatic service
    we created earlier, in that it needs to be a "one-shot" task that only executes
    whenever we create the stack or whenever we deploy a new version of the application:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经建立了一个安全访问堆栈中的db服务的机制，我们需要执行的最后一个配置任务是添加一个将运行数据库迁移的服务。这类似于我们之前创建的collectstatic服务，它需要是一个“一次性”任务，只有在我们创建堆栈或部署新版本的应用程序时才执行：
- en: '[PRE41]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: All of the settings for the new `migrate` service should be self-explanatory,
    as we've configured them previously for other services. The `deploy` configuration
    is especially important and is configured identically to the other one-shot collectstatic
    service, where Docker Swarm will attempt to ensure a single replica of the `migrate`
    service is able to start successfully up to six times with a delay of 30 seconds
    between each attempt.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 新的`migrate`服务的所有设置应该是不言自明的，因为我们之前已经为其他服务配置过它们。`deploy`配置尤其重要，并且与其他一次性collectstatic服务配置相同，Docker
    Swarm将尝试确保`migrate`服务的单个副本能够成功启动最多六次，每次尝试之间延迟30秒。
- en: 'If you now run `make deploy` to deploy your changes, the `migrate` service
    should be able to complete successfully:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您现在运行`make deploy`来部署您的更改，`migrate`服务应该能够成功完成：
- en: '[PRE43]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'To verify that the migrations actually ran, because we enabled CloudWatch logs
    when we created the Docker Swarm cluster, you can review logs for the `migrate`
    service in the CloudWatch logs console. When using the Docker for AWS solution
    templates to deploy your cluster, a single log group called `<cloudformation-stack-name>-lg`
    is created, which in our case is `docker-swarm-lg`. If you open this log group
    in the CloudWatch logs console, you will see that log streams exist for every
    container that is running or has run in the Swarm cluster:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 为了验证迁移实际上已经运行，因为我们在创建Docker Swarm集群时启用了CloudWatch日志，您可以在CloudWatch日志控制台中查看`migrate`服务的日志。当使用Docker
    for AWS解决方案模板部署集群时，会创建一个名为`<cloudformation-stack-name>-lg`的日志组，我们的情况下是`docker-swarm-lg`。如果您在CloudWatch日志控制台中打开此日志组，您将看到为在Swarm集群中运行或已运行的每个容器存在日志流：
- en: '![](assets/54f50ec8-9ee0-4ceb-878e-ac7caf4c352b.png)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/54f50ec8-9ee0-4ceb-878e-ac7caf4c352b.png)'
- en: Deploying the migrate service
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 部署migrate服务
- en: 'You can see that the most recent log stream relates to the `migrate` service,
    and if you open this log stream, you can confirm that database migrations ran
    successfully:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到最近的日志流与`migrate`服务相关，如果您打开此日志流，您可以确认数据库迁移已成功运行：
- en: '![](assets/28559836-2823-487e-95d2-492c1db559e8.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/28559836-2823-487e-95d2-492c1db559e8.png)'
- en: The migrate service log stream
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: migrate服务日志流
- en: 'At this point, your application should be running successfully, and you should
    be able to interact with the application to create, update, view, and delete Todo
    items. One good way to verify this, which could be used as a strategy for automated
    post-deployment testing, is to run the acceptance tests you created in earlier
    chapters that are included in the todobackend release image, ensuring that you
    pass in the external load balancer URL via the `APP_URL` environment variable:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您的应用程序应该已成功运行，并且您应该能够与应用程序交互以创建、更新、查看和删除待办事项。验证这一点的一个好方法是运行您在早期章节中创建的验收测试，这些测试包含在todobackend发布图像中，并确保通过`APP_URL`环境变量传递外部负载均衡器URL，这可以作为自动部署后测试的策略。
- en: '[PRE44]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: You have now successfully deployed the todobackend application to a Docker Swarm
    cluster running in AWS, and I encourage you to further test that your application
    is production ready by tearing down/recreating the stack, and running a few example
    deployments by making test commits and creating new application versions to deploy.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在已成功将todobackend应用程序部署到在AWS上运行的Docker Swarm集群中，我鼓励您进一步测试您的应用程序是否已经准备好投入生产，方法是拆除/重新创建堆栈，并通过进行测试提交和创建新的应用程序版本来运行一些示例部署。
- en: Once complete, you should commit the changes you have made, and don't forget
    to destroy your Docker Swarm cluster by deleting the `docker-swarm` stack in the
    CloudFormation console.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，您应该提交您所做的更改，并不要忘记通过在CloudFormation控制台中删除`docker-swarm`堆栈来销毁您的Docker Swarm集群。
- en: Summary
  id: totrans-277
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you learned how to deploy Docker applications using Docker
    Swarm and the Docker for AWS solution. Docker for AWS provides a CloudFormation
    template that allows you to set up a Docker Swarm cluster within minutes, and
    also provides integration with AWS services including the Elastic Load Balancer
    service, Elastic File System, and Elastic Block Store.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学会了如何使用Docker Swarm和Docker for AWS解决方案部署Docker应用程序。Docker for AWS提供了一个CloudFormation模板，允许您在几分钟内设置一个Docker
    Swarm集群，并提供与AWS服务的集成，包括弹性负载均衡器服务、弹性文件系统和弹性块存储。
- en: After creating a Docker Swarm cluster, you learned how to establish remote access
    to a Swarm manager for your local Docker clients by configuring an SSH tunnel,
    which links to the `/var/run/docker.sock` socket file on your Swarm manager and
    presents it as a local endpoint your Docker client can interact with. This makes
    the experience of managing your Swarm clusters similar to managing your local
    Docker Engine.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建了一个Docker Swarm集群之后，您学会了如何通过配置SSH隧道来为本地Docker客户端建立与Swarm管理器的远程访问，该隧道链接到Swarm管理器上的`/var/run/docker.sock`套接字文件，并将其呈现为本地端点，以便您的Docker客户端可以与之交互。这使得管理Swarm集群的体验类似于管理本地Docker
    Engine。
- en: You learned how to create and deploy Docker services, which typically represent
    a long-running application, but may also represent one-shot tasks like running
    database migrations or generating static content files. Docker stacks represent
    complex multi-service environments, and are defined using the Docker Compose version
    3 specification and deployed using the `docker stack deploy` command. One advantage
    of using Docker Swarm is access to the Docker secrets feature, which allows you
    to store secrets securely in the encrypted raft log that is automatically replicated
    and shared across all nodes in the cluster. Docker secrets can then be exposed
    to services as in-memory tmpfs mounts at `/run/secrets`. You have already learned
    how easy it is to configure your applications to integrate with the Docker secrets
    feature.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 您学会了如何创建和部署Docker服务，这些服务通常代表长时间运行的应用程序，但也可以代表一次性任务，比如运行数据库迁移或生成静态内容文件。Docker堆栈代表复杂的多服务环境，并使用Docker
    Compose版本3规范进行定义，并使用`docker stack deploy`命令进行部署。使用Docker Swarm的一个优势是可以访问Docker
    secrets功能，该功能允许您将秘密安全地存储在加密的raft日志中，该日志会自动复制并在集群中的所有节点之间共享。然后，Docker secrets可以作为内存tmpfs挂载暴露给服务，位于`/run/secrets`。您已经学会了如何轻松地配置您的应用程序以集成Docker
    secrets功能。
- en: Finally, you learned how to address common operational challenges associated
    with running your containers in production, such as how to provide access to durable,
    persistent storage in the form of EBS volumes that can be automatically relocated
    with your containers, how to provide access to shared volumes using EFS, and how
    to orchestrate deployment of new application features , supporting the ability
    to run one-shot tasks and rolling upgrades of your application services.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您学会了如何解决在生产环境中运行容器时遇到的常见操作挑战，例如如何提供持久的、持久的存储访问，以EBS卷的形式，这些卷可以自动与您的容器重新定位，如何使用EFS提供对共享卷的访问，以及如何编排部署新的应用程序功能，支持运行一次性任务和滚动升级您的应用程序服务。
- en: In the next and final chapter of this book, you will be introduced to the AWS
    Elastic Kubernetes Service (EKS), which was launched mid 2018 and provides support
    for Kubernetes, the leading open source container management platform that competes
    with Docker Swarm.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一章和最后一章中，您将了解到AWS弹性Kubernetes服务（EKS），该服务于2018年中期推出，支持Kubernetes，这是一种与Docker
    Swarm竞争的领先开源容器管理平台。
- en: Questions
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'True/false: Docker Swarm is a native feature of the Docker Engine.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 真/假：Docker Swarm是Docker Engine的本机功能。
- en: What Docker client command do you use to create a service?
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您使用哪个Docker客户端命令来创建服务？
- en: 'True/false: Docker Swarm includes three node types—manager, worker, and agent.'
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确/错误：Docker Swarm包括三种节点类型——管理器、工作节点和代理。
- en: 'True/false: Docker for AWS provides integration with AWS application load balancers.'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确/错误：Docker for AWS提供与AWS应用负载均衡器的集成。
- en: 'True/false: The Cloudstor AWS volume plugin creates an EFS-backed volume when
    the backing is set to relocatable.'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确/错误：当后备设置为可重定位时，Cloudstor AWS卷插件会创建一个EFS支持的卷。
- en: 'True/false: You create a database service that uses the Cloudstor AWS volume
    plugin to provide an EBS-backed volume that is located in the availability zone
    us-west-1a. A failure occurs and a new database service container is created in
    the availability zone us-west-1b. In this scenario, the original EBS volume will
    be reattached to the new database service container.'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确/错误：您创建了一个使用Cloudstor AWS卷插件提供位于可用性区域us-west-1a的EBS支持卷的数据库服务。发生故障，并且在可用性区域us-west-1b中创建了一个新的数据库服务容器。在这种情况下，原始的EBS卷将重新附加到新的数据库服务容器上。
- en: What is the flag you need to append to Docker Stack deploy and Docker service
    create commands to integrate with private Docker registries?
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您需要在Docker Stack deploy和Docker service create命令中附加哪个标志以与私有Docker注册表集成？
- en: You deploy a stack that downloads an image from ECR. The first deployment succeeds,
    however when you attempt to perform a new deployment the next day, you notice
    that your Docker swarm nodes cannot pull the ECR image. How can you fix this?
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您部署了一个从ECR下载图像的堆栈。第一次部署成功，但是当您尝试在第二天执行新的部署时，您注意到您的Docker swarm节点无法拉取ECR图像。您该如何解决这个问题？
- en: Which version of the Docker Compose specification should you use for defining
    Docker Swarm stacks?
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您应该使用哪个版本的Docker Compose规范来定义Docker Swarm堆栈？
- en: 'True/false: When configuring a single shot service, you should configure a
    restart policy as always.'
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确/错误：在配置单次服务时，您应该将重启策略配置为always。
- en: Further reading
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'You can check the following links for more information about the topics covered
    in this chapter:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以查看以下链接，了解本章涵盖的主题的更多信息：
- en: Docker Community Edition for AWS: [https://store.docker.com/editions/community/docker-ce-aws](https://store.docker.com/editions/community/docker-ce-aws)
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker社区版适用于AWS：[https://store.docker.com/editions/community/docker-ce-aws](https://store.docker.com/editions/community/docker-ce-aws)
- en: Docker for AWS documentation: [https://docs.docker.com/docker-for-aws](https://docs.docker.com/docker-for-aws)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker for AWS文档：[https://docs.docker.com/docker-for-aws](https://docs.docker.com/docker-for-aws)
- en: Docker Compose file version 3 reference: [https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose文件版本3参考：[https://docs.docker.com/compose/compose-file/](https://docs.docker.com/compose/compose-file/)
- en: Docker for AWS persistent data volumes: [https://docs.docker.com/docker-for-aws/persistent-data-volumes/](https://docs.docker.com/docker-for-aws/persistent-data-volumes/)
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker适用于AWS的持久数据卷：[https://docs.docker.com/docker-for-aws/persistent-data-volumes/](https://docs.docker.com/docker-for-aws/persistent-data-volumes/)
- en: Docker for AWS template archive: [https://docs.docker.com/docker-for-aws/archive/](https://docs.docker.com/docker-for-aws/archive/)
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker for AWS模板存档：[https://docs.docker.com/docker-for-aws/archive/](https://docs.docker.com/docker-for-aws/archive/)
- en: 'Managing sensitive data with Docker secrets: [https://docs.docker.com/engine/swarm/secrets/](https://docs.docker.com/engine/swarm/secrets/)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Docker secrets管理敏感数据：[https://docs.docker.com/engine/swarm/secrets/](https://docs.docker.com/engine/swarm/secrets/)
- en: Docker command-line reference: [https://docs.docker.com/engine/reference/commandline/cli/](https://docs.docker.com/engine/reference/commandline/cli/)
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker命令行参考：[https://docs.docker.com/engine/reference/commandline/cli/](https://docs.docker.com/engine/reference/commandline/cli/)
- en: 'Docker Get Started - Part 4: Swarms: [https://docs.docker.com/get-started/part4/](https://docs.docker.com/get-started/part4/)'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker入门-第4部分：Swarm：[https://docs.docker.com/get-started/part4/](https://docs.docker.com/get-started/part4/)
- en: 'Docker Get Started - Part 5: Stacks: [https://docs.docker.com/get-started/part5](https://docs.docker.com/get-started/part5/)'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker入门-第5部分：Stacks：[https://docs.docker.com/get-started/part5](https://docs.docker.com/get-started/part5/)
- en: 'Docker for AWS Swarm ECR auto login: [https://github.com/mRoca/docker-swarm-aws-ecr-auth](https://github.com/mRoca/docker-swarm-aws-ecr-auth)'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker for AWS Swarm ECR自动登录：[https://github.com/mRoca/docker-swarm-aws-ecr-auth](https://github.com/mRoca/docker-swarm-aws-ecr-auth)
- en: SSH agent forwarding: [https://developer.github.com/v3/guides/using-ssh-agent-forwarding/](https://developer.github.com/v3/guides/using-ssh-agent-forwarding/)
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSH代理转发：[https://developer.github.com/v3/guides/using-ssh-agent-forwarding/](https://developer.github.com/v3/guides/using-ssh-agent-forwarding/)
